{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and validate example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Alex's data\n",
    "# Path in network drive: /Volumes/Projects/FAIMS/txt_CV_data/evidence.txt\n",
    "\n",
    "import_columns = [\n",
    "       'Sequence','Length', \n",
    "       'Charge', 'm/z', 'Resolution',\n",
    "       'Retention time','Retention length', \n",
    "       'Number of data points', 'Number of scans', \n",
    "       'MS/MS count', 'MS/MS scan number', 'Score',\n",
    "       'Intensity']\n",
    "\n",
    "evidence_df = pd.read_csv(\"data/evidence.txt\", sep=\"\\t\", low_memory=False, na_values='NaN', usecols=import_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_df.dropna(how='any', axis=0, inplace=True)\n",
    "evidence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subset1 = ['Length', \n",
    "       'Charge', 'm/z', 'Resolution',\n",
    "       'Retention time','Retention length', \n",
    "       'Number of data points', 'Number of scans', \n",
    "       'MS/MS count', 'MS/MS scan number', 'Score']\n",
    "target_value = ['Intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = evidence_df[feature_subset1]\n",
    "y = evidence_df[target_value]\n",
    "\n",
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "y1 = y1.values.ravel() #Flatten the vector for formatting reasons\n",
    "y2 = y2.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.head()\n",
    "y1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "forest = RandomForestRegressor(200)\n",
    "\n",
    "# fit the model on one set of data\n",
    "forest.fit(X1,y1)\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = forest.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.head().values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y2.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86443145.88969207"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y2, y2_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "forest1 = RandomForestRegressor(200)\n",
    "predicted = cross_val_predict(forest1, X2, y2, cv=10)\n",
    "\n",
    "#lr = linear_model.LinearRegression()\n",
    "#boston = datasets.load_boston()\n",
    "#y = boston.target\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validated:\n",
    "#predicted = cross_val_predict(lr, boston.data, y, cv=10)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.scatter(y, predicted)\n",
    "ax.plot([y2.min(), y2.max()], [y2.min(), y2.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
