{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Processing Step for Multilabel FAIMS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all my packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import skmultilearn\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from skmultilearn.model_selection import  iterative_train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Defining the function for adding the pyteomic pieces\n",
    "from pyteomics import mass\n",
    "from pyteomics import parser\n",
    "from pyteomics import electrochem\n",
    "\n",
    "\n",
    "def addfeatures(featurestable, seqlabel = 'Sequence'):\n",
    "    Mass = list()\n",
    "    pI = list()\n",
    "    Charge = list()\n",
    "    \n",
    "    for i in range(0, featurestable.shape[0]):\n",
    "        ps = parser.parse(featurestable[seqlabel][i], show_unmodified_termini=True)\n",
    "        \n",
    "        Mass.append(mass.calculate_mass(parsed_sequence=ps))\n",
    "        Charge.append(electrochem.charge(ps, 2.5))\n",
    "        pI.append(electrochem.pI(featurestable[seqlabel][i]))\n",
    "        \n",
    "    \n",
    "    featurestable['pyMass'] = Mass\n",
    "    featurestable['pI'] = pI\n",
    "    featurestable['pyCharge'] = Charge\n",
    "    \n",
    "    return(featurestable)\n",
    "\n",
    "\n",
    "\n",
    "#WANT TO TRY ONE-HOT WITH LIST THAT I THEN CONVERT INTO FRAME AFTERWARD\n",
    "#WOULD ALSO ALLOW FOR THE USE OF THE KARAS PADDING FUNCTION SO THAT I CAN HIT THEM ALL WITH ZEROS AT THE SAME TIME\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax         #finds the index of the maximum value in a vector\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "def simpleOneHot(data_frame, sequenceTag = 'ModSequence', alphabet = 'ACDEFGHIKLMNPQRSTVWY'):\n",
    "    #Start by finding the max and calculating needed vector length\n",
    "    VEC_LENGTH = max(data_frame['Length']) * len(alphabet)\n",
    "    \n",
    "    #Define what residues are possible\n",
    "    AMINO_ACIDS = alphabet \n",
    "    \n",
    "    #TURNING CHARACTERS INTO INTEGERS\n",
    "    # Map character keys to integer values in a dictionary, then map integer keys to character values to revers transform\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(AMINO_ACIDS))   #character keys to integer values\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(AMINO_ACIDS))   #integer keys to character values\n",
    "    \n",
    "    \n",
    "    hotlist = list()\n",
    "    #Build out the rest of the sequences' one-hot arrays\n",
    "    \n",
    "    for i in range(0, data_frame.shape[0]):\n",
    "        \n",
    "        pep = data_frame[sequenceTag][i]\n",
    "        #print(pep)\n",
    "        integer_encode = [char_to_int[char] for char in pep]\n",
    "        encoded = to_categorical(integer_encode, num_classes=22)\n",
    "        flatencode = encoded.flatten()\n",
    "        \n",
    "        #numzeros = VEC_LENGTH - len(flatencode)\n",
    "        #flatencode = np.append(flatencode, [[0] * numzeros])\n",
    "        \n",
    "        hotlist.append(flatencode)\n",
    "    \n",
    "    padded = pad_sequences(hotlist, padding= 'post', maxlen=VEC_LENGTH)\n",
    "    \n",
    "    hotarray = np.array(padded)\n",
    "    \n",
    "    hotarray.shape\n",
    "    return(hotarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in the the final labelling scheme data and adding the other features\n",
    "data_df = pd.read_csv(\"D:/Projects/FAIMS_MachineLearning/2020/March/50percentMaxPlusThreshold.csv\", low_memory=False) #read in data generated from R preprocessing\n",
    "data_df = addfeatures(data_df)\n",
    "data_hotarray = simpleOneHot(data_frame=data_df, alphabet='ACDEFGHIKLMNPQRSTVWYam')\n",
    "feature_subset = ['Charge', 'Length', 'pyMass', 'pI']\n",
    "#Generating X and y, features and labels respectively \n",
    "X = np.concatenate((data_df[feature_subset], data_hotarray), axis = 1)\n",
    "y = data_df.loc[ : ,  'X20':'X95'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making unique keys for Xs so can be reattached to after iterative train test split\n",
    "keys = np.transpose(np.array([range(0, data_df.shape[0])]))\n",
    "X_keys = np.concatenate((keys, X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85991, 1105)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the 50%+ threshold data into train and test keeping label distribution proportional\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X_keys, y, test_size=0.30)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling out training data to allow for other thresholds to be applied\n",
    "fulltraining = pd.concat((pd.DataFrame(y_train), data_df.loc[X_train[:, 0],['Sequence','Charge', 'SeqCharge']].reset_index(drop=True), pd.DataFrame(X_train)), axis=1)\n",
    "fulltraining.to_csv(\"50percentplusTraining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling out test data to test those other thresholds\n",
    "fulltesting = pd.concat((pd.DataFrame(y_test), data_df.loc[X_test[:, 0],['Sequence','Charge', 'SeqCharge']].reset_index(drop=True), pd.DataFrame(X_test)), axis=1)\n",
    "fulltesting.to_csv(\"50percentplusTesting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
