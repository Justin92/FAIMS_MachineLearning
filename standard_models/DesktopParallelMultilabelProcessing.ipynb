{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a space to run code while linux computer is busy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmcketney.AD\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jmcketney.AD\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jmcketney.AD\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jmcketney.AD\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jmcketney.AD\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jmcketney.AD\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Load all my packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets  import make_multilabel_classification \n",
    "from sklearn.multiclass  import OneVsRestClassifier\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from sklearn.svm  import SVC \n",
    "from sklearn.decomposition  import PCA \n",
    "from sklearn.cross_decomposition  import CCA \n",
    "from fastai.metrics import accuracy_thresh\n",
    "from fastai.metrics import fbeta\n",
    "from torch import from_numpy\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fastai.torch_core import np2model_tensor\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Defining the function for adding the pyteomic pieces\n",
    "from pyteomics import mass\n",
    "from pyteomics import parser\n",
    "from pyteomics import electrochem\n",
    "\n",
    "\n",
    "def addfeatures(featurestable, seqlabel = 'Sequence'):\n",
    "    Mass = list()\n",
    "    pI = list()\n",
    "    Charge = list()\n",
    "    \n",
    "    for i in range(0, featurestable.shape[0]):\n",
    "        ps = parser.parse(featurestable[seqlabel][i], show_unmodified_termini=True)\n",
    "        \n",
    "        Mass.append(mass.calculate_mass(parsed_sequence=ps))\n",
    "        Charge.append(electrochem.charge(ps, 2.5))\n",
    "        pI.append(electrochem.pI(featurestable[seqlabel][i]))\n",
    "        \n",
    "    \n",
    "    featurestable['pyMass'] = Mass\n",
    "    featurestable['pI'] = pI\n",
    "    featurestable['pyCharge'] = Charge\n",
    "    \n",
    "    return(featurestable)\n",
    "\n",
    "\n",
    "\n",
    "#WANT TO TRY ONE-HOT WITH LIST THAT I THEN CONVERT INTO FRAME AFTERWARD\n",
    "#WOULD ALSO ALLOW FOR THE USE OF THE KARAS PADDING FUNCTION SO THAT I CAN HIT THEM ALL WITH ZEROS AT THE SAME TIME\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax         #finds the index of the maximum value in a vector\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "def simpleOneHot(data_frame, sequenceTag = 'ModSequence', alphabet = 'ACDEFGHIKLMNPQRSTVWY'):\n",
    "    #Start by finding the max and calculating needed vector length\n",
    "    VEC_LENGTH = max(data_frame['Length']) * len(alphabet)\n",
    "    \n",
    "    #Define what residues are possible\n",
    "    AMINO_ACIDS = alphabet \n",
    "    \n",
    "    #TURNING CHARACTERS INTO INTEGERS\n",
    "    # Map character keys to integer values in a dictionary, then map integer keys to character values to revers transform\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(AMINO_ACIDS))   #character keys to integer values\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(AMINO_ACIDS))   #integer keys to character values\n",
    "    \n",
    "    \n",
    "    hotlist = list()\n",
    "    #Build out the rest of the sequences' one-hot arrays\n",
    "    \n",
    "    for i in range(0, data_frame.shape[0]):\n",
    "        \n",
    "        pep = data_frame[sequenceTag][i]\n",
    "        #print(pep)\n",
    "        integer_encode = [char_to_int[char] for char in pep]\n",
    "        encoded = to_categorical(integer_encode, num_classes=22)\n",
    "        flatencode = encoded.flatten()\n",
    "        \n",
    "        #numzeros = VEC_LENGTH - len(flatencode)\n",
    "        #flatencode = np.append(flatencode, [[0] * numzeros])\n",
    "        \n",
    "        hotlist.append(flatencode)\n",
    "    \n",
    "    padded = pad_sequences(hotlist, padding= 'post', maxlen=VEC_LENGTH)\n",
    "    \n",
    "    hotarray = np.array(padded)\n",
    "    \n",
    "    hotarray.shape\n",
    "    return(hotarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df = pd.read_csv(\"ThresholdReportAllContinuous.csv\", low_memory=False)  #read in dynamic threshold only continuous labels\n",
    "#data_df = pd.read_csv(\"ThresholdedRandomEvenSampling.csv\", low_memory=False)  #read in dynamic threshold only continuous labels\n",
    "#data_df = pd.read_csv(\"LimitingLabelCounts.csv\", low_memory=False)  #Label limited with second iteration\n",
    "#data_df = pd.read_csv(\"NewJGMDataWFeatures.csv\", low_memory=False) #Read in second JGM Dataset\n",
    "#data_df = pd.read_csv(\"DynThresh50percentContinuousJGMData.csv\", low_memory=False) #read in 50% dynamic threshold\n",
    "#data_df = pd.read_csv(\"AnyIntensityThreshold.csv\", low_memory=False) #read in static >0 threshold data set\n",
    "#data_df = pd.read_csv(\"AnyIntensityThresholdAllContinuous.csv\", low_memory=False) #read in static > 0 threshold, only continous\n",
    "#data_df = pd.read_csv(\"MixModeThresholdAllContinuous.csv\", low_memory=False) #read in combo threshold with 50% proportiona and static thrsh \n",
    "data_df = pd.read_csv(\"50percentMaxPlusThreshold.csv\", low_memory=False) #read in data for target prediction\n",
    "\n",
    "\n",
    "#Then lets add the pyteomic features always same function \n",
    "data_df = addfeatures(data_df)\n",
    "\n",
    "#And add one-hot array\n",
    "#For JGM data, different alphabet\n",
    "data_hotarray = simpleOneHot(data_frame=data_df, alphabet='ACDEFGHIKLMNPQRSTVWYam')\n",
    "\n",
    "#For MQ data, just standard alphabet\n",
    "#data_hotarray = simpleOneHot(data_frame=MQ_df, sequenceTag='Sequence', alphabet='ACDEFGHIKLMNPQRSTVWY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "#SCALED NON ONE HOT FEATURES\n",
    "#Select the features we actually want to use besides the one-hot array\n",
    "feature_subset = ['Charge', 'Length', 'pyMass', 'pI']#, 'pyCharge']\n",
    "#feature_subset = ['Charge', 'Length','R.Norm', 'N.Norm', 'D.Norm', 'C.Norm', 'Q.Norm', 'E.Norm', 'G.Norm',\n",
    "#       'H.Norm', 'I.Norm', 'L.Norm', 'K.Norm', 'M.Norm', 'F.Norm', 'S.Norm',\n",
    "#       'T.Norm', 'W.Norm', 'Y.Norm', 'V.Norm']\n",
    "#Normalized aa counts available for MQ data\n",
    "\n",
    "#assign those features to X, if using one-hot than will make array\n",
    "#X = np.concatenate((scale(data_df[feature_subset]), data_hotarray), axis = 1)\n",
    "X = np.concatenate((data_df[feature_subset], data_hotarray), axis = 1)\n",
    "#X = data_df[feature_subset]   #IF DON'T WANT TO USE ONE-HOT ARRAY AS FEATURE\n",
    "#X = data_df.loc[0:5000, 'Charge']\n",
    "\n",
    "#Selecting labels to be used as y. Again the \"values\" att makes the output an array\n",
    "y = data_df.loc[ : ,  'X20':'X95'].values\n",
    "\n",
    "#Need different index for MQ data\n",
    "#y = data_df.loc[:, 'CV20':'CV95'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101567, 1104)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# reduce dimensionality or normalized AA counts with PCA\n",
    "pca = PCA(n_components=400)                    #defining pca method parameters. Need 182 to get to 70% variance\n",
    "decomposed_1hot = pca.fit_transform(hotarray)\n",
    "pca.fit_transform(hotarray)\n",
    "type(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split to just make it faster and in interest of train-test-validate system\n",
    "#Will do it iteratively though. NOTE: iterative_train_test_split can only take in array, not data frame\n",
    "from skmultilearn.model_selection import  iterative_train_test_split\n",
    "\n",
    "X1, y1, X2, y2 = iterative_train_test_split(X, y, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiforest = OneVsRestClassifier(RandomForestClassifier(n_estimators = 200, random_state=23), n_jobs=2)#, class_weight='balanced'))\n",
    "#multiforest.fit(X_train, y_train)\n",
    "#y_fpredict = multiforest.predict(X_test)\n",
    "#y_probs = multiforest.predict_proba(X_test)\n",
    "\n",
    "#print(accuracy_thresh(torch.from_numpy(y_probs), y_test, thresh=0.7, sigmoid=False))\n",
    "\n",
    "#scaled_X = scale(X1)\n",
    "\n",
    "bthacc7 = []\n",
    "bthacc5 = []\n",
    "bprec = []\n",
    "broc = []\n",
    "brecall = []\n",
    "\n",
    "k_fold = IterativeStratification(n_splits=5, order=4)#, random_state=123)\n",
    "for train, test in k_fold.split(X1, y1):\n",
    "        \n",
    "        #Train the multiforest using the training indices\n",
    "        multiforest.fit(X1[train], y1[train])\n",
    "        \n",
    "        #Generate predictions\n",
    "        y_predict = multiforest.predict(X1[test])\n",
    "        y_predprobs = multiforest.predict_proba(X1[test])\n",
    "        \n",
    "        #Gotta convert both of them to tensors hahahaha\n",
    "        bthacc7.append(accuracy_thresh(np2model_tensor(y_predprobs), np2model_tensor(y1[test]), thresh=0.7, sigmoid=False))\n",
    "        bthacc5. append(accuracy_thresh(np2model_tensor(y_predprobs), np2model_tensor(y1[test]), thresh=0.5, sigmoid=False))\n",
    "        bprec.append(average_precision_score( y1[test], y_predict, average='weighted'))\n",
    "        broc.append(roc_auc_score( y1[test], y_predprobs, average='weighted'))\n",
    "        brecall.append(recall_score( y1[test], y_predict, average='weighted'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel RFC without OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running multiforest without OneVsRest wrapper\n",
    "multiforest = RandomForestClassifier(n_estimators = 200, random_state=23)#, class_weight='balanced'))\n",
    "\n",
    "bthacc7 = []\n",
    "bthacc5 = []\n",
    "bprec = []\n",
    "broc = []\n",
    "brecall = []\n",
    "\n",
    "k_fold = IterativeStratification(n_splits=5, order=4)#, random_state=123)\n",
    "for train, test in k_fold.split(X1, y1):\n",
    "        \n",
    "        #Train the multiforest using the training indices\n",
    "        multiforest.fit(X1[train], y1[train])\n",
    "        \n",
    "        #Generate predictions\n",
    "        y_predict = multiforest.predict(X1[test])\n",
    "        y_problist = multiforest.predict_proba(X1[test])\n",
    "        \n",
    "        y_predprobs = np.array([[]] *X1[test].shape[0])\n",
    "        for item in y_problist:\n",
    "            y_predprobs = np.concatenate((y_predprobs, np.reshape(item[:, 1], (-1, 1))), axis = 1)\n",
    "\n",
    "            \n",
    "        \n",
    "        #Gotta convert both of them to tensors hahahaha\n",
    "        bthacc7.append(accuracy_thresh(np2model_tensor(y_predprobs), np2model_tensor(y1[test]), thresh=0.7, sigmoid=False))\n",
    "        bthacc5. append(accuracy_thresh(np2model_tensor(y_predprobs), np2model_tensor(y1[test]), thresh=0.5, sigmoid=False))\n",
    "        bprec.append(average_precision_score( y1[test], y_predict, average='weighted'))\n",
    "        broc.append(roc_auc_score( y1[test], y_predprobs, average='weighted'))\n",
    "        brecall.append(recall_score( y1[test], y_predict, average='weighted'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  \n",
      " 0.4891696644645611\n",
      "Precision:  \n",
      " 0.4801360392865387\n",
      "ROCAUC:  \n",
      " 0.8426170260621959\n",
      "Threshold Accuracy:  \n",
      " 0.85394925\n"
     ]
    }
   ],
   "source": [
    "#Mixed Mode threshold\n",
    "print(\"Recall:  \\n\", np.mean(brecall))\n",
    "print(\"Precision:  \\n\", np.mean(bprec))\n",
    "print(\"ROCAUC:  \\n\", np.mean(broc))\n",
    "print(\"Threshold Accuracy:  \\n\", np.mean(bthacc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  \n",
      " 0.5112746552656112\n",
      "Precision:  \n",
      " 0.5008871607387166\n",
      "ROCAUC:  \n",
      " 0.8461252742475986\n",
      "Threshold Accuracy:  \n",
      " 0.8459856\n"
     ]
    }
   ],
   "source": [
    "#Most liberal label assignment dataset  any intensity > 0, continous only\n",
    "print(\"Recall:  \\n\", np.mean(brecall))\n",
    "print(\"Precision:  \\n\", np.mean(bprec))\n",
    "print(\"ROCAUC:  \\n\", np.mean(broc))\n",
    "print(\"Threshold Accuracy:  \\n\", np.mean(bthacc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  \n",
      " 0.49790255223625823\n",
      "Precision:  \n",
      " 0.48889666348606403\n",
      "ROCAUC:  \n",
      " 0.8225078547432855\n",
      "Threshold Accuracy:  \n",
      " 0.8251936\n"
     ]
    }
   ],
   "source": [
    "#Most liberal label assignment dataset  any intensity > 0, discontinuous\n",
    "print(\"Recall:  \\n\", np.mean(brecall))\n",
    "print(\"Precision:  \\n\", np.mean(bprec))\n",
    "print(\"ROCAUC:  \\n\", np.mean(broc))\n",
    "print(\"Threshold Accuracy:  \\n\", np.mean(bthacc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  \n",
      " 0.3608852657553997\n",
      "Precision:  \n",
      " 0.39298243331441457\n",
      "ROCAUC:  \n",
      " 0.848066221932308\n",
      "Threshold Accuracy:  \n",
      " 0.86191213\n"
     ]
    }
   ],
   "source": [
    "#Trying out the non-OVR multiforest 50% median proportional threshold, all continuous\n",
    "print(\"Recall:  \\n\", np.mean(brecall))\n",
    "print(\"Precision:  \\n\", np.mean(bprec))\n",
    "print(\"ROCAUC:  \\n\", np.mean(broc))\n",
    "print(\"Threshold Accuracy:  \\n\", np.mean(bthacc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  \n",
      " 0.35985376551830395\n",
      "Precision:  \n",
      " 0.3885077895130372\n",
      "ROCAUC:  \n",
      " 0.840183994177468\n",
      "Threshold Accuracy:  \n",
      " 0.8602955\n"
     ]
    }
   ],
   "source": [
    "#Weighted 50% proportional dynamic threshold, all continuous\n",
    "print(\"Recall:  \\n\", np.mean(brecall))\n",
    "print(\"Precision:  \\n\", np.mean(bprec))\n",
    "print(\"ROCAUC:  \\n\", np.mean(broc))\n",
    "print(\"Threshold Accuracy:  \\n\", np.mean(bthacc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  \n",
      " 0.3426146128861155\n",
      "Precision:  \n",
      " 0.3770215458640528\n",
      "ROCAUC:  \n",
      " 0.8317985250706521\n",
      "Threshold Accuracy:  \n",
      " 0.852993\n"
     ]
    }
   ],
   "source": [
    "#Weighted 50% proportional dynamic threshold\n",
    "print(\"Recall:  \\n\", np.mean(brecall))\n",
    "print(\"Precision:  \\n\", np.mean(bprec))\n",
    "print(\"ROCAUC:  \\n\", np.mean(broc))\n",
    "print(\"Threshold Accuracy:  \\n\", np.mean(bthacc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  \n",
      " 0.2823234414270637\n",
      "Precision:  \n",
      " 0.3113822179940469\n",
      "ROCAUC:  \n",
      " 0.851138203130487\n",
      "Threshold Accuracy:  \n",
      " 0.85293496\n"
     ]
    }
   ],
   "source": [
    "#Macro 50% proportional dynamic threshold\n",
    "print(\"Recall:  \\n\", np.mean(brecall))\n",
    "print(\"Precision:  \\n\", np.mean(bprec))\n",
    "print(\"ROCAUC:  \\n\", np.mean(broc))\n",
    "print(\"Threshold Accuracy:  \\n\", np.mean(bthacc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 fold split that just collects metrics from each split\n",
    "#Defined above\n",
    "#So could actually make this even more flexible\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "#instantiate the forest and fit it to the subset\n",
    "multiforest = OneVsRestClassifier(RandomForestClassifier(n_estimators = 200, random_state=23), n_jobs = 2)\n",
    "\n",
    "i = 0\n",
    "\n",
    "metricdict = dict()\n",
    "\n",
    "#Iterative stratification doesn't actually need a random state because I haven't set shuffle =True\n",
    "k_fold = IterativeStratification(n_splits=5, order=2)#, random_state=123)\n",
    "for train, test in k_fold.split(X1, y1):\n",
    "    i = i + 1\n",
    "    #Make dictionary to hold metric arrays\n",
    "    kfold = dict()\n",
    "    \n",
    "    #Train the multiforest using the training indices\n",
    "    multiforest.fit(X1[train], y1[train])\n",
    "    \n",
    "    #Generate predictions\n",
    "    y_predict = multiforest.predict(X1[test])\n",
    "    y_predprobs = multiforest.predict_proba(X1[test])\n",
    "    #Add metric arrays to dictionary keys\n",
    "    metricdict[('precision_kfold_' + str(i))] = precision_score(y1[test], y_predict, average=None)\n",
    "    metricdict[('recall_kfold_' + str(i))] = recall_score(y1[test], y_predict, average=None)\n",
    "    metricdict[('rocScore_kfold_' + str(i))] = roc_auc_score(y1[test], y_predprobs, average=None)\n",
    "    metricdict[('accuracy_kfold_' + str(i))] = np.sum(abs(y1[test] - y_predict), axis = 0) / y1[test].shape[0]\n",
    "    metricdict[('realCount_kfold_' + str(i))] = np.sum(y1[test], axis = 0)\n",
    "    metricdict[('predictCount_kfold_' + str(i))] = np.sum(y_predict, axis = 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_kfold_1</th>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.712230</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_1</th>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.739496</td>\n",
       "      <td>0.536765</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.164894</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.458763</td>\n",
       "      <td>0.267081</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_1</th>\n",
       "      <td>0.973600</td>\n",
       "      <td>0.957308</td>\n",
       "      <td>0.916437</td>\n",
       "      <td>0.889862</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.765557</td>\n",
       "      <td>0.737017</td>\n",
       "      <td>0.747444</td>\n",
       "      <td>0.680857</td>\n",
       "      <td>0.725964</td>\n",
       "      <td>0.759628</td>\n",
       "      <td>0.807859</td>\n",
       "      <td>0.862985</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.884546</td>\n",
       "      <td>0.879685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_1</th>\n",
       "      <td>0.047026</td>\n",
       "      <td>0.065007</td>\n",
       "      <td>0.135546</td>\n",
       "      <td>0.131397</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.106501</td>\n",
       "      <td>0.127248</td>\n",
       "      <td>0.159059</td>\n",
       "      <td>0.188105</td>\n",
       "      <td>0.203320</td>\n",
       "      <td>0.244813</td>\n",
       "      <td>0.207469</td>\n",
       "      <td>0.183956</td>\n",
       "      <td>0.178423</td>\n",
       "      <td>0.146611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_1</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_1</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_2</th>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_2</th>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.433824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.483254</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_2</th>\n",
       "      <td>0.981106</td>\n",
       "      <td>0.962086</td>\n",
       "      <td>0.926489</td>\n",
       "      <td>0.899799</td>\n",
       "      <td>0.859669</td>\n",
       "      <td>0.791378</td>\n",
       "      <td>0.704797</td>\n",
       "      <td>0.770230</td>\n",
       "      <td>0.732049</td>\n",
       "      <td>0.753554</td>\n",
       "      <td>0.758249</td>\n",
       "      <td>0.806864</td>\n",
       "      <td>0.857803</td>\n",
       "      <td>0.877346</td>\n",
       "      <td>0.886739</td>\n",
       "      <td>0.844773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_2</th>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.072702</td>\n",
       "      <td>0.137174</td>\n",
       "      <td>0.130316</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.101509</td>\n",
       "      <td>0.124829</td>\n",
       "      <td>0.155007</td>\n",
       "      <td>0.183813</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.245542</td>\n",
       "      <td>0.212620</td>\n",
       "      <td>0.193416</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.153635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_2</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_2</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_3</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.772059</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_3</th>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.423358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.164894</td>\n",
       "      <td>0.516746</td>\n",
       "      <td>0.541237</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_3</th>\n",
       "      <td>0.978922</td>\n",
       "      <td>0.949041</td>\n",
       "      <td>0.917275</td>\n",
       "      <td>0.891172</td>\n",
       "      <td>0.847888</td>\n",
       "      <td>0.761385</td>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.720586</td>\n",
       "      <td>0.703945</td>\n",
       "      <td>0.719421</td>\n",
       "      <td>0.724800</td>\n",
       "      <td>0.833626</td>\n",
       "      <td>0.870391</td>\n",
       "      <td>0.898601</td>\n",
       "      <td>0.895260</td>\n",
       "      <td>0.861114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_3</th>\n",
       "      <td>0.042759</td>\n",
       "      <td>0.075862</td>\n",
       "      <td>0.151724</td>\n",
       "      <td>0.129655</td>\n",
       "      <td>0.086897</td>\n",
       "      <td>0.073103</td>\n",
       "      <td>0.102069</td>\n",
       "      <td>0.125517</td>\n",
       "      <td>0.162759</td>\n",
       "      <td>0.183448</td>\n",
       "      <td>0.201379</td>\n",
       "      <td>0.242759</td>\n",
       "      <td>0.209655</td>\n",
       "      <td>0.165517</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.153103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_3</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_3</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_4</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_4</th>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.547445</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_4</th>\n",
       "      <td>0.981570</td>\n",
       "      <td>0.970353</td>\n",
       "      <td>0.945925</td>\n",
       "      <td>0.886547</td>\n",
       "      <td>0.841940</td>\n",
       "      <td>0.747843</td>\n",
       "      <td>0.726602</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>0.717405</td>\n",
       "      <td>0.732827</td>\n",
       "      <td>0.723469</td>\n",
       "      <td>0.820569</td>\n",
       "      <td>0.869911</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0.853114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_4</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.065278</td>\n",
       "      <td>0.119444</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.073611</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.129167</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.190278</td>\n",
       "      <td>0.209722</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.181944</td>\n",
       "      <td>0.184722</td>\n",
       "      <td>0.152778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_4</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_4</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_5</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_5</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.672269</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.207447</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_5</th>\n",
       "      <td>0.968663</td>\n",
       "      <td>0.961217</td>\n",
       "      <td>0.931410</td>\n",
       "      <td>0.904491</td>\n",
       "      <td>0.828242</td>\n",
       "      <td>0.704928</td>\n",
       "      <td>0.758336</td>\n",
       "      <td>0.709851</td>\n",
       "      <td>0.718146</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>0.754199</td>\n",
       "      <td>0.808659</td>\n",
       "      <td>0.872351</td>\n",
       "      <td>0.871221</td>\n",
       "      <td>0.875601</td>\n",
       "      <td>0.834407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_5</th>\n",
       "      <td>0.053645</td>\n",
       "      <td>0.070151</td>\n",
       "      <td>0.134801</td>\n",
       "      <td>0.129298</td>\n",
       "      <td>0.086657</td>\n",
       "      <td>0.074278</td>\n",
       "      <td>0.100413</td>\n",
       "      <td>0.127923</td>\n",
       "      <td>0.156809</td>\n",
       "      <td>0.184319</td>\n",
       "      <td>0.209078</td>\n",
       "      <td>0.228336</td>\n",
       "      <td>0.189821</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>0.184319</td>\n",
       "      <td>0.160935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_5</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_5</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0           1           2          3          4  \\\n",
       "precision_kfold_1      0.827957    0.846154    0.675926   0.333333   0.000000   \n",
       "recall_kfold_1         0.810526    0.739496    0.536765   0.010638   0.000000   \n",
       "rocScore_kfold_1       0.973600    0.957308    0.916437   0.889862   0.873437   \n",
       "accuracy_kfold_1       0.047026    0.065007    0.135546   0.131397   0.087137   \n",
       "realCount_kfold_1     95.000000  119.000000  136.000000  94.000000  63.000000   \n",
       "predictCount_kfold_1  93.000000  104.000000  108.000000   3.000000   0.000000   \n",
       "precision_kfold_2      0.904110    0.873563    0.719512   0.000000   0.000000   \n",
       "recall_kfold_2         0.694737    0.644068    0.433824   0.000000   0.000000   \n",
       "rocScore_kfold_2       0.981106    0.962086    0.926489   0.899799   0.859669   \n",
       "accuracy_kfold_2       0.049383    0.072702    0.137174   0.130316   0.086420   \n",
       "realCount_kfold_2     95.000000  118.000000  136.000000  94.000000  63.000000   \n",
       "predictCount_kfold_2  73.000000   87.000000   82.000000   1.000000   0.000000   \n",
       "precision_kfold_3      0.900000    0.824742    0.651685   0.000000   0.000000   \n",
       "recall_kfold_3         0.757895    0.677966    0.423358   0.000000   0.000000   \n",
       "rocScore_kfold_3       0.978922    0.949041    0.917275   0.891172   0.847888   \n",
       "accuracy_kfold_3       0.042759    0.075862    0.151724   0.129655   0.086897   \n",
       "realCount_kfold_3     95.000000  118.000000  137.000000  94.000000  63.000000   \n",
       "predictCount_kfold_3  80.000000   97.000000   89.000000   0.000000   0.000000   \n",
       "precision_kfold_4      0.937500    0.873684    0.757576   0.333333   0.000000   \n",
       "recall_kfold_4         0.797872    0.703390    0.547445   0.021277   0.000000   \n",
       "rocScore_kfold_4       0.981570    0.970353    0.945925   0.886547   0.841940   \n",
       "accuracy_kfold_4       0.033333    0.065278    0.119444   0.133333   0.091667   \n",
       "realCount_kfold_4     94.000000  118.000000  137.000000  94.000000  64.000000   \n",
       "predictCount_kfold_4  80.000000   95.000000   99.000000   6.000000   2.000000   \n",
       "precision_kfold_5      0.833333    0.869565    0.720930   0.500000   0.000000   \n",
       "recall_kfold_5         0.736842    0.672269    0.455882   0.010638   0.000000   \n",
       "rocScore_kfold_5       0.968663    0.961217    0.931410   0.904491   0.828242   \n",
       "accuracy_kfold_5       0.053645    0.070151    0.134801   0.129298   0.086657   \n",
       "realCount_kfold_5     95.000000  119.000000  136.000000  94.000000  63.000000   \n",
       "predictCount_kfold_5  84.000000   92.000000   86.000000   2.000000   0.000000   \n",
       "\n",
       "                              5          6          7           8           9  \\\n",
       "precision_kfold_1      0.000000   0.000000   0.000000    0.000000    0.333333   \n",
       "recall_kfold_1         0.000000   0.000000   0.000000    0.000000    0.007407   \n",
       "rocScore_kfold_1       0.765557   0.737017   0.747444    0.680857    0.725964   \n",
       "accuracy_kfold_1       0.074689   0.106501   0.127248    0.159059    0.188105   \n",
       "realCount_kfold_1     54.000000  74.000000  91.000000  113.000000  135.000000   \n",
       "predictCount_kfold_1   0.000000   3.000000   1.000000    2.000000    3.000000   \n",
       "precision_kfold_2      0.000000   0.000000   0.500000    0.000000    0.600000   \n",
       "recall_kfold_2         0.000000   0.000000   0.010989    0.000000    0.022222   \n",
       "rocScore_kfold_2       0.791378   0.704797   0.770230    0.732049    0.753554   \n",
       "accuracy_kfold_2       0.074074   0.101509   0.124829    0.155007    0.183813   \n",
       "realCount_kfold_2     53.000000  74.000000  91.000000  113.000000  135.000000   \n",
       "predictCount_kfold_2   1.000000   0.000000   2.000000    0.000000    5.000000   \n",
       "precision_kfold_3      0.000000   0.000000   0.000000    0.142857    0.800000   \n",
       "recall_kfold_3         0.000000   0.000000   0.000000    0.008850    0.029412   \n",
       "rocScore_kfold_3       0.761385   0.766129   0.720586    0.703945    0.719421   \n",
       "accuracy_kfold_3       0.073103   0.102069   0.125517    0.162759    0.183448   \n",
       "realCount_kfold_3     53.000000  74.000000  91.000000  113.000000  136.000000   \n",
       "predictCount_kfold_3   0.000000   0.000000   0.000000    7.000000    5.000000   \n",
       "precision_kfold_4      0.000000   0.000000   0.000000    1.000000    0.375000   \n",
       "recall_kfold_4         0.000000   0.000000   0.000000    0.008850    0.022222   \n",
       "rocScore_kfold_4       0.747843   0.726602   0.765047    0.717405    0.732827   \n",
       "accuracy_kfold_4       0.073611   0.104167   0.129167    0.155556    0.190278   \n",
       "realCount_kfold_4     53.000000  74.000000  91.000000  113.000000  135.000000   \n",
       "predictCount_kfold_4   0.000000   1.000000   2.000000    1.000000    8.000000   \n",
       "precision_kfold_5      0.000000   0.000000   0.000000    0.000000    1.000000   \n",
       "recall_kfold_5         0.000000   0.000000   0.000000    0.000000    0.014706   \n",
       "rocScore_kfold_5       0.704928   0.758336   0.709851    0.718146    0.721839   \n",
       "accuracy_kfold_5       0.074278   0.100413   0.127923    0.156809    0.184319   \n",
       "realCount_kfold_5     54.000000  73.000000  92.000000  114.000000  136.000000   \n",
       "predictCount_kfold_5   0.000000   0.000000   1.000000    0.000000    2.000000   \n",
       "\n",
       "                              10          11          12          13  \\\n",
       "precision_kfold_1       0.714286    0.607843    0.712230    0.760684   \n",
       "recall_kfold_1          0.033333    0.164894    0.473684    0.458763   \n",
       "rocScore_kfold_1        0.759628    0.807859    0.862985    0.868844   \n",
       "accuracy_kfold_1        0.203320    0.244813    0.207469    0.183956   \n",
       "realCount_kfold_1     150.000000  188.000000  209.000000  194.000000   \n",
       "predictCount_kfold_1    7.000000   51.000000  139.000000  117.000000   \n",
       "precision_kfold_2       0.500000    0.589286    0.682432    0.704545   \n",
       "recall_kfold_2          0.026144    0.174603    0.483254    0.476923   \n",
       "rocScore_kfold_2        0.758249    0.806864    0.857803    0.877346   \n",
       "accuracy_kfold_2        0.209877    0.245542    0.212620    0.193416   \n",
       "realCount_kfold_2     153.000000  189.000000  209.000000  195.000000   \n",
       "predictCount_kfold_2    8.000000   56.000000  148.000000  132.000000   \n",
       "precision_kfold_3       0.666667    0.620000    0.679245    0.772059   \n",
       "recall_kfold_3          0.027027    0.164894    0.516746    0.541237   \n",
       "rocScore_kfold_3        0.724800    0.833626    0.870391    0.898601   \n",
       "accuracy_kfold_3        0.201379    0.242759    0.209655    0.165517   \n",
       "realCount_kfold_3     148.000000  188.000000  209.000000  194.000000   \n",
       "predictCount_kfold_3    6.000000   50.000000  159.000000  136.000000   \n",
       "precision_kfold_4       0.384615    0.680851    0.739726    0.760331   \n",
       "recall_kfold_4          0.033784    0.170213    0.519231    0.474227   \n",
       "rocScore_kfold_4        0.723469    0.820569    0.869911    0.891071   \n",
       "accuracy_kfold_4        0.209722    0.237500    0.191667    0.181944   \n",
       "realCount_kfold_4     148.000000  188.000000  208.000000  194.000000   \n",
       "predictCount_kfold_4   13.000000   47.000000  146.000000  121.000000   \n",
       "precision_kfold_5       0.142857    0.696429    0.779528    0.715596   \n",
       "recall_kfold_5          0.006803    0.207447    0.473684    0.400000   \n",
       "rocScore_kfold_5        0.754199    0.808659    0.872351    0.871221   \n",
       "accuracy_kfold_5        0.209078    0.228336    0.189821    0.203576   \n",
       "realCount_kfold_5     147.000000  188.000000  209.000000  195.000000   \n",
       "predictCount_kfold_5    7.000000   56.000000  127.000000  109.000000   \n",
       "\n",
       "                              14          15  \n",
       "precision_kfold_1       0.796296    0.900000  \n",
       "recall_kfold_1          0.267081    0.078947  \n",
       "rocScore_kfold_1        0.884546    0.879685  \n",
       "accuracy_kfold_1        0.178423    0.146611  \n",
       "realCount_kfold_1     161.000000  114.000000  \n",
       "predictCount_kfold_1   54.000000   10.000000  \n",
       "precision_kfold_2       0.734375    0.600000  \n",
       "recall_kfold_2          0.290123    0.052632  \n",
       "rocScore_kfold_2        0.886739    0.844773  \n",
       "accuracy_kfold_2        0.181070    0.153635  \n",
       "realCount_kfold_2     162.000000  114.000000  \n",
       "predictCount_kfold_2   64.000000   10.000000  \n",
       "precision_kfold_3       0.807018    0.666667  \n",
       "recall_kfold_3          0.287500    0.052632  \n",
       "rocScore_kfold_3        0.895260    0.861114  \n",
       "accuracy_kfold_3        0.172414    0.153103  \n",
       "realCount_kfold_3     160.000000  114.000000  \n",
       "predictCount_kfold_3   57.000000    9.000000  \n",
       "precision_kfold_4       0.800000    0.700000  \n",
       "recall_kfold_4          0.225000    0.061404  \n",
       "rocScore_kfold_4        0.876953    0.853114  \n",
       "accuracy_kfold_4        0.184722    0.152778  \n",
       "realCount_kfold_4     160.000000  114.000000  \n",
       "predictCount_kfold_4   45.000000   10.000000  \n",
       "precision_kfold_5       0.750000    0.333333  \n",
       "recall_kfold_5          0.243750    0.026316  \n",
       "rocScore_kfold_5        0.875601    0.834407  \n",
       "accuracy_kfold_5        0.184319    0.160935  \n",
       "realCount_kfold_5     160.000000  114.000000  \n",
       "predictCount_kfold_5   52.000000    9.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#small_random_metric_df = np.transpose(pd.DataFrame(metricdict))\n",
    "#small_random_metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_random_metric_df['Analysis'] = ['small random'] * small_random_metric_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 593,  764,  853,  587,  395,  334,  461,  570,  708,  846,  932, 1181, 1313, 1242, 1020,  712], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data_df.loc[ : ,  'X20':'X95'].values, axis = 0) #/ y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_kfold_1</th>\n",
       "      <td>0.881988</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.789091</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.394231</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.368794</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_1</th>\n",
       "      <td>0.618736</td>\n",
       "      <td>0.708015</td>\n",
       "      <td>0.410208</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>0.038772</td>\n",
       "      <td>0.044255</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.023845</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>0.049724</td>\n",
       "      <td>0.042017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_1</th>\n",
       "      <td>0.976716</td>\n",
       "      <td>0.979133</td>\n",
       "      <td>0.938930</td>\n",
       "      <td>0.797502</td>\n",
       "      <td>0.750113</td>\n",
       "      <td>0.670650</td>\n",
       "      <td>0.665718</td>\n",
       "      <td>0.673067</td>\n",
       "      <td>0.751746</td>\n",
       "      <td>0.765833</td>\n",
       "      <td>0.817402</td>\n",
       "      <td>0.841002</td>\n",
       "      <td>0.882547</td>\n",
       "      <td>0.900863</td>\n",
       "      <td>0.889950</td>\n",
       "      <td>0.879331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_1</th>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.053085</td>\n",
       "      <td>0.060832</td>\n",
       "      <td>0.160258</td>\n",
       "      <td>0.181492</td>\n",
       "      <td>0.173888</td>\n",
       "      <td>0.111191</td>\n",
       "      <td>0.120373</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.071879</td>\n",
       "      <td>0.062267</td>\n",
       "      <td>0.054950</td>\n",
       "      <td>0.040316</td>\n",
       "      <td>0.025251</td>\n",
       "      <td>0.016786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_1</th>\n",
       "      <td>459.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1238.000000</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_1</th>\n",
       "      <td>322.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_2</th>\n",
       "      <td>0.865103</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.845850</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.415493</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_2</th>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.404537</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.040183</td>\n",
       "      <td>0.047696</td>\n",
       "      <td>0.051064</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>0.025610</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.055749</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.025424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_2</th>\n",
       "      <td>0.982851</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>0.952097</td>\n",
       "      <td>0.777403</td>\n",
       "      <td>0.741025</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.647403</td>\n",
       "      <td>0.678279</td>\n",
       "      <td>0.743603</td>\n",
       "      <td>0.770307</td>\n",
       "      <td>0.796626</td>\n",
       "      <td>0.825002</td>\n",
       "      <td>0.877316</td>\n",
       "      <td>0.871377</td>\n",
       "      <td>0.902511</td>\n",
       "      <td>0.898383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_2</th>\n",
       "      <td>0.030268</td>\n",
       "      <td>0.027686</td>\n",
       "      <td>0.050782</td>\n",
       "      <td>0.060823</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.180892</td>\n",
       "      <td>0.174437</td>\n",
       "      <td>0.110027</td>\n",
       "      <td>0.121790</td>\n",
       "      <td>0.099555</td>\n",
       "      <td>0.071869</td>\n",
       "      <td>0.062114</td>\n",
       "      <td>0.055946</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>0.026252</td>\n",
       "      <td>0.017214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_2</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1237.000000</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_2</th>\n",
       "      <td>341.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_3</th>\n",
       "      <td>0.872832</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.756184</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.362963</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_3</th>\n",
       "      <td>0.656522</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.403774</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.033790</td>\n",
       "      <td>0.039612</td>\n",
       "      <td>0.047660</td>\n",
       "      <td>0.035471</td>\n",
       "      <td>0.035323</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.018330</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.059322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_3</th>\n",
       "      <td>0.979706</td>\n",
       "      <td>0.980554</td>\n",
       "      <td>0.940150</td>\n",
       "      <td>0.778066</td>\n",
       "      <td>0.740880</td>\n",
       "      <td>0.680898</td>\n",
       "      <td>0.649529</td>\n",
       "      <td>0.692469</td>\n",
       "      <td>0.745794</td>\n",
       "      <td>0.765874</td>\n",
       "      <td>0.799305</td>\n",
       "      <td>0.842343</td>\n",
       "      <td>0.886896</td>\n",
       "      <td>0.886186</td>\n",
       "      <td>0.901039</td>\n",
       "      <td>0.882221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_3</th>\n",
       "      <td>0.028965</td>\n",
       "      <td>0.029108</td>\n",
       "      <td>0.055205</td>\n",
       "      <td>0.060941</td>\n",
       "      <td>0.158446</td>\n",
       "      <td>0.182679</td>\n",
       "      <td>0.175366</td>\n",
       "      <td>0.109693</td>\n",
       "      <td>0.121021</td>\n",
       "      <td>0.099799</td>\n",
       "      <td>0.071838</td>\n",
       "      <td>0.061514</td>\n",
       "      <td>0.055348</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.025810</td>\n",
       "      <td>0.016920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_3</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1237.000000</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>821.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_3</th>\n",
       "      <td>346.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_4</th>\n",
       "      <td>0.828255</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.740458</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.383459</td>\n",
       "      <td>0.361290</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_4</th>\n",
       "      <td>0.651416</td>\n",
       "      <td>0.725191</td>\n",
       "      <td>0.366730</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.038356</td>\n",
       "      <td>0.041229</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.018367</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.050420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_4</th>\n",
       "      <td>0.980786</td>\n",
       "      <td>0.984406</td>\n",
       "      <td>0.937891</td>\n",
       "      <td>0.778696</td>\n",
       "      <td>0.752263</td>\n",
       "      <td>0.668646</td>\n",
       "      <td>0.652105</td>\n",
       "      <td>0.678638</td>\n",
       "      <td>0.732994</td>\n",
       "      <td>0.768754</td>\n",
       "      <td>0.810593</td>\n",
       "      <td>0.845093</td>\n",
       "      <td>0.877927</td>\n",
       "      <td>0.895244</td>\n",
       "      <td>0.909821</td>\n",
       "      <td>0.877905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_4</th>\n",
       "      <td>0.031878</td>\n",
       "      <td>0.026134</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.061172</td>\n",
       "      <td>0.160396</td>\n",
       "      <td>0.182079</td>\n",
       "      <td>0.174756</td>\n",
       "      <td>0.109276</td>\n",
       "      <td>0.119759</td>\n",
       "      <td>0.097645</td>\n",
       "      <td>0.070936</td>\n",
       "      <td>0.061746</td>\n",
       "      <td>0.055572</td>\n",
       "      <td>0.041212</td>\n",
       "      <td>0.025704</td>\n",
       "      <td>0.017231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_4</th>\n",
       "      <td>459.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1237.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_4</th>\n",
       "      <td>361.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_5</th>\n",
       "      <td>0.860119</td>\n",
       "      <td>0.876993</td>\n",
       "      <td>0.724528</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.425287</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_5</th>\n",
       "      <td>0.628261</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.362949</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.033759</td>\n",
       "      <td>0.035570</td>\n",
       "      <td>0.040851</td>\n",
       "      <td>0.021828</td>\n",
       "      <td>0.032927</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.036458</td>\n",
       "      <td>0.062718</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_5</th>\n",
       "      <td>0.981319</td>\n",
       "      <td>0.983033</td>\n",
       "      <td>0.942755</td>\n",
       "      <td>0.796498</td>\n",
       "      <td>0.744084</td>\n",
       "      <td>0.684281</td>\n",
       "      <td>0.654339</td>\n",
       "      <td>0.684102</td>\n",
       "      <td>0.742722</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.817265</td>\n",
       "      <td>0.844933</td>\n",
       "      <td>0.873616</td>\n",
       "      <td>0.896615</td>\n",
       "      <td>0.897226</td>\n",
       "      <td>0.892806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_5</th>\n",
       "      <td>0.031308</td>\n",
       "      <td>0.027862</td>\n",
       "      <td>0.058883</td>\n",
       "      <td>0.061468</td>\n",
       "      <td>0.159270</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>0.175212</td>\n",
       "      <td>0.109579</td>\n",
       "      <td>0.120925</td>\n",
       "      <td>0.100244</td>\n",
       "      <td>0.071377</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.056010</td>\n",
       "      <td>0.040787</td>\n",
       "      <td>0.025707</td>\n",
       "      <td>0.016803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_5</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>1237.000000</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_5</th>\n",
       "      <td>336.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0           1           2           3  \\\n",
       "precision_kfold_1       0.881988    0.932161    0.789091    0.315789   \n",
       "recall_kfold_1          0.618736    0.708015    0.410208    0.014388   \n",
       "rocScore_kfold_1        0.976716    0.979133    0.938930    0.797502   \n",
       "accuracy_kfold_1        0.030560    0.025825    0.053085    0.060832   \n",
       "realCount_kfold_1     459.000000  524.000000  529.000000  417.000000   \n",
       "predictCount_kfold_1  322.000000  398.000000  275.000000   19.000000   \n",
       "precision_kfold_2       0.865103    0.915000    0.845850    0.277778   \n",
       "recall_kfold_2          0.641304    0.697143    0.404537    0.012019   \n",
       "rocScore_kfold_2        0.982851    0.978738    0.952097    0.777403   \n",
       "accuracy_kfold_2        0.030268    0.027686    0.050782    0.060823   \n",
       "realCount_kfold_2     460.000000  525.000000  529.000000  416.000000   \n",
       "predictCount_kfold_2  341.000000  400.000000  253.000000   18.000000   \n",
       "precision_kfold_3       0.872832    0.910714    0.756184    0.250000   \n",
       "recall_kfold_3          0.656522    0.680000    0.403774    0.009592   \n",
       "rocScore_kfold_3        0.979706    0.980554    0.940150    0.778066   \n",
       "accuracy_kfold_3        0.028965    0.029108    0.055205    0.060941   \n",
       "realCount_kfold_3     460.000000  525.000000  530.000000  417.000000   \n",
       "predictCount_kfold_3  346.000000  392.000000  283.000000   16.000000   \n",
       "precision_kfold_4       0.828255    0.909091    0.740458    0.187500   \n",
       "recall_kfold_4          0.651416    0.725191    0.366730    0.007212   \n",
       "rocScore_kfold_4        0.980786    0.984406    0.937891    0.778696   \n",
       "accuracy_kfold_4        0.031878    0.026134    0.057869    0.061172   \n",
       "realCount_kfold_4     459.000000  524.000000  529.000000  416.000000   \n",
       "predictCount_kfold_4  361.000000  418.000000  262.000000   16.000000   \n",
       "precision_kfold_5       0.860119    0.876993    0.724528    0.200000   \n",
       "recall_kfold_5          0.628261    0.733333    0.362949    0.009615   \n",
       "rocScore_kfold_5        0.981319    0.983033    0.942755    0.796498   \n",
       "accuracy_kfold_5        0.031308    0.027862    0.058883    0.061468   \n",
       "realCount_kfold_5     460.000000  525.000000  529.000000  416.000000   \n",
       "predictCount_kfold_5  336.000000  439.000000  265.000000   20.000000   \n",
       "\n",
       "                                4            5            6           7  \\\n",
       "precision_kfold_1        0.394231     0.390244     0.368794    0.171875   \n",
       "recall_kfold_1           0.037443     0.038772     0.044255    0.015007   \n",
       "rocScore_kfold_1         0.750113     0.670650     0.665718    0.673067   \n",
       "accuracy_kfold_1         0.160258     0.181492     0.173888    0.111191   \n",
       "realCount_kfold_1     1095.000000  1238.000000  1175.000000  733.000000   \n",
       "predictCount_kfold_1   104.000000   123.000000   141.000000   64.000000   \n",
       "precision_kfold_2        0.389381     0.415493     0.372671    0.210526   \n",
       "recall_kfold_2           0.040183     0.047696     0.051064    0.016349   \n",
       "rocScore_kfold_2         0.741025     0.674510     0.647403    0.678279   \n",
       "accuracy_kfold_2         0.160666     0.180892     0.174437    0.110027   \n",
       "realCount_kfold_2     1095.000000  1237.000000  1175.000000  734.000000   \n",
       "predictCount_kfold_2   113.000000   142.000000   161.000000   57.000000   \n",
       "precision_kfold_3        0.440476     0.362963     0.350000    0.309524   \n",
       "recall_kfold_3           0.033790     0.039612     0.047660    0.035471   \n",
       "rocScore_kfold_3         0.740880     0.680898     0.649529    0.692469   \n",
       "accuracy_kfold_3         0.158446     0.182679     0.175366    0.109693   \n",
       "realCount_kfold_3     1095.000000  1237.000000  1175.000000  733.000000   \n",
       "predictCount_kfold_3    84.000000   135.000000   160.000000   84.000000   \n",
       "precision_kfold_4        0.396226     0.383459     0.361290    0.254545   \n",
       "recall_kfold_4           0.038356     0.041229     0.047700    0.019074   \n",
       "rocScore_kfold_4         0.752263     0.668646     0.652105    0.678638   \n",
       "accuracy_kfold_4         0.160396     0.182079     0.174756    0.109276   \n",
       "realCount_kfold_4     1095.000000  1237.000000  1174.000000  734.000000   \n",
       "predictCount_kfold_4   106.000000   133.000000   155.000000   55.000000   \n",
       "precision_kfold_5        0.425287     0.392857     0.340426    0.258065   \n",
       "recall_kfold_5           0.033759     0.035570     0.040851    0.021828   \n",
       "rocScore_kfold_5         0.744084     0.684281     0.654339    0.684102   \n",
       "accuracy_kfold_5         0.159270     0.181100     0.175212    0.109579   \n",
       "realCount_kfold_5     1096.000000  1237.000000  1175.000000  733.000000   \n",
       "predictCount_kfold_5    87.000000   112.000000   141.000000   62.000000   \n",
       "\n",
       "                               8           9          10          11  \\\n",
       "precision_kfold_1       0.358209    0.320000    0.333333    0.269231   \n",
       "recall_kfold_1          0.029268    0.023845    0.022449    0.016588   \n",
       "rocScore_kfold_1        0.751746    0.765833    0.817402    0.841002   \n",
       "accuracy_kfold_1        0.120373    0.098852    0.071879    0.062267   \n",
       "realCount_kfold_1     820.000000  671.000000  490.000000  422.000000   \n",
       "predictCount_kfold_1   67.000000   50.000000   33.000000   26.000000   \n",
       "precision_kfold_2       0.295775    0.260870    0.291667    0.280000   \n",
       "recall_kfold_2          0.025610    0.017857    0.014257    0.016588   \n",
       "rocScore_kfold_2        0.743603    0.770307    0.796626    0.825002   \n",
       "accuracy_kfold_2        0.121790    0.099555    0.071869    0.062114   \n",
       "realCount_kfold_2     820.000000  672.000000  491.000000  422.000000   \n",
       "predictCount_kfold_2   71.000000   46.000000   24.000000   25.000000   \n",
       "precision_kfold_3       0.358025    0.234043    0.321429    0.315789   \n",
       "recall_kfold_3          0.035323    0.016393    0.018330    0.014218   \n",
       "rocScore_kfold_3        0.745794    0.765874    0.799305    0.842343   \n",
       "accuracy_kfold_3        0.121021    0.099799    0.071838    0.061514   \n",
       "realCount_kfold_3     821.000000  671.000000  491.000000  422.000000   \n",
       "predictCount_kfold_3   81.000000   47.000000   28.000000   19.000000   \n",
       "precision_kfold_4       0.387097    0.394737    0.409091    0.153846   \n",
       "recall_kfold_4          0.029268    0.022321    0.018367    0.004751   \n",
       "rocScore_kfold_4        0.732994    0.768754    0.810593    0.845093   \n",
       "accuracy_kfold_4        0.119759    0.097645    0.070936    0.061746   \n",
       "realCount_kfold_4     820.000000  672.000000  490.000000  421.000000   \n",
       "predictCount_kfold_4   62.000000   38.000000   22.000000   13.000000   \n",
       "precision_kfold_5       0.355263    0.259259    0.363636    0.250000   \n",
       "recall_kfold_5          0.032927    0.020833    0.016293    0.009501   \n",
       "rocScore_kfold_5        0.742722    0.783505    0.817265    0.844933   \n",
       "accuracy_kfold_5        0.120925    0.100244    0.071377    0.061611   \n",
       "realCount_kfold_5     820.000000  672.000000  491.000000  421.000000   \n",
       "predictCount_kfold_5   76.000000   54.000000   22.000000   16.000000   \n",
       "\n",
       "                              12          13          14          15  \n",
       "precision_kfold_1       0.535714    0.666667    0.692308    0.625000  \n",
       "recall_kfold_1          0.038961    0.048611    0.049724    0.042017  \n",
       "rocScore_kfold_1        0.882547    0.900863    0.889950    0.879331  \n",
       "accuracy_kfold_1        0.054950    0.040316    0.025251    0.016786  \n",
       "realCount_kfold_1     385.000000  288.000000  181.000000  119.000000  \n",
       "predictCount_kfold_1   28.000000   21.000000   13.000000    8.000000  \n",
       "precision_kfold_2       0.400000    0.727273    0.416667    0.375000  \n",
       "recall_kfold_2          0.025974    0.055749    0.027624    0.025424  \n",
       "rocScore_kfold_2        0.877316    0.871377    0.902511    0.898383  \n",
       "accuracy_kfold_2        0.055946    0.039736    0.026252    0.017214  \n",
       "realCount_kfold_2     385.000000  287.000000  181.000000  118.000000  \n",
       "predictCount_kfold_2   25.000000   22.000000   12.000000    8.000000  \n",
       "precision_kfold_3       0.461538    0.666667    0.526316    0.500000  \n",
       "recall_kfold_3          0.031250    0.069444    0.055249    0.059322  \n",
       "rocScore_kfold_3        0.886896    0.886186    0.901039    0.882221  \n",
       "accuracy_kfold_3        0.055348    0.039862    0.025810    0.016920  \n",
       "realCount_kfold_3     384.000000  288.000000  181.000000  118.000000  \n",
       "predictCount_kfold_3   26.000000   30.000000   19.000000   14.000000  \n",
       "precision_kfold_4       0.434783    0.500000    0.526316    0.461538  \n",
       "recall_kfold_4          0.026042    0.045296    0.055556    0.050420  \n",
       "rocScore_kfold_4        0.877927    0.895244    0.909821    0.877905  \n",
       "accuracy_kfold_4        0.055572    0.041212    0.025704    0.017231  \n",
       "realCount_kfold_4     384.000000  287.000000  180.000000  119.000000  \n",
       "predictCount_kfold_4   23.000000   26.000000   19.000000   13.000000  \n",
       "precision_kfold_5       0.411765    0.545455    0.545455    0.583333  \n",
       "recall_kfold_5          0.036458    0.062718    0.066298    0.058824  \n",
       "rocScore_kfold_5        0.873616    0.896615    0.897226    0.892806  \n",
       "accuracy_kfold_5        0.056010    0.040787    0.025707    0.016803  \n",
       "realCount_kfold_5     384.000000  287.000000  181.000000  119.000000  \n",
       "predictCount_kfold_5   34.000000   33.000000   22.000000   12.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labelnumbercap_metric_df = np.transpose(pd.DataFrame(metricdict))\n",
    "#labelnumbercap_metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelnumbercap_metric_df['Analysis'] = ['label number cap'] * labelnumbercap_metric_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_kfold_1</th>\n",
       "      <td>0.771704</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.812160</td>\n",
       "      <td>0.737348</td>\n",
       "      <td>0.608586</td>\n",
       "      <td>0.398374</td>\n",
       "      <td>0.419274</td>\n",
       "      <td>0.519828</td>\n",
       "      <td>0.506803</td>\n",
       "      <td>0.542725</td>\n",
       "      <td>0.575456</td>\n",
       "      <td>0.585185</td>\n",
       "      <td>0.562249</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_1</th>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.639024</td>\n",
       "      <td>0.685020</td>\n",
       "      <td>0.510421</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>0.066917</td>\n",
       "      <td>0.090394</td>\n",
       "      <td>0.145406</td>\n",
       "      <td>0.150353</td>\n",
       "      <td>0.135877</td>\n",
       "      <td>0.118027</td>\n",
       "      <td>0.103313</td>\n",
       "      <td>0.086154</td>\n",
       "      <td>0.074669</td>\n",
       "      <td>0.047697</td>\n",
       "      <td>0.035948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_1</th>\n",
       "      <td>0.964773</td>\n",
       "      <td>0.956136</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>0.874833</td>\n",
       "      <td>0.812353</td>\n",
       "      <td>0.743883</td>\n",
       "      <td>0.735949</td>\n",
       "      <td>0.768834</td>\n",
       "      <td>0.802462</td>\n",
       "      <td>0.839295</td>\n",
       "      <td>0.867734</td>\n",
       "      <td>0.881210</td>\n",
       "      <td>0.884704</td>\n",
       "      <td>0.889110</td>\n",
       "      <td>0.901720</td>\n",
       "      <td>0.900852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_1</th>\n",
       "      <td>0.034152</td>\n",
       "      <td>0.051621</td>\n",
       "      <td>0.092016</td>\n",
       "      <td>0.158850</td>\n",
       "      <td>0.196831</td>\n",
       "      <td>0.158903</td>\n",
       "      <td>0.201186</td>\n",
       "      <td>0.215140</td>\n",
       "      <td>0.207114</td>\n",
       "      <td>0.177578</td>\n",
       "      <td>0.149460</td>\n",
       "      <td>0.116724</td>\n",
       "      <td>0.083622</td>\n",
       "      <td>0.054716</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.016945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_1</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2050.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4096.000000</td>\n",
       "      <td>2929.000000</td>\n",
       "      <td>3706.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3964.000000</td>\n",
       "      <td>3459.000000</td>\n",
       "      <td>2940.000000</td>\n",
       "      <td>2294.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_1</th>\n",
       "      <td>311.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>3125.000000</td>\n",
       "      <td>3122.000000</td>\n",
       "      <td>1584.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_2</th>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.855495</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>0.729797</td>\n",
       "      <td>0.599130</td>\n",
       "      <td>0.414687</td>\n",
       "      <td>0.397359</td>\n",
       "      <td>0.504910</td>\n",
       "      <td>0.503100</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.561576</td>\n",
       "      <td>0.584112</td>\n",
       "      <td>0.591912</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_2</th>\n",
       "      <td>0.310976</td>\n",
       "      <td>0.614822</td>\n",
       "      <td>0.663428</td>\n",
       "      <td>0.518625</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>0.089291</td>\n",
       "      <td>0.148782</td>\n",
       "      <td>0.143290</td>\n",
       "      <td>0.117953</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>0.099077</td>\n",
       "      <td>0.084121</td>\n",
       "      <td>0.052464</td>\n",
       "      <td>0.036066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_2</th>\n",
       "      <td>0.962470</td>\n",
       "      <td>0.954419</td>\n",
       "      <td>0.931591</td>\n",
       "      <td>0.875787</td>\n",
       "      <td>0.804768</td>\n",
       "      <td>0.741209</td>\n",
       "      <td>0.728330</td>\n",
       "      <td>0.771223</td>\n",
       "      <td>0.794287</td>\n",
       "      <td>0.831907</td>\n",
       "      <td>0.869203</td>\n",
       "      <td>0.878626</td>\n",
       "      <td>0.892682</td>\n",
       "      <td>0.903449</td>\n",
       "      <td>0.902119</td>\n",
       "      <td>0.905270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_2</th>\n",
       "      <td>0.032547</td>\n",
       "      <td>0.052568</td>\n",
       "      <td>0.095650</td>\n",
       "      <td>0.159172</td>\n",
       "      <td>0.197956</td>\n",
       "      <td>0.157652</td>\n",
       "      <td>0.203249</td>\n",
       "      <td>0.216719</td>\n",
       "      <td>0.207390</td>\n",
       "      <td>0.180346</td>\n",
       "      <td>0.150105</td>\n",
       "      <td>0.116457</td>\n",
       "      <td>0.082547</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.016509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_2</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4096.000000</td>\n",
       "      <td>2929.000000</td>\n",
       "      <td>3707.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3964.000000</td>\n",
       "      <td>3459.000000</td>\n",
       "      <td>2939.000000</td>\n",
       "      <td>2294.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_2</th>\n",
       "      <td>311.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>3036.000000</td>\n",
       "      <td>3205.000000</td>\n",
       "      <td>1609.000000</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>833.000000</td>\n",
       "      <td>1222.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>798.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_3</th>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.832778</td>\n",
       "      <td>0.814342</td>\n",
       "      <td>0.723167</td>\n",
       "      <td>0.602850</td>\n",
       "      <td>0.409190</td>\n",
       "      <td>0.411097</td>\n",
       "      <td>0.519504</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>0.551160</td>\n",
       "      <td>0.593346</td>\n",
       "      <td>0.610315</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.424658</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_3</th>\n",
       "      <td>0.232927</td>\n",
       "      <td>0.609459</td>\n",
       "      <td>0.671255</td>\n",
       "      <td>0.546785</td>\n",
       "      <td>0.237607</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.087942</td>\n",
       "      <td>0.141307</td>\n",
       "      <td>0.139541</td>\n",
       "      <td>0.116763</td>\n",
       "      <td>0.109184</td>\n",
       "      <td>0.092810</td>\n",
       "      <td>0.089626</td>\n",
       "      <td>0.069943</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_3</th>\n",
       "      <td>0.958484</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.931924</td>\n",
       "      <td>0.880413</td>\n",
       "      <td>0.809051</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.730058</td>\n",
       "      <td>0.768877</td>\n",
       "      <td>0.796725</td>\n",
       "      <td>0.836025</td>\n",
       "      <td>0.867190</td>\n",
       "      <td>0.881938</td>\n",
       "      <td>0.892383</td>\n",
       "      <td>0.895695</td>\n",
       "      <td>0.902558</td>\n",
       "      <td>0.892593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_3</th>\n",
       "      <td>0.035664</td>\n",
       "      <td>0.055174</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.156711</td>\n",
       "      <td>0.197357</td>\n",
       "      <td>0.157917</td>\n",
       "      <td>0.201815</td>\n",
       "      <td>0.215189</td>\n",
       "      <td>0.206273</td>\n",
       "      <td>0.177532</td>\n",
       "      <td>0.148896</td>\n",
       "      <td>0.116327</td>\n",
       "      <td>0.083233</td>\n",
       "      <td>0.055593</td>\n",
       "      <td>0.032517</td>\n",
       "      <td>0.016993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_3</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>3707.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3963.000000</td>\n",
       "      <td>3460.000000</td>\n",
       "      <td>2940.000000</td>\n",
       "      <td>2295.000000</td>\n",
       "      <td>1629.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_3</th>\n",
       "      <td>242.000000</td>\n",
       "      <td>1501.000000</td>\n",
       "      <td>3054.000000</td>\n",
       "      <td>3410.000000</td>\n",
       "      <td>1614.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>1128.000000</td>\n",
       "      <td>1076.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_4</th>\n",
       "      <td>0.767347</td>\n",
       "      <td>0.850065</td>\n",
       "      <td>0.827471</td>\n",
       "      <td>0.727565</td>\n",
       "      <td>0.594969</td>\n",
       "      <td>0.409766</td>\n",
       "      <td>0.469921</td>\n",
       "      <td>0.515853</td>\n",
       "      <td>0.484716</td>\n",
       "      <td>0.528678</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_4</th>\n",
       "      <td>0.229268</td>\n",
       "      <td>0.635787</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.501552</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.065915</td>\n",
       "      <td>0.111681</td>\n",
       "      <td>0.145165</td>\n",
       "      <td>0.140010</td>\n",
       "      <td>0.122543</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.105493</td>\n",
       "      <td>0.084923</td>\n",
       "      <td>0.068053</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>0.019355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_4</th>\n",
       "      <td>0.962116</td>\n",
       "      <td>0.955842</td>\n",
       "      <td>0.933034</td>\n",
       "      <td>0.869537</td>\n",
       "      <td>0.804650</td>\n",
       "      <td>0.735130</td>\n",
       "      <td>0.736412</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>0.795884</td>\n",
       "      <td>0.833184</td>\n",
       "      <td>0.856737</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>0.883365</td>\n",
       "      <td>0.889854</td>\n",
       "      <td>0.899402</td>\n",
       "      <td>0.899105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_4</th>\n",
       "      <td>0.036157</td>\n",
       "      <td>0.051270</td>\n",
       "      <td>0.091835</td>\n",
       "      <td>0.162416</td>\n",
       "      <td>0.199045</td>\n",
       "      <td>0.158113</td>\n",
       "      <td>0.197313</td>\n",
       "      <td>0.215680</td>\n",
       "      <td>0.209855</td>\n",
       "      <td>0.179156</td>\n",
       "      <td>0.150609</td>\n",
       "      <td>0.115449</td>\n",
       "      <td>0.082914</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>0.032168</td>\n",
       "      <td>0.016635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_4</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>3707.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3964.000000</td>\n",
       "      <td>3460.000000</td>\n",
       "      <td>2940.000000</td>\n",
       "      <td>2294.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_4</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>1534.000000</td>\n",
       "      <td>2985.000000</td>\n",
       "      <td>3109.000000</td>\n",
       "      <td>1590.000000</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_5</th>\n",
       "      <td>0.824176</td>\n",
       "      <td>0.858294</td>\n",
       "      <td>0.811333</td>\n",
       "      <td>0.730106</td>\n",
       "      <td>0.585766</td>\n",
       "      <td>0.369072</td>\n",
       "      <td>0.403869</td>\n",
       "      <td>0.490700</td>\n",
       "      <td>0.532273</td>\n",
       "      <td>0.551499</td>\n",
       "      <td>0.561189</td>\n",
       "      <td>0.567430</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.541935</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_5</th>\n",
       "      <td>0.274390</td>\n",
       "      <td>0.623111</td>\n",
       "      <td>0.668737</td>\n",
       "      <td>0.535033</td>\n",
       "      <td>0.235165</td>\n",
       "      <td>0.061113</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.133591</td>\n",
       "      <td>0.143578</td>\n",
       "      <td>0.122290</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.081231</td>\n",
       "      <td>0.079395</td>\n",
       "      <td>0.060855</td>\n",
       "      <td>0.039344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_5</th>\n",
       "      <td>0.962492</td>\n",
       "      <td>0.958076</td>\n",
       "      <td>0.932191</td>\n",
       "      <td>0.878449</td>\n",
       "      <td>0.806859</td>\n",
       "      <td>0.742193</td>\n",
       "      <td>0.730628</td>\n",
       "      <td>0.763261</td>\n",
       "      <td>0.795485</td>\n",
       "      <td>0.834551</td>\n",
       "      <td>0.862916</td>\n",
       "      <td>0.882720</td>\n",
       "      <td>0.890295</td>\n",
       "      <td>0.894963</td>\n",
       "      <td>0.894097</td>\n",
       "      <td>0.904397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_5</th>\n",
       "      <td>0.033737</td>\n",
       "      <td>0.051629</td>\n",
       "      <td>0.094601</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.200063</td>\n",
       "      <td>0.160344</td>\n",
       "      <td>0.202844</td>\n",
       "      <td>0.218689</td>\n",
       "      <td>0.204313</td>\n",
       "      <td>0.177344</td>\n",
       "      <td>0.150533</td>\n",
       "      <td>0.117635</td>\n",
       "      <td>0.084632</td>\n",
       "      <td>0.054830</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.016423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_5</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>3704.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>2929.000000</td>\n",
       "      <td>3707.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3963.000000</td>\n",
       "      <td>3459.000000</td>\n",
       "      <td>2939.000000</td>\n",
       "      <td>2295.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_5</th>\n",
       "      <td>273.000000</td>\n",
       "      <td>1489.000000</td>\n",
       "      <td>3053.000000</td>\n",
       "      <td>3305.000000</td>\n",
       "      <td>1644.000000</td>\n",
       "      <td>485.000000</td>\n",
       "      <td>827.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1069.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0            1            2            3  \\\n",
       "precision_kfold_1       0.771704     0.842986     0.812160     0.737348   \n",
       "recall_kfold_1          0.292683     0.639024     0.685020     0.510421   \n",
       "rocScore_kfold_1        0.964773     0.956136     0.936256     0.874833   \n",
       "accuracy_kfold_1        0.034152     0.051621     0.092016     0.158850   \n",
       "realCount_kfold_1     820.000000  2050.000000  3705.000000  4510.000000   \n",
       "predictCount_kfold_1  311.000000  1554.000000  3125.000000  3122.000000   \n",
       "precision_kfold_2       0.819936     0.855495     0.809618     0.729797   \n",
       "recall_kfold_2          0.310976     0.614822     0.663428     0.518625   \n",
       "rocScore_kfold_2        0.962470     0.954419     0.931591     0.875787   \n",
       "accuracy_kfold_2        0.032547     0.052568     0.095650     0.159172   \n",
       "realCount_kfold_2     820.000000  2051.000000  3705.000000  4510.000000   \n",
       "predictCount_kfold_2  311.000000  1474.000000  3036.000000  3205.000000   \n",
       "precision_kfold_3       0.789256     0.832778     0.814342     0.723167   \n",
       "recall_kfold_3          0.232927     0.609459     0.671255     0.546785   \n",
       "rocScore_kfold_3        0.958484     0.951210     0.931924     0.880413   \n",
       "accuracy_kfold_3        0.035664     0.055174     0.093617     0.156711   \n",
       "realCount_kfold_3     820.000000  2051.000000  3705.000000  4510.000000   \n",
       "predictCount_kfold_3  242.000000  1501.000000  3054.000000  3410.000000   \n",
       "precision_kfold_4       0.767347     0.850065     0.827471     0.727565   \n",
       "recall_kfold_4          0.229268     0.635787     0.666667     0.501552   \n",
       "rocScore_kfold_4        0.962116     0.955842     0.933034     0.869537   \n",
       "accuracy_kfold_4        0.036157     0.051270     0.091835     0.162416   \n",
       "realCount_kfold_4     820.000000  2051.000000  3705.000000  4510.000000   \n",
       "predictCount_kfold_4  245.000000  1534.000000  2985.000000  3109.000000   \n",
       "precision_kfold_5       0.824176     0.858294     0.811333     0.730106   \n",
       "recall_kfold_5          0.274390     0.623111     0.668737     0.535033   \n",
       "rocScore_kfold_5        0.962492     0.958076     0.932191     0.878449   \n",
       "accuracy_kfold_5        0.033737     0.051629     0.094601     0.156829   \n",
       "realCount_kfold_5     820.000000  2051.000000  3704.000000  4510.000000   \n",
       "predictCount_kfold_5  273.000000  1489.000000  3053.000000  3305.000000   \n",
       "\n",
       "                                4            5            6            7  \\\n",
       "precision_kfold_1        0.608586     0.398374     0.419274     0.519828   \n",
       "recall_kfold_1           0.235352     0.066917     0.090394     0.145406   \n",
       "rocScore_kfold_1         0.812353     0.743883     0.735949     0.768834   \n",
       "accuracy_kfold_1         0.196831     0.158903     0.201186     0.215140   \n",
       "realCount_kfold_1     4096.000000  2929.000000  3706.000000  4147.000000   \n",
       "predictCount_kfold_1  1584.000000   492.000000   799.000000  1160.000000   \n",
       "precision_kfold_2        0.599130     0.414687     0.397359     0.504910   \n",
       "recall_kfold_2           0.235352     0.065551     0.089291     0.148782   \n",
       "rocScore_kfold_2         0.804768     0.741209     0.728330     0.771223   \n",
       "accuracy_kfold_2         0.197956     0.157652     0.203249     0.216719   \n",
       "realCount_kfold_2     4096.000000  2929.000000  3707.000000  4147.000000   \n",
       "predictCount_kfold_2  1609.000000   463.000000   833.000000  1222.000000   \n",
       "precision_kfold_3        0.602850     0.409190     0.411097     0.519504   \n",
       "recall_kfold_3           0.237607     0.063866     0.087942     0.141307   \n",
       "rocScore_kfold_3         0.809051     0.745000     0.730058     0.768877   \n",
       "accuracy_kfold_3         0.197357     0.157917     0.201815     0.215189   \n",
       "realCount_kfold_3     4095.000000  2928.000000  3707.000000  4147.000000   \n",
       "predictCount_kfold_3  1614.000000   457.000000   793.000000  1128.000000   \n",
       "precision_kfold_4        0.594969     0.409766     0.469921     0.515853   \n",
       "recall_kfold_4           0.231013     0.065915     0.111681     0.145165   \n",
       "rocScore_kfold_4         0.804650     0.735130     0.736412     0.764766   \n",
       "accuracy_kfold_4         0.199045     0.158113     0.197313     0.215680   \n",
       "realCount_kfold_4     4095.000000  2928.000000  3707.000000  4147.000000   \n",
       "predictCount_kfold_4  1590.000000   471.000000   881.000000  1167.000000   \n",
       "precision_kfold_5        0.585766     0.369072     0.403869     0.490700   \n",
       "recall_kfold_5           0.235165     0.061113     0.090100     0.133591   \n",
       "rocScore_kfold_5         0.806859     0.742193     0.730628     0.763261   \n",
       "accuracy_kfold_5         0.200063     0.160344     0.202844     0.218689   \n",
       "realCount_kfold_5     4095.000000  2929.000000  3707.000000  4147.000000   \n",
       "predictCount_kfold_5  1644.000000   485.000000   827.000000  1129.000000   \n",
       "\n",
       "                                8            9           10           11  \\\n",
       "precision_kfold_1        0.506803     0.542725     0.575456     0.585185   \n",
       "recall_kfold_1           0.150353     0.135877     0.118027     0.103313   \n",
       "rocScore_kfold_1         0.802462     0.839295     0.867734     0.881210   \n",
       "accuracy_kfold_1         0.207114     0.177578     0.149460     0.116724   \n",
       "realCount_kfold_1     3964.000000  3459.000000  2940.000000  2294.000000   \n",
       "predictCount_kfold_1  1176.000000   866.000000   603.000000   405.000000   \n",
       "precision_kfold_2        0.503100     0.511278     0.561576     0.584112   \n",
       "recall_kfold_2           0.143290     0.117953     0.116366     0.108980   \n",
       "rocScore_kfold_2         0.794287     0.831907     0.869203     0.878626   \n",
       "accuracy_kfold_2         0.207390     0.180346     0.150105     0.116457   \n",
       "realCount_kfold_2     3964.000000  3459.000000  2939.000000  2294.000000   \n",
       "predictCount_kfold_2  1129.000000   798.000000   609.000000   428.000000   \n",
       "precision_kfold_3        0.513941     0.551160     0.593346     0.610315   \n",
       "recall_kfold_3           0.139541     0.116763     0.109184     0.092810   \n",
       "rocScore_kfold_3         0.796725     0.836025     0.867190     0.881938   \n",
       "accuracy_kfold_3         0.206273     0.177532     0.148896     0.116327   \n",
       "realCount_kfold_3     3963.000000  3460.000000  2940.000000  2295.000000   \n",
       "predictCount_kfold_3  1076.000000   733.000000   541.000000   349.000000   \n",
       "precision_kfold_4        0.484716     0.528678     0.560976     0.620513   \n",
       "recall_kfold_4           0.140010     0.122543     0.109524     0.105493   \n",
       "rocScore_kfold_4         0.795884     0.833184     0.856737     0.881818   \n",
       "accuracy_kfold_4         0.209855     0.179156     0.150609     0.115449   \n",
       "realCount_kfold_4     3964.000000  3460.000000  2940.000000  2294.000000   \n",
       "predictCount_kfold_4  1145.000000   802.000000   574.000000   390.000000   \n",
       "precision_kfold_5        0.532273     0.551499     0.561189     0.567430   \n",
       "recall_kfold_5           0.143578     0.122290     0.109221     0.097168   \n",
       "rocScore_kfold_5         0.795485     0.834551     0.862916     0.882720   \n",
       "accuracy_kfold_5         0.204313     0.177344     0.150533     0.117635   \n",
       "realCount_kfold_5     3963.000000  3459.000000  2939.000000  2295.000000   \n",
       "predictCount_kfold_5  1069.000000   767.000000   572.000000   393.000000   \n",
       "\n",
       "                               12           13          14          15  \n",
       "precision_kfold_1        0.562249     0.552448    0.426471    0.282051  \n",
       "recall_kfold_1           0.086154     0.074669    0.047697    0.035948  \n",
       "rocScore_kfold_1         0.884704     0.889110    0.901720    0.900852  \n",
       "accuracy_kfold_1         0.083622     0.054716    0.032421    0.016945  \n",
       "realCount_kfold_1     1625.000000  1058.000000  608.000000  306.000000  \n",
       "predictCount_kfold_1   249.000000   143.000000   68.000000   39.000000  \n",
       "precision_kfold_2        0.591912     0.552795    0.452055    0.343750  \n",
       "recall_kfold_2           0.099077     0.084121    0.052464    0.036066  \n",
       "rocScore_kfold_2         0.892682     0.903449    0.902119    0.905270  \n",
       "accuracy_kfold_2         0.082547     0.054560    0.033333    0.016509  \n",
       "realCount_kfold_2     1625.000000  1058.000000  629.000000  305.000000  \n",
       "predictCount_kfold_2   272.000000   161.000000   73.000000   32.000000  \n",
       "precision_kfold_3        0.584000     0.493333    0.424658    0.250000  \n",
       "recall_kfold_3           0.089626     0.069943    0.050903    0.029412  \n",
       "rocScore_kfold_3         0.892383     0.895695    0.902558    0.892593  \n",
       "accuracy_kfold_3         0.083233     0.055593    0.032517    0.016993  \n",
       "realCount_kfold_3     1629.000000  1058.000000  609.000000  306.000000  \n",
       "predictCount_kfold_3   250.000000   150.000000   73.000000   36.000000  \n",
       "precision_kfold_4        0.597403     0.595041    0.462963    0.315789  \n",
       "recall_kfold_4           0.084923     0.068053    0.041051    0.019355  \n",
       "rocScore_kfold_4         0.883365     0.889854    0.899402    0.899105  \n",
       "accuracy_kfold_4         0.082914     0.054314    0.032168    0.016635  \n",
       "realCount_kfold_4     1625.000000  1058.000000  609.000000  310.000000  \n",
       "predictCount_kfold_4   231.000000   121.000000   54.000000   19.000000  \n",
       "precision_kfold_5        0.523810     0.541935    0.456790    0.375000  \n",
       "recall_kfold_5           0.081231     0.079395    0.060855    0.039344  \n",
       "rocScore_kfold_5         0.890295     0.894963    0.894097    0.904397  \n",
       "accuracy_kfold_5         0.084632     0.054830    0.032268    0.016423  \n",
       "realCount_kfold_5     1625.000000  1058.000000  608.000000  305.000000  \n",
       "predictCount_kfold_5   252.000000   155.000000   81.000000   32.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dynamic thresholded by median intensity, non continuous removed\n",
    "threshold_metrics_df = np.transpose(pd.DataFrame(metricdict))\n",
    "threshold_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_kfold_1</th>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.842703</td>\n",
       "      <td>0.825995</td>\n",
       "      <td>0.739386</td>\n",
       "      <td>0.673684</td>\n",
       "      <td>0.629281</td>\n",
       "      <td>0.606665</td>\n",
       "      <td>0.593997</td>\n",
       "      <td>0.559094</td>\n",
       "      <td>0.580899</td>\n",
       "      <td>0.574503</td>\n",
       "      <td>0.577215</td>\n",
       "      <td>0.538153</td>\n",
       "      <td>0.496403</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.419355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_1</th>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.621526</td>\n",
       "      <td>0.677300</td>\n",
       "      <td>0.621960</td>\n",
       "      <td>0.515406</td>\n",
       "      <td>0.395374</td>\n",
       "      <td>0.355215</td>\n",
       "      <td>0.294902</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.143571</td>\n",
       "      <td>0.116560</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.082360</td>\n",
       "      <td>0.065652</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.042208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_1</th>\n",
       "      <td>0.960211</td>\n",
       "      <td>0.948306</td>\n",
       "      <td>0.928030</td>\n",
       "      <td>0.875945</td>\n",
       "      <td>0.814299</td>\n",
       "      <td>0.774119</td>\n",
       "      <td>0.766362</td>\n",
       "      <td>0.794459</td>\n",
       "      <td>0.807318</td>\n",
       "      <td>0.841539</td>\n",
       "      <td>0.869358</td>\n",
       "      <td>0.885205</td>\n",
       "      <td>0.892353</td>\n",
       "      <td>0.893879</td>\n",
       "      <td>0.901516</td>\n",
       "      <td>0.896860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_1</th>\n",
       "      <td>0.040560</td>\n",
       "      <td>0.060143</td>\n",
       "      <td>0.100971</td>\n",
       "      <td>0.168679</td>\n",
       "      <td>0.225012</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>0.257471</td>\n",
       "      <td>0.248082</td>\n",
       "      <td>0.225710</td>\n",
       "      <td>0.185471</td>\n",
       "      <td>0.154890</td>\n",
       "      <td>0.120178</td>\n",
       "      <td>0.086271</td>\n",
       "      <td>0.056441</td>\n",
       "      <td>0.032942</td>\n",
       "      <td>0.016793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_1</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2267.000000</td>\n",
       "      <td>4044.000000</td>\n",
       "      <td>5264.000000</td>\n",
       "      <td>5712.000000</td>\n",
       "      <td>5577.000000</td>\n",
       "      <td>5484.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>4400.000000</td>\n",
       "      <td>3601.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2301.000000</td>\n",
       "      <td>1627.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_1</th>\n",
       "      <td>356.000000</td>\n",
       "      <td>1672.000000</td>\n",
       "      <td>3316.000000</td>\n",
       "      <td>4428.000000</td>\n",
       "      <td>4370.000000</td>\n",
       "      <td>3504.000000</td>\n",
       "      <td>3211.000000</td>\n",
       "      <td>2532.000000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_2</th>\n",
       "      <td>0.768546</td>\n",
       "      <td>0.830489</td>\n",
       "      <td>0.824186</td>\n",
       "      <td>0.748571</td>\n",
       "      <td>0.680074</td>\n",
       "      <td>0.616233</td>\n",
       "      <td>0.592661</td>\n",
       "      <td>0.600078</td>\n",
       "      <td>0.554493</td>\n",
       "      <td>0.579429</td>\n",
       "      <td>0.602369</td>\n",
       "      <td>0.622685</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.601307</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_2</th>\n",
       "      <td>0.274364</td>\n",
       "      <td>0.643739</td>\n",
       "      <td>0.694362</td>\n",
       "      <td>0.622032</td>\n",
       "      <td>0.511990</td>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.353456</td>\n",
       "      <td>0.302216</td>\n",
       "      <td>0.197727</td>\n",
       "      <td>0.140833</td>\n",
       "      <td>0.119583</td>\n",
       "      <td>0.115699</td>\n",
       "      <td>0.098341</td>\n",
       "      <td>0.087536</td>\n",
       "      <td>0.067434</td>\n",
       "      <td>0.035599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_2</th>\n",
       "      <td>0.961874</td>\n",
       "      <td>0.951757</td>\n",
       "      <td>0.931761</td>\n",
       "      <td>0.882484</td>\n",
       "      <td>0.819973</td>\n",
       "      <td>0.772229</td>\n",
       "      <td>0.766034</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>0.808856</td>\n",
       "      <td>0.840379</td>\n",
       "      <td>0.869875</td>\n",
       "      <td>0.882259</td>\n",
       "      <td>0.888263</td>\n",
       "      <td>0.896851</td>\n",
       "      <td>0.903893</td>\n",
       "      <td>0.903724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_2</th>\n",
       "      <td>0.040885</td>\n",
       "      <td>0.059265</td>\n",
       "      <td>0.098328</td>\n",
       "      <td>0.165577</td>\n",
       "      <td>0.223127</td>\n",
       "      <td>0.254796</td>\n",
       "      <td>0.261333</td>\n",
       "      <td>0.245686</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>0.185457</td>\n",
       "      <td>0.153038</td>\n",
       "      <td>0.118905</td>\n",
       "      <td>0.083967</td>\n",
       "      <td>0.054657</td>\n",
       "      <td>0.032204</td>\n",
       "      <td>0.017094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_2</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>4044.000000</td>\n",
       "      <td>5265.000000</td>\n",
       "      <td>5713.000000</td>\n",
       "      <td>5577.000000</td>\n",
       "      <td>5483.000000</td>\n",
       "      <td>5099.000000</td>\n",
       "      <td>4400.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>1627.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_2</th>\n",
       "      <td>337.000000</td>\n",
       "      <td>1758.000000</td>\n",
       "      <td>3407.000000</td>\n",
       "      <td>4375.000000</td>\n",
       "      <td>4301.000000</td>\n",
       "      <td>3536.000000</td>\n",
       "      <td>3270.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>1569.000000</td>\n",
       "      <td>875.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_3</th>\n",
       "      <td>0.788177</td>\n",
       "      <td>0.834352</td>\n",
       "      <td>0.825872</td>\n",
       "      <td>0.748072</td>\n",
       "      <td>0.690233</td>\n",
       "      <td>0.615558</td>\n",
       "      <td>0.595764</td>\n",
       "      <td>0.577363</td>\n",
       "      <td>0.561702</td>\n",
       "      <td>0.583790</td>\n",
       "      <td>0.620339</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.551867</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_3</th>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.662109</td>\n",
       "      <td>0.702522</td>\n",
       "      <td>0.607977</td>\n",
       "      <td>0.497374</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.364217</td>\n",
       "      <td>0.297117</td>\n",
       "      <td>0.209952</td>\n",
       "      <td>0.148056</td>\n",
       "      <td>0.122943</td>\n",
       "      <td>0.104257</td>\n",
       "      <td>0.081796</td>\n",
       "      <td>0.070962</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>0.032468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_3</th>\n",
       "      <td>0.964252</td>\n",
       "      <td>0.956244</td>\n",
       "      <td>0.936196</td>\n",
       "      <td>0.880218</td>\n",
       "      <td>0.822757</td>\n",
       "      <td>0.772768</td>\n",
       "      <td>0.766596</td>\n",
       "      <td>0.793086</td>\n",
       "      <td>0.813861</td>\n",
       "      <td>0.843355</td>\n",
       "      <td>0.868092</td>\n",
       "      <td>0.882087</td>\n",
       "      <td>0.884501</td>\n",
       "      <td>0.895517</td>\n",
       "      <td>0.899745</td>\n",
       "      <td>0.895909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_3</th>\n",
       "      <td>0.038060</td>\n",
       "      <td>0.057036</td>\n",
       "      <td>0.096596</td>\n",
       "      <td>0.168427</td>\n",
       "      <td>0.222246</td>\n",
       "      <td>0.254999</td>\n",
       "      <td>0.259501</td>\n",
       "      <td>0.251568</td>\n",
       "      <td>0.225034</td>\n",
       "      <td>0.184776</td>\n",
       "      <td>0.151970</td>\n",
       "      <td>0.118896</td>\n",
       "      <td>0.085821</td>\n",
       "      <td>0.057089</td>\n",
       "      <td>0.033181</td>\n",
       "      <td>0.016886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_3</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2267.000000</td>\n",
       "      <td>4044.000000</td>\n",
       "      <td>5265.000000</td>\n",
       "      <td>5712.000000</td>\n",
       "      <td>5577.000000</td>\n",
       "      <td>5483.000000</td>\n",
       "      <td>5099.000000</td>\n",
       "      <td>4401.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2302.000000</td>\n",
       "      <td>1626.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_3</th>\n",
       "      <td>406.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>3440.000000</td>\n",
       "      <td>4279.000000</td>\n",
       "      <td>4116.000000</td>\n",
       "      <td>3548.000000</td>\n",
       "      <td>3352.000000</td>\n",
       "      <td>2624.000000</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>913.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_4</th>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.844178</td>\n",
       "      <td>0.822548</td>\n",
       "      <td>0.750751</td>\n",
       "      <td>0.685238</td>\n",
       "      <td>0.625701</td>\n",
       "      <td>0.596305</td>\n",
       "      <td>0.587369</td>\n",
       "      <td>0.573935</td>\n",
       "      <td>0.538546</td>\n",
       "      <td>0.537671</td>\n",
       "      <td>0.611675</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_4</th>\n",
       "      <td>0.283598</td>\n",
       "      <td>0.652116</td>\n",
       "      <td>0.694781</td>\n",
       "      <td>0.617401</td>\n",
       "      <td>0.503763</td>\n",
       "      <td>0.399857</td>\n",
       "      <td>0.359044</td>\n",
       "      <td>0.297255</td>\n",
       "      <td>0.208182</td>\n",
       "      <td>0.135833</td>\n",
       "      <td>0.105475</td>\n",
       "      <td>0.104737</td>\n",
       "      <td>0.094653</td>\n",
       "      <td>0.084601</td>\n",
       "      <td>0.055829</td>\n",
       "      <td>0.029221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_4</th>\n",
       "      <td>0.957629</td>\n",
       "      <td>0.950741</td>\n",
       "      <td>0.930607</td>\n",
       "      <td>0.879760</td>\n",
       "      <td>0.819754</td>\n",
       "      <td>0.775301</td>\n",
       "      <td>0.766452</td>\n",
       "      <td>0.786799</td>\n",
       "      <td>0.810699</td>\n",
       "      <td>0.838891</td>\n",
       "      <td>0.867590</td>\n",
       "      <td>0.887030</td>\n",
       "      <td>0.898012</td>\n",
       "      <td>0.900344</td>\n",
       "      <td>0.906406</td>\n",
       "      <td>0.897369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_4</th>\n",
       "      <td>0.039867</td>\n",
       "      <td>0.056983</td>\n",
       "      <td>0.098728</td>\n",
       "      <td>0.165960</td>\n",
       "      <td>0.223051</td>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.260128</td>\n",
       "      <td>0.249450</td>\n",
       "      <td>0.223427</td>\n",
       "      <td>0.189408</td>\n",
       "      <td>0.157375</td>\n",
       "      <td>0.118742</td>\n",
       "      <td>0.084187</td>\n",
       "      <td>0.054515</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>0.016848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_4</th>\n",
       "      <td>945.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>4043.000000</td>\n",
       "      <td>5264.000000</td>\n",
       "      <td>5713.000000</td>\n",
       "      <td>5577.000000</td>\n",
       "      <td>5484.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>4400.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2301.000000</td>\n",
       "      <td>1627.000000</td>\n",
       "      <td>1052.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_4</th>\n",
       "      <td>334.000000</td>\n",
       "      <td>1752.000000</td>\n",
       "      <td>3415.000000</td>\n",
       "      <td>4329.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>3564.000000</td>\n",
       "      <td>3302.000000</td>\n",
       "      <td>2581.000000</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>908.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_5</th>\n",
       "      <td>0.781538</td>\n",
       "      <td>0.842710</td>\n",
       "      <td>0.823687</td>\n",
       "      <td>0.752289</td>\n",
       "      <td>0.688331</td>\n",
       "      <td>0.611596</td>\n",
       "      <td>0.594659</td>\n",
       "      <td>0.598697</td>\n",
       "      <td>0.568096</td>\n",
       "      <td>0.539560</td>\n",
       "      <td>0.584843</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_5</th>\n",
       "      <td>0.269068</td>\n",
       "      <td>0.647266</td>\n",
       "      <td>0.682740</td>\n",
       "      <td>0.624240</td>\n",
       "      <td>0.498687</td>\n",
       "      <td>0.389566</td>\n",
       "      <td>0.361415</td>\n",
       "      <td>0.306335</td>\n",
       "      <td>0.204726</td>\n",
       "      <td>0.136351</td>\n",
       "      <td>0.119248</td>\n",
       "      <td>0.105606</td>\n",
       "      <td>0.094653</td>\n",
       "      <td>0.078631</td>\n",
       "      <td>0.055016</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_5</th>\n",
       "      <td>0.959203</td>\n",
       "      <td>0.954712</td>\n",
       "      <td>0.928747</td>\n",
       "      <td>0.881214</td>\n",
       "      <td>0.820166</td>\n",
       "      <td>0.768661</td>\n",
       "      <td>0.765291</td>\n",
       "      <td>0.796087</td>\n",
       "      <td>0.813583</td>\n",
       "      <td>0.839698</td>\n",
       "      <td>0.869460</td>\n",
       "      <td>0.884460</td>\n",
       "      <td>0.893886</td>\n",
       "      <td>0.898296</td>\n",
       "      <td>0.902544</td>\n",
       "      <td>0.903734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_5</th>\n",
       "      <td>0.040741</td>\n",
       "      <td>0.057498</td>\n",
       "      <td>0.100327</td>\n",
       "      <td>0.163820</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>0.256170</td>\n",
       "      <td>0.259810</td>\n",
       "      <td>0.245409</td>\n",
       "      <td>0.224048</td>\n",
       "      <td>0.188929</td>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.117940</td>\n",
       "      <td>0.083998</td>\n",
       "      <td>0.056748</td>\n",
       "      <td>0.033460</td>\n",
       "      <td>0.017132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_5</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>4044.000000</td>\n",
       "      <td>5264.000000</td>\n",
       "      <td>5713.000000</td>\n",
       "      <td>5578.000000</td>\n",
       "      <td>5484.000000</td>\n",
       "      <td>5099.000000</td>\n",
       "      <td>4401.000000</td>\n",
       "      <td>3601.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2301.000000</td>\n",
       "      <td>1627.000000</td>\n",
       "      <td>1081.000000</td>\n",
       "      <td>618.000000</td>\n",
       "      <td>308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_5</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>1742.000000</td>\n",
       "      <td>3352.000000</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>4139.000000</td>\n",
       "      <td>3553.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>2609.000000</td>\n",
       "      <td>1586.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0            1            2            3  \\\n",
       "precision_kfold_1       0.764045     0.842703     0.825995     0.739386   \n",
       "recall_kfold_1          0.288136     0.621526     0.677300     0.621960   \n",
       "rocScore_kfold_1        0.960211     0.948306     0.928030     0.875945   \n",
       "accuracy_kfold_1        0.040560     0.060143     0.100971     0.168679   \n",
       "realCount_kfold_1     944.000000  2267.000000  4044.000000  5264.000000   \n",
       "predictCount_kfold_1  356.000000  1672.000000  3316.000000  4428.000000   \n",
       "precision_kfold_2       0.768546     0.830489     0.824186     0.748571   \n",
       "recall_kfold_2          0.274364     0.643739     0.694362     0.622032   \n",
       "rocScore_kfold_2        0.961874     0.951757     0.931761     0.882484   \n",
       "accuracy_kfold_2        0.040885     0.059265     0.098328     0.165577   \n",
       "realCount_kfold_2     944.000000  2268.000000  4044.000000  5265.000000   \n",
       "predictCount_kfold_2  337.000000  1758.000000  3407.000000  4375.000000   \n",
       "precision_kfold_3       0.788177     0.834352     0.825872     0.748072   \n",
       "recall_kfold_3          0.338983     0.662109     0.702522     0.607977   \n",
       "rocScore_kfold_3        0.964252     0.956244     0.936196     0.880218   \n",
       "accuracy_kfold_3        0.038060     0.057036     0.096596     0.168427   \n",
       "realCount_kfold_3     944.000000  2267.000000  4044.000000  5265.000000   \n",
       "predictCount_kfold_3  406.000000  1799.000000  3440.000000  4279.000000   \n",
       "precision_kfold_4       0.802395     0.844178     0.822548     0.750751   \n",
       "recall_kfold_4          0.283598     0.652116     0.694781     0.617401   \n",
       "rocScore_kfold_4        0.957629     0.950741     0.930607     0.879760   \n",
       "accuracy_kfold_4        0.039867     0.056983     0.098728     0.165960   \n",
       "realCount_kfold_4     945.000000  2268.000000  4043.000000  5264.000000   \n",
       "predictCount_kfold_4  334.000000  1752.000000  3415.000000  4329.000000   \n",
       "precision_kfold_5       0.781538     0.842710     0.823687     0.752289   \n",
       "recall_kfold_5          0.269068     0.647266     0.682740     0.624240   \n",
       "rocScore_kfold_5        0.959203     0.954712     0.928747     0.881214   \n",
       "accuracy_kfold_5        0.040741     0.057498     0.100327     0.163820   \n",
       "realCount_kfold_5     944.000000  2268.000000  4044.000000  5264.000000   \n",
       "predictCount_kfold_5  325.000000  1742.000000  3352.000000  4368.000000   \n",
       "\n",
       "                                4            5            6            7  \\\n",
       "precision_kfold_1        0.673684     0.629281     0.606665     0.593997   \n",
       "recall_kfold_1           0.515406     0.395374     0.355215     0.294902   \n",
       "rocScore_kfold_1         0.814299     0.774119     0.766362     0.794459   \n",
       "accuracy_kfold_1         0.225012     0.250604     0.257471     0.248082   \n",
       "realCount_kfold_1     5712.000000  5577.000000  5484.000000  5100.000000   \n",
       "predictCount_kfold_1  4370.000000  3504.000000  3211.000000  2532.000000   \n",
       "precision_kfold_2        0.680074     0.616233     0.592661     0.600078   \n",
       "recall_kfold_2           0.511990     0.390712     0.353456     0.302216   \n",
       "rocScore_kfold_2         0.819973     0.772229     0.766034     0.794100   \n",
       "accuracy_kfold_2         0.223127     0.254796     0.261333     0.245686   \n",
       "realCount_kfold_2     5713.000000  5577.000000  5483.000000  5099.000000   \n",
       "predictCount_kfold_2  4301.000000  3536.000000  3270.000000  2568.000000   \n",
       "precision_kfold_3        0.690233     0.615558     0.595764     0.577363   \n",
       "recall_kfold_3           0.497374     0.391608     0.364217     0.297117   \n",
       "rocScore_kfold_3         0.822757     0.772768     0.766596     0.793086   \n",
       "accuracy_kfold_3         0.222246     0.254999     0.259501     0.251568   \n",
       "realCount_kfold_3     5712.000000  5577.000000  5483.000000  5099.000000   \n",
       "predictCount_kfold_3  4116.000000  3548.000000  3352.000000  2624.000000   \n",
       "precision_kfold_4        0.685238     0.625701     0.596305     0.587369   \n",
       "recall_kfold_4           0.503763     0.399857     0.359044     0.297255   \n",
       "rocScore_kfold_4         0.819754     0.775301     0.766452     0.786799   \n",
       "accuracy_kfold_4         0.223051     0.251167     0.260128     0.249450   \n",
       "realCount_kfold_4     5713.000000  5577.000000  5484.000000  5100.000000   \n",
       "predictCount_kfold_4  4200.000000  3564.000000  3302.000000  2581.000000   \n",
       "precision_kfold_5        0.688331     0.611596     0.594659     0.598697   \n",
       "recall_kfold_5           0.498687     0.389566     0.361415     0.306335   \n",
       "rocScore_kfold_5         0.820166     0.768661     0.765291     0.796087   \n",
       "accuracy_kfold_5         0.222389     0.256170     0.259810     0.245409   \n",
       "realCount_kfold_5     5713.000000  5578.000000  5484.000000  5099.000000   \n",
       "predictCount_kfold_5  4139.000000  3553.000000  3333.000000  2609.000000   \n",
       "\n",
       "                                8            9           10           11  \\\n",
       "precision_kfold_1        0.559094     0.580899     0.574503     0.577215   \n",
       "recall_kfold_1           0.207500     0.143571     0.116560     0.099087   \n",
       "rocScore_kfold_1         0.807318     0.841539     0.869358     0.885205   \n",
       "accuracy_kfold_1         0.225710     0.185471     0.154890     0.120178   \n",
       "realCount_kfold_1     4400.000000  3601.000000  2977.000000  2301.000000   \n",
       "predictCount_kfold_1  1633.000000   890.000000   604.000000   395.000000   \n",
       "precision_kfold_2        0.554493     0.579429     0.602369     0.622685   \n",
       "recall_kfold_2           0.197727     0.140833     0.119583     0.115699   \n",
       "rocScore_kfold_2         0.808856     0.840379     0.869875     0.882259   \n",
       "accuracy_kfold_2         0.226610     0.185457     0.153038     0.118905   \n",
       "realCount_kfold_2     4400.000000  3600.000000  2977.000000  2325.000000   \n",
       "predictCount_kfold_2  1569.000000   875.000000   591.000000   432.000000   \n",
       "precision_kfold_3        0.561702     0.583790     0.620339     0.606061   \n",
       "recall_kfold_3           0.209952     0.148056     0.122943     0.104257   \n",
       "rocScore_kfold_3         0.813861     0.843355     0.868092     0.882087   \n",
       "accuracy_kfold_3         0.225034     0.184776     0.151970     0.118896   \n",
       "realCount_kfold_3     4401.000000  3600.000000  2977.000000  2302.000000   \n",
       "predictCount_kfold_3  1645.000000   913.000000   590.000000   396.000000   \n",
       "precision_kfold_4        0.573935     0.538546     0.537671     0.611675   \n",
       "recall_kfold_4           0.208182     0.135833     0.105475     0.104737   \n",
       "rocScore_kfold_4         0.810699     0.838891     0.867590     0.887030   \n",
       "accuracy_kfold_4         0.223427     0.189408     0.157375     0.118742   \n",
       "realCount_kfold_4     4400.000000  3600.000000  2977.000000  2301.000000   \n",
       "predictCount_kfold_4  1596.000000   908.000000   584.000000   394.000000   \n",
       "precision_kfold_5        0.568096     0.539560     0.584843     0.626289   \n",
       "recall_kfold_5           0.204726     0.136351     0.119248     0.105606   \n",
       "rocScore_kfold_5         0.813583     0.839698     0.869460     0.884460   \n",
       "accuracy_kfold_5         0.224048     0.188929     0.153863     0.117940   \n",
       "realCount_kfold_5     4401.000000  3601.000000  2977.000000  2301.000000   \n",
       "predictCount_kfold_5  1586.000000   910.000000   607.000000   388.000000   \n",
       "\n",
       "                               12           13          14          15  \n",
       "precision_kfold_1        0.538153     0.496403    0.483871    0.419355  \n",
       "recall_kfold_1           0.082360     0.065652    0.049020    0.042208  \n",
       "rocScore_kfold_1         0.892353     0.893879    0.901516    0.896860  \n",
       "accuracy_kfold_1         0.086271     0.056441    0.032942    0.016793  \n",
       "realCount_kfold_1     1627.000000  1051.000000  612.000000  308.000000  \n",
       "predictCount_kfold_1   249.000000   139.000000   62.000000   31.000000  \n",
       "precision_kfold_2        0.615385     0.601307    0.546667    0.343750  \n",
       "recall_kfold_2           0.098341     0.087536    0.067434    0.035599  \n",
       "rocScore_kfold_2         0.888263     0.896851    0.903893    0.903724  \n",
       "accuracy_kfold_2         0.083967     0.054657    0.032204    0.017094  \n",
       "realCount_kfold_2     1627.000000  1051.000000  608.000000  309.000000  \n",
       "predictCount_kfold_2   260.000000   153.000000   75.000000   32.000000  \n",
       "precision_kfold_3        0.551867     0.520548    0.422535    0.370370  \n",
       "recall_kfold_3           0.081796     0.070962    0.049342    0.032468  \n",
       "rocScore_kfold_3         0.884501     0.895517    0.899745    0.895909  \n",
       "accuracy_kfold_3         0.085821     0.057089    0.033181    0.016886  \n",
       "realCount_kfold_3     1626.000000  1071.000000  608.000000  308.000000  \n",
       "predictCount_kfold_3   241.000000   146.000000   71.000000   27.000000  \n",
       "precision_kfold_4        0.616000     0.626761    0.539683    0.375000  \n",
       "recall_kfold_4           0.094653     0.084601    0.055829    0.029221  \n",
       "rocScore_kfold_4         0.898012     0.900344    0.906406    0.897369  \n",
       "accuracy_kfold_4         0.084187     0.054515    0.032409    0.016848  \n",
       "realCount_kfold_4     1627.000000  1052.000000  609.000000  308.000000  \n",
       "predictCount_kfold_4   250.000000   142.000000   63.000000   24.000000  \n",
       "precision_kfold_5        0.616000     0.570470    0.453333    0.323529  \n",
       "recall_kfold_5           0.094653     0.078631    0.055016    0.035714  \n",
       "rocScore_kfold_5         0.893886     0.898296    0.902544    0.903734  \n",
       "accuracy_kfold_5         0.083998     0.056748    0.033460    0.017132  \n",
       "realCount_kfold_5     1627.000000  1081.000000  618.000000  308.000000  \n",
       "predictCount_kfold_5   250.000000   149.000000   75.000000   34.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dynamic thresholded by median intensity 50%, non continuous removed\n",
    "#threshold50p_metrics_df = np.transpose(pd.DataFrame(metricdict))\n",
    "#threshold50p_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_kfold_1</th>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.812288</td>\n",
       "      <td>0.811523</td>\n",
       "      <td>0.770130</td>\n",
       "      <td>0.739621</td>\n",
       "      <td>0.702652</td>\n",
       "      <td>0.666087</td>\n",
       "      <td>0.645473</td>\n",
       "      <td>0.633572</td>\n",
       "      <td>0.620755</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.634021</td>\n",
       "      <td>0.635071</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_1</th>\n",
       "      <td>0.305533</td>\n",
       "      <td>0.626726</td>\n",
       "      <td>0.719325</td>\n",
       "      <td>0.719638</td>\n",
       "      <td>0.705923</td>\n",
       "      <td>0.672725</td>\n",
       "      <td>0.592512</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>0.331426</td>\n",
       "      <td>0.189680</td>\n",
       "      <td>0.155258</td>\n",
       "      <td>0.113416</td>\n",
       "      <td>0.087070</td>\n",
       "      <td>0.080629</td>\n",
       "      <td>0.064348</td>\n",
       "      <td>0.051903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_1</th>\n",
       "      <td>0.922111</td>\n",
       "      <td>0.930183</td>\n",
       "      <td>0.917246</td>\n",
       "      <td>0.872992</td>\n",
       "      <td>0.822699</td>\n",
       "      <td>0.794601</td>\n",
       "      <td>0.789976</td>\n",
       "      <td>0.810467</td>\n",
       "      <td>0.825525</td>\n",
       "      <td>0.844708</td>\n",
       "      <td>0.870956</td>\n",
       "      <td>0.885811</td>\n",
       "      <td>0.893816</td>\n",
       "      <td>0.905705</td>\n",
       "      <td>0.904170</td>\n",
       "      <td>0.897481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_1</th>\n",
       "      <td>0.061393</td>\n",
       "      <td>0.085384</td>\n",
       "      <td>0.127276</td>\n",
       "      <td>0.195128</td>\n",
       "      <td>0.241757</td>\n",
       "      <td>0.271346</td>\n",
       "      <td>0.280143</td>\n",
       "      <td>0.268885</td>\n",
       "      <td>0.240465</td>\n",
       "      <td>0.197650</td>\n",
       "      <td>0.162032</td>\n",
       "      <td>0.127030</td>\n",
       "      <td>0.091166</td>\n",
       "      <td>0.060531</td>\n",
       "      <td>0.034633</td>\n",
       "      <td>0.017655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_1</th>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2679.000000</td>\n",
       "      <td>4621.000000</td>\n",
       "      <td>6406.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7208.000000</td>\n",
       "      <td>6464.000000</td>\n",
       "      <td>5547.000000</td>\n",
       "      <td>4544.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>2834.000000</td>\n",
       "      <td>2169.000000</td>\n",
       "      <td>1539.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>289.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_1</th>\n",
       "      <td>513.000000</td>\n",
       "      <td>2067.000000</td>\n",
       "      <td>4096.000000</td>\n",
       "      <td>5986.000000</td>\n",
       "      <td>6913.000000</td>\n",
       "      <td>6901.000000</td>\n",
       "      <td>5750.000000</td>\n",
       "      <td>4042.000000</td>\n",
       "      <td>2377.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_2</th>\n",
       "      <td>0.748201</td>\n",
       "      <td>0.818408</td>\n",
       "      <td>0.808925</td>\n",
       "      <td>0.768249</td>\n",
       "      <td>0.738939</td>\n",
       "      <td>0.696892</td>\n",
       "      <td>0.660882</td>\n",
       "      <td>0.651067</td>\n",
       "      <td>0.628727</td>\n",
       "      <td>0.618100</td>\n",
       "      <td>0.655523</td>\n",
       "      <td>0.706186</td>\n",
       "      <td>0.659193</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_2</th>\n",
       "      <td>0.333601</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.710019</td>\n",
       "      <td>0.732636</td>\n",
       "      <td>0.694049</td>\n",
       "      <td>0.681232</td>\n",
       "      <td>0.589109</td>\n",
       "      <td>0.483958</td>\n",
       "      <td>0.329373</td>\n",
       "      <td>0.196830</td>\n",
       "      <td>0.159139</td>\n",
       "      <td>0.125573</td>\n",
       "      <td>0.096711</td>\n",
       "      <td>0.087562</td>\n",
       "      <td>0.066890</td>\n",
       "      <td>0.034602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_2</th>\n",
       "      <td>0.924238</td>\n",
       "      <td>0.930136</td>\n",
       "      <td>0.912625</td>\n",
       "      <td>0.871348</td>\n",
       "      <td>0.819478</td>\n",
       "      <td>0.791762</td>\n",
       "      <td>0.788124</td>\n",
       "      <td>0.815500</td>\n",
       "      <td>0.824755</td>\n",
       "      <td>0.852015</td>\n",
       "      <td>0.874297</td>\n",
       "      <td>0.894025</td>\n",
       "      <td>0.893784</td>\n",
       "      <td>0.897723</td>\n",
       "      <td>0.903848</td>\n",
       "      <td>0.889210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_2</th>\n",
       "      <td>0.059699</td>\n",
       "      <td>0.086013</td>\n",
       "      <td>0.130034</td>\n",
       "      <td>0.192376</td>\n",
       "      <td>0.245435</td>\n",
       "      <td>0.272610</td>\n",
       "      <td>0.283431</td>\n",
       "      <td>0.264494</td>\n",
       "      <td>0.241746</td>\n",
       "      <td>0.197295</td>\n",
       "      <td>0.161082</td>\n",
       "      <td>0.124316</td>\n",
       "      <td>0.089087</td>\n",
       "      <td>0.060068</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.017830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_2</th>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2679.000000</td>\n",
       "      <td>4621.000000</td>\n",
       "      <td>6407.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7209.000000</td>\n",
       "      <td>6464.000000</td>\n",
       "      <td>5548.000000</td>\n",
       "      <td>4545.000000</td>\n",
       "      <td>3470.000000</td>\n",
       "      <td>2834.000000</td>\n",
       "      <td>2182.000000</td>\n",
       "      <td>1520.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>289.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_2</th>\n",
       "      <td>556.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4056.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>6803.000000</td>\n",
       "      <td>7047.000000</td>\n",
       "      <td>5762.000000</td>\n",
       "      <td>4124.000000</td>\n",
       "      <td>2381.000000</td>\n",
       "      <td>1105.000000</td>\n",
       "      <td>688.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_3</th>\n",
       "      <td>0.744954</td>\n",
       "      <td>0.818093</td>\n",
       "      <td>0.817602</td>\n",
       "      <td>0.775579</td>\n",
       "      <td>0.742163</td>\n",
       "      <td>0.704436</td>\n",
       "      <td>0.662232</td>\n",
       "      <td>0.652311</td>\n",
       "      <td>0.633248</td>\n",
       "      <td>0.598010</td>\n",
       "      <td>0.623358</td>\n",
       "      <td>0.603365</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>0.624113</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_3</th>\n",
       "      <td>0.325321</td>\n",
       "      <td>0.627846</td>\n",
       "      <td>0.693723</td>\n",
       "      <td>0.721823</td>\n",
       "      <td>0.696258</td>\n",
       "      <td>0.687431</td>\n",
       "      <td>0.593068</td>\n",
       "      <td>0.485941</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>0.150617</td>\n",
       "      <td>0.115722</td>\n",
       "      <td>0.096711</td>\n",
       "      <td>0.087475</td>\n",
       "      <td>0.067826</td>\n",
       "      <td>0.048443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_3</th>\n",
       "      <td>0.927516</td>\n",
       "      <td>0.927074</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.873873</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.798602</td>\n",
       "      <td>0.787650</td>\n",
       "      <td>0.814339</td>\n",
       "      <td>0.828488</td>\n",
       "      <td>0.847894</td>\n",
       "      <td>0.876558</td>\n",
       "      <td>0.895651</td>\n",
       "      <td>0.906751</td>\n",
       "      <td>0.910114</td>\n",
       "      <td>0.913456</td>\n",
       "      <td>0.909904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_3</th>\n",
       "      <td>0.060447</td>\n",
       "      <td>0.084478</td>\n",
       "      <td>0.131247</td>\n",
       "      <td>0.192248</td>\n",
       "      <td>0.243515</td>\n",
       "      <td>0.266930</td>\n",
       "      <td>0.282519</td>\n",
       "      <td>0.264280</td>\n",
       "      <td>0.241728</td>\n",
       "      <td>0.201614</td>\n",
       "      <td>0.164274</td>\n",
       "      <td>0.128350</td>\n",
       "      <td>0.089469</td>\n",
       "      <td>0.059831</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>0.017684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_3</th>\n",
       "      <td>1248.000000</td>\n",
       "      <td>2679.000000</td>\n",
       "      <td>4620.000000</td>\n",
       "      <td>6406.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7208.000000</td>\n",
       "      <td>6463.000000</td>\n",
       "      <td>5548.000000</td>\n",
       "      <td>4545.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>2835.000000</td>\n",
       "      <td>2169.000000</td>\n",
       "      <td>1520.000000</td>\n",
       "      <td>1006.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>289.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_3</th>\n",
       "      <td>545.000000</td>\n",
       "      <td>2056.000000</td>\n",
       "      <td>3920.000000</td>\n",
       "      <td>5962.000000</td>\n",
       "      <td>6795.000000</td>\n",
       "      <td>7034.000000</td>\n",
       "      <td>5788.000000</td>\n",
       "      <td>4133.000000</td>\n",
       "      <td>2334.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_4</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.816767</td>\n",
       "      <td>0.813012</td>\n",
       "      <td>0.774822</td>\n",
       "      <td>0.747545</td>\n",
       "      <td>0.705217</td>\n",
       "      <td>0.667140</td>\n",
       "      <td>0.652913</td>\n",
       "      <td>0.637280</td>\n",
       "      <td>0.606805</td>\n",
       "      <td>0.654219</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.589928</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_4</th>\n",
       "      <td>0.319968</td>\n",
       "      <td>0.607090</td>\n",
       "      <td>0.708658</td>\n",
       "      <td>0.732126</td>\n",
       "      <td>0.693773</td>\n",
       "      <td>0.675083</td>\n",
       "      <td>0.581154</td>\n",
       "      <td>0.484859</td>\n",
       "      <td>0.334067</td>\n",
       "      <td>0.185068</td>\n",
       "      <td>0.166843</td>\n",
       "      <td>0.119410</td>\n",
       "      <td>0.104516</td>\n",
       "      <td>0.081592</td>\n",
       "      <td>0.060870</td>\n",
       "      <td>0.044983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_4</th>\n",
       "      <td>0.924701</td>\n",
       "      <td>0.928791</td>\n",
       "      <td>0.915065</td>\n",
       "      <td>0.877509</td>\n",
       "      <td>0.824740</td>\n",
       "      <td>0.797300</td>\n",
       "      <td>0.787845</td>\n",
       "      <td>0.810258</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.849533</td>\n",
       "      <td>0.878279</td>\n",
       "      <td>0.890663</td>\n",
       "      <td>0.894982</td>\n",
       "      <td>0.902110</td>\n",
       "      <td>0.908678</td>\n",
       "      <td>0.886916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_4</th>\n",
       "      <td>0.060347</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.129122</td>\n",
       "      <td>0.189407</td>\n",
       "      <td>0.240834</td>\n",
       "      <td>0.269193</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.263780</td>\n",
       "      <td>0.239296</td>\n",
       "      <td>0.199496</td>\n",
       "      <td>0.160679</td>\n",
       "      <td>0.126538</td>\n",
       "      <td>0.090367</td>\n",
       "      <td>0.060285</td>\n",
       "      <td>0.035310</td>\n",
       "      <td>0.018147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_4</th>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>4620.000000</td>\n",
       "      <td>6406.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7208.000000</td>\n",
       "      <td>6463.000000</td>\n",
       "      <td>5548.000000</td>\n",
       "      <td>4544.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>2835.000000</td>\n",
       "      <td>2169.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>289.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_4</th>\n",
       "      <td>532.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>6053.000000</td>\n",
       "      <td>6722.000000</td>\n",
       "      <td>6900.000000</td>\n",
       "      <td>5630.000000</td>\n",
       "      <td>4120.000000</td>\n",
       "      <td>2382.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_5</th>\n",
       "      <td>0.726126</td>\n",
       "      <td>0.829517</td>\n",
       "      <td>0.812307</td>\n",
       "      <td>0.774511</td>\n",
       "      <td>0.740488</td>\n",
       "      <td>0.698145</td>\n",
       "      <td>0.662234</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.626216</td>\n",
       "      <td>0.611546</td>\n",
       "      <td>0.617479</td>\n",
       "      <td>0.625360</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_5</th>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.608436</td>\n",
       "      <td>0.682753</td>\n",
       "      <td>0.723853</td>\n",
       "      <td>0.703990</td>\n",
       "      <td>0.684101</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>0.490355</td>\n",
       "      <td>0.325924</td>\n",
       "      <td>0.180115</td>\n",
       "      <td>0.152082</td>\n",
       "      <td>0.100046</td>\n",
       "      <td>0.080921</td>\n",
       "      <td>0.075416</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.031142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_5</th>\n",
       "      <td>0.918232</td>\n",
       "      <td>0.928359</td>\n",
       "      <td>0.909081</td>\n",
       "      <td>0.875438</td>\n",
       "      <td>0.823645</td>\n",
       "      <td>0.795781</td>\n",
       "      <td>0.787620</td>\n",
       "      <td>0.812009</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.850245</td>\n",
       "      <td>0.882598</td>\n",
       "      <td>0.895062</td>\n",
       "      <td>0.896161</td>\n",
       "      <td>0.899396</td>\n",
       "      <td>0.906636</td>\n",
       "      <td>0.897333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_5</th>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.085164</td>\n",
       "      <td>0.135069</td>\n",
       "      <td>0.191927</td>\n",
       "      <td>0.241893</td>\n",
       "      <td>0.271306</td>\n",
       "      <td>0.280660</td>\n",
       "      <td>0.265276</td>\n",
       "      <td>0.242877</td>\n",
       "      <td>0.199495</td>\n",
       "      <td>0.164298</td>\n",
       "      <td>0.128115</td>\n",
       "      <td>0.091133</td>\n",
       "      <td>0.060735</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>0.017968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_5</th>\n",
       "      <td>1248.000000</td>\n",
       "      <td>2679.000000</td>\n",
       "      <td>4621.000000</td>\n",
       "      <td>6406.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7208.000000</td>\n",
       "      <td>6464.000000</td>\n",
       "      <td>5547.000000</td>\n",
       "      <td>4544.000000</td>\n",
       "      <td>3470.000000</td>\n",
       "      <td>2834.000000</td>\n",
       "      <td>2169.000000</td>\n",
       "      <td>1520.000000</td>\n",
       "      <td>1021.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>289.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_5</th>\n",
       "      <td>555.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>3884.000000</td>\n",
       "      <td>5987.000000</td>\n",
       "      <td>6886.000000</td>\n",
       "      <td>7063.000000</td>\n",
       "      <td>5865.000000</td>\n",
       "      <td>4204.000000</td>\n",
       "      <td>2365.000000</td>\n",
       "      <td>1022.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0            1            2            3  \\\n",
       "precision_kfold_1        0.742690     0.812288     0.811523     0.770130   \n",
       "recall_kfold_1           0.305533     0.626726     0.719325     0.719638   \n",
       "rocScore_kfold_1         0.922111     0.930183     0.917246     0.872992   \n",
       "accuracy_kfold_1         0.061393     0.085384     0.127276     0.195128   \n",
       "realCount_kfold_1     1247.000000  2679.000000  4621.000000  6406.000000   \n",
       "predictCount_kfold_1   513.000000  2067.000000  4096.000000  5986.000000   \n",
       "precision_kfold_2        0.748201     0.818408     0.808925     0.768249   \n",
       "recall_kfold_2           0.333601     0.614035     0.710019     0.732636   \n",
       "rocScore_kfold_2         0.924238     0.930136     0.912625     0.871348   \n",
       "accuracy_kfold_2         0.059699     0.086013     0.130034     0.192376   \n",
       "realCount_kfold_2     1247.000000  2679.000000  4621.000000  6407.000000   \n",
       "predictCount_kfold_2   556.000000  2010.000000  4056.000000  6110.000000   \n",
       "precision_kfold_3        0.744954     0.818093     0.817602     0.775579   \n",
       "recall_kfold_3           0.325321     0.627846     0.693723     0.721823   \n",
       "rocScore_kfold_3         0.927516     0.927074     0.908898     0.873873   \n",
       "accuracy_kfold_3         0.060447     0.084478     0.131247     0.192248   \n",
       "realCount_kfold_3     1248.000000  2679.000000  4620.000000  6406.000000   \n",
       "predictCount_kfold_3   545.000000  2056.000000  3920.000000  5962.000000   \n",
       "precision_kfold_4        0.750000     0.816767     0.813012     0.774822   \n",
       "recall_kfold_4           0.319968     0.607090     0.708658     0.732126   \n",
       "rocScore_kfold_4         0.924701     0.928791     0.915065     0.877509   \n",
       "accuracy_kfold_4         0.060347     0.087229     0.129122     0.189407   \n",
       "realCount_kfold_4     1247.000000  2680.000000  4620.000000  6406.000000   \n",
       "predictCount_kfold_4   532.000000  1992.000000  4027.000000  6053.000000   \n",
       "precision_kfold_5        0.726126     0.829517     0.812307     0.774511   \n",
       "recall_kfold_5           0.322917     0.608436     0.682753     0.723853   \n",
       "rocScore_kfold_5         0.918232     0.928359     0.909081     0.875438   \n",
       "accuracy_kfold_5         0.061350     0.085164     0.135069     0.191927   \n",
       "realCount_kfold_5     1248.000000  2679.000000  4621.000000  6406.000000   \n",
       "predictCount_kfold_5   555.000000  1965.000000  3884.000000  5987.000000   \n",
       "\n",
       "                                4            5            6            7  \\\n",
       "precision_kfold_1        0.739621     0.702652     0.666087     0.645473   \n",
       "recall_kfold_1           0.705923     0.672725     0.592512     0.470344   \n",
       "rocScore_kfold_1         0.822699     0.794601     0.789976     0.810467   \n",
       "accuracy_kfold_1         0.241757     0.271346     0.280143     0.268885   \n",
       "realCount_kfold_1     7243.000000  7208.000000  6464.000000  5547.000000   \n",
       "predictCount_kfold_1  6913.000000  6901.000000  5750.000000  4042.000000   \n",
       "precision_kfold_2        0.738939     0.696892     0.660882     0.651067   \n",
       "recall_kfold_2           0.694049     0.681232     0.589109     0.483958   \n",
       "rocScore_kfold_2         0.819478     0.791762     0.788124     0.815500   \n",
       "accuracy_kfold_2         0.245435     0.272610     0.283431     0.264494   \n",
       "realCount_kfold_2     7243.000000  7209.000000  6464.000000  5548.000000   \n",
       "predictCount_kfold_2  6803.000000  7047.000000  5762.000000  4124.000000   \n",
       "precision_kfold_3        0.742163     0.704436     0.662232     0.652311   \n",
       "recall_kfold_3           0.696258     0.687431     0.593068     0.485941   \n",
       "rocScore_kfold_3         0.820020     0.798602     0.787650     0.814339   \n",
       "accuracy_kfold_3         0.243515     0.266930     0.282519     0.264280   \n",
       "realCount_kfold_3     7243.000000  7208.000000  6463.000000  5548.000000   \n",
       "predictCount_kfold_3  6795.000000  7034.000000  5788.000000  4133.000000   \n",
       "precision_kfold_4        0.747545     0.705217     0.667140     0.652913   \n",
       "recall_kfold_4           0.693773     0.675083     0.581154     0.484859   \n",
       "rocScore_kfold_4         0.824740     0.797300     0.787845     0.810258   \n",
       "accuracy_kfold_4         0.240834     0.269193     0.281804     0.263780   \n",
       "realCount_kfold_4     7243.000000  7208.000000  6463.000000  5548.000000   \n",
       "predictCount_kfold_4  6722.000000  6900.000000  5630.000000  4120.000000   \n",
       "precision_kfold_5        0.740488     0.698145     0.662234     0.647003   \n",
       "recall_kfold_5           0.703990     0.684101     0.600866     0.490355   \n",
       "rocScore_kfold_5         0.823645     0.795781     0.787620     0.812009   \n",
       "accuracy_kfold_5         0.241893     0.271306     0.280660     0.265276   \n",
       "realCount_kfold_5     7243.000000  7208.000000  6464.000000  5547.000000   \n",
       "predictCount_kfold_5  6886.000000  7063.000000  5865.000000  4204.000000   \n",
       "\n",
       "                                8            9           10           11  \\\n",
       "precision_kfold_1        0.633572     0.620755     0.647059     0.634021   \n",
       "recall_kfold_1           0.331426     0.189680     0.155258     0.113416   \n",
       "rocScore_kfold_1         0.825525     0.844708     0.870956     0.885811   \n",
       "accuracy_kfold_1         0.240465     0.197650     0.162032     0.127030   \n",
       "realCount_kfold_1     4544.000000  3469.000000  2834.000000  2169.000000   \n",
       "predictCount_kfold_1  2377.000000  1060.000000   680.000000   388.000000   \n",
       "precision_kfold_2        0.628727     0.618100     0.655523     0.706186   \n",
       "recall_kfold_2           0.329373     0.196830     0.159139     0.125573   \n",
       "rocScore_kfold_2         0.824755     0.852015     0.874297     0.894025   \n",
       "accuracy_kfold_2         0.241746     0.197295     0.161082     0.124316   \n",
       "realCount_kfold_2     4545.000000  3470.000000  2834.000000  2182.000000   \n",
       "predictCount_kfold_2  2381.000000  1105.000000   688.000000   388.000000   \n",
       "precision_kfold_3        0.633248     0.598010     0.623358     0.603365   \n",
       "recall_kfold_3           0.325193     0.173249     0.150617     0.115722   \n",
       "rocScore_kfold_3         0.828488     0.847894     0.876558     0.895651   \n",
       "accuracy_kfold_3         0.241728     0.201614     0.164274     0.128350   \n",
       "realCount_kfold_3     4545.000000  3469.000000  2835.000000  2169.000000   \n",
       "predictCount_kfold_3  2334.000000  1005.000000   685.000000   416.000000   \n",
       "precision_kfold_4        0.637280     0.606805     0.654219     0.637931   \n",
       "recall_kfold_4           0.334067     0.185068     0.166843     0.119410   \n",
       "rocScore_kfold_4         0.831514     0.849533     0.878279     0.890663   \n",
       "accuracy_kfold_4         0.239296     0.199496     0.160679     0.126538   \n",
       "realCount_kfold_4     4544.000000  3469.000000  2835.000000  2169.000000   \n",
       "predictCount_kfold_4  2382.000000  1058.000000   723.000000   406.000000   \n",
       "precision_kfold_5        0.626216     0.611546     0.617479     0.625360   \n",
       "recall_kfold_5           0.325924     0.180115     0.152082     0.100046   \n",
       "rocScore_kfold_5         0.826907     0.850245     0.882598     0.895062   \n",
       "accuracy_kfold_5         0.242877     0.199495     0.164298     0.128115   \n",
       "realCount_kfold_5     4544.000000  3470.000000  2834.000000  2169.000000   \n",
       "predictCount_kfold_5  2365.000000  1022.000000   698.000000   347.000000   \n",
       "\n",
       "                               12           13          14          15  \n",
       "precision_kfold_1        0.635071     0.625954    0.596774    0.535714  \n",
       "recall_kfold_1           0.087070     0.080629    0.064348    0.051903  \n",
       "rocScore_kfold_1         0.893816     0.905705    0.904170    0.897481  \n",
       "accuracy_kfold_1         0.091166     0.060531    0.034633    0.017655  \n",
       "realCount_kfold_1     1539.000000  1017.000000  575.000000  289.000000  \n",
       "predictCount_kfold_1   211.000000   131.000000   62.000000   28.000000  \n",
       "precision_kfold_2        0.659193     0.594595    0.606061    0.476190  \n",
       "recall_kfold_2           0.096711     0.087562    0.066890    0.034602  \n",
       "rocScore_kfold_2         0.893784     0.897723    0.903848    0.889210  \n",
       "accuracy_kfold_2         0.089087     0.060068    0.035905    0.017830  \n",
       "realCount_kfold_2     1520.000000  1005.000000  598.000000  289.000000  \n",
       "predictCount_kfold_2   223.000000   148.000000   66.000000   21.000000  \n",
       "precision_kfold_3        0.650442     0.624113    0.650000    0.538462  \n",
       "recall_kfold_3           0.096711     0.087475    0.067826    0.048443  \n",
       "rocScore_kfold_3         0.906751     0.910114    0.913456    0.909904  \n",
       "accuracy_kfold_3         0.089469     0.059831    0.034321    0.017684  \n",
       "realCount_kfold_3     1520.000000  1006.000000  575.000000  289.000000  \n",
       "predictCount_kfold_3   226.000000   141.000000   60.000000   26.000000  \n",
       "precision_kfold_4        0.666667     0.589928    0.507246    0.406250  \n",
       "recall_kfold_4           0.104516     0.081592    0.060870    0.044983  \n",
       "rocScore_kfold_4         0.894982     0.902110    0.908678    0.886916  \n",
       "accuracy_kfold_4         0.090367     0.060285    0.035310    0.018147  \n",
       "realCount_kfold_4     1550.000000  1005.000000  575.000000  289.000000  \n",
       "predictCount_kfold_4   243.000000   139.000000   69.000000   32.000000  \n",
       "precision_kfold_5        0.594203     0.641667    0.468085    0.428571  \n",
       "recall_kfold_5           0.080921     0.075416    0.037736    0.031142  \n",
       "rocScore_kfold_5         0.896161     0.899396    0.906636    0.897333  \n",
       "accuracy_kfold_5         0.091133     0.060735    0.036059    0.017968  \n",
       "realCount_kfold_5     1520.000000  1021.000000  583.000000  289.000000  \n",
       "predictCount_kfold_5   207.000000   120.000000   47.000000   21.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Static greater than zero intensity threshold, all continuous\n",
    "#anyintensity_metrics_df = np.transpose(pd.DataFrame(metricdict))\n",
    "anyintensity_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_kfold_1</th>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.844610</td>\n",
       "      <td>0.812685</td>\n",
       "      <td>0.748709</td>\n",
       "      <td>0.737525</td>\n",
       "      <td>0.703887</td>\n",
       "      <td>0.673339</td>\n",
       "      <td>0.660547</td>\n",
       "      <td>0.627772</td>\n",
       "      <td>0.625905</td>\n",
       "      <td>0.631367</td>\n",
       "      <td>0.598063</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.650630</td>\n",
       "      <td>0.684688</td>\n",
       "      <td>0.540373</td>\n",
       "      <td>0.690521</td>\n",
       "      <td>0.695067</td>\n",
       "      <td>0.627148</td>\n",
       "      <td>0.524318</td>\n",
       "      <td>0.358373</td>\n",
       "      <td>0.212743</td>\n",
       "      <td>0.159014</td>\n",
       "      <td>0.109583</td>\n",
       "      <td>0.091545</td>\n",
       "      <td>0.079922</td>\n",
       "      <td>0.069257</td>\n",
       "      <td>0.044118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_1</th>\n",
       "      <td>0.968211</td>\n",
       "      <td>0.958130</td>\n",
       "      <td>0.935129</td>\n",
       "      <td>0.880205</td>\n",
       "      <td>0.819733</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.793618</td>\n",
       "      <td>0.815184</td>\n",
       "      <td>0.822094</td>\n",
       "      <td>0.849650</td>\n",
       "      <td>0.873042</td>\n",
       "      <td>0.889995</td>\n",
       "      <td>0.900013</td>\n",
       "      <td>0.900215</td>\n",
       "      <td>0.907716</td>\n",
       "      <td>0.911544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_1</th>\n",
       "      <td>0.034750</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>0.090399</td>\n",
       "      <td>0.154048</td>\n",
       "      <td>0.245522</td>\n",
       "      <td>0.270420</td>\n",
       "      <td>0.277585</td>\n",
       "      <td>0.262539</td>\n",
       "      <td>0.245761</td>\n",
       "      <td>0.199666</td>\n",
       "      <td>0.165154</td>\n",
       "      <td>0.129747</td>\n",
       "      <td>0.090877</td>\n",
       "      <td>0.060485</td>\n",
       "      <td>0.034989</td>\n",
       "      <td>0.016718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_1</th>\n",
       "      <td>675.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>4025.000000</td>\n",
       "      <td>7406.000000</td>\n",
       "      <td>7582.000000</td>\n",
       "      <td>6866.000000</td>\n",
       "      <td>5901.000000</td>\n",
       "      <td>4819.000000</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>2962.000000</td>\n",
       "      <td>2254.000000</td>\n",
       "      <td>1573.000000</td>\n",
       "      <td>1026.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_1</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1345.000000</td>\n",
       "      <td>2696.000000</td>\n",
       "      <td>2905.000000</td>\n",
       "      <td>6934.000000</td>\n",
       "      <td>7487.000000</td>\n",
       "      <td>6395.000000</td>\n",
       "      <td>4684.000000</td>\n",
       "      <td>2751.000000</td>\n",
       "      <td>1243.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_2</th>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.851080</td>\n",
       "      <td>0.814658</td>\n",
       "      <td>0.737462</td>\n",
       "      <td>0.741682</td>\n",
       "      <td>0.706330</td>\n",
       "      <td>0.672724</td>\n",
       "      <td>0.653829</td>\n",
       "      <td>0.646662</td>\n",
       "      <td>0.621689</td>\n",
       "      <td>0.658762</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>0.607930</td>\n",
       "      <td>0.543624</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_2</th>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.631730</td>\n",
       "      <td>0.663230</td>\n",
       "      <td>0.544213</td>\n",
       "      <td>0.713244</td>\n",
       "      <td>0.697573</td>\n",
       "      <td>0.625492</td>\n",
       "      <td>0.503474</td>\n",
       "      <td>0.357751</td>\n",
       "      <td>0.205360</td>\n",
       "      <td>0.168805</td>\n",
       "      <td>0.118456</td>\n",
       "      <td>0.086520</td>\n",
       "      <td>0.078717</td>\n",
       "      <td>0.057530</td>\n",
       "      <td>0.039427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_2</th>\n",
       "      <td>0.962687</td>\n",
       "      <td>0.955885</td>\n",
       "      <td>0.929956</td>\n",
       "      <td>0.880159</td>\n",
       "      <td>0.827418</td>\n",
       "      <td>0.795835</td>\n",
       "      <td>0.795247</td>\n",
       "      <td>0.807499</td>\n",
       "      <td>0.825641</td>\n",
       "      <td>0.848021</td>\n",
       "      <td>0.876566</td>\n",
       "      <td>0.892200</td>\n",
       "      <td>0.902444</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>0.911069</td>\n",
       "      <td>0.884585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_2</th>\n",
       "      <td>0.032614</td>\n",
       "      <td>0.049845</td>\n",
       "      <td>0.093072</td>\n",
       "      <td>0.155915</td>\n",
       "      <td>0.236346</td>\n",
       "      <td>0.267827</td>\n",
       "      <td>0.277844</td>\n",
       "      <td>0.268483</td>\n",
       "      <td>0.240699</td>\n",
       "      <td>0.200513</td>\n",
       "      <td>0.162235</td>\n",
       "      <td>0.128130</td>\n",
       "      <td>0.092177</td>\n",
       "      <td>0.060577</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.016993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_2</th>\n",
       "      <td>675.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>3201.000000</td>\n",
       "      <td>4026.000000</td>\n",
       "      <td>7407.000000</td>\n",
       "      <td>7582.000000</td>\n",
       "      <td>6865.000000</td>\n",
       "      <td>5901.000000</td>\n",
       "      <td>4819.000000</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>2962.000000</td>\n",
       "      <td>2254.000000</td>\n",
       "      <td>1595.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_2</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>1296.000000</td>\n",
       "      <td>2606.000000</td>\n",
       "      <td>2971.000000</td>\n",
       "      <td>7123.000000</td>\n",
       "      <td>7488.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>4544.000000</td>\n",
       "      <td>2666.000000</td>\n",
       "      <td>1208.000000</td>\n",
       "      <td>759.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_3</th>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.859828</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.742741</td>\n",
       "      <td>0.738310</td>\n",
       "      <td>0.705027</td>\n",
       "      <td>0.669994</td>\n",
       "      <td>0.647845</td>\n",
       "      <td>0.618684</td>\n",
       "      <td>0.603758</td>\n",
       "      <td>0.626087</td>\n",
       "      <td>0.618824</td>\n",
       "      <td>0.582329</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_3</th>\n",
       "      <td>0.235556</td>\n",
       "      <td>0.628506</td>\n",
       "      <td>0.674477</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.707709</td>\n",
       "      <td>0.697401</td>\n",
       "      <td>0.625783</td>\n",
       "      <td>0.517200</td>\n",
       "      <td>0.353185</td>\n",
       "      <td>0.202133</td>\n",
       "      <td>0.170155</td>\n",
       "      <td>0.116630</td>\n",
       "      <td>0.092239</td>\n",
       "      <td>0.078923</td>\n",
       "      <td>0.060504</td>\n",
       "      <td>0.040293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_3</th>\n",
       "      <td>0.963903</td>\n",
       "      <td>0.955852</td>\n",
       "      <td>0.935588</td>\n",
       "      <td>0.881698</td>\n",
       "      <td>0.825747</td>\n",
       "      <td>0.796318</td>\n",
       "      <td>0.791302</td>\n",
       "      <td>0.811014</td>\n",
       "      <td>0.822896</td>\n",
       "      <td>0.845780</td>\n",
       "      <td>0.872997</td>\n",
       "      <td>0.891491</td>\n",
       "      <td>0.889700</td>\n",
       "      <td>0.899129</td>\n",
       "      <td>0.900831</td>\n",
       "      <td>0.890499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_3</th>\n",
       "      <td>0.033740</td>\n",
       "      <td>0.049271</td>\n",
       "      <td>0.090211</td>\n",
       "      <td>0.154002</td>\n",
       "      <td>0.239393</td>\n",
       "      <td>0.268134</td>\n",
       "      <td>0.278786</td>\n",
       "      <td>0.268253</td>\n",
       "      <td>0.247902</td>\n",
       "      <td>0.202440</td>\n",
       "      <td>0.164177</td>\n",
       "      <td>0.128176</td>\n",
       "      <td>0.091104</td>\n",
       "      <td>0.062481</td>\n",
       "      <td>0.034930</td>\n",
       "      <td>0.016305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_3</th>\n",
       "      <td>675.000000</td>\n",
       "      <td>1747.000000</td>\n",
       "      <td>3201.000000</td>\n",
       "      <td>4026.000000</td>\n",
       "      <td>7407.000000</td>\n",
       "      <td>7581.000000</td>\n",
       "      <td>6865.000000</td>\n",
       "      <td>5901.000000</td>\n",
       "      <td>4819.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>2962.000000</td>\n",
       "      <td>2255.000000</td>\n",
       "      <td>1572.000000</td>\n",
       "      <td>1077.000000</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>273.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_3</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>1277.000000</td>\n",
       "      <td>2633.000000</td>\n",
       "      <td>2962.000000</td>\n",
       "      <td>7100.000000</td>\n",
       "      <td>7499.000000</td>\n",
       "      <td>6412.000000</td>\n",
       "      <td>4711.000000</td>\n",
       "      <td>2751.000000</td>\n",
       "      <td>1224.000000</td>\n",
       "      <td>805.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_4</th>\n",
       "      <td>0.822335</td>\n",
       "      <td>0.851910</td>\n",
       "      <td>0.820856</td>\n",
       "      <td>0.742747</td>\n",
       "      <td>0.731759</td>\n",
       "      <td>0.705797</td>\n",
       "      <td>0.670764</td>\n",
       "      <td>0.653167</td>\n",
       "      <td>0.641293</td>\n",
       "      <td>0.597808</td>\n",
       "      <td>0.620448</td>\n",
       "      <td>0.618454</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_4</th>\n",
       "      <td>0.239645</td>\n",
       "      <td>0.626002</td>\n",
       "      <td>0.671562</td>\n",
       "      <td>0.527819</td>\n",
       "      <td>0.698663</td>\n",
       "      <td>0.703376</td>\n",
       "      <td>0.627968</td>\n",
       "      <td>0.513811</td>\n",
       "      <td>0.370616</td>\n",
       "      <td>0.193928</td>\n",
       "      <td>0.149561</td>\n",
       "      <td>0.110027</td>\n",
       "      <td>0.095178</td>\n",
       "      <td>0.085770</td>\n",
       "      <td>0.045608</td>\n",
       "      <td>0.029304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_4</th>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.958682</td>\n",
       "      <td>0.934056</td>\n",
       "      <td>0.879149</td>\n",
       "      <td>0.817674</td>\n",
       "      <td>0.798576</td>\n",
       "      <td>0.792222</td>\n",
       "      <td>0.806049</td>\n",
       "      <td>0.826286</td>\n",
       "      <td>0.844311</td>\n",
       "      <td>0.868168</td>\n",
       "      <td>0.890066</td>\n",
       "      <td>0.899319</td>\n",
       "      <td>0.896801</td>\n",
       "      <td>0.902895</td>\n",
       "      <td>0.896295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_4</th>\n",
       "      <td>0.032770</td>\n",
       "      <td>0.050319</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.157405</td>\n",
       "      <td>0.246463</td>\n",
       "      <td>0.266937</td>\n",
       "      <td>0.278756</td>\n",
       "      <td>0.267355</td>\n",
       "      <td>0.240673</td>\n",
       "      <td>0.204381</td>\n",
       "      <td>0.166537</td>\n",
       "      <td>0.128872</td>\n",
       "      <td>0.089894</td>\n",
       "      <td>0.059094</td>\n",
       "      <td>0.035158</td>\n",
       "      <td>0.016534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_4</th>\n",
       "      <td>676.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>4026.000000</td>\n",
       "      <td>7407.000000</td>\n",
       "      <td>7582.000000</td>\n",
       "      <td>6865.000000</td>\n",
       "      <td>5901.000000</td>\n",
       "      <td>4819.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>2962.000000</td>\n",
       "      <td>2254.000000</td>\n",
       "      <td>1576.000000</td>\n",
       "      <td>1026.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>273.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_4</th>\n",
       "      <td>197.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>2618.000000</td>\n",
       "      <td>2861.000000</td>\n",
       "      <td>7072.000000</td>\n",
       "      <td>7556.000000</td>\n",
       "      <td>6427.000000</td>\n",
       "      <td>4642.000000</td>\n",
       "      <td>2785.000000</td>\n",
       "      <td>1186.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_5</th>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.820100</td>\n",
       "      <td>0.735068</td>\n",
       "      <td>0.735929</td>\n",
       "      <td>0.701471</td>\n",
       "      <td>0.670492</td>\n",
       "      <td>0.656162</td>\n",
       "      <td>0.636999</td>\n",
       "      <td>0.628059</td>\n",
       "      <td>0.628342</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_5</th>\n",
       "      <td>0.210370</td>\n",
       "      <td>0.635739</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>0.547193</td>\n",
       "      <td>0.704334</td>\n",
       "      <td>0.692034</td>\n",
       "      <td>0.621267</td>\n",
       "      <td>0.515167</td>\n",
       "      <td>0.359336</td>\n",
       "      <td>0.210555</td>\n",
       "      <td>0.158677</td>\n",
       "      <td>0.123780</td>\n",
       "      <td>0.100509</td>\n",
       "      <td>0.080692</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.029304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_5</th>\n",
       "      <td>0.967492</td>\n",
       "      <td>0.956202</td>\n",
       "      <td>0.935438</td>\n",
       "      <td>0.883029</td>\n",
       "      <td>0.825553</td>\n",
       "      <td>0.794012</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>0.813573</td>\n",
       "      <td>0.826267</td>\n",
       "      <td>0.849082</td>\n",
       "      <td>0.869506</td>\n",
       "      <td>0.884602</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.899016</td>\n",
       "      <td>0.901311</td>\n",
       "      <td>0.898575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_5</th>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.091327</td>\n",
       "      <td>0.156108</td>\n",
       "      <td>0.242305</td>\n",
       "      <td>0.272489</td>\n",
       "      <td>0.280124</td>\n",
       "      <td>0.265688</td>\n",
       "      <td>0.243080</td>\n",
       "      <td>0.199415</td>\n",
       "      <td>0.165235</td>\n",
       "      <td>0.126939</td>\n",
       "      <td>0.090134</td>\n",
       "      <td>0.061143</td>\n",
       "      <td>0.035851</td>\n",
       "      <td>0.016941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_5</th>\n",
       "      <td>675.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>4026.000000</td>\n",
       "      <td>7407.000000</td>\n",
       "      <td>7582.000000</td>\n",
       "      <td>6865.000000</td>\n",
       "      <td>5901.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>2962.000000</td>\n",
       "      <td>2254.000000</td>\n",
       "      <td>1572.000000</td>\n",
       "      <td>1041.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>273.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_5</th>\n",
       "      <td>182.000000</td>\n",
       "      <td>1295.000000</td>\n",
       "      <td>2607.000000</td>\n",
       "      <td>2997.000000</td>\n",
       "      <td>7089.000000</td>\n",
       "      <td>7480.000000</td>\n",
       "      <td>6361.000000</td>\n",
       "      <td>4633.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>1226.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0            1            2            3  \\\n",
       "precision_kfold_1       0.762712     0.844610     0.812685     0.748709   \n",
       "recall_kfold_1          0.200000     0.650630     0.684688     0.540373   \n",
       "rocScore_kfold_1        0.968211     0.958130     0.935129     0.880205   \n",
       "accuracy_kfold_1        0.034750     0.048901     0.090399     0.154048   \n",
       "realCount_kfold_1     675.000000  1746.000000  3200.000000  4025.000000   \n",
       "predictCount_kfold_1  177.000000  1345.000000  2696.000000  2905.000000   \n",
       "precision_kfold_2       0.799065     0.851080     0.814658     0.737462   \n",
       "recall_kfold_2          0.253333     0.631730     0.663230     0.544213   \n",
       "rocScore_kfold_2        0.962687     0.955885     0.929956     0.880159   \n",
       "accuracy_kfold_2        0.032614     0.049845     0.093072     0.155915   \n",
       "realCount_kfold_2     675.000000  1746.000000  3201.000000  4026.000000   \n",
       "predictCount_kfold_2  214.000000  1296.000000  2606.000000  2971.000000   \n",
       "precision_kfold_3       0.757143     0.859828     0.819977     0.742741   \n",
       "recall_kfold_3          0.235556     0.628506     0.674477     0.546448   \n",
       "rocScore_kfold_3        0.963903     0.955852     0.935588     0.881698   \n",
       "accuracy_kfold_3        0.033740     0.049271     0.090211     0.154002   \n",
       "realCount_kfold_3     675.000000  1747.000000  3201.000000  4026.000000   \n",
       "predictCount_kfold_3  210.000000  1277.000000  2633.000000  2962.000000   \n",
       "precision_kfold_4       0.822335     0.851910     0.820856     0.742747   \n",
       "recall_kfold_4          0.239645     0.626002     0.671562     0.527819   \n",
       "rocScore_kfold_4        0.966423     0.958682     0.934056     0.879149   \n",
       "accuracy_kfold_4        0.032770     0.050319     0.090730     0.157405   \n",
       "realCount_kfold_4     676.000000  1746.000000  3200.000000  4026.000000   \n",
       "predictCount_kfold_4  197.000000  1283.000000  2618.000000  2861.000000   \n",
       "precision_kfold_5       0.780220     0.857143     0.820100     0.735068   \n",
       "recall_kfold_5          0.210370     0.635739     0.668125     0.547193   \n",
       "rocScore_kfold_5        0.967492     0.956202     0.935438     0.883029   \n",
       "accuracy_kfold_5        0.034180     0.048974     0.091327     0.156108   \n",
       "realCount_kfold_5     675.000000  1746.000000  3200.000000  4026.000000   \n",
       "predictCount_kfold_5  182.000000  1295.000000  2607.000000  2997.000000   \n",
       "\n",
       "                                4            5            6            7  \\\n",
       "precision_kfold_1        0.737525     0.703887     0.673339     0.660547   \n",
       "recall_kfold_1           0.690521     0.695067     0.627148     0.524318   \n",
       "rocScore_kfold_1         0.819733     0.797203     0.793618     0.815184   \n",
       "accuracy_kfold_1         0.245522     0.270420     0.277585     0.262539   \n",
       "realCount_kfold_1     7406.000000  7582.000000  6866.000000  5901.000000   \n",
       "predictCount_kfold_1  6934.000000  7487.000000  6395.000000  4684.000000   \n",
       "precision_kfold_2        0.741682     0.706330     0.672724     0.653829   \n",
       "recall_kfold_2           0.713244     0.697573     0.625492     0.503474   \n",
       "rocScore_kfold_2         0.827418     0.795835     0.795247     0.807499   \n",
       "accuracy_kfold_2         0.236346     0.267827     0.277844     0.268483   \n",
       "realCount_kfold_2     7407.000000  7582.000000  6865.000000  5901.000000   \n",
       "predictCount_kfold_2  7123.000000  7488.000000  6383.000000  4544.000000   \n",
       "precision_kfold_3        0.738310     0.705027     0.669994     0.647845   \n",
       "recall_kfold_3           0.707709     0.697401     0.625783     0.517200   \n",
       "rocScore_kfold_3         0.825747     0.796318     0.791302     0.811014   \n",
       "accuracy_kfold_3         0.239393     0.268134     0.278786     0.268253   \n",
       "realCount_kfold_3     7407.000000  7581.000000  6865.000000  5901.000000   \n",
       "predictCount_kfold_3  7100.000000  7499.000000  6412.000000  4711.000000   \n",
       "precision_kfold_4        0.731759     0.705797     0.670764     0.653167   \n",
       "recall_kfold_4           0.698663     0.703376     0.627968     0.513811   \n",
       "rocScore_kfold_4         0.817674     0.798576     0.792222     0.806049   \n",
       "accuracy_kfold_4         0.246463     0.266937     0.278756     0.267355   \n",
       "realCount_kfold_4     7407.000000  7582.000000  6865.000000  5901.000000   \n",
       "predictCount_kfold_4  7072.000000  7556.000000  6427.000000  4642.000000   \n",
       "precision_kfold_5        0.735929     0.701471     0.670492     0.656162   \n",
       "recall_kfold_5           0.704334     0.692034     0.621267     0.515167   \n",
       "rocScore_kfold_5         0.825553     0.794012     0.791919     0.813573   \n",
       "accuracy_kfold_5         0.242305     0.272489     0.280124     0.265688   \n",
       "realCount_kfold_5     7407.000000  7582.000000  6865.000000  5901.000000   \n",
       "predictCount_kfold_5  7089.000000  7480.000000  6361.000000  4633.000000   \n",
       "\n",
       "                                8            9           10           11  \\\n",
       "precision_kfold_1        0.627772     0.625905     0.631367     0.598063   \n",
       "recall_kfold_1           0.358373     0.212743     0.159014     0.109583   \n",
       "rocScore_kfold_1         0.822094     0.849650     0.873042     0.889995   \n",
       "accuracy_kfold_1         0.245761     0.199666     0.165154     0.129747   \n",
       "realCount_kfold_1     4819.000000  3657.000000  2962.000000  2254.000000   \n",
       "predictCount_kfold_1  2751.000000  1243.000000   746.000000   413.000000   \n",
       "precision_kfold_2        0.646662     0.621689     0.658762     0.622378   \n",
       "recall_kfold_2           0.357751     0.205360     0.168805     0.118456   \n",
       "rocScore_kfold_2         0.825641     0.848021     0.876566     0.892200   \n",
       "accuracy_kfold_2         0.240699     0.200513     0.162235     0.128130   \n",
       "realCount_kfold_2     4819.000000  3657.000000  2962.000000  2254.000000   \n",
       "predictCount_kfold_2  2666.000000  1208.000000   759.000000   429.000000   \n",
       "precision_kfold_3        0.618684     0.603758     0.626087     0.618824   \n",
       "recall_kfold_3           0.353185     0.202133     0.170155     0.116630   \n",
       "rocScore_kfold_3         0.822896     0.845780     0.872997     0.891491   \n",
       "accuracy_kfold_3         0.247902     0.202440     0.164177     0.128176   \n",
       "realCount_kfold_3     4819.000000  3656.000000  2962.000000  2255.000000   \n",
       "predictCount_kfold_3  2751.000000  1224.000000   805.000000   425.000000   \n",
       "precision_kfold_4        0.641293     0.597808     0.620448     0.618454   \n",
       "recall_kfold_4           0.370616     0.193928     0.149561     0.110027   \n",
       "rocScore_kfold_4         0.826286     0.844311     0.868168     0.890066   \n",
       "accuracy_kfold_4         0.240673     0.204381     0.166537     0.128872   \n",
       "realCount_kfold_4     4819.000000  3656.000000  2962.000000  2254.000000   \n",
       "predictCount_kfold_4  2785.000000  1186.000000   714.000000   401.000000   \n",
       "precision_kfold_5        0.636999     0.628059     0.628342     0.645833   \n",
       "recall_kfold_5           0.359336     0.210555     0.158677     0.123780   \n",
       "rocScore_kfold_5         0.826267     0.849082     0.869506     0.884602   \n",
       "accuracy_kfold_5         0.243080     0.199415     0.165235     0.126939   \n",
       "realCount_kfold_5     4820.000000  3657.000000  2962.000000  2254.000000   \n",
       "predictCount_kfold_5  2719.000000  1226.000000   748.000000   432.000000   \n",
       "\n",
       "                               12           13          14          15  \n",
       "precision_kfold_1        0.607595     0.543046    0.539474    0.375000  \n",
       "recall_kfold_1           0.091545     0.079922    0.069257    0.044118  \n",
       "rocScore_kfold_1         0.900013     0.900215    0.907716    0.911544  \n",
       "accuracy_kfold_1         0.090877     0.060485    0.034989    0.016718  \n",
       "realCount_kfold_1     1573.000000  1026.000000  592.000000  272.000000  \n",
       "predictCount_kfold_1   237.000000   151.000000   76.000000   32.000000  \n",
       "precision_kfold_2        0.607930     0.543624    0.447368    0.392857  \n",
       "recall_kfold_2           0.086520     0.078717    0.057530    0.039427  \n",
       "rocScore_kfold_2         0.902444     0.908876    0.911069    0.884585  \n",
       "accuracy_kfold_2         0.092177     0.060577    0.035714    0.016993  \n",
       "realCount_kfold_2     1595.000000  1029.000000  591.000000  279.000000  \n",
       "predictCount_kfold_2   227.000000   149.000000   76.000000   28.000000  \n",
       "precision_kfold_3        0.582329     0.594406    0.562500    0.478261  \n",
       "recall_kfold_3           0.092239     0.078923    0.060504    0.040293  \n",
       "rocScore_kfold_3         0.889700     0.899129    0.900831    0.890499  \n",
       "accuracy_kfold_3         0.091104     0.062481    0.034930    0.016305  \n",
       "realCount_kfold_3     1572.000000  1077.000000  595.000000  273.000000  \n",
       "predictCount_kfold_3   249.000000   143.000000   64.000000   23.000000  \n",
       "precision_kfold_4        0.652174     0.628571    0.529412    0.400000  \n",
       "recall_kfold_4           0.095178     0.085770    0.045608    0.029304  \n",
       "rocScore_kfold_4         0.899319     0.896801    0.902895    0.896295  \n",
       "accuracy_kfold_4         0.089894     0.059094    0.035158    0.016534  \n",
       "realCount_kfold_4     1576.000000  1026.000000  592.000000  273.000000  \n",
       "predictCount_kfold_4   230.000000   140.000000   51.000000   20.000000  \n",
       "precision_kfold_5        0.619608     0.552632    0.438356    0.296296  \n",
       "recall_kfold_5           0.100509     0.080692    0.054054    0.029304  \n",
       "rocScore_kfold_5         0.893204     0.899016    0.901311    0.898575  \n",
       "accuracy_kfold_5         0.090134     0.061143    0.035851    0.016941  \n",
       "realCount_kfold_5     1572.000000  1041.000000  592.000000  273.000000  \n",
       "predictCount_kfold_5   255.000000   152.000000   73.000000   27.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining edge cutoff with any intensity middle, all continuous\n",
    "mixedthresh_metrics_df = np.transpose(pd.DataFrame(metricdict))\n",
    "mixedthresh_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_df['Analysis'] = ['threshold continuous'] * threshold_metrics_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_kfold_1</th>\n",
       "      <td>0.771704</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.812160</td>\n",
       "      <td>0.737348</td>\n",
       "      <td>0.608586</td>\n",
       "      <td>0.398374</td>\n",
       "      <td>0.419274</td>\n",
       "      <td>0.519828</td>\n",
       "      <td>0.506803</td>\n",
       "      <td>0.542725</td>\n",
       "      <td>0.575456</td>\n",
       "      <td>0.585185</td>\n",
       "      <td>0.562249</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_1</th>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.639024</td>\n",
       "      <td>0.685020</td>\n",
       "      <td>0.510421</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>0.066917</td>\n",
       "      <td>0.090394</td>\n",
       "      <td>0.145406</td>\n",
       "      <td>0.150353</td>\n",
       "      <td>0.135877</td>\n",
       "      <td>0.118027</td>\n",
       "      <td>0.103313</td>\n",
       "      <td>0.086154</td>\n",
       "      <td>0.074669</td>\n",
       "      <td>0.047697</td>\n",
       "      <td>0.035948</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_1</th>\n",
       "      <td>0.964773</td>\n",
       "      <td>0.956136</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>0.874833</td>\n",
       "      <td>0.812353</td>\n",
       "      <td>0.743883</td>\n",
       "      <td>0.735949</td>\n",
       "      <td>0.768834</td>\n",
       "      <td>0.802462</td>\n",
       "      <td>0.839295</td>\n",
       "      <td>0.867734</td>\n",
       "      <td>0.881210</td>\n",
       "      <td>0.884704</td>\n",
       "      <td>0.889110</td>\n",
       "      <td>0.901720</td>\n",
       "      <td>0.900852</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_1</th>\n",
       "      <td>0.034152</td>\n",
       "      <td>0.051621</td>\n",
       "      <td>0.092016</td>\n",
       "      <td>0.158850</td>\n",
       "      <td>0.196831</td>\n",
       "      <td>0.158903</td>\n",
       "      <td>0.201186</td>\n",
       "      <td>0.215140</td>\n",
       "      <td>0.207114</td>\n",
       "      <td>0.177578</td>\n",
       "      <td>0.149460</td>\n",
       "      <td>0.116724</td>\n",
       "      <td>0.083622</td>\n",
       "      <td>0.054716</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.016945</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_1</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2050.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4096.000000</td>\n",
       "      <td>2929.000000</td>\n",
       "      <td>3706.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3964.000000</td>\n",
       "      <td>3459.000000</td>\n",
       "      <td>2940.000000</td>\n",
       "      <td>2294.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_1</th>\n",
       "      <td>311.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>3125.000000</td>\n",
       "      <td>3122.000000</td>\n",
       "      <td>1584.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_2</th>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.855495</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>0.729797</td>\n",
       "      <td>0.599130</td>\n",
       "      <td>0.414687</td>\n",
       "      <td>0.397359</td>\n",
       "      <td>0.504910</td>\n",
       "      <td>0.503100</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.561576</td>\n",
       "      <td>0.584112</td>\n",
       "      <td>0.591912</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_2</th>\n",
       "      <td>0.310976</td>\n",
       "      <td>0.614822</td>\n",
       "      <td>0.663428</td>\n",
       "      <td>0.518625</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>0.089291</td>\n",
       "      <td>0.148782</td>\n",
       "      <td>0.143290</td>\n",
       "      <td>0.117953</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>0.099077</td>\n",
       "      <td>0.084121</td>\n",
       "      <td>0.052464</td>\n",
       "      <td>0.036066</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_2</th>\n",
       "      <td>0.962470</td>\n",
       "      <td>0.954419</td>\n",
       "      <td>0.931591</td>\n",
       "      <td>0.875787</td>\n",
       "      <td>0.804768</td>\n",
       "      <td>0.741209</td>\n",
       "      <td>0.728330</td>\n",
       "      <td>0.771223</td>\n",
       "      <td>0.794287</td>\n",
       "      <td>0.831907</td>\n",
       "      <td>0.869203</td>\n",
       "      <td>0.878626</td>\n",
       "      <td>0.892682</td>\n",
       "      <td>0.903449</td>\n",
       "      <td>0.902119</td>\n",
       "      <td>0.905270</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_2</th>\n",
       "      <td>0.032547</td>\n",
       "      <td>0.052568</td>\n",
       "      <td>0.095650</td>\n",
       "      <td>0.159172</td>\n",
       "      <td>0.197956</td>\n",
       "      <td>0.157652</td>\n",
       "      <td>0.203249</td>\n",
       "      <td>0.216719</td>\n",
       "      <td>0.207390</td>\n",
       "      <td>0.180346</td>\n",
       "      <td>0.150105</td>\n",
       "      <td>0.116457</td>\n",
       "      <td>0.082547</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_2</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4096.000000</td>\n",
       "      <td>2929.000000</td>\n",
       "      <td>3707.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3964.000000</td>\n",
       "      <td>3459.000000</td>\n",
       "      <td>2939.000000</td>\n",
       "      <td>2294.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_2</th>\n",
       "      <td>311.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>3036.000000</td>\n",
       "      <td>3205.000000</td>\n",
       "      <td>1609.000000</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>833.000000</td>\n",
       "      <td>1222.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>798.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_3</th>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.832778</td>\n",
       "      <td>0.814342</td>\n",
       "      <td>0.723167</td>\n",
       "      <td>0.602850</td>\n",
       "      <td>0.409190</td>\n",
       "      <td>0.411097</td>\n",
       "      <td>0.519504</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>0.551160</td>\n",
       "      <td>0.593346</td>\n",
       "      <td>0.610315</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.424658</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_3</th>\n",
       "      <td>0.232927</td>\n",
       "      <td>0.609459</td>\n",
       "      <td>0.671255</td>\n",
       "      <td>0.546785</td>\n",
       "      <td>0.237607</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.087942</td>\n",
       "      <td>0.141307</td>\n",
       "      <td>0.139541</td>\n",
       "      <td>0.116763</td>\n",
       "      <td>0.109184</td>\n",
       "      <td>0.092810</td>\n",
       "      <td>0.089626</td>\n",
       "      <td>0.069943</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_3</th>\n",
       "      <td>0.958484</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.931924</td>\n",
       "      <td>0.880413</td>\n",
       "      <td>0.809051</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.730058</td>\n",
       "      <td>0.768877</td>\n",
       "      <td>0.796725</td>\n",
       "      <td>0.836025</td>\n",
       "      <td>0.867190</td>\n",
       "      <td>0.881938</td>\n",
       "      <td>0.892383</td>\n",
       "      <td>0.895695</td>\n",
       "      <td>0.902558</td>\n",
       "      <td>0.892593</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_3</th>\n",
       "      <td>0.035664</td>\n",
       "      <td>0.055174</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.156711</td>\n",
       "      <td>0.197357</td>\n",
       "      <td>0.157917</td>\n",
       "      <td>0.201815</td>\n",
       "      <td>0.215189</td>\n",
       "      <td>0.206273</td>\n",
       "      <td>0.177532</td>\n",
       "      <td>0.148896</td>\n",
       "      <td>0.116327</td>\n",
       "      <td>0.083233</td>\n",
       "      <td>0.055593</td>\n",
       "      <td>0.032517</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_3</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>3707.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3963.000000</td>\n",
       "      <td>3460.000000</td>\n",
       "      <td>2940.000000</td>\n",
       "      <td>2295.000000</td>\n",
       "      <td>1629.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_3</th>\n",
       "      <td>242.000000</td>\n",
       "      <td>1501.000000</td>\n",
       "      <td>3054.000000</td>\n",
       "      <td>3410.000000</td>\n",
       "      <td>1614.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>1128.000000</td>\n",
       "      <td>1076.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_4</th>\n",
       "      <td>0.767347</td>\n",
       "      <td>0.850065</td>\n",
       "      <td>0.827471</td>\n",
       "      <td>0.727565</td>\n",
       "      <td>0.594969</td>\n",
       "      <td>0.409766</td>\n",
       "      <td>0.469921</td>\n",
       "      <td>0.515853</td>\n",
       "      <td>0.484716</td>\n",
       "      <td>0.528678</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_4</th>\n",
       "      <td>0.229268</td>\n",
       "      <td>0.635787</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.501552</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.065915</td>\n",
       "      <td>0.111681</td>\n",
       "      <td>0.145165</td>\n",
       "      <td>0.140010</td>\n",
       "      <td>0.122543</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.105493</td>\n",
       "      <td>0.084923</td>\n",
       "      <td>0.068053</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_4</th>\n",
       "      <td>0.962116</td>\n",
       "      <td>0.955842</td>\n",
       "      <td>0.933034</td>\n",
       "      <td>0.869537</td>\n",
       "      <td>0.804650</td>\n",
       "      <td>0.735130</td>\n",
       "      <td>0.736412</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>0.795884</td>\n",
       "      <td>0.833184</td>\n",
       "      <td>0.856737</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>0.883365</td>\n",
       "      <td>0.889854</td>\n",
       "      <td>0.899402</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_4</th>\n",
       "      <td>0.036157</td>\n",
       "      <td>0.051270</td>\n",
       "      <td>0.091835</td>\n",
       "      <td>0.162416</td>\n",
       "      <td>0.199045</td>\n",
       "      <td>0.158113</td>\n",
       "      <td>0.197313</td>\n",
       "      <td>0.215680</td>\n",
       "      <td>0.209855</td>\n",
       "      <td>0.179156</td>\n",
       "      <td>0.150609</td>\n",
       "      <td>0.115449</td>\n",
       "      <td>0.082914</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>0.032168</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_4</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>3707.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3964.000000</td>\n",
       "      <td>3460.000000</td>\n",
       "      <td>2940.000000</td>\n",
       "      <td>2294.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_4</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>1534.000000</td>\n",
       "      <td>2985.000000</td>\n",
       "      <td>3109.000000</td>\n",
       "      <td>1590.000000</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_5</th>\n",
       "      <td>0.824176</td>\n",
       "      <td>0.858294</td>\n",
       "      <td>0.811333</td>\n",
       "      <td>0.730106</td>\n",
       "      <td>0.585766</td>\n",
       "      <td>0.369072</td>\n",
       "      <td>0.403869</td>\n",
       "      <td>0.490700</td>\n",
       "      <td>0.532273</td>\n",
       "      <td>0.551499</td>\n",
       "      <td>0.561189</td>\n",
       "      <td>0.567430</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.541935</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_5</th>\n",
       "      <td>0.274390</td>\n",
       "      <td>0.623111</td>\n",
       "      <td>0.668737</td>\n",
       "      <td>0.535033</td>\n",
       "      <td>0.235165</td>\n",
       "      <td>0.061113</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.133591</td>\n",
       "      <td>0.143578</td>\n",
       "      <td>0.122290</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.081231</td>\n",
       "      <td>0.079395</td>\n",
       "      <td>0.060855</td>\n",
       "      <td>0.039344</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_5</th>\n",
       "      <td>0.962492</td>\n",
       "      <td>0.958076</td>\n",
       "      <td>0.932191</td>\n",
       "      <td>0.878449</td>\n",
       "      <td>0.806859</td>\n",
       "      <td>0.742193</td>\n",
       "      <td>0.730628</td>\n",
       "      <td>0.763261</td>\n",
       "      <td>0.795485</td>\n",
       "      <td>0.834551</td>\n",
       "      <td>0.862916</td>\n",
       "      <td>0.882720</td>\n",
       "      <td>0.890295</td>\n",
       "      <td>0.894963</td>\n",
       "      <td>0.894097</td>\n",
       "      <td>0.904397</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_5</th>\n",
       "      <td>0.033737</td>\n",
       "      <td>0.051629</td>\n",
       "      <td>0.094601</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.200063</td>\n",
       "      <td>0.160344</td>\n",
       "      <td>0.202844</td>\n",
       "      <td>0.218689</td>\n",
       "      <td>0.204313</td>\n",
       "      <td>0.177344</td>\n",
       "      <td>0.150533</td>\n",
       "      <td>0.117635</td>\n",
       "      <td>0.084632</td>\n",
       "      <td>0.054830</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.016423</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_5</th>\n",
       "      <td>820.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>3704.000000</td>\n",
       "      <td>4510.000000</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>2929.000000</td>\n",
       "      <td>3707.000000</td>\n",
       "      <td>4147.000000</td>\n",
       "      <td>3963.000000</td>\n",
       "      <td>3459.000000</td>\n",
       "      <td>2939.000000</td>\n",
       "      <td>2295.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_5</th>\n",
       "      <td>273.000000</td>\n",
       "      <td>1489.000000</td>\n",
       "      <td>3053.000000</td>\n",
       "      <td>3305.000000</td>\n",
       "      <td>1644.000000</td>\n",
       "      <td>485.000000</td>\n",
       "      <td>827.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1069.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>threshold continuous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0            1            2            3  \\\n",
       "precision_kfold_1       0.771704     0.842986     0.812160     0.737348   \n",
       "recall_kfold_1          0.292683     0.639024     0.685020     0.510421   \n",
       "rocScore_kfold_1        0.964773     0.956136     0.936256     0.874833   \n",
       "accuracy_kfold_1        0.034152     0.051621     0.092016     0.158850   \n",
       "realCount_kfold_1     820.000000  2050.000000  3705.000000  4510.000000   \n",
       "predictCount_kfold_1  311.000000  1554.000000  3125.000000  3122.000000   \n",
       "precision_kfold_2       0.819936     0.855495     0.809618     0.729797   \n",
       "recall_kfold_2          0.310976     0.614822     0.663428     0.518625   \n",
       "rocScore_kfold_2        0.962470     0.954419     0.931591     0.875787   \n",
       "accuracy_kfold_2        0.032547     0.052568     0.095650     0.159172   \n",
       "realCount_kfold_2     820.000000  2051.000000  3705.000000  4510.000000   \n",
       "predictCount_kfold_2  311.000000  1474.000000  3036.000000  3205.000000   \n",
       "precision_kfold_3       0.789256     0.832778     0.814342     0.723167   \n",
       "recall_kfold_3          0.232927     0.609459     0.671255     0.546785   \n",
       "rocScore_kfold_3        0.958484     0.951210     0.931924     0.880413   \n",
       "accuracy_kfold_3        0.035664     0.055174     0.093617     0.156711   \n",
       "realCount_kfold_3     820.000000  2051.000000  3705.000000  4510.000000   \n",
       "predictCount_kfold_3  242.000000  1501.000000  3054.000000  3410.000000   \n",
       "precision_kfold_4       0.767347     0.850065     0.827471     0.727565   \n",
       "recall_kfold_4          0.229268     0.635787     0.666667     0.501552   \n",
       "rocScore_kfold_4        0.962116     0.955842     0.933034     0.869537   \n",
       "accuracy_kfold_4        0.036157     0.051270     0.091835     0.162416   \n",
       "realCount_kfold_4     820.000000  2051.000000  3705.000000  4510.000000   \n",
       "predictCount_kfold_4  245.000000  1534.000000  2985.000000  3109.000000   \n",
       "precision_kfold_5       0.824176     0.858294     0.811333     0.730106   \n",
       "recall_kfold_5          0.274390     0.623111     0.668737     0.535033   \n",
       "rocScore_kfold_5        0.962492     0.958076     0.932191     0.878449   \n",
       "accuracy_kfold_5        0.033737     0.051629     0.094601     0.156829   \n",
       "realCount_kfold_5     820.000000  2051.000000  3704.000000  4510.000000   \n",
       "predictCount_kfold_5  273.000000  1489.000000  3053.000000  3305.000000   \n",
       "\n",
       "                                4            5            6            7  \\\n",
       "precision_kfold_1        0.608586     0.398374     0.419274     0.519828   \n",
       "recall_kfold_1           0.235352     0.066917     0.090394     0.145406   \n",
       "rocScore_kfold_1         0.812353     0.743883     0.735949     0.768834   \n",
       "accuracy_kfold_1         0.196831     0.158903     0.201186     0.215140   \n",
       "realCount_kfold_1     4096.000000  2929.000000  3706.000000  4147.000000   \n",
       "predictCount_kfold_1  1584.000000   492.000000   799.000000  1160.000000   \n",
       "precision_kfold_2        0.599130     0.414687     0.397359     0.504910   \n",
       "recall_kfold_2           0.235352     0.065551     0.089291     0.148782   \n",
       "rocScore_kfold_2         0.804768     0.741209     0.728330     0.771223   \n",
       "accuracy_kfold_2         0.197956     0.157652     0.203249     0.216719   \n",
       "realCount_kfold_2     4096.000000  2929.000000  3707.000000  4147.000000   \n",
       "predictCount_kfold_2  1609.000000   463.000000   833.000000  1222.000000   \n",
       "precision_kfold_3        0.602850     0.409190     0.411097     0.519504   \n",
       "recall_kfold_3           0.237607     0.063866     0.087942     0.141307   \n",
       "rocScore_kfold_3         0.809051     0.745000     0.730058     0.768877   \n",
       "accuracy_kfold_3         0.197357     0.157917     0.201815     0.215189   \n",
       "realCount_kfold_3     4095.000000  2928.000000  3707.000000  4147.000000   \n",
       "predictCount_kfold_3  1614.000000   457.000000   793.000000  1128.000000   \n",
       "precision_kfold_4        0.594969     0.409766     0.469921     0.515853   \n",
       "recall_kfold_4           0.231013     0.065915     0.111681     0.145165   \n",
       "rocScore_kfold_4         0.804650     0.735130     0.736412     0.764766   \n",
       "accuracy_kfold_4         0.199045     0.158113     0.197313     0.215680   \n",
       "realCount_kfold_4     4095.000000  2928.000000  3707.000000  4147.000000   \n",
       "predictCount_kfold_4  1590.000000   471.000000   881.000000  1167.000000   \n",
       "precision_kfold_5        0.585766     0.369072     0.403869     0.490700   \n",
       "recall_kfold_5           0.235165     0.061113     0.090100     0.133591   \n",
       "rocScore_kfold_5         0.806859     0.742193     0.730628     0.763261   \n",
       "accuracy_kfold_5         0.200063     0.160344     0.202844     0.218689   \n",
       "realCount_kfold_5     4095.000000  2929.000000  3707.000000  4147.000000   \n",
       "predictCount_kfold_5  1644.000000   485.000000   827.000000  1129.000000   \n",
       "\n",
       "                                8            9           10           11  \\\n",
       "precision_kfold_1        0.506803     0.542725     0.575456     0.585185   \n",
       "recall_kfold_1           0.150353     0.135877     0.118027     0.103313   \n",
       "rocScore_kfold_1         0.802462     0.839295     0.867734     0.881210   \n",
       "accuracy_kfold_1         0.207114     0.177578     0.149460     0.116724   \n",
       "realCount_kfold_1     3964.000000  3459.000000  2940.000000  2294.000000   \n",
       "predictCount_kfold_1  1176.000000   866.000000   603.000000   405.000000   \n",
       "precision_kfold_2        0.503100     0.511278     0.561576     0.584112   \n",
       "recall_kfold_2           0.143290     0.117953     0.116366     0.108980   \n",
       "rocScore_kfold_2         0.794287     0.831907     0.869203     0.878626   \n",
       "accuracy_kfold_2         0.207390     0.180346     0.150105     0.116457   \n",
       "realCount_kfold_2     3964.000000  3459.000000  2939.000000  2294.000000   \n",
       "predictCount_kfold_2  1129.000000   798.000000   609.000000   428.000000   \n",
       "precision_kfold_3        0.513941     0.551160     0.593346     0.610315   \n",
       "recall_kfold_3           0.139541     0.116763     0.109184     0.092810   \n",
       "rocScore_kfold_3         0.796725     0.836025     0.867190     0.881938   \n",
       "accuracy_kfold_3         0.206273     0.177532     0.148896     0.116327   \n",
       "realCount_kfold_3     3963.000000  3460.000000  2940.000000  2295.000000   \n",
       "predictCount_kfold_3  1076.000000   733.000000   541.000000   349.000000   \n",
       "precision_kfold_4        0.484716     0.528678     0.560976     0.620513   \n",
       "recall_kfold_4           0.140010     0.122543     0.109524     0.105493   \n",
       "rocScore_kfold_4         0.795884     0.833184     0.856737     0.881818   \n",
       "accuracy_kfold_4         0.209855     0.179156     0.150609     0.115449   \n",
       "realCount_kfold_4     3964.000000  3460.000000  2940.000000  2294.000000   \n",
       "predictCount_kfold_4  1145.000000   802.000000   574.000000   390.000000   \n",
       "precision_kfold_5        0.532273     0.551499     0.561189     0.567430   \n",
       "recall_kfold_5           0.143578     0.122290     0.109221     0.097168   \n",
       "rocScore_kfold_5         0.795485     0.834551     0.862916     0.882720   \n",
       "accuracy_kfold_5         0.204313     0.177344     0.150533     0.117635   \n",
       "realCount_kfold_5     3963.000000  3459.000000  2939.000000  2295.000000   \n",
       "predictCount_kfold_5  1069.000000   767.000000   572.000000   393.000000   \n",
       "\n",
       "                               12           13          14          15  \\\n",
       "precision_kfold_1        0.562249     0.552448    0.426471    0.282051   \n",
       "recall_kfold_1           0.086154     0.074669    0.047697    0.035948   \n",
       "rocScore_kfold_1         0.884704     0.889110    0.901720    0.900852   \n",
       "accuracy_kfold_1         0.083622     0.054716    0.032421    0.016945   \n",
       "realCount_kfold_1     1625.000000  1058.000000  608.000000  306.000000   \n",
       "predictCount_kfold_1   249.000000   143.000000   68.000000   39.000000   \n",
       "precision_kfold_2        0.591912     0.552795    0.452055    0.343750   \n",
       "recall_kfold_2           0.099077     0.084121    0.052464    0.036066   \n",
       "rocScore_kfold_2         0.892682     0.903449    0.902119    0.905270   \n",
       "accuracy_kfold_2         0.082547     0.054560    0.033333    0.016509   \n",
       "realCount_kfold_2     1625.000000  1058.000000  629.000000  305.000000   \n",
       "predictCount_kfold_2   272.000000   161.000000   73.000000   32.000000   \n",
       "precision_kfold_3        0.584000     0.493333    0.424658    0.250000   \n",
       "recall_kfold_3           0.089626     0.069943    0.050903    0.029412   \n",
       "rocScore_kfold_3         0.892383     0.895695    0.902558    0.892593   \n",
       "accuracy_kfold_3         0.083233     0.055593    0.032517    0.016993   \n",
       "realCount_kfold_3     1629.000000  1058.000000  609.000000  306.000000   \n",
       "predictCount_kfold_3   250.000000   150.000000   73.000000   36.000000   \n",
       "precision_kfold_4        0.597403     0.595041    0.462963    0.315789   \n",
       "recall_kfold_4           0.084923     0.068053    0.041051    0.019355   \n",
       "rocScore_kfold_4         0.883365     0.889854    0.899402    0.899105   \n",
       "accuracy_kfold_4         0.082914     0.054314    0.032168    0.016635   \n",
       "realCount_kfold_4     1625.000000  1058.000000  609.000000  310.000000   \n",
       "predictCount_kfold_4   231.000000   121.000000   54.000000   19.000000   \n",
       "precision_kfold_5        0.523810     0.541935    0.456790    0.375000   \n",
       "recall_kfold_5           0.081231     0.079395    0.060855    0.039344   \n",
       "rocScore_kfold_5         0.890295     0.894963    0.894097    0.904397   \n",
       "accuracy_kfold_5         0.084632     0.054830    0.032268    0.016423   \n",
       "realCount_kfold_5     1625.000000  1058.000000  608.000000  305.000000   \n",
       "predictCount_kfold_5   252.000000   155.000000   81.000000   32.000000   \n",
       "\n",
       "                                  Analysis  \n",
       "precision_kfold_1     threshold continuous  \n",
       "recall_kfold_1        threshold continuous  \n",
       "rocScore_kfold_1      threshold continuous  \n",
       "accuracy_kfold_1      threshold continuous  \n",
       "realCount_kfold_1     threshold continuous  \n",
       "predictCount_kfold_1  threshold continuous  \n",
       "precision_kfold_2     threshold continuous  \n",
       "recall_kfold_2        threshold continuous  \n",
       "rocScore_kfold_2      threshold continuous  \n",
       "accuracy_kfold_2      threshold continuous  \n",
       "realCount_kfold_2     threshold continuous  \n",
       "predictCount_kfold_2  threshold continuous  \n",
       "precision_kfold_3     threshold continuous  \n",
       "recall_kfold_3        threshold continuous  \n",
       "rocScore_kfold_3      threshold continuous  \n",
       "accuracy_kfold_3      threshold continuous  \n",
       "realCount_kfold_3     threshold continuous  \n",
       "predictCount_kfold_3  threshold continuous  \n",
       "precision_kfold_4     threshold continuous  \n",
       "recall_kfold_4        threshold continuous  \n",
       "rocScore_kfold_4      threshold continuous  \n",
       "accuracy_kfold_4      threshold continuous  \n",
       "realCount_kfold_4     threshold continuous  \n",
       "predictCount_kfold_4  threshold continuous  \n",
       "precision_kfold_5     threshold continuous  \n",
       "recall_kfold_5        threshold continuous  \n",
       "rocScore_kfold_5      threshold continuous  \n",
       "accuracy_kfold_5      threshold continuous  \n",
       "realCount_kfold_5     threshold continuous  \n",
       "predictCount_kfold_5  threshold continuous  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So the problem is related to the accuracy\n",
    "masterframe = pd.DataFrame()\n",
    "masterframe.append(small_random_metric_df) #, labelnumbercap_metric_df, threshold_metrics_df)\n",
    "masterframe.append(labelnumbercap_metric_df)\n",
    "masterframe.append(threshold_metrics_df)\n",
    "\n",
    "#for key in featuredict.keys():\n",
    "#    metricdict = StratifiedCVMetrics(X1, y1, featuredict[str(key)])\n",
    "#    metric_df = pd.DataFrame(metricdict)\n",
    "#    metric_df = pd.DataFrame.transpose(metric_df)\n",
    "#    featlist = [str(key)] * 30\n",
    "#    metric_df['Features'] = featlist\n",
    "#    masterframe = masterframe.append(metric_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterframe.to_csv(\"DifferentSamplingStrategyMetrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot Checking the RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0],\n",
       "       [     1],\n",
       "       [     2],\n",
       "       [     3],\n",
       "       ...,\n",
       "       [104816],\n",
       "       [104817],\n",
       "       [104818],\n",
       "       [104819]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make unique keys\n",
    "keys = np.transpose(np.array([range(0, data_df.shape[0])]))\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104820, 1105)\n",
      "(104820, 1104)\n"
     ]
    }
   ],
   "source": [
    "#Attach the keys to the feature array\n",
    "X_keys = np.concatenate((keys, X), axis=1)\n",
    "print(X_keys.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split to just make it faster and in interest of train-test-validate system\n",
    "#Will do it iteratively though. NOTE: iterative_train_test_split can only take in array, not data frame\n",
    "\n",
    "from skmultilearn.model_selection import  iterative_train_test_split\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X_keys, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56877, 1105)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split again so we have values to train the model and to predict it\n",
    "X_keys1, y_1, X_keys2, y_2 = iterative_train_test_split(X_train, y_train, test_size=0.30)\n",
    "X_keys1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24377, 16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiforest = OneVsRestClassifier(RandomForestClassifier(n_estimators = 200, random_state=23), n_jobs=2)#, class_weight='balanced'))\n",
    "\n",
    "multiforest.fit(X_keys1[: , 1:], y_1)\n",
    "\n",
    "predict_probs = multiforest.predict_proba(X_keys2[: , 1:])\n",
    "predict_labels = multiforest.predict(X_keys2[: , 1:])\n",
    "predict_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predict_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27981, 1105)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_keys2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_probs_full = np.concatenate((X_keys2[:, 0:1], predict_labels, predict_probs, y_2), axis=1)\n",
    "predict_probs_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27976, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_data_df = data_df.loc[list(predict_probs_full[:, 0]), ['SeqCharge', 'Charge', 'Sequence']]\n",
    "select_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27976, 52)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gotta reset index for \n",
    "select_data_df = select_data_df.reset_index(drop=True)\n",
    "data_df_predictplus = pd.concat([select_data_df, pd.DataFrame(predict_probs_full)], axis=1, sort=False)\n",
    "data_df_predictplus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqCharge</th>\n",
       "      <th>Charge</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2AACLCFR</td>\n",
       "      <td>2</td>\n",
       "      <td>AACLCFR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3SEQEDEVLLVSSSR</td>\n",
       "      <td>3</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SeqCharge  Charge        Sequence    0    1    2    3    4    5    6  \\\n",
       "0         2AACLCFR       2         AACLCFR  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  3SEQEDEVLLVSSSR       3  SEQEDEVLLVSSSR  2.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   ...     17     18    19    20    21     22    23     24     25    26  \n",
       "0  ...  0.000  0.000  0.03  0.08  0.14  0.245  0.36  0.385  0.400  0.39  \n",
       "1  ...  0.005  0.005  0.12  0.18  0.11  0.145  0.14  0.250  0.445  0.44  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_predictplus.iloc[0:2, 0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_predictplus.to_csv(\"SpotCheckingRFC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the any intensity threshold see a large dip in proportion of peptides that go without labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16987324116995528 instead of ~30%. So cut it down by about half\n"
     ]
    }
   ],
   "source": [
    "print(4141/predict_labels.shape[0], \"instead of ~30%. So cut it down by about half\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     9923\n",
       "4     4424\n",
       "0     4141\n",
       "2     3137\n",
       "1     1799\n",
       "5      644\n",
       "6      167\n",
       "7       82\n",
       "8       44\n",
       "9       12\n",
       "10       2\n",
       "13       1\n",
       "12       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Any intensity threshold\n",
    "#pd.Series(np.sum(predict_labels, axis = 1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9439\n",
       "2    9334\n",
       "3    4543\n",
       "1    3985\n",
       "4     462\n",
       "5     141\n",
       "6      54\n",
       "7      14\n",
       "8       3\n",
       "9       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Median proportional 50% dynamic threshold\n",
    "#predictedlabsums.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedlabsums = predictedlabsums[0]\n",
    "type(predictedlabsums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Dictionary for the multilabel forest without OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 fold split that just collects metrics from each split\n",
    "#Defined above\n",
    "#So could actually make this even more flexible\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "#instantiate the forest and fit it to the subset\n",
    "multiforest = RandomForestClassifier(n_estimators = 200, random_state=23)\n",
    "\n",
    "i = 0\n",
    "\n",
    "metricdict = dict()\n",
    "\n",
    "#Iterative stratification doesn't actually need a random state because I haven't set shuffle =True\n",
    "k_fold = IterativeStratification(n_splits=5, order=2)#, random_state=123)\n",
    "for train, test in k_fold.split(X1, y1):\n",
    "    i = i + 1\n",
    "    #Make dictionary to hold metric arrays\n",
    "    kfold = dict()\n",
    "    \n",
    "    #Train the multiforest using the training indices\n",
    "    multiforest.fit(X1[train], y1[train])\n",
    "    \n",
    "    #Generate predictions\n",
    "    y_predict = multiforest.predict(X1[test])\n",
    "    y_problist = multiforest.predict_proba(X1[test])\n",
    "        \n",
    "    y_predprobs = np.array([[]] *X1[test].shape[0])\n",
    "    for item in y_problist:\n",
    "        y_predprobs = np.concatenate((y_predprobs, np.reshape(item[:, 1], (-1, 1))), axis = 1)\n",
    "    \n",
    "    #Add metric arrays to dictionary keys\n",
    "    metricdict[('precision_kfold_' + str(i))] = precision_score(y1[test], y_predict, average=None)\n",
    "    metricdict[('recall_kfold_' + str(i))] = recall_score(y1[test], y_predict, average=None)\n",
    "    metricdict[('rocScore_kfold_' + str(i))] = roc_auc_score(y1[test], y_predprobs, average=None)\n",
    "    metricdict[('accuracy_kfold_' + str(i))] = np.sum(abs(y1[test] - y_predict), axis = 0) / y1[test].shape[0]\n",
    "    metricdict[('realCount_kfold_' + str(i))] = np.sum(y1[test], axis = 0)\n",
    "    metricdict[('predictCount_kfold_' + str(i))] = np.sum(y_predict, axis = 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_kfold_1</th>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.857731</td>\n",
       "      <td>0.840233</td>\n",
       "      <td>0.757716</td>\n",
       "      <td>0.681721</td>\n",
       "      <td>0.626077</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>0.599846</td>\n",
       "      <td>0.588725</td>\n",
       "      <td>0.565584</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.598985</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.699387</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_1</th>\n",
       "      <td>0.341102</td>\n",
       "      <td>0.643582</td>\n",
       "      <td>0.677547</td>\n",
       "      <td>0.592213</td>\n",
       "      <td>0.504639</td>\n",
       "      <td>0.403801</td>\n",
       "      <td>0.365062</td>\n",
       "      <td>0.304570</td>\n",
       "      <td>0.208816</td>\n",
       "      <td>0.130519</td>\n",
       "      <td>0.113201</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.107852</td>\n",
       "      <td>0.087315</td>\n",
       "      <td>0.055195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_1</th>\n",
       "      <td>0.963028</td>\n",
       "      <td>0.956493</td>\n",
       "      <td>0.933224</td>\n",
       "      <td>0.878836</td>\n",
       "      <td>0.825664</td>\n",
       "      <td>0.788735</td>\n",
       "      <td>0.784179</td>\n",
       "      <td>0.804312</td>\n",
       "      <td>0.816588</td>\n",
       "      <td>0.838700</td>\n",
       "      <td>0.861485</td>\n",
       "      <td>0.886729</td>\n",
       "      <td>0.899888</td>\n",
       "      <td>0.903197</td>\n",
       "      <td>0.916461</td>\n",
       "      <td>0.915232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_1</th>\n",
       "      <td>0.037859</td>\n",
       "      <td>0.056306</td>\n",
       "      <td>0.097866</td>\n",
       "      <td>0.168597</td>\n",
       "      <td>0.223938</td>\n",
       "      <td>0.250429</td>\n",
       "      <td>0.257508</td>\n",
       "      <td>0.245710</td>\n",
       "      <td>0.221150</td>\n",
       "      <td>0.187259</td>\n",
       "      <td>0.155674</td>\n",
       "      <td>0.119262</td>\n",
       "      <td>0.083548</td>\n",
       "      <td>0.053196</td>\n",
       "      <td>0.031639</td>\n",
       "      <td>0.016517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_1</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2267.000000</td>\n",
       "      <td>4044.000000</td>\n",
       "      <td>5265.000000</td>\n",
       "      <td>5713.000000</td>\n",
       "      <td>5577.000000</td>\n",
       "      <td>5484.000000</td>\n",
       "      <td>5099.000000</td>\n",
       "      <td>4401.000000</td>\n",
       "      <td>3601.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2302.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>1057.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_1</th>\n",
       "      <td>406.000000</td>\n",
       "      <td>1701.000000</td>\n",
       "      <td>3261.000000</td>\n",
       "      <td>4115.000000</td>\n",
       "      <td>4229.000000</td>\n",
       "      <td>3597.000000</td>\n",
       "      <td>3322.000000</td>\n",
       "      <td>2589.000000</td>\n",
       "      <td>1561.000000</td>\n",
       "      <td>831.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_2</th>\n",
       "      <td>0.772379</td>\n",
       "      <td>0.851076</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.758946</td>\n",
       "      <td>0.680743</td>\n",
       "      <td>0.631206</td>\n",
       "      <td>0.617736</td>\n",
       "      <td>0.590202</td>\n",
       "      <td>0.578023</td>\n",
       "      <td>0.561305</td>\n",
       "      <td>0.586847</td>\n",
       "      <td>0.589873</td>\n",
       "      <td>0.625498</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.342105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_2</th>\n",
       "      <td>0.319915</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.672107</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.493873</td>\n",
       "      <td>0.398960</td>\n",
       "      <td>0.372174</td>\n",
       "      <td>0.297647</td>\n",
       "      <td>0.202045</td>\n",
       "      <td>0.138611</td>\n",
       "      <td>0.116896</td>\n",
       "      <td>0.101172</td>\n",
       "      <td>0.096437</td>\n",
       "      <td>0.090823</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.042345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_2</th>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.958953</td>\n",
       "      <td>0.936451</td>\n",
       "      <td>0.878383</td>\n",
       "      <td>0.821275</td>\n",
       "      <td>0.784161</td>\n",
       "      <td>0.781308</td>\n",
       "      <td>0.796571</td>\n",
       "      <td>0.818705</td>\n",
       "      <td>0.844476</td>\n",
       "      <td>0.868037</td>\n",
       "      <td>0.885817</td>\n",
       "      <td>0.896301</td>\n",
       "      <td>0.900844</td>\n",
       "      <td>0.909024</td>\n",
       "      <td>0.912283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_2</th>\n",
       "      <td>0.039192</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.099078</td>\n",
       "      <td>0.167382</td>\n",
       "      <td>0.225928</td>\n",
       "      <td>0.249410</td>\n",
       "      <td>0.252305</td>\n",
       "      <td>0.248552</td>\n",
       "      <td>0.223032</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.154085</td>\n",
       "      <td>0.119665</td>\n",
       "      <td>0.083905</td>\n",
       "      <td>0.054847</td>\n",
       "      <td>0.032436</td>\n",
       "      <td>0.017103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_2</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>4044.000000</td>\n",
       "      <td>5264.000000</td>\n",
       "      <td>5712.000000</td>\n",
       "      <td>5577.000000</td>\n",
       "      <td>5484.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>4400.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2303.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>1057.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_2</th>\n",
       "      <td>391.000000</td>\n",
       "      <td>1719.000000</td>\n",
       "      <td>3240.000000</td>\n",
       "      <td>4136.000000</td>\n",
       "      <td>4144.000000</td>\n",
       "      <td>3525.000000</td>\n",
       "      <td>3304.000000</td>\n",
       "      <td>2572.000000</td>\n",
       "      <td>1538.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>593.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_3</th>\n",
       "      <td>0.784173</td>\n",
       "      <td>0.829226</td>\n",
       "      <td>0.821087</td>\n",
       "      <td>0.754063</td>\n",
       "      <td>0.686091</td>\n",
       "      <td>0.631383</td>\n",
       "      <td>0.615292</td>\n",
       "      <td>0.604325</td>\n",
       "      <td>0.585733</td>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.622871</td>\n",
       "      <td>0.624506</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_3</th>\n",
       "      <td>0.346398</td>\n",
       "      <td>0.638007</td>\n",
       "      <td>0.679941</td>\n",
       "      <td>0.590503</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.394586</td>\n",
       "      <td>0.372789</td>\n",
       "      <td>0.312414</td>\n",
       "      <td>0.203409</td>\n",
       "      <td>0.134685</td>\n",
       "      <td>0.116896</td>\n",
       "      <td>0.111159</td>\n",
       "      <td>0.097052</td>\n",
       "      <td>0.089877</td>\n",
       "      <td>0.066343</td>\n",
       "      <td>0.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_3</th>\n",
       "      <td>0.966907</td>\n",
       "      <td>0.957104</td>\n",
       "      <td>0.934236</td>\n",
       "      <td>0.881009</td>\n",
       "      <td>0.828050</td>\n",
       "      <td>0.786357</td>\n",
       "      <td>0.786153</td>\n",
       "      <td>0.802797</td>\n",
       "      <td>0.819467</td>\n",
       "      <td>0.837540</td>\n",
       "      <td>0.864001</td>\n",
       "      <td>0.883033</td>\n",
       "      <td>0.898628</td>\n",
       "      <td>0.907575</td>\n",
       "      <td>0.913552</td>\n",
       "      <td>0.913405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_3</th>\n",
       "      <td>0.037889</td>\n",
       "      <td>0.059968</td>\n",
       "      <td>0.101447</td>\n",
       "      <td>0.169882</td>\n",
       "      <td>0.222990</td>\n",
       "      <td>0.249839</td>\n",
       "      <td>0.252787</td>\n",
       "      <td>0.243783</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.184673</td>\n",
       "      <td>0.153323</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>0.083869</td>\n",
       "      <td>0.054555</td>\n",
       "      <td>0.032422</td>\n",
       "      <td>0.016131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_3</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>4043.000000</td>\n",
       "      <td>5265.000000</td>\n",
       "      <td>5713.000000</td>\n",
       "      <td>5578.000000</td>\n",
       "      <td>5483.000000</td>\n",
       "      <td>5099.000000</td>\n",
       "      <td>4400.000000</td>\n",
       "      <td>3601.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2303.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>1057.000000</td>\n",
       "      <td>618.000000</td>\n",
       "      <td>308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_3</th>\n",
       "      <td>417.000000</td>\n",
       "      <td>1745.000000</td>\n",
       "      <td>3348.000000</td>\n",
       "      <td>4123.000000</td>\n",
       "      <td>4170.000000</td>\n",
       "      <td>3486.000000</td>\n",
       "      <td>3322.000000</td>\n",
       "      <td>2636.000000</td>\n",
       "      <td>1528.000000</td>\n",
       "      <td>815.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_4</th>\n",
       "      <td>0.800971</td>\n",
       "      <td>0.845974</td>\n",
       "      <td>0.835241</td>\n",
       "      <td>0.758514</td>\n",
       "      <td>0.704906</td>\n",
       "      <td>0.626989</td>\n",
       "      <td>0.608947</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.579589</td>\n",
       "      <td>0.550575</td>\n",
       "      <td>0.589189</td>\n",
       "      <td>0.604278</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.585034</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.431818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_4</th>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.639330</td>\n",
       "      <td>0.685707</td>\n",
       "      <td>0.605053</td>\n",
       "      <td>0.505514</td>\n",
       "      <td>0.395732</td>\n",
       "      <td>0.364946</td>\n",
       "      <td>0.303785</td>\n",
       "      <td>0.205181</td>\n",
       "      <td>0.133056</td>\n",
       "      <td>0.109842</td>\n",
       "      <td>0.098175</td>\n",
       "      <td>0.083487</td>\n",
       "      <td>0.081362</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>0.061688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_4</th>\n",
       "      <td>0.967368</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.934719</td>\n",
       "      <td>0.883483</td>\n",
       "      <td>0.827601</td>\n",
       "      <td>0.786184</td>\n",
       "      <td>0.791297</td>\n",
       "      <td>0.806439</td>\n",
       "      <td>0.823938</td>\n",
       "      <td>0.842489</td>\n",
       "      <td>0.874528</td>\n",
       "      <td>0.890425</td>\n",
       "      <td>0.896831</td>\n",
       "      <td>0.907015</td>\n",
       "      <td>0.910957</td>\n",
       "      <td>0.915473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_4</th>\n",
       "      <td>0.037401</td>\n",
       "      <td>0.058060</td>\n",
       "      <td>0.097553</td>\n",
       "      <td>0.165969</td>\n",
       "      <td>0.216463</td>\n",
       "      <td>0.251288</td>\n",
       "      <td>0.255795</td>\n",
       "      <td>0.245493</td>\n",
       "      <td>0.222848</td>\n",
       "      <td>0.188452</td>\n",
       "      <td>0.154432</td>\n",
       "      <td>0.119339</td>\n",
       "      <td>0.085050</td>\n",
       "      <td>0.055377</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.016849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_4</th>\n",
       "      <td>945.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>4044.000000</td>\n",
       "      <td>5264.000000</td>\n",
       "      <td>5713.000000</td>\n",
       "      <td>5577.000000</td>\n",
       "      <td>5483.000000</td>\n",
       "      <td>5099.000000</td>\n",
       "      <td>4401.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2302.000000</td>\n",
       "      <td>1629.000000</td>\n",
       "      <td>1057.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_4</th>\n",
       "      <td>412.000000</td>\n",
       "      <td>1714.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>4199.000000</td>\n",
       "      <td>4097.000000</td>\n",
       "      <td>3520.000000</td>\n",
       "      <td>3286.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>1558.000000</td>\n",
       "      <td>870.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_kfold_5</th>\n",
       "      <td>0.765172</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.844933</td>\n",
       "      <td>0.746486</td>\n",
       "      <td>0.690980</td>\n",
       "      <td>0.630156</td>\n",
       "      <td>0.623544</td>\n",
       "      <td>0.607352</td>\n",
       "      <td>0.572959</td>\n",
       "      <td>0.567961</td>\n",
       "      <td>0.535902</td>\n",
       "      <td>0.609948</td>\n",
       "      <td>0.582329</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_kfold_5</th>\n",
       "      <td>0.307203</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>0.684471</td>\n",
       "      <td>0.595175</td>\n",
       "      <td>0.497549</td>\n",
       "      <td>0.397167</td>\n",
       "      <td>0.370897</td>\n",
       "      <td>0.304510</td>\n",
       "      <td>0.194545</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.102788</td>\n",
       "      <td>0.100431</td>\n",
       "      <td>0.089012</td>\n",
       "      <td>0.094620</td>\n",
       "      <td>0.074013</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocScore_kfold_5</th>\n",
       "      <td>0.965547</td>\n",
       "      <td>0.958554</td>\n",
       "      <td>0.936680</td>\n",
       "      <td>0.875317</td>\n",
       "      <td>0.824743</td>\n",
       "      <td>0.784188</td>\n",
       "      <td>0.790422</td>\n",
       "      <td>0.801493</td>\n",
       "      <td>0.820076</td>\n",
       "      <td>0.843616</td>\n",
       "      <td>0.863581</td>\n",
       "      <td>0.884154</td>\n",
       "      <td>0.896127</td>\n",
       "      <td>0.901676</td>\n",
       "      <td>0.915381</td>\n",
       "      <td>0.917941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_kfold_5</th>\n",
       "      <td>0.039771</td>\n",
       "      <td>0.058131</td>\n",
       "      <td>0.095493</td>\n",
       "      <td>0.171020</td>\n",
       "      <td>0.221657</td>\n",
       "      <td>0.249545</td>\n",
       "      <td>0.250401</td>\n",
       "      <td>0.243603</td>\n",
       "      <td>0.223852</td>\n",
       "      <td>0.186704</td>\n",
       "      <td>0.157157</td>\n",
       "      <td>0.119687</td>\n",
       "      <td>0.085002</td>\n",
       "      <td>0.055026</td>\n",
       "      <td>0.031742</td>\n",
       "      <td>0.016058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realCount_kfold_5</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2267.000000</td>\n",
       "      <td>4044.000000</td>\n",
       "      <td>5264.000000</td>\n",
       "      <td>5712.000000</td>\n",
       "      <td>5577.000000</td>\n",
       "      <td>5484.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>4400.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>2977.000000</td>\n",
       "      <td>2320.000000</td>\n",
       "      <td>1629.000000</td>\n",
       "      <td>1078.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictCount_kfold_5</th>\n",
       "      <td>379.000000</td>\n",
       "      <td>1707.000000</td>\n",
       "      <td>3276.000000</td>\n",
       "      <td>4197.000000</td>\n",
       "      <td>4113.000000</td>\n",
       "      <td>3515.000000</td>\n",
       "      <td>3262.000000</td>\n",
       "      <td>2557.000000</td>\n",
       "      <td>1494.000000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>571.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0            1            2            3  \\\n",
       "precision_kfold_1       0.793103     0.857731     0.840233     0.757716   \n",
       "recall_kfold_1          0.341102     0.643582     0.677547     0.592213   \n",
       "rocScore_kfold_1        0.963028     0.956493     0.933224     0.878836   \n",
       "accuracy_kfold_1        0.037859     0.056306     0.097866     0.168597   \n",
       "realCount_kfold_1     944.000000  2267.000000  4044.000000  5265.000000   \n",
       "predictCount_kfold_1  406.000000  1701.000000  3261.000000  4115.000000   \n",
       "precision_kfold_2       0.772379     0.851076     0.838889     0.758946   \n",
       "recall_kfold_2          0.319915     0.645062     0.672107     0.596315   \n",
       "rocScore_kfold_2        0.969554     0.958953     0.936451     0.878383   \n",
       "accuracy_kfold_2        0.039192     0.056884     0.099078     0.167382   \n",
       "realCount_kfold_2     944.000000  2268.000000  4044.000000  5264.000000   \n",
       "predictCount_kfold_2  391.000000  1719.000000  3240.000000  4136.000000   \n",
       "precision_kfold_3       0.784173     0.829226     0.821087     0.754063   \n",
       "recall_kfold_3          0.346398     0.638007     0.679941     0.590503   \n",
       "rocScore_kfold_3        0.966907     0.957104     0.934236     0.881009   \n",
       "accuracy_kfold_3        0.037889     0.059968     0.101447     0.169882   \n",
       "realCount_kfold_3     944.000000  2268.000000  4043.000000  5265.000000   \n",
       "predictCount_kfold_3  417.000000  1745.000000  3348.000000  4123.000000   \n",
       "precision_kfold_4       0.800971     0.845974     0.835241     0.758514   \n",
       "recall_kfold_4          0.349206     0.639330     0.685707     0.605053   \n",
       "rocScore_kfold_4        0.967368     0.959021     0.934719     0.883483   \n",
       "accuracy_kfold_4        0.037401     0.058060     0.097553     0.165969   \n",
       "realCount_kfold_4     945.000000  2268.000000  4044.000000  5264.000000   \n",
       "predictCount_kfold_4  412.000000  1714.000000  3320.000000  4199.000000   \n",
       "precision_kfold_5       0.765172     0.845929     0.844933     0.746486   \n",
       "recall_kfold_5          0.307203     0.636965     0.684471     0.595175   \n",
       "rocScore_kfold_5        0.965547     0.958554     0.936680     0.875317   \n",
       "accuracy_kfold_5        0.039771     0.058131     0.095493     0.171020   \n",
       "realCount_kfold_5     944.000000  2267.000000  4044.000000  5264.000000   \n",
       "predictCount_kfold_5  379.000000  1707.000000  3276.000000  4197.000000   \n",
       "\n",
       "                                4            5            6            7  \\\n",
       "precision_kfold_1        0.681721     0.626077     0.602649     0.599846   \n",
       "recall_kfold_1           0.504639     0.403801     0.365062     0.304570   \n",
       "rocScore_kfold_1         0.825664     0.788735     0.784179     0.804312   \n",
       "accuracy_kfold_1         0.223938     0.250429     0.257508     0.245710   \n",
       "realCount_kfold_1     5713.000000  5577.000000  5484.000000  5099.000000   \n",
       "predictCount_kfold_1  4229.000000  3597.000000  3322.000000  2589.000000   \n",
       "precision_kfold_2        0.680743     0.631206     0.617736     0.590202   \n",
       "recall_kfold_2           0.493873     0.398960     0.372174     0.297647   \n",
       "rocScore_kfold_2         0.821275     0.784161     0.781308     0.796571   \n",
       "accuracy_kfold_2         0.225928     0.249410     0.252305     0.248552   \n",
       "realCount_kfold_2     5712.000000  5577.000000  5484.000000  5100.000000   \n",
       "predictCount_kfold_2  4144.000000  3525.000000  3304.000000  2572.000000   \n",
       "precision_kfold_3        0.686091     0.631383     0.615292     0.604325   \n",
       "recall_kfold_3           0.500788     0.394586     0.372789     0.312414   \n",
       "rocScore_kfold_3         0.828050     0.786357     0.786153     0.802797   \n",
       "accuracy_kfold_3         0.222990     0.249839     0.252787     0.243783   \n",
       "realCount_kfold_3     5713.000000  5578.000000  5483.000000  5099.000000   \n",
       "predictCount_kfold_3  4170.000000  3486.000000  3322.000000  2636.000000   \n",
       "precision_kfold_4        0.704906     0.626989     0.608947     0.601787   \n",
       "recall_kfold_4           0.505514     0.395732     0.364946     0.303785   \n",
       "rocScore_kfold_4         0.827601     0.786184     0.791297     0.806439   \n",
       "accuracy_kfold_4         0.216463     0.251288     0.255795     0.245493   \n",
       "realCount_kfold_4     5713.000000  5577.000000  5483.000000  5099.000000   \n",
       "predictCount_kfold_4  4097.000000  3520.000000  3286.000000  2574.000000   \n",
       "precision_kfold_5        0.690980     0.630156     0.623544     0.607352   \n",
       "recall_kfold_5           0.497549     0.397167     0.370897     0.304510   \n",
       "rocScore_kfold_5         0.824743     0.784188     0.790422     0.801493   \n",
       "accuracy_kfold_5         0.221657     0.249545     0.250401     0.243603   \n",
       "realCount_kfold_5     5712.000000  5577.000000  5484.000000  5100.000000   \n",
       "predictCount_kfold_5  4113.000000  3515.000000  3262.000000  2557.000000   \n",
       "\n",
       "                                8            9           10           11  \\\n",
       "precision_kfold_1        0.588725     0.565584     0.561667     0.598985   \n",
       "recall_kfold_1           0.208816     0.130519     0.113201     0.102520   \n",
       "rocScore_kfold_1         0.816588     0.838700     0.861485     0.886729   \n",
       "accuracy_kfold_1         0.221150     0.187259     0.155674     0.119262   \n",
       "realCount_kfold_1     4401.000000  3601.000000  2977.000000  2302.000000   \n",
       "predictCount_kfold_1  1561.000000   831.000000   600.000000   394.000000   \n",
       "precision_kfold_2        0.578023     0.561305     0.586847     0.589873   \n",
       "recall_kfold_2           0.202045     0.138611     0.116896     0.101172   \n",
       "rocScore_kfold_2         0.818705     0.844476     0.868037     0.885817   \n",
       "accuracy_kfold_2         0.223032     0.187165     0.154085     0.119665   \n",
       "realCount_kfold_2     4400.000000  3600.000000  2977.000000  2303.000000   \n",
       "predictCount_kfold_2  1538.000000   889.000000   593.000000   395.000000   \n",
       "precision_kfold_3        0.585733     0.595092     0.600000     0.622871   \n",
       "recall_kfold_3           0.203409     0.134685     0.116896     0.111159   \n",
       "rocScore_kfold_3         0.819467     0.837540     0.864001     0.883033   \n",
       "accuracy_kfold_3         0.221758     0.184673     0.153323     0.118006   \n",
       "realCount_kfold_3     4400.000000  3601.000000  2977.000000  2303.000000   \n",
       "predictCount_kfold_3  1528.000000   815.000000   580.000000   411.000000   \n",
       "precision_kfold_4        0.579589     0.550575     0.589189     0.604278   \n",
       "recall_kfold_4           0.205181     0.133056     0.109842     0.098175   \n",
       "rocScore_kfold_4         0.823938     0.842489     0.874528     0.890425   \n",
       "accuracy_kfold_4         0.222848     0.188452     0.154432     0.119339   \n",
       "realCount_kfold_4     4401.000000  3600.000000  2977.000000  2302.000000   \n",
       "predictCount_kfold_4  1558.000000   870.000000   555.000000   374.000000   \n",
       "precision_kfold_5        0.572959     0.567961     0.535902     0.609948   \n",
       "recall_kfold_5           0.194545     0.130000     0.102788     0.100431   \n",
       "rocScore_kfold_5         0.820076     0.843616     0.863581     0.884154   \n",
       "accuracy_kfold_5         0.223852     0.186704     0.157157     0.119687   \n",
       "realCount_kfold_5     4400.000000  3600.000000  2977.000000  2320.000000   \n",
       "predictCount_kfold_5  1494.000000   824.000000   571.000000   382.000000   \n",
       "\n",
       "                               12           13          14          15  \n",
       "precision_kfold_1        0.647059     0.699387    0.595506    0.500000  \n",
       "recall_kfold_1           0.094595     0.107852    0.087315    0.055195  \n",
       "rocScore_kfold_1         0.899888     0.903197    0.916461    0.915232  \n",
       "accuracy_kfold_1         0.083548     0.053196    0.031639    0.016517  \n",
       "realCount_kfold_1     1628.000000  1057.000000  607.000000  308.000000  \n",
       "predictCount_kfold_1   238.000000   163.000000   89.000000   34.000000  \n",
       "precision_kfold_2        0.625498     0.607595    0.542169    0.342105  \n",
       "recall_kfold_2           0.096437     0.090823    0.073529    0.042345  \n",
       "rocScore_kfold_2         0.896301     0.900844    0.909024    0.912283  \n",
       "accuracy_kfold_2         0.083905     0.054847    0.032436    0.017103  \n",
       "realCount_kfold_2     1628.000000  1057.000000  612.000000  307.000000  \n",
       "predictCount_kfold_2   251.000000   158.000000   83.000000   38.000000  \n",
       "precision_kfold_3        0.624506     0.629139    0.594203    0.606061  \n",
       "recall_kfold_3           0.097052     0.089877    0.066343    0.064935  \n",
       "rocScore_kfold_3         0.898628     0.907575    0.913552    0.913405  \n",
       "accuracy_kfold_3         0.083869     0.054555    0.032422    0.016131  \n",
       "realCount_kfold_3     1628.000000  1057.000000  618.000000  308.000000  \n",
       "predictCount_kfold_3   253.000000   151.000000   69.000000   33.000000  \n",
       "precision_kfold_4        0.596491     0.585034    0.644737    0.431818  \n",
       "recall_kfold_4           0.083487     0.081362    0.080592    0.061688  \n",
       "rocScore_kfold_4         0.896831     0.907015    0.910957    0.915473  \n",
       "accuracy_kfold_4         0.085050     0.055377    0.031445    0.016849  \n",
       "realCount_kfold_4     1629.000000  1057.000000  608.000000  308.000000  \n",
       "predictCount_kfold_4   228.000000   147.000000   76.000000   44.000000  \n",
       "precision_kfold_5        0.582329     0.662338    0.600000    0.666667  \n",
       "recall_kfold_5           0.089012     0.094620    0.074013    0.064516  \n",
       "rocScore_kfold_5         0.896127     0.901676    0.915381    0.917941  \n",
       "accuracy_kfold_5         0.085002     0.055026    0.031742    0.016058  \n",
       "realCount_kfold_5     1629.000000  1078.000000  608.000000  310.000000  \n",
       "predictCount_kfold_5   249.000000   154.000000   75.000000   30.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "innaterfc_metrics_df = np.transpose(pd.DataFrame(metricdict))\n",
    "innaterfc_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking about what we want the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.transpose(np.array([range(0, data_df.shape[0])]))\n",
    "X_keys = np.concatenate((keys, X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85990, 1105)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the 50%+ threshold data into train and test keeping label distribution proportional\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X_keys, y, test_size=0.30)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling out training data to allow for other thresholds to be applied\n",
    "fulltraining = pd.concat((pd.DataFrame(y_train), data_df.loc[X_train[:, 0],['Sequence','Charge', 'SeqCharge']].reset_index(drop=True), pd.DataFrame(X_train)), axis=1)\n",
    "fulltraining.to_csv(\"50percentplusTraining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling out test data to test those other thresholds\n",
    "fulltesting = pd.concat((pd.DataFrame(y_test), data_df.loc[X_test[:, 0],['Sequence','Charge', 'SeqCharge']].reset_index(drop=True), pd.DataFrame(X_test)), axis=1)\n",
    "fulltesting.to_csv(\"50percentplusTesting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiforest = OneVsRestClassifier(RandomForestClassifier(n_estimators = 200, random_state=23), n_jobs=2)\n",
    "multiforest.fit(X_train[:, 1:], y_train)\n",
    "\n",
    "predictedlabels = multiforest.predict(X_test[:, 1:])\n",
    "predictprobs = multiforest.predict_proba(X_test[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4413001600781398"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Almost 50% of peptides then end up with no labels\n",
    "pd.Series(np.sum(predictedlabels, axis = 1)).value_counts()[0] / predictedlabels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5550666863724357\n",
      "Recall:  0.376041971823484\n",
      "F2:  tensor(0.4649)\n",
      "ROC AUC Score:  0.832460820380697\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", precision_score(y_test, predictedlabels, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, predictedlabels, average='weighted'))\n",
    "print(\"F2: \", fbeta(np2model_tensor(predictprobs), np2model_tensor(y_test), beta=2, thresh=0.5))\n",
    "print(\"ROC AUC Score: \", roc_auc_score(y_test, predictprobs, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  [0.565217 0.811295 0.790083 0.72961  0.686147 0.629434 0.61414  0.591301 0.520235 0.430636 0.565104 0.580994 0.491667\n",
      " 0.457447 0.297872 0.315789]\n",
      "Recall:  [0.059633 0.372078 0.523434 0.464137 0.45716  0.356171 0.29211  0.201767 0.129773 0.070616 0.097397 0.088545 0.061748\n",
      " 0.039963 0.023372 0.020548]\n",
      "ROC AUC Score:  [0.965561 0.966198 0.939953 0.885261 0.83223  0.789386 0.776454 0.791669 0.801569 0.81803  0.85998  0.876704 0.890677\n",
      " 0.899746 0.893891 0.891377]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", precision_score(y_test, predictedlabels, average=None))\n",
    "print(\"Recall: \", recall_score(y_test, predictedlabels, average=None))\n",
    "print(\"ROC AUC Score: \", roc_auc_score(y_test, predictprobs, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  23,  726, 3025, 4745, 6742, 5864, 4696, 2897, 1705,  692,  768,  463,  240,   94,   47,   19])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictedlabels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add layer that will label completely unlabelled peptides\n",
    "def fill_unlabelled(predictedlabels, predictprobs): \n",
    "    labelsums = np.sum(predictedlabels, axis = 1)\n",
    "    maxcol = np.argmax(predictprobs[: , :], axis=1)\n",
    "    for row in range(0, predictedlabels.shape[0]):\n",
    "        if(labelsums[row] == 0):\n",
    "            predictedlabels[row, maxcol[row]] = 1\n",
    "    return(predictedlabels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  89, 1001, 3560, 5629, 8441, 7883, 7394, 6287, 4123,  906, 2500,  700,  280,  121,   70,   27])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictedlabels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5550666863724357\n",
      "Recall:  0.376041971823484\n",
      "ROC AUC Score:  0.832460820380697\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", precision_score(y_test, predictedlabels, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, predictedlabels, average='weighted'))\n",
    "print(\"ROC AUC Score: \", roc_auc_score(y_test, predictprobs, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  [0.179775 0.727273 0.739045 0.695683 0.639261 0.573766 0.542737 0.490377 0.445549 0.389625 0.4672   0.514286 0.467857\n",
      " 0.454545 0.3      0.333333]\n",
      "Recall:  [0.073394 0.459886 0.576216 0.525003 0.533254 0.436457 0.406462 0.363133 0.268764 0.083649 0.262118 0.118499 0.06855\n",
      " 0.051115 0.035058 0.030822]\n",
      "ROC AUC Score:  [0.965561 0.966198 0.939953 0.885261 0.83223  0.789386 0.776454 0.791669 0.801569 0.81803  0.85998  0.876704 0.890677\n",
      " 0.899746 0.893891 0.891377]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", precision_score(y_test, predictedlabels, average=None))\n",
    "print(\"Recall: \", recall_score(y_test, predictedlabels, average=None))\n",
    "print(\"ROC AUC Score: \", roc_auc_score(y_test, predictprobs, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Natural non-OVR RFC\n",
    "multiforest = RandomForestClassifier(n_estimators = 200, random_state=23)\n",
    "multiforest.fit(X_train[:, 1:], y_train)\n",
    "\n",
    "y_predictedlabels = multiforest.predict(X_test[:, 1:])\n",
    "y_problist = multiforest.predict_proba(X_test[:, 1:])\n",
    "\n",
    "y_predprobs = np.array([[]] *X_test.shape[0])\n",
    "for item in y_problist:\n",
    "    y_predprobs = np.concatenate((y_predprobs, np.reshape(item[:, 1], (-1, 1))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6347340293696658\n",
      "Recall:  0.2932168632986231\n",
      "ROC AUC Score:  0.8409962767860546\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", precision_score(y_test, y_predictedlabels, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, y_predictedlabels, average='weighted'))\n",
    "print(\"ROC AUC Score: \", roc_auc_score(y_test, y_predprobs, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44007922511327563"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.sum(y_predictedlabels, axis = 1)).value_counts()[0] / y_predictedlabels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictedlabelsed = fill_unlabelled(y_predictedlabels, y_predprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5760837639711667\n",
      "Recall:  0.386468348025247\n",
      "ROC AUC Score:  0.8409962767860546\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", precision_score(y_test, y_predictedlabelsed, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, y_predictedlabelsed, average='weighted'))\n",
    "print(\"ROC AUC Score: \", roc_auc_score(y_test, y_predprobs, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>50</th>\n",
       "      <th>55</th>\n",
       "      <th>60</th>\n",
       "      <th>65</th>\n",
       "      <th>70</th>\n",
       "      <th>75</th>\n",
       "      <th>80</th>\n",
       "      <th>85</th>\n",
       "      <th>90</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.739045</td>\n",
       "      <td>0.695683</td>\n",
       "      <td>0.639261</td>\n",
       "      <td>0.573766</td>\n",
       "      <td>0.542737</td>\n",
       "      <td>0.490377</td>\n",
       "      <td>0.445549</td>\n",
       "      <td>0.389625</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.467857</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.073394</td>\n",
       "      <td>0.459886</td>\n",
       "      <td>0.576216</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.533254</td>\n",
       "      <td>0.436457</td>\n",
       "      <td>0.406462</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.268764</td>\n",
       "      <td>0.083649</td>\n",
       "      <td>0.262118</td>\n",
       "      <td>0.118499</td>\n",
       "      <td>0.068550</td>\n",
       "      <td>0.051115</td>\n",
       "      <td>0.035058</td>\n",
       "      <td>0.030822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.965561</td>\n",
       "      <td>0.966198</td>\n",
       "      <td>0.939953</td>\n",
       "      <td>0.885261</td>\n",
       "      <td>0.832230</td>\n",
       "      <td>0.789386</td>\n",
       "      <td>0.776454</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.801569</td>\n",
       "      <td>0.818030</td>\n",
       "      <td>0.859980</td>\n",
       "      <td>0.876704</td>\n",
       "      <td>0.890677</td>\n",
       "      <td>0.899746</td>\n",
       "      <td>0.893891</td>\n",
       "      <td>0.891377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_count</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>3560.000000</td>\n",
       "      <td>5629.000000</td>\n",
       "      <td>8441.000000</td>\n",
       "      <td>7883.000000</td>\n",
       "      <td>7394.000000</td>\n",
       "      <td>6287.000000</td>\n",
       "      <td>4123.000000</td>\n",
       "      <td>906.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real_count</th>\n",
       "      <td>218.000000</td>\n",
       "      <td>1583.000000</td>\n",
       "      <td>4566.000000</td>\n",
       "      <td>7459.000000</td>\n",
       "      <td>10119.000000</td>\n",
       "      <td>10363.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>8490.000000</td>\n",
       "      <td>6835.000000</td>\n",
       "      <td>4220.000000</td>\n",
       "      <td>4456.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>1911.000000</td>\n",
       "      <td>1076.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>292.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       20           25           30           35  \\\n",
       "precision        0.179775     0.727273     0.739045     0.695683   \n",
       "recall           0.073394     0.459886     0.576216     0.525003   \n",
       "roc_auc          0.965561     0.966198     0.939953     0.885261   \n",
       "predict_count   89.000000  1001.000000  3560.000000  5629.000000   \n",
       "real_count     218.000000  1583.000000  4566.000000  7459.000000   \n",
       "\n",
       "                         40            45           50           55  \\\n",
       "precision          0.639261      0.573766     0.542737     0.490377   \n",
       "recall             0.533254      0.436457     0.406462     0.363133   \n",
       "roc_auc            0.832230      0.789386     0.776454     0.791669   \n",
       "predict_count   8441.000000   7883.000000  7394.000000  6287.000000   \n",
       "real_count     10119.000000  10363.000000  9873.000000  8490.000000   \n",
       "\n",
       "                        60           65           70           75  \\\n",
       "precision         0.445549     0.389625     0.467200     0.514286   \n",
       "recall            0.268764     0.083649     0.262118     0.118499   \n",
       "roc_auc           0.801569     0.818030     0.859980     0.876704   \n",
       "predict_count  4123.000000   906.000000  2500.000000   700.000000   \n",
       "real_count     6835.000000  4220.000000  4456.000000  3038.000000   \n",
       "\n",
       "                        80           85          90          95  \n",
       "precision         0.467857     0.454545    0.300000    0.333333  \n",
       "recall            0.068550     0.051115    0.035058    0.030822  \n",
       "roc_auc           0.890677     0.899746    0.893891    0.891377  \n",
       "predict_count   280.000000   121.000000   70.000000   27.000000  \n",
       "real_count     1911.000000  1076.000000  599.000000  292.000000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using OVR Classifier\n",
    "precision = pd.DataFrame(precision_score(y_test, predictedlabels, average=None))\n",
    "recall = pd.DataFrame(recall_score(y_test, predictedlabels, average=None))\n",
    "roc_auc = pd.DataFrame(roc_auc_score(y_test, predictprobs, average=None))\n",
    "#f2_score = fbeta\n",
    "predict_count = pd.DataFrame(np.sum(predictedlabels, axis=0))\n",
    "real_count = pd.DataFrame(np.sum(y_test, axis=0) )\n",
    "\n",
    "metric_df = (pd.concat((precision, recall, roc_auc, predict_count, real_count), axis=1)).transpose()\n",
    "metric_df.index = ['precision', 'recall', 'roc_auc', 'predict_count', 'real_count']\n",
    "metric_df.columns = [list(range(20, 100, 5))]\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Calibrating Prediction Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from matplotlib import pyplot\n",
    "# reliability diagram for CV30 which has pretty good predicitons\n",
    "fop, mpv = calibration_curve(y_test[:, 2], predictprobs[:, 2], n_bins=10)\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reliability diagram for CV20 which has worse predictions\n",
    "fop, mpv = calibration_curve(y_test[:, 0], predictprobs[:, 0], n_bins=10)\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reliability diagram for CV50 which has worst ROCAUC\n",
    "fop, mpv = calibration_curve(y_test[:, 6], predictprobs[:, 6], n_bins=10)\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reliability diagram for CV90 which has bad recall like 20\n",
    "fop, mpv = calibration_curve(y_test[:, 14], predictprobs[:, 14], n_bins=10)\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reliability diagram for CV65 which should be an underestimate, so above the diagonal\n",
    "fop, mpv = calibration_curve(y_test[:, 9], predictprobs[:, 9], n_bins=10)\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5652173913043478\n",
      "Recall:  0.05963302752293578\n",
      "ROC AUC:  0.9655609616363572\n",
      "Predict Count:  23\n",
      "Real Count:  218\n"
     ]
    }
   ],
   "source": [
    "#Single label training for just CV20\n",
    "forest_20 = RandomForestClassifier(n_estimators=200, random_state=23)\n",
    "forest_20.fit(X_train[:, 1:], y_train[:, 0])\n",
    "\n",
    "predict20 = forest_20.predict(X_test[:, 1:])\n",
    "predprob20 = forest_20.predict_proba(X_test[:, 1:])\n",
    "\n",
    "print('Precision: ', precision_score(y_test[:, 0], predict20))\n",
    "print('Recall: ', recall_score(y_test[:, 0], predict20))\n",
    "print('ROC AUC: ', roc_auc_score(y_test[:, 0], predprob20[:, 1]))\n",
    "print('Predict Count: ', np.sum(predict20, axis = 0))\n",
    "print('Real Count: ', np.sum(y_test[:, 0], axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reliability diagram for CV20 which has worse predictions\n",
    "fop, mpv = calibration_curve(y_test[:, 0], predprob20[:, 1], n_bins=10)\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Feed the model into calibration classifier which makes new model\n",
    "calibrated = CalibratedClassifierCV(forest_20, method='sigmoid', cv=5)\n",
    "#Fitting that new model\n",
    "calibrated.fit(X_train[:, 1:], y_train[:, 0])\n",
    "# predict probabilities\n",
    "probs = calibrated.predict_proba(X_test[:, 1:])[:, 1]\n",
    "# reliability diagram\n",
    "fop, mpv = calibration_curve(y_test[:, 0], probs, n_bins=10, normalize=True)\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot calibrated reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
