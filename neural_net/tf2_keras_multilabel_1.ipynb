{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Processing Step for Multilabel FAIMS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all my packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax         #finds the index of the maximum value in a vector\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import skmultilearn\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from skmultilearn.model_selection import  iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff for exploring the classes\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from collections import Counter\n",
    "from skmultilearn.model_selection import iterative_train_test_split, iterative_stratification\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "from skmultilearn.cluster.networkx import NetworkXLabelGraphClusterer\n",
    "from skmultilearn.cluster.igraph import IGraphLabelGraphClusterer\n",
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function for adding the pyteomic pieces\n",
    "from pyteomics import mass\n",
    "from pyteomics import parser\n",
    "from pyteomics import electrochem\n",
    "\n",
    "\n",
    "def addfeatures(featurestable, seqlabel = 'Sequence'):\n",
    "    Mass = list()\n",
    "    pI = list()\n",
    "    Charge = list()\n",
    "    \n",
    "    for i in range(0, featurestable.shape[0]):\n",
    "        ps = parser.parse(featurestable[seqlabel][i], show_unmodified_termini=True)\n",
    "        \n",
    "        Mass.append(mass.calculate_mass(parsed_sequence=ps))\n",
    "        Charge.append(electrochem.charge(ps, 2.5))\n",
    "        pI.append(electrochem.pI(featurestable[seqlabel][i]))\n",
    "        \n",
    "    \n",
    "    featurestable['pyMass'] = Mass\n",
    "    featurestable['pI'] = pI\n",
    "    featurestable['pyCharge'] = Charge\n",
    "    \n",
    "    return(featurestable)\n",
    "\n",
    "\n",
    "\n",
    "#WANT TO TRY ONE-HOT WITH LIST THAT I THEN CONVERT INTO FRAME AFTERWARD\n",
    "#WOULD ALSO ALLOW FOR THE USE OF THE KARAS PADDING FUNCTION SO THAT I CAN HIT THEM ALL WITH ZEROS AT THE SAME TIME\n",
    "\n",
    "\n",
    "\n",
    "def simpleOneHot(data_frame, sequenceTag = 'ModSequence', alphabet = 'ACDEFGHIKLMNPQRSTVWY'):\n",
    "    #Start by finding the max and calculating needed vector length\n",
    "    VEC_LENGTH = max(data_frame['Length']) * len(alphabet)\n",
    "    \n",
    "    #Define what residues are possible\n",
    "    AMINO_ACIDS = alphabet \n",
    "    \n",
    "    #TURNING CHARACTERS INTO INTEGERS\n",
    "    # Map character keys to integer values in a dictionary, then map integer keys to character values to revers transform\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(AMINO_ACIDS))   #character keys to integer values\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(AMINO_ACIDS))   #integer keys to character values\n",
    "    \n",
    "    \n",
    "    hotlist = list()\n",
    "    #Build out the rest of the sequences' one-hot arrays\n",
    "    \n",
    "    for i in range(0, data_frame.shape[0]):\n",
    "        \n",
    "        pep = data_frame[sequenceTag][i]\n",
    "        #print(pep)\n",
    "        integer_encode = [char_to_int[char] for char in pep]\n",
    "        encoded = to_categorical(integer_encode, num_classes=22)\n",
    "        flatencode = encoded.flatten()\n",
    "        \n",
    "        #numzeros = VEC_LENGTH - len(flatencode)\n",
    "        #flatencode = np.append(flatencode, [[0] * numzeros])\n",
    "        \n",
    "        hotlist.append(flatencode)\n",
    "    \n",
    "    padded = pad_sequences(hotlist, padding= 'post', maxlen=VEC_LENGTH)\n",
    "    \n",
    "    hotarray = np.array(padded)\n",
    "    \n",
    "    hotarray.shape\n",
    "    return(hotarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in the the final labelling scheme data and adding the other features\n",
    "df = pd.read_csv(\"P:/JGM_FAIMS_CVprediction/JMM_PreProcessed_Data/50percentMaxPlusThreshold.csv\", low_memory=False) #read in data generated from R preprocessing\n",
    "#data_df = addfeatures(data_df)\n",
    "#data_hotarray = simpleOneHot(data_frame=data_df, alphabet='ACDEFGHIKLMNPQRSTVWYam')\n",
    "#feature_subset = ['Charge', 'Length', 'pyMass', 'pI']\n",
    "#Generating X and y, features and labels respectively \n",
    "#seq = np.concatenate((data_df[feature_subset], data_hotarray), axis = 1)\n",
    "y = data_df.loc[ : ,  'X20':'X95'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqCharge</th>\n",
       "      <th>X20</th>\n",
       "      <th>X25</th>\n",
       "      <th>X30</th>\n",
       "      <th>X35</th>\n",
       "      <th>X40</th>\n",
       "      <th>X45</th>\n",
       "      <th>X50</th>\n",
       "      <th>X55</th>\n",
       "      <th>X60</th>\n",
       "      <th>...</th>\n",
       "      <th>X80</th>\n",
       "      <th>X85</th>\n",
       "      <th>X90</th>\n",
       "      <th>X95</th>\n",
       "      <th>maxcv_naomit</th>\n",
       "      <th>Charge</th>\n",
       "      <th>ModSequence</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>LabelSequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2AACLCFR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>AACLCFR</td>\n",
       "      <td>7</td>\n",
       "      <td>AACLCFR</td>\n",
       "      <td>1110000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2SEQEDEVLLVSSSR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>14</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>1100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3SEQEDEVLLVSSSR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>14</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>111100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>24</td>\n",
       "      <td>YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>110000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>24</td>\n",
       "      <td>YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>11100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SeqCharge  X20  X25  X30  X35  X40  X45  X50  X55  X60  \\\n",
       "0                   2AACLCFR    0    0    0    0    0    0    1    1    1   \n",
       "1            2SEQEDEVLLVSSSR    0    0    0    1    1    0    0    0    0   \n",
       "2            3SEQEDEVLLVSSSR    0    0    0    0    0    0    0    1    1   \n",
       "3  2YPDQWIVPGGGMEPEEEPGGAAVR    0    1    1    0    0    0    0    0    0   \n",
       "4  3YPDQWIVPGGGMEPEEEPGGAAVR    0    0    0    0    0    0    0    0    1   \n",
       "\n",
       "   ...  X80  X85  X90  X95  maxcv_naomit  Charge               ModSequence  \\\n",
       "0  ...    0    0    0    0            50       2                   AACLCFR   \n",
       "1  ...    0    0    0    0            40       2            SEQEDEVLLVSSSR   \n",
       "2  ...    0    0    0    0            60       3            SEQEDEVLLVSSSR   \n",
       "3  ...    0    0    0    0            30       2  YPDQWIVPGGGMEPEEEPGGAAVR   \n",
       "4  ...    0    0    0    0            70       3  YPDQWIVPGGGMEPEEEPGGAAVR   \n",
       "\n",
       "   Length                  Sequence    LabelSequence  \n",
       "0       7                   AACLCFR       1110000000  \n",
       "1      14            SEQEDEVLLVSSSR    1100000000000  \n",
       "2      14            SEQEDEVLLVSSSR        111100000  \n",
       "3      24  YPDQWIVPGGGMEPEEEPGGAAVR  110000000000000  \n",
       "4      24  YPDQWIVPGGGMEPEEEPGGAAVR         11100000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "### combine all the letters into a long string, take the set to find the unique values, add 'END' (for use with one-hot), then get length\n",
    "seq = df['SeqCharge']\n",
    "vocab = set(''.join([str(i) for i in seq]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)\n",
    "print(len_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'END',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'V',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'a',\n",
       " 'm'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = df['maxcv_naomit']\n",
    "set(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122847, 16)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122847,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2AACLCFR'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Y': 0, '5': 1, 'T': 2, 'S': 3, 'G': 4, '2': 5, 'F': 6, 'A': 7, 'H': 8, 'I': 9, 'L': 10, 'K': 11, 'Q': 12, 'a': 13, 'D': 14, '3': 15, 'V': 16, 'P': 17, 'C': 18, 'END': 19, 'W': 20, 'E': 21, 'M': 22, 'N': 23, 'm': 24, '4': 25, 'R': 26}\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "## make index of the characters in vocab\n",
    "char_index = dict((c, i) for i, c in enumerate(vocab))\n",
    "maxlen = max([len(x) for x in df.SeqCharge])\n",
    "print(char_index)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max and truncate rest\n",
    "# get index in char_index\n",
    "#padd 'END' to shorter sequences\n",
    "\n",
    "x = []\n",
    "x_name = [str(i)[0:maxlen] for i in seq]\n",
    "for i in x_name:\n",
    "    tmp = [char_index[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_index[\"END\"])\n",
    "    x.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2AACLCFR'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 7,\n",
       " 7,\n",
       " 18,\n",
       " 10,\n",
       " 18,\n",
       " 6,\n",
       " 26,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          2AACLCFR\n",
       "1                   2SEQEDEVLLVSSSR\n",
       "2                   3SEQEDEVLLVSSSR\n",
       "3         2YPDQWIVPGGGMEPEEEPGGAAVR\n",
       "4         3YPDQWIVPGGGMEPEEEPGGAAVR\n",
       "                    ...            \n",
       "122842              2AHTSSTQLQEELEK\n",
       "122843              3AHTSSTQLQEELEK\n",
       "122844                   2VVESPDFSK\n",
       "122845                 2TMNISPEQPQH\n",
       "122846                 2TmNISPEQPQH\n",
       "Name: SeqCharge, Length: 122847, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  7,  7, 18, 10, 18,  6, 26, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85991, 51)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the 50%+ threshold data into train and test keeping label distribution proportional\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(np.asarray(x), y, test_size=0.30)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  7,  7, 18, 10, 18,  6, 26, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 labels, 66 edges\n",
      "{(6, 7): 16741.0, (6, 8): 5937.0, (7, 8): 14873.0, (3, 4): 12975.0, (7, 9): 4052.0, (8, 9): 9697.0, (7, 10): 1460.0, (8, 10): 5288.0, (9, 10): 8372.0, (1, 2): 3055.0, (10, 11): 7697.0, (2, 3): 7371.0, (10, 12): 3232.0, (11, 12): 5122.0, (4, 5): 17640.0, (4, 6): 4292.0, (5, 6): 17998.0, (3, 5): 1498.0, (11, 13): 2064.0, (12, 13): 2976.0, (11, 14): 649.0, (12, 14): 1190.0, (13, 14): 1618.0, (5, 7): 5137.0, (10, 13): 1010.0, (0, 1): 533.0, (12, 15): 328.0, (13, 15): 573.0, (14, 15): 803.0, (7, 11): 140.0, (8, 11): 1317.0, (9, 11): 2889.0, (5, 8): 536.0, (8, 12): 194.0, (9, 12): 587.0, (9, 13): 81.0, (6, 9): 509.0, (11, 15): 140.0, (3, 6): 60.0, (3, 7): 11.0, (4, 7): 206.0, (6, 10): 110.0, (2, 4): 461.0, (0, 2): 42.0, (0, 3): 1.0, (1, 3): 57.0, (8, 13): 26.0, (3, 8): 1.0, (4, 8): 23.0, (10, 14): 227.0, (10, 15): 37.0, (4, 9): 2.0, (5, 9): 15.0, (4, 10): 1.0, (5, 10): 6.0, (9, 14): 6.0, (2, 5): 24.0, (1, 4): 5.0, (7, 12): 19.0, (5, 11): 2.0, (6, 11): 6.0, (5, 12): 1.0, (6, 12): 1.0, (2, 6): 3.0, (7, 13): 1.0, (8, 14): 1.0}\n"
     ]
    }
   ],
   "source": [
    "graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "edge_map = graph_builder.transform(y)\n",
    "print(\"{} labels, {} edges\".format(len(y[1]), len(edge_map)))\n",
    "print(edge_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a helper function for visualization purposes\n",
    "def to_membership_vector(partition):\n",
    "    return {\n",
    "        member :  partition_id\n",
    "        for partition_id, members in enumerate(partition)\n",
    "        for member in members\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 1, 2, 3, 4, 5, 6]),\n",
       "       list([7, 8, 9, 10, 11, 12, 13, 14, 15])], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = NetworkXLabelGraphClusterer(graph_builder, method='louvain')\n",
    "clusterer_igraph = IGraphLabelGraphClusterer(graph_builder=graph_builder, method='walktrap')\n",
    "partition = clusterer_igraph.fit_predict(X_keys, y)\n",
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"500pt\" height=\"500pt\" viewBox=\"0 0 500 500\" version=\"1.1\">\n",
       "<defs>\n",
       "<g>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-0\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.75 0 L 1.75 -8.75 L 8.75 -8.75 L 8.75 0 Z M 1.96875 -0.21875 L 8.53125 -0.21875 L 8.53125 -8.53125 L 1.96875 -8.53125 Z M 1.96875 -0.21875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 7.046875 -1.183594 L 7.046875 0 L 0.421875 0 C 0.414063 -0.296875 0.460938 -0.582031 0.566406 -0.855469 C 0.734375 -1.304688 1.003906 -1.746094 1.375 -2.1875 C 1.746094 -2.621094 2.285156 -3.128906 2.988281 -3.703125 C 4.074219 -4.597656 4.808594 -5.304688 5.195313 -5.828125 C 5.574219 -6.347656 5.765625 -6.839844 5.769531 -7.308594 C 5.765625 -7.792969 5.589844 -8.203125 5.246094 -8.539063 C 4.894531 -8.871094 4.441406 -9.039063 3.882813 -9.042969 C 3.285156 -9.039063 2.8125 -8.863281 2.460938 -8.507813 C 2.105469 -8.152344 1.925781 -7.660156 1.921875 -7.035156 L 0.65625 -7.164063 C 0.742188 -8.105469 1.066406 -8.824219 1.632813 -9.320313 C 2.195313 -9.8125 2.953125 -10.058594 3.910156 -10.0625 C 4.867188 -10.058594 5.628906 -9.792969 6.191406 -9.261719 C 6.75 -8.726563 7.03125 -8.066406 7.035156 -7.28125 C 7.03125 -6.878906 6.949219 -6.484375 6.789063 -6.097656 C 6.621094 -5.707031 6.347656 -5.296875 5.96875 -4.871094 C 5.585938 -4.441406 4.953125 -3.855469 4.074219 -3.109375 C 3.332031 -2.488281 2.859375 -2.066406 2.652344 -1.847656 C 2.4375 -1.621094 2.265625 -1.402344 2.132813 -1.183594 Z M 7.046875 -1.183594 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.582031 -4.941406 C 0.578125 -6.121094 0.699219 -7.074219 0.945313 -7.800781 C 1.1875 -8.519531 1.550781 -9.078125 2.03125 -9.472656 C 2.511719 -9.863281 3.117188 -10.058594 3.847656 -10.0625 C 4.382813 -10.058594 4.855469 -9.953125 5.261719 -9.738281 C 5.667969 -9.519531 6 -9.207031 6.265625 -8.800781 C 6.527344 -8.390625 6.738281 -7.890625 6.890625 -7.308594 C 7.039063 -6.722656 7.113281 -5.933594 7.117188 -4.941406 C 7.113281 -3.761719 6.992188 -2.8125 6.753906 -2.09375 C 6.507813 -1.367188 6.144531 -0.808594 5.667969 -0.417969 C 5.183594 -0.0234375 4.578125 0.167969 3.847656 0.171875 C 2.878906 0.167969 2.121094 -0.175781 1.570313 -0.867188 C 0.910156 -1.699219 0.578125 -3.054688 0.582031 -4.941406 Z M 1.84375 -4.941406 C 1.839844 -3.292969 2.03125 -2.199219 2.421875 -1.65625 C 2.804688 -1.109375 3.28125 -0.835938 3.847656 -0.839844 C 4.410156 -0.835938 4.886719 -1.109375 5.273438 -1.660156 C 5.65625 -2.203125 5.847656 -3.296875 5.851563 -4.941406 C 5.847656 -6.589844 5.65625 -7.6875 5.273438 -8.230469 C 4.886719 -8.769531 4.40625 -9.039063 3.835938 -9.042969 C 3.269531 -9.039063 2.816406 -8.800781 2.480469 -8.328125 C 2.050781 -7.710938 1.839844 -6.582031 1.84375 -4.941406 Z M 1.84375 -4.941406 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.582031 -2.625 L 1.875 -2.734375 C 1.96875 -2.101563 2.1875 -1.628906 2.539063 -1.3125 C 2.882813 -0.996094 3.304688 -0.835938 3.800781 -0.839844 C 4.390625 -0.835938 4.890625 -1.058594 5.304688 -1.507813 C 5.710938 -1.953125 5.917969 -2.546875 5.921875 -3.289063 C 5.917969 -3.984375 5.71875 -4.539063 5.328125 -4.949219 C 4.929688 -5.351563 4.414063 -5.554688 3.78125 -5.558594 C 3.382813 -5.554688 3.027344 -5.464844 2.707031 -5.285156 C 2.386719 -5.105469 2.132813 -4.871094 1.953125 -4.585938 L 0.800781 -4.738281 L 1.769531 -9.882813 L 6.753906 -9.882813 L 6.753906 -8.710938 L 2.753906 -8.710938 L 2.214844 -6.015625 C 2.816406 -6.433594 3.445313 -6.644531 4.109375 -6.644531 C 4.980469 -6.644531 5.71875 -6.339844 6.324219 -5.734375 C 6.921875 -5.128906 7.222656 -4.351563 7.226563 -3.398438 C 7.222656 -2.492188 6.960938 -1.707031 6.433594 -1.046875 C 5.789063 -0.234375 4.910156 0.167969 3.800781 0.171875 C 2.886719 0.167969 2.140625 -0.0820313 1.566406 -0.59375 C 0.988281 -1.101563 0.660156 -1.78125 0.582031 -2.625 Z M 0.582031 -2.625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-4\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.585938 -2.644531 L 1.820313 -2.808594 C 1.957031 -2.109375 2.195313 -1.609375 2.539063 -1.300781 C 2.875 -0.992188 3.289063 -0.835938 3.78125 -0.839844 C 4.355469 -0.835938 4.84375 -1.039063 5.246094 -1.441406 C 5.640625 -1.839844 5.839844 -2.335938 5.84375 -2.933594 C 5.839844 -3.496094 5.65625 -3.960938 5.289063 -4.332031 C 4.917969 -4.695313 4.449219 -4.878906 3.882813 -4.882813 C 3.648438 -4.878906 3.359375 -4.832031 3.015625 -4.742188 L 3.152344 -5.824219 C 3.230469 -5.816406 3.296875 -5.8125 3.351563 -5.8125 C 3.875 -5.8125 4.34375 -5.949219 4.765625 -6.222656 C 5.179688 -6.496094 5.390625 -6.914063 5.394531 -7.484375 C 5.390625 -7.933594 5.238281 -8.308594 4.933594 -8.605469 C 4.628906 -8.898438 4.234375 -9.046875 3.753906 -9.050781 C 3.273438 -9.046875 2.875 -8.894531 2.554688 -8.597656 C 2.234375 -8.292969 2.027344 -7.84375 1.941406 -7.246094 L 0.710938 -7.464844 C 0.859375 -8.289063 1.203125 -8.925781 1.734375 -9.382813 C 2.265625 -9.832031 2.929688 -10.058594 3.726563 -10.0625 C 4.273438 -10.058594 4.773438 -9.941406 5.234375 -9.710938 C 5.691406 -9.472656 6.042969 -9.152344 6.289063 -8.75 C 6.53125 -8.339844 6.65625 -7.910156 6.65625 -7.457031 C 6.65625 -7.023438 6.539063 -6.628906 6.308594 -6.273438 C 6.074219 -5.917969 5.730469 -5.636719 5.277344 -5.429688 C 5.867188 -5.289063 6.328125 -5.003906 6.65625 -4.574219 C 6.984375 -4.140625 7.148438 -3.601563 7.148438 -2.960938 C 7.148438 -2.082031 6.828125 -1.339844 6.191406 -0.734375 C 5.550781 -0.125 4.746094 0.175781 3.773438 0.179688 C 2.890625 0.175781 2.160156 -0.0820313 1.582031 -0.605469 C 1 -1.128906 0.667969 -1.808594 0.585938 -2.644531 Z M 0.585938 -2.644531 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-5\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.523438 0 L 4.523438 -2.398438 L 0.179688 -2.398438 L 0.179688 -3.527344 L 4.75 -10.023438 L 5.757813 -10.023438 L 5.757813 -3.527344 L 7.109375 -3.527344 L 7.109375 -2.398438 L 5.757813 -2.398438 L 5.757813 0 Z M 4.523438 -3.527344 L 4.523438 -8.046875 L 1.386719 -3.527344 Z M 4.523438 -3.527344 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-6\">\n",
       "<path style=\"stroke:none;\" d=\"M 6.964844 -7.566406 L 5.742188 -7.472656 C 5.632813 -7.949219 5.476563 -8.300781 5.277344 -8.523438 C 4.941406 -8.871094 4.53125 -9.046875 4.046875 -9.050781 C 3.652344 -9.046875 3.308594 -8.9375 3.015625 -8.722656 C 2.625 -8.4375 2.320313 -8.023438 2.097656 -7.484375 C 1.875 -6.9375 1.757813 -6.167969 1.75 -5.167969 C 2.042969 -5.617188 2.40625 -5.949219 2.835938 -6.171875 C 3.265625 -6.386719 3.714844 -6.496094 4.183594 -6.5 C 5.003906 -6.496094 5.699219 -6.195313 6.277344 -5.59375 C 6.851563 -4.988281 7.140625 -4.207031 7.144531 -3.253906 C 7.140625 -2.621094 7.003906 -2.039063 6.734375 -1.5 C 6.460938 -0.960938 6.089844 -0.546875 5.617188 -0.257813 C 5.140625 0.0273438 4.605469 0.167969 4.007813 0.171875 C 2.980469 0.167969 2.140625 -0.207031 1.496094 -0.960938 C 0.847656 -1.714844 0.527344 -2.957031 0.527344 -4.6875 C 0.527344 -6.625 0.882813 -8.03125 1.601563 -8.914063 C 2.21875 -9.675781 3.058594 -10.058594 4.121094 -10.0625 C 4.90625 -10.058594 5.554688 -9.839844 6.058594 -9.398438 C 6.5625 -8.953125 6.863281 -8.339844 6.964844 -7.566406 Z M 1.941406 -3.246094 C 1.9375 -2.820313 2.027344 -2.414063 2.210938 -2.027344 C 2.386719 -1.640625 2.640625 -1.34375 2.964844 -1.144531 C 3.289063 -0.9375 3.628906 -0.835938 3.984375 -0.839844 C 4.503906 -0.835938 4.949219 -1.046875 5.324219 -1.46875 C 5.695313 -1.886719 5.882813 -2.457031 5.886719 -3.179688 C 5.882813 -3.871094 5.699219 -4.417969 5.332031 -4.816406 C 4.960938 -5.214844 4.496094 -5.414063 3.9375 -5.414063 C 3.378906 -5.414063 2.90625 -5.214844 2.519531 -4.816406 C 2.132813 -4.417969 1.9375 -3.894531 1.941406 -3.246094 Z M 1.941406 -3.246094 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-7\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.664063 -8.710938 L 0.664063 -9.890625 L 7.148438 -9.890625 L 7.148438 -8.933594 C 6.511719 -8.25 5.878906 -7.347656 5.253906 -6.226563 C 4.625 -5.097656 4.140625 -3.941406 3.800781 -2.753906 C 3.550781 -1.914063 3.394531 -0.996094 3.328125 0 L 2.0625 0 C 2.078125 -0.789063 2.230469 -1.738281 2.527344 -2.855469 C 2.820313 -3.96875 3.246094 -5.046875 3.800781 -6.085938 C 4.351563 -7.121094 4.941406 -7.996094 5.570313 -8.710938 Z M 0.664063 -8.710938 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-8\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.476563 -5.433594 C 1.964844 -5.617188 1.585938 -5.886719 1.339844 -6.234375 C 1.089844 -6.578125 0.964844 -6.992188 0.96875 -7.476563 C 0.964844 -8.203125 1.226563 -8.816406 1.753906 -9.316406 C 2.277344 -9.8125 2.976563 -10.058594 3.847656 -10.0625 C 4.71875 -10.058594 5.421875 -9.804688 5.960938 -9.300781 C 6.492188 -8.789063 6.761719 -8.171875 6.761719 -7.445313 C 6.761719 -6.976563 6.636719 -6.570313 6.394531 -6.230469 C 6.148438 -5.882813 5.78125 -5.617188 5.285156 -5.433594 C 5.898438 -5.230469 6.363281 -4.90625 6.6875 -4.460938 C 7.007813 -4.011719 7.171875 -3.480469 7.171875 -2.863281 C 7.171875 -2.003906 6.867188 -1.285156 6.261719 -0.703125 C 5.652344 -0.121094 4.855469 0.167969 3.867188 0.171875 C 2.878906 0.167969 2.082031 -0.121094 1.476563 -0.707031 C 0.867188 -1.289063 0.5625 -2.019531 0.566406 -2.898438 C 0.5625 -3.546875 0.726563 -4.09375 1.0625 -4.535156 C 1.390625 -4.972656 1.863281 -5.269531 2.476563 -5.433594 Z M 2.226563 -7.519531 C 2.226563 -7.042969 2.378906 -6.65625 2.683594 -6.355469 C 2.988281 -6.054688 3.382813 -5.90625 3.875 -5.90625 C 4.34375 -5.90625 4.734375 -6.054688 5.039063 -6.351563 C 5.34375 -6.648438 5.496094 -7.015625 5.496094 -7.453125 C 5.496094 -7.902344 5.339844 -8.28125 5.027344 -8.589844 C 4.714844 -8.894531 4.324219 -9.046875 3.863281 -9.050781 C 3.386719 -9.046875 2.996094 -8.894531 2.691406 -8.597656 C 2.378906 -8.292969 2.226563 -7.933594 2.226563 -7.519531 Z M 1.832031 -2.890625 C 1.828125 -2.539063 1.910156 -2.203125 2.082031 -1.875 C 2.246094 -1.546875 2.496094 -1.289063 2.824219 -1.109375 C 3.152344 -0.925781 3.503906 -0.835938 3.882813 -0.839844 C 4.46875 -0.835938 4.953125 -1.027344 5.339844 -1.40625 C 5.71875 -1.785156 5.910156 -2.265625 5.914063 -2.851563 C 5.910156 -3.441406 5.714844 -3.929688 5.320313 -4.320313 C 4.925781 -4.703125 4.433594 -4.898438 3.84375 -4.902344 C 3.261719 -4.898438 2.78125 -4.707031 2.402344 -4.328125 C 2.019531 -3.941406 1.828125 -3.460938 1.832031 -2.890625 Z M 1.832031 -2.890625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-9\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.765625 -2.316406 L 1.949219 -2.425781 C 2.046875 -1.871094 2.238281 -1.464844 2.519531 -1.214844 C 2.800781 -0.960938 3.164063 -0.835938 3.609375 -0.839844 C 3.984375 -0.835938 4.3125 -0.921875 4.601563 -1.097656 C 4.882813 -1.269531 5.117188 -1.503906 5.304688 -1.792969 C 5.484375 -2.082031 5.636719 -2.472656 5.761719 -2.964844 C 5.878906 -3.457031 5.941406 -3.957031 5.945313 -4.46875 C 5.941406 -4.523438 5.941406 -4.605469 5.941406 -4.71875 C 5.691406 -4.320313 5.351563 -4.003906 4.929688 -3.761719 C 4.5 -3.519531 4.039063 -3.398438 3.546875 -3.398438 C 2.714844 -3.398438 2.015625 -3.699219 1.441406 -4.300781 C 0.867188 -4.902344 0.578125 -5.695313 0.582031 -6.679688 C 0.578125 -7.695313 0.878906 -8.511719 1.480469 -9.132813 C 2.078125 -9.75 2.828125 -10.058594 3.734375 -10.0625 C 4.382813 -10.058594 4.980469 -9.882813 5.519531 -9.535156 C 6.058594 -9.179688 6.46875 -8.679688 6.75 -8.035156 C 7.03125 -7.382813 7.171875 -6.445313 7.171875 -5.214844 C 7.171875 -3.933594 7.03125 -2.914063 6.753906 -2.15625 C 6.472656 -1.398438 6.058594 -0.820313 5.511719 -0.421875 C 4.960938 -0.0273438 4.316406 0.167969 3.582031 0.171875 C 2.792969 0.167969 2.152344 -0.046875 1.660156 -0.480469 C 1.160156 -0.914063 0.863281 -1.523438 0.765625 -2.316406 Z M 5.804688 -6.742188 C 5.800781 -7.445313 5.613281 -8.003906 5.238281 -8.421875 C 4.863281 -8.832031 4.410156 -9.039063 3.882813 -9.042969 C 3.332031 -9.039063 2.855469 -8.816406 2.453125 -8.371094 C 2.042969 -7.921875 1.839844 -7.34375 1.84375 -6.636719 C 1.839844 -5.996094 2.03125 -5.476563 2.421875 -5.082031 C 2.804688 -4.679688 3.28125 -4.480469 3.847656 -4.484375 C 4.414063 -4.480469 4.882813 -4.679688 5.253906 -5.082031 C 5.617188 -5.476563 5.800781 -6.03125 5.804688 -6.742188 Z M 5.804688 -6.742188 \"/>\n",
       "</symbol>\n",
       "</g>\n",
       "</defs>\n",
       "<g id=\"surface169\">\n",
       "<rect x=\"0\" y=\"0\" width=\"500\" height=\"500\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n",
       "<path style=\"fill:none;stroke-width:7.387242;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 159.226563 320.820313 149.832031 306.761719 129.894531 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.891662;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 168.363281 301.761719 155.671875 271.121094 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:7.216552;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 139.035156 280.691406 135.734375 264.109375 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:7.019591;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 370.105469 C 280.691406 360.964844 264.109375 364.265625 250 380 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.340562;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 154.769531 266.582031 154.769531 233.417969 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.599467;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 135.734375 235.890625 139.035156 219.308594 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.867896;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 174.707031 259.570313 184.101563 212.34375 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.72465;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 155.671875 228.878906 168.363281 198.238281 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.3875;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 149.832031 193.238281 159.226563 179.179688 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.9331;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 370.105469 299.75 C 350.167969 306.761719 340.773438 320.820313 341.925781 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.266224;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 179.179688 159.226563 193.238281 149.832031 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.203788;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 341.925781 C 320.820313 340.773438 306.761719 350.167969 299.75 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.014355;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 198.238281 168.363281 228.878906 155.671875 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.678635;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 219.308594 139.035156 235.890625 135.734375 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:7.462707;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 380 C 235.890625 364.265625 219.308594 360.964844 200.25 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.423578;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 380 C 228.878906 344.328125 198.238281 331.636719 158.074219 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:7.491693;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 193.238281 350.167969 179.179688 340.773438 158.074219 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.904966;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 370.105469 C 266.582031 345.230469 233.417969 345.230469 200.25 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.367371;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 233.417969 154.769531 266.582031 154.769531 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.895303;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 264.109375 135.734375 280.691406 139.035156 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.698218;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 240.429688 174.707031 287.65625 184.101563 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.57289;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 271.121094 155.671875 301.761719 168.363281 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.01614;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 129.894531 C 306.761719 149.832031 320.820313 159.226563 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.682854;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 194.386719 329.0625 170.9375 305.613281 129.894531 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.336283;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 212.34375 184.101563 259.570313 174.707031 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.414136;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 380 250 C 364.265625 264.109375 360.964844 280.691406 370.105469 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.713696;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 269.972656 176.777344 310.007813 203.527344 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.518535;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 129.894531 C 305.613281 170.9375 329.0625 194.386719 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.0054;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 158.074219 C 340.773438 179.179688 350.167969 193.238281 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.485427;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 195.8125 260.71875 219.261719 204.101563 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.719183;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 176.777344 230.027344 203.527344 189.992188 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.852498;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 170.9375 194.386719 194.386719 170.9375 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.422233;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 203.527344 310.007813 176.777344 269.972656 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.956057;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 195.832031 239.167969 239.167969 195.832031 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.553361;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 189.992188 203.527344 230.027344 176.777344 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.347666;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 184.101563 287.65625 174.707031 240.429688 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.485427;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 239.28125 195.8125 295.898438 219.261719 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.042644;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 380 C 230.027344 323.222656 189.992188 296.472656 129.894531 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.137504;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 204.039063 280.640625 204.039063 219.359375 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.204767;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 341.925781 C 301.761719 331.636719 271.121094 344.328125 250 380 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.182692;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 219.359375 204.039063 280.640625 204.039063 341.925781 158.074219 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 395 250 C 395 258.285156 388.285156 265 380 265 C 371.714844 265 365 258.285156 365 250 C 365 241.714844 371.714844 235 380 235 C 388.285156 235 395 241.714844 395 250 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 385.105469 299.75 C 385.105469 308.03125 378.386719 314.75 370.105469 314.75 C 361.820313 314.75 355.105469 308.03125 355.105469 299.75 C 355.105469 291.464844 361.820313 284.75 370.105469 284.75 C 378.386719 284.75 385.105469 291.464844 385.105469 299.75 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 356.925781 341.925781 C 356.925781 350.207031 350.207031 356.925781 341.925781 356.925781 C 333.640625 356.925781 326.925781 350.207031 326.925781 341.925781 C 326.925781 333.640625 333.640625 326.925781 341.925781 326.925781 C 350.207031 326.925781 356.925781 333.640625 356.925781 341.925781 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 314.75 370.105469 C 314.75 378.386719 308.03125 385.105469 299.75 385.105469 C 291.464844 385.105469 284.75 378.386719 284.75 370.105469 C 284.75 361.820313 291.464844 355.105469 299.75 355.105469 C 308.03125 355.105469 314.75 361.820313 314.75 370.105469 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 265 380 C 265 388.285156 258.285156 395 250 395 C 241.714844 395 235 388.285156 235 380 C 235 371.714844 241.714844 365 250 365 C 258.285156 365 265 371.714844 265 380 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 215.25 370.105469 C 215.25 378.386719 208.535156 385.105469 200.25 385.105469 C 191.96875 385.105469 185.25 378.386719 185.25 370.105469 C 185.25 361.820313 191.96875 355.105469 200.25 355.105469 C 208.535156 355.105469 215.25 361.820313 215.25 370.105469 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 173.074219 341.925781 C 173.074219 350.207031 166.359375 356.925781 158.074219 356.925781 C 149.792969 356.925781 143.074219 350.207031 143.074219 341.925781 C 143.074219 333.640625 149.792969 326.925781 158.074219 326.925781 C 166.359375 326.925781 173.074219 333.640625 173.074219 341.925781 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 144.894531 299.75 C 144.894531 308.03125 138.179688 314.75 129.894531 314.75 C 121.613281 314.75 114.894531 308.03125 114.894531 299.75 C 114.894531 291.464844 121.613281 284.75 129.894531 284.75 C 138.179688 284.75 144.894531 291.464844 144.894531 299.75 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 135 250 C 135 258.285156 128.285156 265 120 265 C 111.714844 265 105 258.285156 105 250 C 105 241.714844 111.714844 235 120 235 C 128.285156 235 135 241.714844 135 250 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 144.894531 200.25 C 144.894531 208.535156 138.179688 215.25 129.894531 215.25 C 121.613281 215.25 114.894531 208.535156 114.894531 200.25 C 114.894531 191.96875 121.613281 185.25 129.894531 185.25 C 138.179688 185.25 144.894531 191.96875 144.894531 200.25 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 173.074219 158.074219 C 173.074219 166.359375 166.359375 173.074219 158.074219 173.074219 C 149.792969 173.074219 143.074219 166.359375 143.074219 158.074219 C 143.074219 149.792969 149.792969 143.074219 158.074219 143.074219 C 166.359375 143.074219 173.074219 149.792969 173.074219 158.074219 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 215.25 129.894531 C 215.25 138.179688 208.535156 144.894531 200.25 144.894531 C 191.96875 144.894531 185.25 138.179688 185.25 129.894531 C 185.25 121.613281 191.96875 114.894531 200.25 114.894531 C 208.535156 114.894531 215.25 121.613281 215.25 129.894531 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 265 120 C 265 128.285156 258.285156 135 250 135 C 241.714844 135 235 128.285156 235 120 C 235 111.714844 241.714844 105 250 105 C 258.285156 105 265 111.714844 265 120 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 314.75 129.894531 C 314.75 138.179688 308.03125 144.894531 299.75 144.894531 C 291.464844 144.894531 284.75 138.179688 284.75 129.894531 C 284.75 121.613281 291.464844 114.894531 299.75 114.894531 C 308.03125 114.894531 314.75 121.613281 314.75 129.894531 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 356.925781 158.074219 C 356.925781 166.359375 350.207031 173.074219 341.925781 173.074219 C 333.640625 173.074219 326.925781 166.359375 326.925781 158.074219 C 326.925781 149.792969 333.640625 143.074219 341.925781 143.074219 C 350.207031 143.074219 356.925781 149.792969 356.925781 158.074219 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 385.105469 200.25 C 385.105469 208.535156 378.386719 215.25 370.105469 215.25 C 361.820313 215.25 355.105469 208.535156 355.105469 200.25 C 355.105469 191.96875 361.820313 185.25 370.105469 185.25 C 378.386719 185.25 385.105469 191.96875 385.105469 200.25 \"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"372.34375\" y=\"256.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"380.129883\" y=\"256.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"362.394531\" y=\"306.28125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"370.180664\" y=\"306.28125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"334.179688\" y=\"348.457031\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"341.96582\" y=\"348.457031\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"291.949219\" y=\"376.636719\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"299.735352\" y=\"376.636719\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"242.460938\" y=\"386.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"250.24707\" y=\"386.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"192.65625\" y=\"376.613281\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"200.442383\" y=\"376.613281\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"150.335938\" y=\"348.457031\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"158.12207\" y=\"348.457031\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"122.097656\" y=\"306.191406\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"129.883789\" y=\"306.191406\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"112.285156\" y=\"256.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"120.071289\" y=\"256.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"122.125\" y=\"206.78125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"129.911133\" y=\"206.78125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"150.292969\" y=\"164.605469\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"158.079102\" y=\"164.605469\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"192.414063\" y=\"136.339844\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"200.200195\" y=\"136.339844\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"242.265625\" y=\"126.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"250.051758\" y=\"126.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"291.960938\" y=\"136.425781\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"299.74707\" y=\"136.425781\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"334.183594\" y=\"164.605469\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"341.969727\" y=\"164.605469\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"362.308594\" y=\"206.78125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"370.094727\" y=\"206.78125\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<igraph.drawing.Plot at 0x1ecd32200c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "image/svg+xml": {
       "isolated": true
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "colors = ['red', 'white', 'blue', 'green']\n",
    "membership_vector = to_membership_vector(partition)\n",
    "visual_style = {\n",
    "    \"vertex_size\" : 30,\n",
    "    \"vertex_label\": [ x[1:] for x in data_df.loc[ : ,  'X20':'X95'].columns.values],\n",
    "    \"edge_width\" : [np.log2(x/100) for x in clusterer_igraph.graph_.es['weight']],\n",
    "    \"vertex_color\": [colors[membership_vector[i]] for i in range(y.shape[1])],\n",
    "    \"bbox\": (500,500),\n",
    "    \"margin\": 120,\n",
    "    \"layout\": clusterer_igraph.graph_.layout_circle(),\n",
    "    \"autocurve\":True,\n",
    "    \"edge_curved\":0.5\n",
    "}\n",
    "\n",
    "def testplot(graph, name):\n",
    "    graph.vs['label'] = graph.vs['name']\n",
    "    out = ig.plot(clusterer_igraph.graph_, **visual_style)\n",
    "    out.save(name + '_all_peptides.png')\n",
    "    \n",
    "testplot(clusterer_igraph.graph_, 'test1')\n",
    "ig.plot(clusterer_igraph.graph_, **visual_style)\n",
    "#ig.write(clusterer_igraph.graph_, filename=\"test.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 labels, 64 edges\n",
      "{(6, 7): 11719.0, (6, 8): 4142.0, (7, 8): 10411.0, (8, 9): 6788.0, (8, 10): 3705.0, (9, 10): 5860.0, (10, 11): 5388.0, (2, 3): 5160.0, (1, 2): 2138.0, (4, 5): 12348.0, (3, 4): 9082.0, (3, 5): 1036.0, (10, 12): 2274.0, (11, 12): 3585.0, (5, 6): 12599.0, (4, 6): 3030.0, (5, 7): 3612.0, (12, 13): 2083.0, (12, 14): 823.0, (13, 14): 1133.0, (7, 9): 2831.0, (7, 10): 1028.0, (9, 11): 2008.0, (5, 8): 376.0, (8, 11): 910.0, (14, 15): 562.0, (11, 13): 1477.0, (11, 14): 459.0, (11, 15): 101.0, (12, 15): 227.0, (13, 15): 406.0, (9, 12): 418.0, (6, 9): 370.0, (6, 10): 86.0, (3, 6): 42.0, (0, 1): 373.0, (10, 13): 738.0, (0, 2): 32.0, (0, 3): 1.0, (1, 3): 38.0, (8, 12): 146.0, (8, 13): 19.0, (9, 13): 62.0, (4, 7): 145.0, (2, 4): 311.0, (4, 8): 16.0, (10, 14): 166.0, (10, 15): 29.0, (7, 11): 97.0, (4, 9): 1.0, (5, 9): 11.0, (4, 10): 1.0, (5, 10): 5.0, (1, 4): 2.0, (2, 5): 19.0, (7, 12): 15.0, (5, 11): 2.0, (6, 11): 5.0, (5, 12): 1.0, (6, 12): 1.0, (3, 7): 8.0, (9, 14): 5.0, (2, 6): 2.0, (8, 14): 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([0, 1, 2, 3, 4, 5, 6]),\n",
       "       list([7, 8, 9, 10, 11, 12, 13, 14, 15])], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "edge_map = graph_builder.transform(y_train)\n",
    "print(\"{} labels, {} edges\".format(len(y[1]), len(edge_map)))\n",
    "print(edge_map)\n",
    "clusterer = NetworkXLabelGraphClusterer(graph_builder, method='louvain')\n",
    "clusterer_igraph = IGraphLabelGraphClusterer(graph_builder=graph_builder, method='walktrap')\n",
    "partition = clusterer_igraph.fit_predict(X_keys, y_train)\n",
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"500pt\" height=\"500pt\" viewBox=\"0 0 500 500\" version=\"1.1\">\n",
       "<defs>\n",
       "<g>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-0\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.75 0 L 1.75 -8.75 L 8.75 -8.75 L 8.75 0 Z M 1.96875 -0.21875 L 8.53125 -0.21875 L 8.53125 -8.53125 L 1.96875 -8.53125 Z M 1.96875 -0.21875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 7.046875 -1.183594 L 7.046875 0 L 0.421875 0 C 0.414063 -0.296875 0.460938 -0.582031 0.566406 -0.855469 C 0.734375 -1.304688 1.003906 -1.746094 1.375 -2.1875 C 1.746094 -2.621094 2.285156 -3.128906 2.988281 -3.703125 C 4.074219 -4.597656 4.808594 -5.304688 5.195313 -5.828125 C 5.574219 -6.347656 5.765625 -6.839844 5.769531 -7.308594 C 5.765625 -7.792969 5.589844 -8.203125 5.246094 -8.539063 C 4.894531 -8.871094 4.441406 -9.039063 3.882813 -9.042969 C 3.285156 -9.039063 2.8125 -8.863281 2.460938 -8.507813 C 2.105469 -8.152344 1.925781 -7.660156 1.921875 -7.035156 L 0.65625 -7.164063 C 0.742188 -8.105469 1.066406 -8.824219 1.632813 -9.320313 C 2.195313 -9.8125 2.953125 -10.058594 3.910156 -10.0625 C 4.867188 -10.058594 5.628906 -9.792969 6.191406 -9.261719 C 6.75 -8.726563 7.03125 -8.066406 7.035156 -7.28125 C 7.03125 -6.878906 6.949219 -6.484375 6.789063 -6.097656 C 6.621094 -5.707031 6.347656 -5.296875 5.96875 -4.871094 C 5.585938 -4.441406 4.953125 -3.855469 4.074219 -3.109375 C 3.332031 -2.488281 2.859375 -2.066406 2.652344 -1.847656 C 2.4375 -1.621094 2.265625 -1.402344 2.132813 -1.183594 Z M 7.046875 -1.183594 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.582031 -4.941406 C 0.578125 -6.121094 0.699219 -7.074219 0.945313 -7.800781 C 1.1875 -8.519531 1.550781 -9.078125 2.03125 -9.472656 C 2.511719 -9.863281 3.117188 -10.058594 3.847656 -10.0625 C 4.382813 -10.058594 4.855469 -9.953125 5.261719 -9.738281 C 5.667969 -9.519531 6 -9.207031 6.265625 -8.800781 C 6.527344 -8.390625 6.738281 -7.890625 6.890625 -7.308594 C 7.039063 -6.722656 7.113281 -5.933594 7.117188 -4.941406 C 7.113281 -3.761719 6.992188 -2.8125 6.753906 -2.09375 C 6.507813 -1.367188 6.144531 -0.808594 5.667969 -0.417969 C 5.183594 -0.0234375 4.578125 0.167969 3.847656 0.171875 C 2.878906 0.167969 2.121094 -0.175781 1.570313 -0.867188 C 0.910156 -1.699219 0.578125 -3.054688 0.582031 -4.941406 Z M 1.84375 -4.941406 C 1.839844 -3.292969 2.03125 -2.199219 2.421875 -1.65625 C 2.804688 -1.109375 3.28125 -0.835938 3.847656 -0.839844 C 4.410156 -0.835938 4.886719 -1.109375 5.273438 -1.660156 C 5.65625 -2.203125 5.847656 -3.296875 5.851563 -4.941406 C 5.847656 -6.589844 5.65625 -7.6875 5.273438 -8.230469 C 4.886719 -8.769531 4.40625 -9.039063 3.835938 -9.042969 C 3.269531 -9.039063 2.816406 -8.800781 2.480469 -8.328125 C 2.050781 -7.710938 1.839844 -6.582031 1.84375 -4.941406 Z M 1.84375 -4.941406 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.582031 -2.625 L 1.875 -2.734375 C 1.96875 -2.101563 2.1875 -1.628906 2.539063 -1.3125 C 2.882813 -0.996094 3.304688 -0.835938 3.800781 -0.839844 C 4.390625 -0.835938 4.890625 -1.058594 5.304688 -1.507813 C 5.710938 -1.953125 5.917969 -2.546875 5.921875 -3.289063 C 5.917969 -3.984375 5.71875 -4.539063 5.328125 -4.949219 C 4.929688 -5.351563 4.414063 -5.554688 3.78125 -5.558594 C 3.382813 -5.554688 3.027344 -5.464844 2.707031 -5.285156 C 2.386719 -5.105469 2.132813 -4.871094 1.953125 -4.585938 L 0.800781 -4.738281 L 1.769531 -9.882813 L 6.753906 -9.882813 L 6.753906 -8.710938 L 2.753906 -8.710938 L 2.214844 -6.015625 C 2.816406 -6.433594 3.445313 -6.644531 4.109375 -6.644531 C 4.980469 -6.644531 5.71875 -6.339844 6.324219 -5.734375 C 6.921875 -5.128906 7.222656 -4.351563 7.226563 -3.398438 C 7.222656 -2.492188 6.960938 -1.707031 6.433594 -1.046875 C 5.789063 -0.234375 4.910156 0.167969 3.800781 0.171875 C 2.886719 0.167969 2.140625 -0.0820313 1.566406 -0.59375 C 0.988281 -1.101563 0.660156 -1.78125 0.582031 -2.625 Z M 0.582031 -2.625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-4\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.585938 -2.644531 L 1.820313 -2.808594 C 1.957031 -2.109375 2.195313 -1.609375 2.539063 -1.300781 C 2.875 -0.992188 3.289063 -0.835938 3.78125 -0.839844 C 4.355469 -0.835938 4.84375 -1.039063 5.246094 -1.441406 C 5.640625 -1.839844 5.839844 -2.335938 5.84375 -2.933594 C 5.839844 -3.496094 5.65625 -3.960938 5.289063 -4.332031 C 4.917969 -4.695313 4.449219 -4.878906 3.882813 -4.882813 C 3.648438 -4.878906 3.359375 -4.832031 3.015625 -4.742188 L 3.152344 -5.824219 C 3.230469 -5.816406 3.296875 -5.8125 3.351563 -5.8125 C 3.875 -5.8125 4.34375 -5.949219 4.765625 -6.222656 C 5.179688 -6.496094 5.390625 -6.914063 5.394531 -7.484375 C 5.390625 -7.933594 5.238281 -8.308594 4.933594 -8.605469 C 4.628906 -8.898438 4.234375 -9.046875 3.753906 -9.050781 C 3.273438 -9.046875 2.875 -8.894531 2.554688 -8.597656 C 2.234375 -8.292969 2.027344 -7.84375 1.941406 -7.246094 L 0.710938 -7.464844 C 0.859375 -8.289063 1.203125 -8.925781 1.734375 -9.382813 C 2.265625 -9.832031 2.929688 -10.058594 3.726563 -10.0625 C 4.273438 -10.058594 4.773438 -9.941406 5.234375 -9.710938 C 5.691406 -9.472656 6.042969 -9.152344 6.289063 -8.75 C 6.53125 -8.339844 6.65625 -7.910156 6.65625 -7.457031 C 6.65625 -7.023438 6.539063 -6.628906 6.308594 -6.273438 C 6.074219 -5.917969 5.730469 -5.636719 5.277344 -5.429688 C 5.867188 -5.289063 6.328125 -5.003906 6.65625 -4.574219 C 6.984375 -4.140625 7.148438 -3.601563 7.148438 -2.960938 C 7.148438 -2.082031 6.828125 -1.339844 6.191406 -0.734375 C 5.550781 -0.125 4.746094 0.175781 3.773438 0.179688 C 2.890625 0.175781 2.160156 -0.0820313 1.582031 -0.605469 C 1 -1.128906 0.667969 -1.808594 0.585938 -2.644531 Z M 0.585938 -2.644531 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-5\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.523438 0 L 4.523438 -2.398438 L 0.179688 -2.398438 L 0.179688 -3.527344 L 4.75 -10.023438 L 5.757813 -10.023438 L 5.757813 -3.527344 L 7.109375 -3.527344 L 7.109375 -2.398438 L 5.757813 -2.398438 L 5.757813 0 Z M 4.523438 -3.527344 L 4.523438 -8.046875 L 1.386719 -3.527344 Z M 4.523438 -3.527344 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-6\">\n",
       "<path style=\"stroke:none;\" d=\"M 6.964844 -7.566406 L 5.742188 -7.472656 C 5.632813 -7.949219 5.476563 -8.300781 5.277344 -8.523438 C 4.941406 -8.871094 4.53125 -9.046875 4.046875 -9.050781 C 3.652344 -9.046875 3.308594 -8.9375 3.015625 -8.722656 C 2.625 -8.4375 2.320313 -8.023438 2.097656 -7.484375 C 1.875 -6.9375 1.757813 -6.167969 1.75 -5.167969 C 2.042969 -5.617188 2.40625 -5.949219 2.835938 -6.171875 C 3.265625 -6.386719 3.714844 -6.496094 4.183594 -6.5 C 5.003906 -6.496094 5.699219 -6.195313 6.277344 -5.59375 C 6.851563 -4.988281 7.140625 -4.207031 7.144531 -3.253906 C 7.140625 -2.621094 7.003906 -2.039063 6.734375 -1.5 C 6.460938 -0.960938 6.089844 -0.546875 5.617188 -0.257813 C 5.140625 0.0273438 4.605469 0.167969 4.007813 0.171875 C 2.980469 0.167969 2.140625 -0.207031 1.496094 -0.960938 C 0.847656 -1.714844 0.527344 -2.957031 0.527344 -4.6875 C 0.527344 -6.625 0.882813 -8.03125 1.601563 -8.914063 C 2.21875 -9.675781 3.058594 -10.058594 4.121094 -10.0625 C 4.90625 -10.058594 5.554688 -9.839844 6.058594 -9.398438 C 6.5625 -8.953125 6.863281 -8.339844 6.964844 -7.566406 Z M 1.941406 -3.246094 C 1.9375 -2.820313 2.027344 -2.414063 2.210938 -2.027344 C 2.386719 -1.640625 2.640625 -1.34375 2.964844 -1.144531 C 3.289063 -0.9375 3.628906 -0.835938 3.984375 -0.839844 C 4.503906 -0.835938 4.949219 -1.046875 5.324219 -1.46875 C 5.695313 -1.886719 5.882813 -2.457031 5.886719 -3.179688 C 5.882813 -3.871094 5.699219 -4.417969 5.332031 -4.816406 C 4.960938 -5.214844 4.496094 -5.414063 3.9375 -5.414063 C 3.378906 -5.414063 2.90625 -5.214844 2.519531 -4.816406 C 2.132813 -4.417969 1.9375 -3.894531 1.941406 -3.246094 Z M 1.941406 -3.246094 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-7\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.664063 -8.710938 L 0.664063 -9.890625 L 7.148438 -9.890625 L 7.148438 -8.933594 C 6.511719 -8.25 5.878906 -7.347656 5.253906 -6.226563 C 4.625 -5.097656 4.140625 -3.941406 3.800781 -2.753906 C 3.550781 -1.914063 3.394531 -0.996094 3.328125 0 L 2.0625 0 C 2.078125 -0.789063 2.230469 -1.738281 2.527344 -2.855469 C 2.820313 -3.96875 3.246094 -5.046875 3.800781 -6.085938 C 4.351563 -7.121094 4.941406 -7.996094 5.570313 -8.710938 Z M 0.664063 -8.710938 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-8\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.476563 -5.433594 C 1.964844 -5.617188 1.585938 -5.886719 1.339844 -6.234375 C 1.089844 -6.578125 0.964844 -6.992188 0.96875 -7.476563 C 0.964844 -8.203125 1.226563 -8.816406 1.753906 -9.316406 C 2.277344 -9.8125 2.976563 -10.058594 3.847656 -10.0625 C 4.71875 -10.058594 5.421875 -9.804688 5.960938 -9.300781 C 6.492188 -8.789063 6.761719 -8.171875 6.761719 -7.445313 C 6.761719 -6.976563 6.636719 -6.570313 6.394531 -6.230469 C 6.148438 -5.882813 5.78125 -5.617188 5.285156 -5.433594 C 5.898438 -5.230469 6.363281 -4.90625 6.6875 -4.460938 C 7.007813 -4.011719 7.171875 -3.480469 7.171875 -2.863281 C 7.171875 -2.003906 6.867188 -1.285156 6.261719 -0.703125 C 5.652344 -0.121094 4.855469 0.167969 3.867188 0.171875 C 2.878906 0.167969 2.082031 -0.121094 1.476563 -0.707031 C 0.867188 -1.289063 0.5625 -2.019531 0.566406 -2.898438 C 0.5625 -3.546875 0.726563 -4.09375 1.0625 -4.535156 C 1.390625 -4.972656 1.863281 -5.269531 2.476563 -5.433594 Z M 2.226563 -7.519531 C 2.226563 -7.042969 2.378906 -6.65625 2.683594 -6.355469 C 2.988281 -6.054688 3.382813 -5.90625 3.875 -5.90625 C 4.34375 -5.90625 4.734375 -6.054688 5.039063 -6.351563 C 5.34375 -6.648438 5.496094 -7.015625 5.496094 -7.453125 C 5.496094 -7.902344 5.339844 -8.28125 5.027344 -8.589844 C 4.714844 -8.894531 4.324219 -9.046875 3.863281 -9.050781 C 3.386719 -9.046875 2.996094 -8.894531 2.691406 -8.597656 C 2.378906 -8.292969 2.226563 -7.933594 2.226563 -7.519531 Z M 1.832031 -2.890625 C 1.828125 -2.539063 1.910156 -2.203125 2.082031 -1.875 C 2.246094 -1.546875 2.496094 -1.289063 2.824219 -1.109375 C 3.152344 -0.925781 3.503906 -0.835938 3.882813 -0.839844 C 4.46875 -0.835938 4.953125 -1.027344 5.339844 -1.40625 C 5.71875 -1.785156 5.910156 -2.265625 5.914063 -2.851563 C 5.910156 -3.441406 5.714844 -3.929688 5.320313 -4.320313 C 4.925781 -4.703125 4.433594 -4.898438 3.84375 -4.902344 C 3.261719 -4.898438 2.78125 -4.707031 2.402344 -4.328125 C 2.019531 -3.941406 1.828125 -3.460938 1.832031 -2.890625 Z M 1.832031 -2.890625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-9\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.765625 -2.316406 L 1.949219 -2.425781 C 2.046875 -1.871094 2.238281 -1.464844 2.519531 -1.214844 C 2.800781 -0.960938 3.164063 -0.835938 3.609375 -0.839844 C 3.984375 -0.835938 4.3125 -0.921875 4.601563 -1.097656 C 4.882813 -1.269531 5.117188 -1.503906 5.304688 -1.792969 C 5.484375 -2.082031 5.636719 -2.472656 5.761719 -2.964844 C 5.878906 -3.457031 5.941406 -3.957031 5.945313 -4.46875 C 5.941406 -4.523438 5.941406 -4.605469 5.941406 -4.71875 C 5.691406 -4.320313 5.351563 -4.003906 4.929688 -3.761719 C 4.5 -3.519531 4.039063 -3.398438 3.546875 -3.398438 C 2.714844 -3.398438 2.015625 -3.699219 1.441406 -4.300781 C 0.867188 -4.902344 0.578125 -5.695313 0.582031 -6.679688 C 0.578125 -7.695313 0.878906 -8.511719 1.480469 -9.132813 C 2.078125 -9.75 2.828125 -10.058594 3.734375 -10.0625 C 4.382813 -10.058594 4.980469 -9.882813 5.519531 -9.535156 C 6.058594 -9.179688 6.46875 -8.679688 6.75 -8.035156 C 7.03125 -7.382813 7.171875 -6.445313 7.171875 -5.214844 C 7.171875 -3.933594 7.03125 -2.914063 6.753906 -2.15625 C 6.472656 -1.398438 6.058594 -0.820313 5.511719 -0.421875 C 4.960938 -0.0273438 4.316406 0.167969 3.582031 0.171875 C 2.792969 0.167969 2.152344 -0.046875 1.660156 -0.480469 C 1.160156 -0.914063 0.863281 -1.523438 0.765625 -2.316406 Z M 5.804688 -6.742188 C 5.800781 -7.445313 5.613281 -8.003906 5.238281 -8.421875 C 4.863281 -8.832031 4.410156 -9.039063 3.882813 -9.042969 C 3.332031 -9.039063 2.855469 -8.816406 2.453125 -8.371094 C 2.042969 -7.921875 1.839844 -7.34375 1.84375 -6.636719 C 1.839844 -5.996094 2.03125 -5.476563 2.421875 -5.082031 C 2.804688 -4.679688 3.28125 -4.480469 3.847656 -4.484375 C 4.414063 -4.480469 4.882813 -4.679688 5.253906 -5.082031 C 5.617188 -5.476563 5.800781 -6.03125 5.804688 -6.742188 Z M 5.804688 -6.742188 \"/>\n",
       "</symbol>\n",
       "</g>\n",
       "</defs>\n",
       "<g id=\"surface192\">\n",
       "<rect x=\"0\" y=\"0\" width=\"500\" height=\"500\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n",
       "<path style=\"fill:none;stroke-width:6.872706;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 159.226563 320.820313 149.832031 306.761719 129.894531 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.372256;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 168.363281 301.761719 155.671875 271.121094 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.701965;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 139.035156 280.691406 135.734375 264.109375 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.084915;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 135.734375 235.890625 139.035156 219.308594 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.211402;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 155.671875 228.878906 168.363281 198.238281 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.872829;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 149.832031 193.238281 159.226563 179.179688 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.751678;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 179.179688 159.226563 193.238281 149.832031 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.689299;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 341.925781 C 320.820313 340.773438 306.761719 350.167969 299.75 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.41819;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 370.105469 299.75 C 350.167969 306.761719 340.773438 320.820313 341.925781 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.948134;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 380 C 235.890625 364.265625 219.308594 360.964844 200.25 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.504938;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 370.105469 C 280.691406 360.964844 264.109375 364.265625 250 380 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.372952;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 370.105469 C 266.582031 345.230469 233.417969 345.230469 200.25 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.50716;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 198.238281 168.363281 228.878906 155.671875 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.163901;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 219.308594 139.035156 235.890625 135.734375 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:6.977165;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 193.238281 350.167969 179.179688 340.773438 158.074219 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.921246;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 380 C 228.878906 344.328125 198.238281 331.636719 158.074219 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.174726;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 194.386719 329.0625 170.9375 305.613281 129.894531 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.380591;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 264.109375 135.734375 280.691406 139.035156 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.040892;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 271.121094 155.671875 301.761719 168.363281 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.502076;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 129.894531 C 306.761719 149.832031 320.820313 159.226563 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.82324;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 154.769531 266.582031 154.769531 233.417969 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.361768;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 174.707031 259.570313 184.101563 212.34375 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.327687;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 170.9375 194.386719 194.386719 170.9375 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.910733;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 203.527344 310.007813 176.777344 269.972656 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.185867;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 176.777344 230.027344 203.527344 189.992188 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.49057;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 158.074219 C 340.773438 179.179688 350.167969 193.238281 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.884598;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 233.417969 154.769531 266.582031 154.769531 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.198494;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 240.429688 174.707031 287.65625 184.101563 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.0143553;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 239.28125 195.8125 295.898438 219.261719 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.182692;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 269.972656 176.777344 310.007813 203.527344 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.02148;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 129.894531 C 305.613281 170.9375 329.0625 194.386719 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.063503;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 189.992188 203.527344 230.027344 176.777344 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.887525;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 184.101563 287.65625 174.707031 240.429688 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.899176;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 380 250 C 364.265625 264.109375 360.964844 280.691406 370.105469 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.883621;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 212.34375 184.101563 259.570313 174.707031 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.545968;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 195.832031 239.167969 239.167969 195.832031 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.536053;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 380 C 230.027344 323.222656 189.992188 296.472656 129.894531 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.636915;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 341.925781 C 301.761719 331.636719 271.121094 344.328125 250 380 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.731183;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 219.359375 204.039063 280.640625 204.039063 341.925781 158.074219 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 395 250 C 395 258.285156 388.285156 265 380 265 C 371.714844 265 365 258.285156 365 250 C 365 241.714844 371.714844 235 380 235 C 388.285156 235 395 241.714844 395 250 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 385.105469 299.75 C 385.105469 308.03125 378.386719 314.75 370.105469 314.75 C 361.820313 314.75 355.105469 308.03125 355.105469 299.75 C 355.105469 291.464844 361.820313 284.75 370.105469 284.75 C 378.386719 284.75 385.105469 291.464844 385.105469 299.75 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 356.925781 341.925781 C 356.925781 350.207031 350.207031 356.925781 341.925781 356.925781 C 333.640625 356.925781 326.925781 350.207031 326.925781 341.925781 C 326.925781 333.640625 333.640625 326.925781 341.925781 326.925781 C 350.207031 326.925781 356.925781 333.640625 356.925781 341.925781 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 314.75 370.105469 C 314.75 378.386719 308.03125 385.105469 299.75 385.105469 C 291.464844 385.105469 284.75 378.386719 284.75 370.105469 C 284.75 361.820313 291.464844 355.105469 299.75 355.105469 C 308.03125 355.105469 314.75 361.820313 314.75 370.105469 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 265 380 C 265 388.285156 258.285156 395 250 395 C 241.714844 395 235 388.285156 235 380 C 235 371.714844 241.714844 365 250 365 C 258.285156 365 265 371.714844 265 380 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 215.25 370.105469 C 215.25 378.386719 208.535156 385.105469 200.25 385.105469 C 191.96875 385.105469 185.25 378.386719 185.25 370.105469 C 185.25 361.820313 191.96875 355.105469 200.25 355.105469 C 208.535156 355.105469 215.25 361.820313 215.25 370.105469 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 173.074219 341.925781 C 173.074219 350.207031 166.359375 356.925781 158.074219 356.925781 C 149.792969 356.925781 143.074219 350.207031 143.074219 341.925781 C 143.074219 333.640625 149.792969 326.925781 158.074219 326.925781 C 166.359375 326.925781 173.074219 333.640625 173.074219 341.925781 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 144.894531 299.75 C 144.894531 308.03125 138.179688 314.75 129.894531 314.75 C 121.613281 314.75 114.894531 308.03125 114.894531 299.75 C 114.894531 291.464844 121.613281 284.75 129.894531 284.75 C 138.179688 284.75 144.894531 291.464844 144.894531 299.75 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 135 250 C 135 258.285156 128.285156 265 120 265 C 111.714844 265 105 258.285156 105 250 C 105 241.714844 111.714844 235 120 235 C 128.285156 235 135 241.714844 135 250 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 144.894531 200.25 C 144.894531 208.535156 138.179688 215.25 129.894531 215.25 C 121.613281 215.25 114.894531 208.535156 114.894531 200.25 C 114.894531 191.96875 121.613281 185.25 129.894531 185.25 C 138.179688 185.25 144.894531 191.96875 144.894531 200.25 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 173.074219 158.074219 C 173.074219 166.359375 166.359375 173.074219 158.074219 173.074219 C 149.792969 173.074219 143.074219 166.359375 143.074219 158.074219 C 143.074219 149.792969 149.792969 143.074219 158.074219 143.074219 C 166.359375 143.074219 173.074219 149.792969 173.074219 158.074219 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 215.25 129.894531 C 215.25 138.179688 208.535156 144.894531 200.25 144.894531 C 191.96875 144.894531 185.25 138.179688 185.25 129.894531 C 185.25 121.613281 191.96875 114.894531 200.25 114.894531 C 208.535156 114.894531 215.25 121.613281 215.25 129.894531 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 265 120 C 265 128.285156 258.285156 135 250 135 C 241.714844 135 235 128.285156 235 120 C 235 111.714844 241.714844 105 250 105 C 258.285156 105 265 111.714844 265 120 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 314.75 129.894531 C 314.75 138.179688 308.03125 144.894531 299.75 144.894531 C 291.464844 144.894531 284.75 138.179688 284.75 129.894531 C 284.75 121.613281 291.464844 114.894531 299.75 114.894531 C 308.03125 114.894531 314.75 121.613281 314.75 129.894531 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 356.925781 158.074219 C 356.925781 166.359375 350.207031 173.074219 341.925781 173.074219 C 333.640625 173.074219 326.925781 166.359375 326.925781 158.074219 C 326.925781 149.792969 333.640625 143.074219 341.925781 143.074219 C 350.207031 143.074219 356.925781 149.792969 356.925781 158.074219 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 385.105469 200.25 C 385.105469 208.535156 378.386719 215.25 370.105469 215.25 C 361.820313 215.25 355.105469 208.535156 355.105469 200.25 C 355.105469 191.96875 361.820313 185.25 370.105469 185.25 C 378.386719 185.25 385.105469 191.96875 385.105469 200.25 \"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"372.34375\" y=\"256.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"380.129883\" y=\"256.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"362.394531\" y=\"306.28125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"370.180664\" y=\"306.28125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"334.179688\" y=\"348.457031\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"341.96582\" y=\"348.457031\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"291.949219\" y=\"376.636719\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"299.735352\" y=\"376.636719\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"242.460938\" y=\"386.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"250.24707\" y=\"386.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"192.65625\" y=\"376.613281\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"200.442383\" y=\"376.613281\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"150.335938\" y=\"348.457031\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"158.12207\" y=\"348.457031\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"122.097656\" y=\"306.191406\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"129.883789\" y=\"306.191406\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"112.285156\" y=\"256.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"120.071289\" y=\"256.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"122.125\" y=\"206.78125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"129.911133\" y=\"206.78125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"150.292969\" y=\"164.605469\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"158.079102\" y=\"164.605469\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"192.414063\" y=\"136.339844\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"200.200195\" y=\"136.339844\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"242.265625\" y=\"126.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"250.051758\" y=\"126.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"291.960938\" y=\"136.425781\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"299.74707\" y=\"136.425781\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"334.183594\" y=\"164.605469\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"341.969727\" y=\"164.605469\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"362.308594\" y=\"206.78125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"370.094727\" y=\"206.78125\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<igraph.drawing.Plot at 0x1ec835abc08>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "image/svg+xml": {
       "isolated": true
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### plottrain set\n",
    "colors = ['red', 'white', 'blue', 'green']\n",
    "membership_vector = to_membership_vector(partition)\n",
    "visual_style = {\n",
    "    \"vertex_size\" : 30,\n",
    "    \"vertex_label\": [ x[1:] for x in data_df.loc[ : ,  'X20':'X95'].columns.values],\n",
    "    \"edge_width\" : [np.log2(x/100) for x in clusterer_igraph.graph_.es['weight']],\n",
    "    \"vertex_color\": [colors[membership_vector[i]] for i in range(y.shape[1])],\n",
    "    \"bbox\": (500,500),\n",
    "    \"margin\": 120,\n",
    "    \"layout\": clusterer_igraph.graph_.layout_circle(),\n",
    "    \"autocurve\":True,\n",
    "    \"edge_curved\":0.5\n",
    "}\n",
    "\n",
    "def testplot(graph, name):\n",
    "    graph.vs['label'] = graph.vs['name']\n",
    "    out = ig.plot(clusterer_igraph.graph_, **visual_style)\n",
    "    out.save(name + '_train_peptides.png')\n",
    "    \n",
    "testplot(clusterer_igraph.graph_, 'test1')\n",
    "ig.plot(clusterer_igraph.graph_, **visual_style)\n",
    "#ig.write(clusterer_igraph.graph_, filename=\"test.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 labels, 60 edges\n",
      "{(3, 4): 3893.0, (7, 8): 4462.0, (7, 9): 1221.0, (8, 9): 2909.0, (7, 10): 432.0, (8, 10): 1583.0, (9, 10): 2512.0, (1, 2): 917.0, (6, 7): 5022.0, (10, 11): 2309.0, (10, 12): 958.0, (11, 12): 1537.0, (2, 3): 2211.0, (4, 5): 5292.0, (4, 6): 1262.0, (5, 6): 5399.0, (11, 13): 587.0, (12, 13): 893.0, (11, 14): 190.0, (12, 14): 367.0, (13, 14): 485.0, (5, 7): 1525.0, (10, 13): 272.0, (0, 1): 160.0, (12, 15): 101.0, (13, 15): 167.0, (14, 15): 241.0, (7, 11): 43.0, (8, 11): 407.0, (9, 11): 881.0, (6, 8): 1795.0, (5, 8): 160.0, (3, 5): 462.0, (8, 12): 48.0, (9, 12): 169.0, (9, 13): 19.0, (6, 9): 139.0, (3, 6): 18.0, (3, 7): 3.0, (4, 7): 61.0, (6, 10): 24.0, (2, 4): 150.0, (3, 8): 1.0, (4, 8): 7.0, (10, 14): 61.0, (0, 2): 10.0, (8, 13): 7.0, (11, 15): 39.0, (9, 14): 1.0, (2, 5): 5.0, (5, 9): 4.0, (5, 10): 1.0, (1, 3): 19.0, (7, 12): 4.0, (10, 15): 8.0, (1, 4): 3.0, (2, 6): 1.0, (6, 11): 1.0, (4, 9): 1.0, (7, 13): 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([0, 1, 2, 3, 4, 5, 6]),\n",
       "       list([7, 8, 9, 10, 11, 12, 13, 14, 15])], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "edge_map = graph_builder.transform(y_test)\n",
    "print(\"{} labels, {} edges\".format(len(y[1]), len(edge_map)))\n",
    "print(edge_map)\n",
    "clusterer = NetworkXLabelGraphClusterer(graph_builder, method='louvain')\n",
    "clusterer_igraph = IGraphLabelGraphClusterer(graph_builder=graph_builder, method='walktrap')\n",
    "partition = clusterer_igraph.fit_predict(X_keys, y_test)\n",
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"500pt\" height=\"500pt\" viewBox=\"0 0 500 500\" version=\"1.1\">\n",
       "<defs>\n",
       "<g>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-0\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.75 0 L 1.75 -8.75 L 8.75 -8.75 L 8.75 0 Z M 1.96875 -0.21875 L 8.53125 -0.21875 L 8.53125 -8.53125 L 1.96875 -8.53125 Z M 1.96875 -0.21875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 7.046875 -1.183594 L 7.046875 0 L 0.421875 0 C 0.414063 -0.296875 0.460938 -0.582031 0.566406 -0.855469 C 0.734375 -1.304688 1.003906 -1.746094 1.375 -2.1875 C 1.746094 -2.621094 2.285156 -3.128906 2.988281 -3.703125 C 4.074219 -4.597656 4.808594 -5.304688 5.195313 -5.828125 C 5.574219 -6.347656 5.765625 -6.839844 5.769531 -7.308594 C 5.765625 -7.792969 5.589844 -8.203125 5.246094 -8.539063 C 4.894531 -8.871094 4.441406 -9.039063 3.882813 -9.042969 C 3.285156 -9.039063 2.8125 -8.863281 2.460938 -8.507813 C 2.105469 -8.152344 1.925781 -7.660156 1.921875 -7.035156 L 0.65625 -7.164063 C 0.742188 -8.105469 1.066406 -8.824219 1.632813 -9.320313 C 2.195313 -9.8125 2.953125 -10.058594 3.910156 -10.0625 C 4.867188 -10.058594 5.628906 -9.792969 6.191406 -9.261719 C 6.75 -8.726563 7.03125 -8.066406 7.035156 -7.28125 C 7.03125 -6.878906 6.949219 -6.484375 6.789063 -6.097656 C 6.621094 -5.707031 6.347656 -5.296875 5.96875 -4.871094 C 5.585938 -4.441406 4.953125 -3.855469 4.074219 -3.109375 C 3.332031 -2.488281 2.859375 -2.066406 2.652344 -1.847656 C 2.4375 -1.621094 2.265625 -1.402344 2.132813 -1.183594 Z M 7.046875 -1.183594 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.582031 -4.941406 C 0.578125 -6.121094 0.699219 -7.074219 0.945313 -7.800781 C 1.1875 -8.519531 1.550781 -9.078125 2.03125 -9.472656 C 2.511719 -9.863281 3.117188 -10.058594 3.847656 -10.0625 C 4.382813 -10.058594 4.855469 -9.953125 5.261719 -9.738281 C 5.667969 -9.519531 6 -9.207031 6.265625 -8.800781 C 6.527344 -8.390625 6.738281 -7.890625 6.890625 -7.308594 C 7.039063 -6.722656 7.113281 -5.933594 7.117188 -4.941406 C 7.113281 -3.761719 6.992188 -2.8125 6.753906 -2.09375 C 6.507813 -1.367188 6.144531 -0.808594 5.667969 -0.417969 C 5.183594 -0.0234375 4.578125 0.167969 3.847656 0.171875 C 2.878906 0.167969 2.121094 -0.175781 1.570313 -0.867188 C 0.910156 -1.699219 0.578125 -3.054688 0.582031 -4.941406 Z M 1.84375 -4.941406 C 1.839844 -3.292969 2.03125 -2.199219 2.421875 -1.65625 C 2.804688 -1.109375 3.28125 -0.835938 3.847656 -0.839844 C 4.410156 -0.835938 4.886719 -1.109375 5.273438 -1.660156 C 5.65625 -2.203125 5.847656 -3.296875 5.851563 -4.941406 C 5.847656 -6.589844 5.65625 -7.6875 5.273438 -8.230469 C 4.886719 -8.769531 4.40625 -9.039063 3.835938 -9.042969 C 3.269531 -9.039063 2.816406 -8.800781 2.480469 -8.328125 C 2.050781 -7.710938 1.839844 -6.582031 1.84375 -4.941406 Z M 1.84375 -4.941406 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.582031 -2.625 L 1.875 -2.734375 C 1.96875 -2.101563 2.1875 -1.628906 2.539063 -1.3125 C 2.882813 -0.996094 3.304688 -0.835938 3.800781 -0.839844 C 4.390625 -0.835938 4.890625 -1.058594 5.304688 -1.507813 C 5.710938 -1.953125 5.917969 -2.546875 5.921875 -3.289063 C 5.917969 -3.984375 5.71875 -4.539063 5.328125 -4.949219 C 4.929688 -5.351563 4.414063 -5.554688 3.78125 -5.558594 C 3.382813 -5.554688 3.027344 -5.464844 2.707031 -5.285156 C 2.386719 -5.105469 2.132813 -4.871094 1.953125 -4.585938 L 0.800781 -4.738281 L 1.769531 -9.882813 L 6.753906 -9.882813 L 6.753906 -8.710938 L 2.753906 -8.710938 L 2.214844 -6.015625 C 2.816406 -6.433594 3.445313 -6.644531 4.109375 -6.644531 C 4.980469 -6.644531 5.71875 -6.339844 6.324219 -5.734375 C 6.921875 -5.128906 7.222656 -4.351563 7.226563 -3.398438 C 7.222656 -2.492188 6.960938 -1.707031 6.433594 -1.046875 C 5.789063 -0.234375 4.910156 0.167969 3.800781 0.171875 C 2.886719 0.167969 2.140625 -0.0820313 1.566406 -0.59375 C 0.988281 -1.101563 0.660156 -1.78125 0.582031 -2.625 Z M 0.582031 -2.625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-4\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.585938 -2.644531 L 1.820313 -2.808594 C 1.957031 -2.109375 2.195313 -1.609375 2.539063 -1.300781 C 2.875 -0.992188 3.289063 -0.835938 3.78125 -0.839844 C 4.355469 -0.835938 4.84375 -1.039063 5.246094 -1.441406 C 5.640625 -1.839844 5.839844 -2.335938 5.84375 -2.933594 C 5.839844 -3.496094 5.65625 -3.960938 5.289063 -4.332031 C 4.917969 -4.695313 4.449219 -4.878906 3.882813 -4.882813 C 3.648438 -4.878906 3.359375 -4.832031 3.015625 -4.742188 L 3.152344 -5.824219 C 3.230469 -5.816406 3.296875 -5.8125 3.351563 -5.8125 C 3.875 -5.8125 4.34375 -5.949219 4.765625 -6.222656 C 5.179688 -6.496094 5.390625 -6.914063 5.394531 -7.484375 C 5.390625 -7.933594 5.238281 -8.308594 4.933594 -8.605469 C 4.628906 -8.898438 4.234375 -9.046875 3.753906 -9.050781 C 3.273438 -9.046875 2.875 -8.894531 2.554688 -8.597656 C 2.234375 -8.292969 2.027344 -7.84375 1.941406 -7.246094 L 0.710938 -7.464844 C 0.859375 -8.289063 1.203125 -8.925781 1.734375 -9.382813 C 2.265625 -9.832031 2.929688 -10.058594 3.726563 -10.0625 C 4.273438 -10.058594 4.773438 -9.941406 5.234375 -9.710938 C 5.691406 -9.472656 6.042969 -9.152344 6.289063 -8.75 C 6.53125 -8.339844 6.65625 -7.910156 6.65625 -7.457031 C 6.65625 -7.023438 6.539063 -6.628906 6.308594 -6.273438 C 6.074219 -5.917969 5.730469 -5.636719 5.277344 -5.429688 C 5.867188 -5.289063 6.328125 -5.003906 6.65625 -4.574219 C 6.984375 -4.140625 7.148438 -3.601563 7.148438 -2.960938 C 7.148438 -2.082031 6.828125 -1.339844 6.191406 -0.734375 C 5.550781 -0.125 4.746094 0.175781 3.773438 0.179688 C 2.890625 0.175781 2.160156 -0.0820313 1.582031 -0.605469 C 1 -1.128906 0.667969 -1.808594 0.585938 -2.644531 Z M 0.585938 -2.644531 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-5\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.523438 0 L 4.523438 -2.398438 L 0.179688 -2.398438 L 0.179688 -3.527344 L 4.75 -10.023438 L 5.757813 -10.023438 L 5.757813 -3.527344 L 7.109375 -3.527344 L 7.109375 -2.398438 L 5.757813 -2.398438 L 5.757813 0 Z M 4.523438 -3.527344 L 4.523438 -8.046875 L 1.386719 -3.527344 Z M 4.523438 -3.527344 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-6\">\n",
       "<path style=\"stroke:none;\" d=\"M 6.964844 -7.566406 L 5.742188 -7.472656 C 5.632813 -7.949219 5.476563 -8.300781 5.277344 -8.523438 C 4.941406 -8.871094 4.53125 -9.046875 4.046875 -9.050781 C 3.652344 -9.046875 3.308594 -8.9375 3.015625 -8.722656 C 2.625 -8.4375 2.320313 -8.023438 2.097656 -7.484375 C 1.875 -6.9375 1.757813 -6.167969 1.75 -5.167969 C 2.042969 -5.617188 2.40625 -5.949219 2.835938 -6.171875 C 3.265625 -6.386719 3.714844 -6.496094 4.183594 -6.5 C 5.003906 -6.496094 5.699219 -6.195313 6.277344 -5.59375 C 6.851563 -4.988281 7.140625 -4.207031 7.144531 -3.253906 C 7.140625 -2.621094 7.003906 -2.039063 6.734375 -1.5 C 6.460938 -0.960938 6.089844 -0.546875 5.617188 -0.257813 C 5.140625 0.0273438 4.605469 0.167969 4.007813 0.171875 C 2.980469 0.167969 2.140625 -0.207031 1.496094 -0.960938 C 0.847656 -1.714844 0.527344 -2.957031 0.527344 -4.6875 C 0.527344 -6.625 0.882813 -8.03125 1.601563 -8.914063 C 2.21875 -9.675781 3.058594 -10.058594 4.121094 -10.0625 C 4.90625 -10.058594 5.554688 -9.839844 6.058594 -9.398438 C 6.5625 -8.953125 6.863281 -8.339844 6.964844 -7.566406 Z M 1.941406 -3.246094 C 1.9375 -2.820313 2.027344 -2.414063 2.210938 -2.027344 C 2.386719 -1.640625 2.640625 -1.34375 2.964844 -1.144531 C 3.289063 -0.9375 3.628906 -0.835938 3.984375 -0.839844 C 4.503906 -0.835938 4.949219 -1.046875 5.324219 -1.46875 C 5.695313 -1.886719 5.882813 -2.457031 5.886719 -3.179688 C 5.882813 -3.871094 5.699219 -4.417969 5.332031 -4.816406 C 4.960938 -5.214844 4.496094 -5.414063 3.9375 -5.414063 C 3.378906 -5.414063 2.90625 -5.214844 2.519531 -4.816406 C 2.132813 -4.417969 1.9375 -3.894531 1.941406 -3.246094 Z M 1.941406 -3.246094 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-7\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.664063 -8.710938 L 0.664063 -9.890625 L 7.148438 -9.890625 L 7.148438 -8.933594 C 6.511719 -8.25 5.878906 -7.347656 5.253906 -6.226563 C 4.625 -5.097656 4.140625 -3.941406 3.800781 -2.753906 C 3.550781 -1.914063 3.394531 -0.996094 3.328125 0 L 2.0625 0 C 2.078125 -0.789063 2.230469 -1.738281 2.527344 -2.855469 C 2.820313 -3.96875 3.246094 -5.046875 3.800781 -6.085938 C 4.351563 -7.121094 4.941406 -7.996094 5.570313 -8.710938 Z M 0.664063 -8.710938 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-8\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.476563 -5.433594 C 1.964844 -5.617188 1.585938 -5.886719 1.339844 -6.234375 C 1.089844 -6.578125 0.964844 -6.992188 0.96875 -7.476563 C 0.964844 -8.203125 1.226563 -8.816406 1.753906 -9.316406 C 2.277344 -9.8125 2.976563 -10.058594 3.847656 -10.0625 C 4.71875 -10.058594 5.421875 -9.804688 5.960938 -9.300781 C 6.492188 -8.789063 6.761719 -8.171875 6.761719 -7.445313 C 6.761719 -6.976563 6.636719 -6.570313 6.394531 -6.230469 C 6.148438 -5.882813 5.78125 -5.617188 5.285156 -5.433594 C 5.898438 -5.230469 6.363281 -4.90625 6.6875 -4.460938 C 7.007813 -4.011719 7.171875 -3.480469 7.171875 -2.863281 C 7.171875 -2.003906 6.867188 -1.285156 6.261719 -0.703125 C 5.652344 -0.121094 4.855469 0.167969 3.867188 0.171875 C 2.878906 0.167969 2.082031 -0.121094 1.476563 -0.707031 C 0.867188 -1.289063 0.5625 -2.019531 0.566406 -2.898438 C 0.5625 -3.546875 0.726563 -4.09375 1.0625 -4.535156 C 1.390625 -4.972656 1.863281 -5.269531 2.476563 -5.433594 Z M 2.226563 -7.519531 C 2.226563 -7.042969 2.378906 -6.65625 2.683594 -6.355469 C 2.988281 -6.054688 3.382813 -5.90625 3.875 -5.90625 C 4.34375 -5.90625 4.734375 -6.054688 5.039063 -6.351563 C 5.34375 -6.648438 5.496094 -7.015625 5.496094 -7.453125 C 5.496094 -7.902344 5.339844 -8.28125 5.027344 -8.589844 C 4.714844 -8.894531 4.324219 -9.046875 3.863281 -9.050781 C 3.386719 -9.046875 2.996094 -8.894531 2.691406 -8.597656 C 2.378906 -8.292969 2.226563 -7.933594 2.226563 -7.519531 Z M 1.832031 -2.890625 C 1.828125 -2.539063 1.910156 -2.203125 2.082031 -1.875 C 2.246094 -1.546875 2.496094 -1.289063 2.824219 -1.109375 C 3.152344 -0.925781 3.503906 -0.835938 3.882813 -0.839844 C 4.46875 -0.835938 4.953125 -1.027344 5.339844 -1.40625 C 5.71875 -1.785156 5.910156 -2.265625 5.914063 -2.851563 C 5.910156 -3.441406 5.714844 -3.929688 5.320313 -4.320313 C 4.925781 -4.703125 4.433594 -4.898438 3.84375 -4.902344 C 3.261719 -4.898438 2.78125 -4.707031 2.402344 -4.328125 C 2.019531 -3.941406 1.828125 -3.460938 1.832031 -2.890625 Z M 1.832031 -2.890625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-9\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.765625 -2.316406 L 1.949219 -2.425781 C 2.046875 -1.871094 2.238281 -1.464844 2.519531 -1.214844 C 2.800781 -0.960938 3.164063 -0.835938 3.609375 -0.839844 C 3.984375 -0.835938 4.3125 -0.921875 4.601563 -1.097656 C 4.882813 -1.269531 5.117188 -1.503906 5.304688 -1.792969 C 5.484375 -2.082031 5.636719 -2.472656 5.761719 -2.964844 C 5.878906 -3.457031 5.941406 -3.957031 5.945313 -4.46875 C 5.941406 -4.523438 5.941406 -4.605469 5.941406 -4.71875 C 5.691406 -4.320313 5.351563 -4.003906 4.929688 -3.761719 C 4.5 -3.519531 4.039063 -3.398438 3.546875 -3.398438 C 2.714844 -3.398438 2.015625 -3.699219 1.441406 -4.300781 C 0.867188 -4.902344 0.578125 -5.695313 0.582031 -6.679688 C 0.578125 -7.695313 0.878906 -8.511719 1.480469 -9.132813 C 2.078125 -9.75 2.828125 -10.058594 3.734375 -10.0625 C 4.382813 -10.058594 4.980469 -9.882813 5.519531 -9.535156 C 6.058594 -9.179688 6.46875 -8.679688 6.75 -8.035156 C 7.03125 -7.382813 7.171875 -6.445313 7.171875 -5.214844 C 7.171875 -3.933594 7.03125 -2.914063 6.753906 -2.15625 C 6.472656 -1.398438 6.058594 -0.820313 5.511719 -0.421875 C 4.960938 -0.0273438 4.316406 0.167969 3.582031 0.171875 C 2.792969 0.167969 2.152344 -0.046875 1.660156 -0.480469 C 1.160156 -0.914063 0.863281 -1.523438 0.765625 -2.316406 Z M 5.804688 -6.742188 C 5.800781 -7.445313 5.613281 -8.003906 5.238281 -8.421875 C 4.863281 -8.832031 4.410156 -9.039063 3.882813 -9.042969 C 3.332031 -9.039063 2.855469 -8.816406 2.453125 -8.371094 C 2.042969 -7.921875 1.839844 -7.34375 1.84375 -6.636719 C 1.839844 -5.996094 2.03125 -5.476563 2.421875 -5.082031 C 2.804688 -4.679688 3.28125 -4.480469 3.847656 -4.484375 C 4.414063 -4.480469 4.882813 -4.679688 5.253906 -5.082031 C 5.617188 -5.476563 5.800781 -6.03125 5.804688 -6.742188 Z M 5.804688 -6.742188 \"/>\n",
       "</symbol>\n",
       "</g>\n",
       "</defs>\n",
       "<g id=\"surface215\">\n",
       "<rect x=\"0\" y=\"0\" width=\"500\" height=\"500\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n",
       "<path style=\"fill:none;stroke-width:5.28281;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 370.105469 C 280.691406 360.964844 264.109375 364.265625 250 380 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.479619;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 139.035156 280.691406 135.734375 264.109375 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.609991;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 154.769531 266.582031 154.769531 233.417969 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.862451;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 135.734375 235.890625 139.035156 219.308594 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.111031;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 299.75 C 174.707031 259.570313 184.101563 212.34375 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.984589;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 155.671875 228.878906 168.363281 198.238281 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.650765;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 149.832031 193.238281 159.226563 179.179688 158.074219 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.196922;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 370.105469 299.75 C 350.167969 306.761719 340.773438 320.820313 341.925781 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.65019;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 159.226563 320.820313 149.832031 306.761719 129.894531 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.529196;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 179.179688 159.226563 193.238281 149.832031 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.260026;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 198.238281 168.363281 228.878906 155.671875 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.942045;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 219.308594 139.035156 235.890625 135.734375 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.466627;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 341.925781 C 320.820313 340.773438 306.761719 350.167969 299.75 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.725741;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 380 C 235.890625 364.265625 219.308594 360.964844 200.25 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.65764;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 380 C 228.878906 344.328125 198.238281 331.636719 158.074219 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:5.75462;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 193.238281 350.167969 179.179688 340.773438 158.074219 341.925781 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.553361;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 233.417969 154.769531 266.582031 154.769531 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.15866;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 264.109375 135.734375 280.691406 139.035156 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.925999;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 129.894531 C 240.429688 174.707031 287.65625 184.101563 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.87578;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 271.121094 155.671875 301.761719 168.363281 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.277985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 129.894531 C 306.761719 149.832031 320.820313 159.226563 341.925781 158.074219 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.930737;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 194.386719 329.0625 170.9375 305.613281 129.894531 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.443607;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 158.074219 C 212.34375 184.101563 259.570313 174.707031 299.75 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.678072;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 380 250 C 364.265625 264.109375 360.964844 280.691406 370.105469 299.75 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.0143553;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250 120 C 269.972656 176.777344 310.007813 203.527344 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.739848;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 129.894531 C 305.613281 170.9375 329.0625 194.386719 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.269033;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 158.074219 C 340.773438 179.179688 350.167969 193.238281 370.105469 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.025029;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 120 250 C 176.777344 230.027344 203.527344 189.992188 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:3.139142;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 170.9375 194.386719 194.386719 170.9375 200.25 129.894531 \"/>\n",
       "<path style=\"fill:none;stroke-width:4.165912;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 168.363281 301.761719 155.671875 271.121094 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.678072;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 200.25 370.105469 C 203.527344 310.007813 176.777344 269.972656 120 250 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.207893;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 299.75 370.105469 C 266.582031 345.230469 233.417969 345.230469 200.25 370.105469 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.757023;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 129.894531 200.25 C 189.992188 203.527344 230.027344 176.777344 250 120 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.475085;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 158.074219 341.925781 C 184.101563 287.65625 174.707031 240.429688 129.894531 200.25 \"/>\n",
       "<path style=\"fill:none;stroke-width:0.584963;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 341.925781 341.925781 C 301.761719 331.636719 271.121094 344.328125 250 380 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 395 250 C 395 258.285156 388.285156 265 380 265 C 371.714844 265 365 258.285156 365 250 C 365 241.714844 371.714844 235 380 235 C 388.285156 235 395 241.714844 395 250 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 385.105469 299.75 C 385.105469 308.03125 378.386719 314.75 370.105469 314.75 C 361.820313 314.75 355.105469 308.03125 355.105469 299.75 C 355.105469 291.464844 361.820313 284.75 370.105469 284.75 C 378.386719 284.75 385.105469 291.464844 385.105469 299.75 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 356.925781 341.925781 C 356.925781 350.207031 350.207031 356.925781 341.925781 356.925781 C 333.640625 356.925781 326.925781 350.207031 326.925781 341.925781 C 326.925781 333.640625 333.640625 326.925781 341.925781 326.925781 C 350.207031 326.925781 356.925781 333.640625 356.925781 341.925781 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 314.75 370.105469 C 314.75 378.386719 308.03125 385.105469 299.75 385.105469 C 291.464844 385.105469 284.75 378.386719 284.75 370.105469 C 284.75 361.820313 291.464844 355.105469 299.75 355.105469 C 308.03125 355.105469 314.75 361.820313 314.75 370.105469 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 265 380 C 265 388.285156 258.285156 395 250 395 C 241.714844 395 235 388.285156 235 380 C 235 371.714844 241.714844 365 250 365 C 258.285156 365 265 371.714844 265 380 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 215.25 370.105469 C 215.25 378.386719 208.535156 385.105469 200.25 385.105469 C 191.96875 385.105469 185.25 378.386719 185.25 370.105469 C 185.25 361.820313 191.96875 355.105469 200.25 355.105469 C 208.535156 355.105469 215.25 361.820313 215.25 370.105469 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 173.074219 341.925781 C 173.074219 350.207031 166.359375 356.925781 158.074219 356.925781 C 149.792969 356.925781 143.074219 350.207031 143.074219 341.925781 C 143.074219 333.640625 149.792969 326.925781 158.074219 326.925781 C 166.359375 326.925781 173.074219 333.640625 173.074219 341.925781 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 144.894531 299.75 C 144.894531 308.03125 138.179688 314.75 129.894531 314.75 C 121.613281 314.75 114.894531 308.03125 114.894531 299.75 C 114.894531 291.464844 121.613281 284.75 129.894531 284.75 C 138.179688 284.75 144.894531 291.464844 144.894531 299.75 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 135 250 C 135 258.285156 128.285156 265 120 265 C 111.714844 265 105 258.285156 105 250 C 105 241.714844 111.714844 235 120 235 C 128.285156 235 135 241.714844 135 250 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 144.894531 200.25 C 144.894531 208.535156 138.179688 215.25 129.894531 215.25 C 121.613281 215.25 114.894531 208.535156 114.894531 200.25 C 114.894531 191.96875 121.613281 185.25 129.894531 185.25 C 138.179688 185.25 144.894531 191.96875 144.894531 200.25 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 173.074219 158.074219 C 173.074219 166.359375 166.359375 173.074219 158.074219 173.074219 C 149.792969 173.074219 143.074219 166.359375 143.074219 158.074219 C 143.074219 149.792969 149.792969 143.074219 158.074219 143.074219 C 166.359375 143.074219 173.074219 149.792969 173.074219 158.074219 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 215.25 129.894531 C 215.25 138.179688 208.535156 144.894531 200.25 144.894531 C 191.96875 144.894531 185.25 138.179688 185.25 129.894531 C 185.25 121.613281 191.96875 114.894531 200.25 114.894531 C 208.535156 114.894531 215.25 121.613281 215.25 129.894531 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 265 120 C 265 128.285156 258.285156 135 250 135 C 241.714844 135 235 128.285156 235 120 C 235 111.714844 241.714844 105 250 105 C 258.285156 105 265 111.714844 265 120 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 314.75 129.894531 C 314.75 138.179688 308.03125 144.894531 299.75 144.894531 C 291.464844 144.894531 284.75 138.179688 284.75 129.894531 C 284.75 121.613281 291.464844 114.894531 299.75 114.894531 C 308.03125 114.894531 314.75 121.613281 314.75 129.894531 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 356.925781 158.074219 C 356.925781 166.359375 350.207031 173.074219 341.925781 173.074219 C 333.640625 173.074219 326.925781 166.359375 326.925781 158.074219 C 326.925781 149.792969 333.640625 143.074219 341.925781 143.074219 C 350.207031 143.074219 356.925781 149.792969 356.925781 158.074219 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 385.105469 200.25 C 385.105469 208.535156 378.386719 215.25 370.105469 215.25 C 361.820313 215.25 355.105469 208.535156 355.105469 200.25 C 355.105469 191.96875 361.820313 185.25 370.105469 185.25 C 378.386719 185.25 385.105469 191.96875 385.105469 200.25 \"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"372.34375\" y=\"256.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"380.129883\" y=\"256.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"362.394531\" y=\"306.28125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"370.180664\" y=\"306.28125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"334.179688\" y=\"348.457031\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"341.96582\" y=\"348.457031\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"291.949219\" y=\"376.636719\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"299.735352\" y=\"376.636719\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"242.460938\" y=\"386.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"250.24707\" y=\"386.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"192.65625\" y=\"376.613281\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"200.442383\" y=\"376.613281\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"150.335938\" y=\"348.457031\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"158.12207\" y=\"348.457031\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"122.097656\" y=\"306.191406\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"129.883789\" y=\"306.191406\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"112.285156\" y=\"256.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"120.071289\" y=\"256.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"122.125\" y=\"206.78125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"129.911133\" y=\"206.78125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"150.292969\" y=\"164.605469\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"158.079102\" y=\"164.605469\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"192.414063\" y=\"136.339844\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"200.200195\" y=\"136.339844\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"242.265625\" y=\"126.53125\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"250.051758\" y=\"126.53125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"291.960938\" y=\"136.425781\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"299.74707\" y=\"136.425781\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"334.183594\" y=\"164.605469\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"341.969727\" y=\"164.605469\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"362.308594\" y=\"206.78125\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"370.094727\" y=\"206.78125\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<igraph.drawing.Plot at 0x1ecd0ab9f08>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "image/svg+xml": {
       "isolated": true
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### plottrain set\n",
    "colors = ['red', 'white', 'blue', 'green']\n",
    "membership_vector = to_membership_vector(partition)\n",
    "visual_style = {\n",
    "    \"vertex_size\" : 30,\n",
    "    \"vertex_label\": [ x[1:] for x in data_df.loc[ : ,  'X20':'X95'].columns.values],\n",
    "    \"edge_width\" : [np.log2(x/100) for x in clusterer_igraph.graph_.es['weight']],\n",
    "    \"vertex_color\": [colors[membership_vector[i]] for i in range(y.shape[1])],\n",
    "    \"bbox\": (500,500),\n",
    "    \"margin\": 120,\n",
    "    \"layout\": clusterer_igraph.graph_.layout_circle(),\n",
    "    \"autocurve\":True,\n",
    "    \"edge_curved\":0.5\n",
    "}\n",
    "\n",
    "def testplot(graph, name):\n",
    "    graph.vs['label'] = graph.vs['name']\n",
    "    out = ig.plot(clusterer_igraph.graph_, **visual_style)\n",
    "    out.save(name + '_test_peptides.png')\n",
    "    \n",
    "testplot(clusterer_igraph.graph_, 'test1')\n",
    "ig.plot(clusterer_igraph.graph_, **visual_style)\n",
    "#ig.write(clusterer_igraph.graph_, filename=\"test.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "        \n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kwargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-8ad39d87534d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m adam = tf.keras.optimizers.Adam(\n\u001b[0;32m     10\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-07\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinaryAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kwargs' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=51, output_dim=40))\n",
    "model.add(layers.LSTM(128, return_sequences=True, input_shape=(maxlen,len_vocab)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(128, return_sequences=False))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(set(cv)), activation='sigmoid'))\n",
    "adam = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy, optimizer=adam,  metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 40)          2040      \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, None, 128)         86528     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 229,448\n",
      "Trainable params: 229,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85991 samples, validate on 36856 samples\n",
      "Epoch 1/25\n",
      "85991/85991 [==============================] - 7s 76us/sample - loss: 0.3908 - binary_accuracy: 0.8481 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 2/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3371 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 3/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3362 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 4/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3358 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 5/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3355 - binary_accuracy: 0.8726 - val_loss: 0.3345 - val_binary_accuracy: 0.8727\n",
      "Epoch 6/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3354 - binary_accuracy: 0.8726 - val_loss: 0.3346 - val_binary_accuracy: 0.8727\n",
      "Epoch 7/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3353 - binary_accuracy: 0.8726 - val_loss: 0.3345 - val_binary_accuracy: 0.8727\n",
      "Epoch 8/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3352 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 9/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3351 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 10/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3350 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 11/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3351 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 12/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3350 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 13/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3350 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 14/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3349 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 15/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3349 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 16/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3348 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 17/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3349 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 18/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3349 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 19/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3349 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 20/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3348 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 21/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3349 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 22/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3345 - val_binary_accuracy: 0.8727\n",
      "Epoch 23/25\n",
      "85991/85991 [==============================] - 4s 42us/sample - loss: 0.3348 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 24/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3351 - binary_accuracy: 0.8725 - val_loss: 0.3346 - val_binary_accuracy: 0.8727\n",
      "Epoch 25/25\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.3348 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=25, batch_size=2048, workers=4, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85991 samples, validate on 36856 samples\n",
      "Epoch 1/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 2/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 3/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 4/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 5/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 6/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 7/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3346 - val_binary_accuracy: 0.8727\n",
      "Epoch 8/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3349 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 9/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 10/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 11/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 12/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3351 - binary_accuracy: 0.8726 - val_loss: 0.3341 - val_binary_accuracy: 0.8727\n",
      "Epoch 13/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3349 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 14/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3348 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 15/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3348 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 16/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3348 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 17/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3348 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 18/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 19/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 20/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 21/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 22/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 23/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 24/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 25/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 26/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 27/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 28/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 29/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3347 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 30/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 31/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 32/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 33/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 34/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 35/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 36/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 37/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 38/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 39/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 40/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.87270.3354 - bi\n",
      "Epoch 41/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 42/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 43/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 44/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 45/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 46/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 47/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 48/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 49/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3341 - val_binary_accuracy: 0.8727\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 51/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 52/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 53/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 54/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 55/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 56/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 57/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 58/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 59/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 60/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 61/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 62/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 63/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 64/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 65/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 66/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 67/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 68/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 69/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 70/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 71/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 72/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 73/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 74/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3346 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 75/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 76/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 77/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 78/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 79/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 80/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 81/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 82/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 83/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 84/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 85/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727ss: 0.3346 - binary_accura\n",
      "Epoch 86/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727- loss: 0.3349 - binary_a\n",
      "Epoch 87/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 88/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 89/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 90/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 91/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 92/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 93/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 94/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 95/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 96/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 97/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727343 - binary_\n",
      "Epoch 99/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 100/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 101/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727- binary_accuracy: 0 - ETA: 0s - loss: 0.3344 - binary_accuracy: 0.872\n",
      "Epoch 102/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 103/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 104/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 105/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 106/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3345 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 107/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 108/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3344 - val_binary_accuracy: 0.8727\n",
      "Epoch 109/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 110/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 111/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 112/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 113/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 114/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 115/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3341 - val_binary_accuracy: 0.8727\n",
      "Epoch 116/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 117/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 118/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 119/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 120/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 121/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 122/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 123/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 124/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 125/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 126/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 127/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 128/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 129/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 130/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3344 - binary_accuracy: 0.8726 - val_loss: 0.3343 - val_binary_accuracy: 0.8727\n",
      "Epoch 131/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3341 - binary_accuracy: 0.8726 - val_loss: 0.3331 - val_binary_accuracy: 0.8727\n",
      "Epoch 132/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3219 - binary_accuracy: 0.8726 - val_loss: 0.3149 - val_binary_accuracy: 0.8727\n",
      "Epoch 133/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3174 - binary_accuracy: 0.8726 - val_loss: 0.3182 - val_binary_accuracy: 0.8727\n",
      "Epoch 134/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3164 - binary_accuracy: 0.8726 - val_loss: 0.3171 - val_binary_accuracy: 0.8727\n",
      "Epoch 135/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3152 - binary_accuracy: 0.8726 - val_loss: 0.3163 - val_binary_accuracy: 0.8727\n",
      "Epoch 136/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.3097 - binary_accuracy: 0.8726 - val_loss: 0.2820 - val_binary_accuracy: 0.8742nary_accura\n",
      "Epoch 137/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2685 - binary_accuracy: 0.8793 - val_loss: 0.2591 - val_binary_accuracy: 0.8828loss: 0.2712 - binary_accura\n",
      "Epoch 138/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2576 - binary_accuracy: 0.8838 - val_loss: 0.2554 - val_binary_accuracy: 0.8847\n",
      "Epoch 139/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2513 - binary_accuracy: 0.8857 - val_loss: 0.2473 - val_binary_accuracy: 0.8868\n",
      "Epoch 140/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2463 - binary_accuracy: 0.8873 - val_loss: 0.2444 - val_binary_accuracy: 0.8878\n",
      "Epoch 141/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2424 - binary_accuracy: 0.8886 - val_loss: 0.2385 - val_binary_accuracy: 0.8897\n",
      "Epoch 142/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2400 - binary_accuracy: 0.8892 - val_loss: 0.2360 - val_binary_accuracy: 0.8901\n",
      "Epoch 143/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2354 - binary_accuracy: 0.8906 - val_loss: 0.2327 - val_binary_accuracy: 0.8916\n",
      "Epoch 144/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2318 - binary_accuracy: 0.8917 - val_loss: 0.2276 - val_binary_accuracy: 0.8928\n",
      "Epoch 145/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2282 - binary_accuracy: 0.8928 - val_loss: 0.2246 - val_binary_accuracy: 0.8931\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2252 - binary_accuracy: 0.8937 - val_loss: 0.2235 - val_binary_accuracy: 0.8934\n",
      "Epoch 147/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2227 - binary_accuracy: 0.8945 - val_loss: 0.2210 - val_binary_accuracy: 0.8950\n",
      "Epoch 148/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2205 - binary_accuracy: 0.8953 - val_loss: 0.2172 - val_binary_accuracy: 0.8966\n",
      "Epoch 149/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2186 - binary_accuracy: 0.8961 - val_loss: 0.2159 - val_binary_accuracy: 0.8969\n",
      "Epoch 150/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.2167 - binary_accuracy: 0.8967 - val_loss: 0.2151 - val_binary_accuracy: 0.8973\n",
      "Epoch 151/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2164 - binary_accuracy: 0.8970 - val_loss: 0.2136 - val_binary_accuracy: 0.8981\n",
      "Epoch 152/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2151 - binary_accuracy: 0.8974 - val_loss: 0.2126 - val_binary_accuracy: 0.8983\n",
      "Epoch 153/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2140 - binary_accuracy: 0.8981 - val_loss: 0.2137 - val_binary_accuracy: 0.8978\n",
      "Epoch 154/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2131 - binary_accuracy: 0.8985 - val_loss: 0.2115 - val_binary_accuracy: 0.8991\n",
      "Epoch 155/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.2121 - binary_accuracy: 0.8990 - val_loss: 0.2109 - val_binary_accuracy: 0.8992\n",
      "Epoch 156/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2122 - binary_accuracy: 0.8990 - val_loss: 0.2106 - val_binary_accuracy: 0.8990\n",
      "Epoch 157/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.2108 - binary_accuracy: 0.8995 - val_loss: 0.2092 - val_binary_accuracy: 0.8999\n",
      "Epoch 158/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2091 - binary_accuracy: 0.9002 - val_loss: 0.2080 - val_binary_accuracy: 0.9006\n",
      "Epoch 159/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2090 - binary_accuracy: 0.9002 - val_loss: 0.2090 - val_binary_accuracy: 0.8997ccuracy: 0.\n",
      "Epoch 160/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2077 - binary_accuracy: 0.9011 - val_loss: 0.2092 - val_binary_accuracy: 0.8998\n",
      "Epoch 161/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2078 - binary_accuracy: 0.9010 - val_loss: 0.2067 - val_binary_accuracy: 0.9013\n",
      "Epoch 162/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2064 - binary_accuracy: 0.9016 - val_loss: 0.2064 - val_binary_accuracy: 0.9013\n",
      "Epoch 163/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2059 - binary_accuracy: 0.9018 - val_loss: 0.2057 - val_binary_accuracy: 0.9015\n",
      "Epoch 164/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2053 - binary_accuracy: 0.9022 - val_loss: 0.2058 - val_binary_accuracy: 0.9016\n",
      "Epoch 165/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2050 - binary_accuracy: 0.9021 - val_loss: 0.2047 - val_binary_accuracy: 0.9023\n",
      "Epoch 166/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2042 - binary_accuracy: 0.9027 - val_loss: 0.2034 - val_binary_accuracy: 0.9023\n",
      "Epoch 167/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2036 - binary_accuracy: 0.9032 - val_loss: 0.2049 - val_binary_accuracy: 0.9018\n",
      "Epoch 168/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2033 - binary_accuracy: 0.9031 - val_loss: 0.2037 - val_binary_accuracy: 0.9023\n",
      "Epoch 169/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2027 - binary_accuracy: 0.9033 - val_loss: 0.2046 - val_binary_accuracy: 0.9025\n",
      "Epoch 170/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2028 - binary_accuracy: 0.9035 - val_loss: 0.2029 - val_binary_accuracy: 0.9031\n",
      "Epoch 171/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.2023 - binary_accuracy: 0.9039 - val_loss: 0.2031 - val_binary_accuracy: 0.9029\n",
      "Epoch 172/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2013 - binary_accuracy: 0.9042 - val_loss: 0.2034 - val_binary_accuracy: 0.9027\n",
      "Epoch 173/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2006 - binary_accuracy: 0.9044 - val_loss: 0.2013 - val_binary_accuracy: 0.9037\n",
      "Epoch 174/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2005 - binary_accuracy: 0.9046 - val_loss: 0.2021 - val_binary_accuracy: 0.9032\n",
      "Epoch 175/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.2002 - binary_accuracy: 0.9049 - val_loss: 0.2006 - val_binary_accuracy: 0.9040\n",
      "Epoch 176/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1993 - binary_accuracy: 0.9053 - val_loss: 0.2006 - val_binary_accuracy: 0.9040\n",
      "Epoch 177/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1991 - binary_accuracy: 0.9052 - val_loss: 0.2008 - val_binary_accuracy: 0.9041\n",
      "Epoch 178/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1987 - binary_accuracy: 0.9054 - val_loss: 0.2014 - val_binary_accuracy: 0.9037\n",
      "Epoch 179/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1988 - binary_accuracy: 0.9054 - val_loss: 0.1995 - val_binary_accuracy: 0.9046\n",
      "Epoch 180/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1981 - binary_accuracy: 0.9059 - val_loss: 0.2007 - val_binary_accuracy: 0.9042\n",
      "Epoch 181/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1972 - binary_accuracy: 0.9064 - val_loss: 0.2000 - val_binary_accuracy: 0.9044\n",
      "Epoch 182/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1969 - binary_accuracy: 0.9066 - val_loss: 0.2005 - val_binary_accuracy: 0.9040\n",
      "Epoch 183/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1975 - binary_accuracy: 0.9060 - val_loss: 0.1982 - val_binary_accuracy: 0.9052\n",
      "Epoch 184/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1961 - binary_accuracy: 0.9070 - val_loss: 0.1984 - val_binary_accuracy: 0.9055\n",
      "Epoch 185/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1960 - binary_accuracy: 0.9070 - val_loss: 0.1992 - val_binary_accuracy: 0.9046\n",
      "Epoch 186/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1957 - binary_accuracy: 0.9072 - val_loss: 0.1989 - val_binary_accuracy: 0.9052\n",
      "Epoch 187/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1954 - binary_accuracy: 0.9074 - val_loss: 0.1993 - val_binary_accuracy: 0.9050\n",
      "Epoch 188/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1953 - binary_accuracy: 0.9074 - val_loss: 0.1982 - val_binary_accuracy: 0.9054\n",
      "Epoch 189/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1945 - binary_accuracy: 0.9077 - val_loss: 0.1986 - val_binary_accuracy: 0.9052\n",
      "Epoch 190/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1945 - binary_accuracy: 0.9080 - val_loss: 0.1975 - val_binary_accuracy: 0.9057\n",
      "Epoch 191/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1937 - binary_accuracy: 0.9084 - val_loss: 0.1982 - val_binary_accuracy: 0.9056\n",
      "Epoch 192/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1937 - binary_accuracy: 0.9080 - val_loss: 0.1994 - val_binary_accuracy: 0.9045\n",
      "Epoch 193/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1936 - binary_accuracy: 0.9083 - val_loss: 0.1978 - val_binary_accuracy: 0.9052\n",
      "Epoch 194/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1925 - binary_accuracy: 0.9089 - val_loss: 0.1970 - val_binary_accuracy: 0.9062\n",
      "Epoch 195/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1923 - binary_accuracy: 0.9089 - val_loss: 0.1973 - val_binary_accuracy: 0.9059\n",
      "Epoch 196/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1921 - binary_accuracy: 0.9092 - val_loss: 0.1967 - val_binary_accuracy: 0.9062\n",
      "Epoch 197/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1919 - binary_accuracy: 0.9092 - val_loss: 0.1971 - val_binary_accuracy: 0.9057\n",
      "Epoch 198/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1913 - binary_accuracy: 0.9096 - val_loss: 0.1970 - val_binary_accuracy: 0.9060\n",
      "Epoch 199/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1913 - binary_accuracy: 0.9095 - val_loss: 0.1994 - val_binary_accuracy: 0.9052\n",
      "Epoch 200/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1910 - binary_accuracy: 0.9096 - val_loss: 0.1962 - val_binary_accuracy: 0.9064\n",
      "Epoch 201/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1905 - binary_accuracy: 0.9099 - val_loss: 0.1974 - val_binary_accuracy: 0.9061\n",
      "Epoch 202/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1903 - binary_accuracy: 0.9100 - val_loss: 0.1966 - val_binary_accuracy: 0.9060\n",
      "Epoch 203/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1899 - binary_accuracy: 0.9104 - val_loss: 0.1979 - val_binary_accuracy: 0.9059\n",
      "Epoch 204/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1899 - binary_accuracy: 0.9104 - val_loss: 0.1956 - val_binary_accuracy: 0.9070\n",
      "Epoch 205/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1893 - binary_accuracy: 0.9107 - val_loss: 0.1965 - val_binary_accuracy: 0.9062\n",
      "Epoch 206/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1890 - binary_accuracy: 0.9107 - val_loss: 0.1970 - val_binary_accuracy: 0.9061\n",
      "Epoch 207/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1885 - binary_accuracy: 0.9114 - val_loss: 0.1957 - val_binary_accuracy: 0.9070\n",
      "Epoch 208/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1879 - binary_accuracy: 0.9114 - val_loss: 0.1963 - val_binary_accuracy: 0.9067\n",
      "Epoch 209/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1877 - binary_accuracy: 0.9116 - val_loss: 0.1964 - val_binary_accuracy: 0.9067\n",
      "Epoch 210/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1873 - binary_accuracy: 0.9117 - val_loss: 0.1957 - val_binary_accuracy: 0.9072\n",
      "Epoch 211/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1868 - binary_accuracy: 0.9118 - val_loss: 0.1964 - val_binary_accuracy: 0.9068\n",
      "Epoch 212/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1869 - binary_accuracy: 0.9120 - val_loss: 0.1966 - val_binary_accuracy: 0.9064\n",
      "Epoch 213/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1863 - binary_accuracy: 0.9124 - val_loss: 0.1966 - val_binary_accuracy: 0.9067\n",
      "Epoch 214/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1859 - binary_accuracy: 0.9125 - val_loss: 0.1968 - val_binary_accuracy: 0.9062\n",
      "Epoch 215/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1858 - binary_accuracy: 0.9127 - val_loss: 0.1969 - val_binary_accuracy: 0.9066\n",
      "Epoch 216/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1852 - binary_accuracy: 0.9131 - val_loss: 0.1955 - val_binary_accuracy: 0.9075\n",
      "Epoch 217/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1851 - binary_accuracy: 0.9130 - val_loss: 0.1959 - val_binary_accuracy: 0.9069\n",
      "Epoch 218/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1845 - binary_accuracy: 0.9134 - val_loss: 0.1964 - val_binary_accuracy: 0.9068\n",
      "Epoch 219/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1842 - binary_accuracy: 0.9135 - val_loss: 0.1972 - val_binary_accuracy: 0.9060\n",
      "Epoch 220/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1844 - binary_accuracy: 0.9135 - val_loss: 0.1972 - val_binary_accuracy: 0.9068\n",
      "Epoch 221/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1835 - binary_accuracy: 0.9139 - val_loss: 0.1966 - val_binary_accuracy: 0.9070\n",
      "Epoch 222/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1833 - binary_accuracy: 0.9140 - val_loss: 0.1973 - val_binary_accuracy: 0.9067\n",
      "Epoch 223/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1831 - binary_accuracy: 0.9142 - val_loss: 0.1965 - val_binary_accuracy: 0.9067\n",
      "Epoch 224/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1821 - binary_accuracy: 0.9146 - val_loss: 0.1967 - val_binary_accuracy: 0.9067\n",
      "Epoch 225/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1819 - binary_accuracy: 0.9147 - val_loss: 0.1964 - val_binary_accuracy: 0.9071\n",
      "Epoch 226/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1820 - binary_accuracy: 0.9147 - val_loss: 0.1963 - val_binary_accuracy: 0.9070\n",
      "Epoch 227/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1815 - binary_accuracy: 0.9148 - val_loss: 0.1966 - val_binary_accuracy: 0.9071\n",
      "Epoch 228/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1812 - binary_accuracy: 0.9153 - val_loss: 0.1977 - val_binary_accuracy: 0.9068\n",
      "Epoch 229/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1802 - binary_accuracy: 0.9157 - val_loss: 0.1959 - val_binary_accuracy: 0.9076\n",
      "Epoch 230/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1799 - binary_accuracy: 0.9158 - val_loss: 0.1970 - val_binary_accuracy: 0.9073 2s - los\n",
      "Epoch 231/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1799 - binary_accuracy: 0.9158 - val_loss: 0.1978 - val_binary_accuracy: 0.9068\n",
      "Epoch 232/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1792 - binary_accuracy: 0.9162 - val_loss: 0.1964 - val_binary_accuracy: 0.9072\n",
      "Epoch 233/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1789 - binary_accuracy: 0.9165 - val_loss: 0.1976 - val_binary_accuracy: 0.9071\n",
      "Epoch 234/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1793 - binary_accuracy: 0.9162 - val_loss: 0.1965 - val_binary_accuracy: 0.9076\n",
      "Epoch 235/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1781 - binary_accuracy: 0.9168 - val_loss: 0.1972 - val_binary_accuracy: 0.9067\n",
      "Epoch 236/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1785 - binary_accuracy: 0.9166 - val_loss: 0.1977 - val_binary_accuracy: 0.9064\n",
      "Epoch 237/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1783 - binary_accuracy: 0.9168 - val_loss: 0.1974 - val_binary_accuracy: 0.9070\n",
      "Epoch 238/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1771 - binary_accuracy: 0.9173 - val_loss: 0.1997 - val_binary_accuracy: 0.9057\n",
      "Epoch 239/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1765 - binary_accuracy: 0.9175 - val_loss: 0.1984 - val_binary_accuracy: 0.9071\n",
      "Epoch 240/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1763 - binary_accuracy: 0.9176 - val_loss: 0.1969 - val_binary_accuracy: 0.9074\n",
      "Epoch 241/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1759 - binary_accuracy: 0.9181 - val_loss: 0.1984 - val_binary_accuracy: 0.9067\n",
      "Epoch 242/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1748 - binary_accuracy: 0.9186 - val_loss: 0.1989 - val_binary_accuracy: 0.9070\n",
      "Epoch 243/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1752 - binary_accuracy: 0.9183 - val_loss: 0.1985 - val_binary_accuracy: 0.9070\n",
      "Epoch 244/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1749 - binary_accuracy: 0.9187 - val_loss: 0.2002 - val_binary_accuracy: 0.9063\n",
      "Epoch 245/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1749 - binary_accuracy: 0.9187 - val_loss: 0.1988 - val_binary_accuracy: 0.9068\n",
      "Epoch 246/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1741 - binary_accuracy: 0.9189 - val_loss: 0.1984 - val_binary_accuracy: 0.9073\n",
      "Epoch 247/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1735 - binary_accuracy: 0.9193 - val_loss: 0.2007 - val_binary_accuracy: 0.9054\n",
      "Epoch 248/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1738 - binary_accuracy: 0.9192 - val_loss: 0.1999 - val_binary_accuracy: 0.9062\n",
      "Epoch 249/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1725 - binary_accuracy: 0.9200 - val_loss: 0.1997 - val_binary_accuracy: 0.9067\n",
      "Epoch 250/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1720 - binary_accuracy: 0.9203 - val_loss: 0.2006 - val_binary_accuracy: 0.9062\n",
      "Epoch 251/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1716 - binary_accuracy: 0.9205 - val_loss: 0.2030 - val_binary_accuracy: 0.9056\n",
      "Epoch 252/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1719 - binary_accuracy: 0.9202 - val_loss: 0.2008 - val_binary_accuracy: 0.9067\n",
      "Epoch 253/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1710 - binary_accuracy: 0.9208 - val_loss: 0.2014 - val_binary_accuracy: 0.9062\n",
      "Epoch 254/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1712 - binary_accuracy: 0.9206 - val_loss: 0.2006 - val_binary_accuracy: 0.9068\n",
      "Epoch 255/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1702 - binary_accuracy: 0.9211 - val_loss: 0.2018 - val_binary_accuracy: 0.9063\n",
      "Epoch 256/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1700 - binary_accuracy: 0.9214 - val_loss: 0.2013 - val_binary_accuracy: 0.9064\n",
      "Epoch 257/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1697 - binary_accuracy: 0.9214 - val_loss: 0.2023 - val_binary_accuracy: 0.9063\n",
      "Epoch 258/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1693 - binary_accuracy: 0.9217 - val_loss: 0.2019 - val_binary_accuracy: 0.9065\n",
      "Epoch 259/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1681 - binary_accuracy: 0.9224 - val_loss: 0.2017 - val_binary_accuracy: 0.9063\n",
      "Epoch 260/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1682 - binary_accuracy: 0.9223 - val_loss: 0.2035 - val_binary_accuracy: 0.9057\n",
      "Epoch 261/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1676 - binary_accuracy: 0.9227 - val_loss: 0.2032 - val_binary_accuracy: 0.9063\n",
      "Epoch 262/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1711 - binary_accuracy: 0.9206 - val_loss: 0.2028 - val_binary_accuracy: 0.9061\n",
      "Epoch 263/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1679 - binary_accuracy: 0.9225 - val_loss: 0.2026 - val_binary_accuracy: 0.9063\n",
      "Epoch 264/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1673 - binary_accuracy: 0.9227 - val_loss: 0.2039 - val_binary_accuracy: 0.9064\n",
      "Epoch 265/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1667 - binary_accuracy: 0.9230 - val_loss: 0.2047 - val_binary_accuracy: 0.9054\n",
      "Epoch 266/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1666 - binary_accuracy: 0.9232 - val_loss: 0.2033 - val_binary_accuracy: 0.9059\n",
      "Epoch 267/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1658 - binary_accuracy: 0.9235 - val_loss: 0.2056 - val_binary_accuracy: 0.9053\n",
      "Epoch 268/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1654 - binary_accuracy: 0.9237 - val_loss: 0.2047 - val_binary_accuracy: 0.9057\n",
      "Epoch 269/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1655 - binary_accuracy: 0.9236 - val_loss: 0.2034 - val_binary_accuracy: 0.9065\n",
      "Epoch 270/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1646 - binary_accuracy: 0.9241 - val_loss: 0.2058 - val_binary_accuracy: 0.9060\n",
      "Epoch 271/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1639 - binary_accuracy: 0.9246 - val_loss: 0.2065 - val_binary_accuracy: 0.9059\n",
      "Epoch 272/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1633 - binary_accuracy: 0.9250 - val_loss: 0.2064 - val_binary_accuracy: 0.9057loss: 0.1627 - binary_accuracy: 0. - ETA: 0s - loss: 0.1628 - binary_accu\n",
      "Epoch 273/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1632 - binary_accuracy: 0.9250 - val_loss: 0.2060 - val_binary_accuracy: 0.9058\n",
      "Epoch 274/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1628 - binary_accuracy: 0.9251 - val_loss: 0.2068 - val_binary_accuracy: 0.9059\n",
      "Epoch 275/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1621 - binary_accuracy: 0.9256 - val_loss: 0.2085 - val_binary_accuracy: 0.9057\n",
      "Epoch 276/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1618 - binary_accuracy: 0.9258 - val_loss: 0.2076 - val_binary_accuracy: 0.9059\n",
      "Epoch 277/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1616 - binary_accuracy: 0.9258 - val_loss: 0.2072 - val_binary_accuracy: 0.9062\n",
      "Epoch 278/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1611 - binary_accuracy: 0.9263 - val_loss: 0.2083 - val_binary_accuracy: 0.9051\n",
      "Epoch 279/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1611 - binary_accuracy: 0.9261 - val_loss: 0.2096 - val_binary_accuracy: 0.9052\n",
      "Epoch 280/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1604 - binary_accuracy: 0.9264 - val_loss: 0.2091 - val_binary_accuracy: 0.9052\n",
      "Epoch 281/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1597 - binary_accuracy: 0.9269 - val_loss: 0.2110 - val_binary_accuracy: 0.9047\n",
      "Epoch 282/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1597 - binary_accuracy: 0.9269 - val_loss: 0.2085 - val_binary_accuracy: 0.9058\n",
      "Epoch 283/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1593 - binary_accuracy: 0.9271 - val_loss: 0.2094 - val_binary_accuracy: 0.9053\n",
      "Epoch 284/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1590 - binary_accuracy: 0.9272 - val_loss: 0.2106 - val_binary_accuracy: 0.9052\n",
      "Epoch 285/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1584 - binary_accuracy: 0.9278 - val_loss: 0.2109 - val_binary_accuracy: 0.9053\n",
      "Epoch 286/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1582 - binary_accuracy: 0.9278 - val_loss: 0.2122 - val_binary_accuracy: 0.9047\n",
      "Epoch 287/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1577 - binary_accuracy: 0.9279 - val_loss: 0.2130 - val_binary_accuracy: 0.9043\n",
      "Epoch 288/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1574 - binary_accuracy: 0.9281 - val_loss: 0.2137 - val_binary_accuracy: 0.9041\n",
      "Epoch 289/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1575 - binary_accuracy: 0.9281 - val_loss: 0.2123 - val_binary_accuracy: 0.9045\n",
      "Epoch 290/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1568 - binary_accuracy: 0.9285 - val_loss: 0.2129 - val_binary_accuracy: 0.9047\n",
      "Epoch 291/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1559 - binary_accuracy: 0.9289 - val_loss: 0.2137 - val_binary_accuracy: 0.9046\n",
      "Epoch 292/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1552 - binary_accuracy: 0.9294 - val_loss: 0.2151 - val_binary_accuracy: 0.9045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1556 - binary_accuracy: 0.9292 - val_loss: 0.2139 - val_binary_accuracy: 0.9048\n",
      "Epoch 294/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1552 - binary_accuracy: 0.9293 - val_loss: 0.2164 - val_binary_accuracy: 0.9041\n",
      "Epoch 295/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1552 - binary_accuracy: 0.9294 - val_loss: 0.2149 - val_binary_accuracy: 0.9043\n",
      "Epoch 296/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1544 - binary_accuracy: 0.9297 - val_loss: 0.2156 - val_binary_accuracy: 0.9043\n",
      "Epoch 297/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1541 - binary_accuracy: 0.9300 - val_loss: 0.2152 - val_binary_accuracy: 0.9046\n",
      "Epoch 298/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1536 - binary_accuracy: 0.9303 - val_loss: 0.2197 - val_binary_accuracy: 0.9036\n",
      "Epoch 299/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1531 - binary_accuracy: 0.9305 - val_loss: 0.2160 - val_binary_accuracy: 0.9042\n",
      "Epoch 300/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1528 - binary_accuracy: 0.9307 - val_loss: 0.2190 - val_binary_accuracy: 0.9035\n",
      "Epoch 301/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1528 - binary_accuracy: 0.9308 - val_loss: 0.2186 - val_binary_accuracy: 0.9044\n",
      "Epoch 302/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1520 - binary_accuracy: 0.9310 - val_loss: 0.2194 - val_binary_accuracy: 0.9044\n",
      "Epoch 303/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1512 - binary_accuracy: 0.9314 - val_loss: 0.2207 - val_binary_accuracy: 0.9035\n",
      "Epoch 304/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1513 - binary_accuracy: 0.9316 - val_loss: 0.2206 - val_binary_accuracy: 0.9038\n",
      "Epoch 305/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1512 - binary_accuracy: 0.9315 - val_loss: 0.2199 - val_binary_accuracy: 0.9037\n",
      "Epoch 306/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1509 - binary_accuracy: 0.9317 - val_loss: 0.2212 - val_binary_accuracy: 0.9034\n",
      "Epoch 307/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1503 - binary_accuracy: 0.9321 - val_loss: 0.2204 - val_binary_accuracy: 0.9042\n",
      "Epoch 308/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1505 - binary_accuracy: 0.9320 - val_loss: 0.2211 - val_binary_accuracy: 0.9036\n",
      "Epoch 309/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1492 - binary_accuracy: 0.9326 - val_loss: 0.2232 - val_binary_accuracy: 0.9035\n",
      "Epoch 310/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1494 - binary_accuracy: 0.9326 - val_loss: 0.2212 - val_binary_accuracy: 0.9032\n",
      "Epoch 311/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1493 - binary_accuracy: 0.9325 - val_loss: 0.2218 - val_binary_accuracy: 0.9040\n",
      "Epoch 312/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1485 - binary_accuracy: 0.9328 - val_loss: 0.2231 - val_binary_accuracy: 0.9039\n",
      "Epoch 313/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1489 - binary_accuracy: 0.9328 - val_loss: 0.2234 - val_binary_accuracy: 0.9033\n",
      "Epoch 314/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1480 - binary_accuracy: 0.9333 - val_loss: 0.2243 - val_binary_accuracy: 0.9034\n",
      "Epoch 315/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1476 - binary_accuracy: 0.9334 - val_loss: 0.2251 - val_binary_accuracy: 0.9033\n",
      "Epoch 316/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1475 - binary_accuracy: 0.9336 - val_loss: 0.2257 - val_binary_accuracy: 0.9024\n",
      "Epoch 317/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1476 - binary_accuracy: 0.9333 - val_loss: 0.2257 - val_binary_accuracy: 0.9031\n",
      "Epoch 318/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1468 - binary_accuracy: 0.9339 - val_loss: 0.2256 - val_binary_accuracy: 0.9033\n",
      "Epoch 319/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1462 - binary_accuracy: 0.9342 - val_loss: 0.2276 - val_binary_accuracy: 0.9028\n",
      "Epoch 320/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1457 - binary_accuracy: 0.9344 - val_loss: 0.2291 - val_binary_accuracy: 0.9028\n",
      "Epoch 321/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1454 - binary_accuracy: 0.9345 - val_loss: 0.2276 - val_binary_accuracy: 0.9033\n",
      "Epoch 322/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1462 - binary_accuracy: 0.9342 - val_loss: 0.2253 - val_binary_accuracy: 0.9033\n",
      "Epoch 323/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1443 - binary_accuracy: 0.9351 - val_loss: 0.2284 - val_binary_accuracy: 0.9028\n",
      "Epoch 324/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1447 - binary_accuracy: 0.9350 - val_loss: 0.2273 - val_binary_accuracy: 0.9029\n",
      "Epoch 325/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1443 - binary_accuracy: 0.9351 - val_loss: 0.2299 - val_binary_accuracy: 0.9026\n",
      "Epoch 326/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1438 - binary_accuracy: 0.9354 - val_loss: 0.2302 - val_binary_accuracy: 0.9029\n",
      "Epoch 327/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1437 - binary_accuracy: 0.9356 - val_loss: 0.2297 - val_binary_accuracy: 0.9028\n",
      "Epoch 328/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1436 - binary_accuracy: 0.9355 - val_loss: 0.2324 - val_binary_accuracy: 0.9023\n",
      "Epoch 329/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1433 - binary_accuracy: 0.9357 - val_loss: 0.2311 - val_binary_accuracy: 0.9030\n",
      "Epoch 330/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1427 - binary_accuracy: 0.9358 - val_loss: 0.2323 - val_binary_accuracy: 0.9024\n",
      "Epoch 331/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1425 - binary_accuracy: 0.9360 - val_loss: 0.2313 - val_binary_accuracy: 0.9021s: 0.1\n",
      "Epoch 332/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1423 - binary_accuracy: 0.9362 - val_loss: 0.2315 - val_binary_accuracy: 0.9021\n",
      "Epoch 333/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1419 - binary_accuracy: 0.9362 - val_loss: 0.2356 - val_binary_accuracy: 0.9023\n",
      "Epoch 334/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1414 - binary_accuracy: 0.9368 - val_loss: 0.2358 - val_binary_accuracy: 0.9024\n",
      "Epoch 335/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1412 - binary_accuracy: 0.9366 - val_loss: 0.2340 - val_binary_accuracy: 0.9024\n",
      "Epoch 336/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1417 - binary_accuracy: 0.9366 - val_loss: 0.2357 - val_binary_accuracy: 0.9028\n",
      "Epoch 337/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1410 - binary_accuracy: 0.9369 - val_loss: 0.2357 - val_binary_accuracy: 0.9022\n",
      "Epoch 338/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1411 - binary_accuracy: 0.9370 - val_loss: 0.2385 - val_binary_accuracy: 0.9025\n",
      "Epoch 339/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1408 - binary_accuracy: 0.9368 - val_loss: 0.2361 - val_binary_accuracy: 0.9025\n",
      "Epoch 340/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1400 - binary_accuracy: 0.9375 - val_loss: 0.2362 - val_binary_accuracy: 0.9025\n",
      "Epoch 341/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1395 - binary_accuracy: 0.9378 - val_loss: 0.2375 - val_binary_accuracy: 0.9017\n",
      "Epoch 342/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1397 - binary_accuracy: 0.9375 - val_loss: 0.2374 - val_binary_accuracy: 0.9021\n",
      "Epoch 343/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1389 - binary_accuracy: 0.9382 - val_loss: 0.2399 - val_binary_accuracy: 0.9013\n",
      "Epoch 344/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1391 - binary_accuracy: 0.9378 - val_loss: 0.2367 - val_binary_accuracy: 0.9020\n",
      "Epoch 345/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1384 - binary_accuracy: 0.9382 - val_loss: 0.2381 - val_binary_accuracy: 0.9014\n",
      "Epoch 346/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1383 - binary_accuracy: 0.9383 - val_loss: 0.2395 - val_binary_accuracy: 0.9017\n",
      "Epoch 347/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1388 - binary_accuracy: 0.9381 - val_loss: 0.2400 - val_binary_accuracy: 0.9018\n",
      "Epoch 348/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1371 - binary_accuracy: 0.9390 - val_loss: 0.2420 - val_binary_accuracy: 0.9011\n",
      "Epoch 349/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1370 - binary_accuracy: 0.9389 - val_loss: 0.2408 - val_binary_accuracy: 0.9019\n",
      "Epoch 350/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1368 - binary_accuracy: 0.9391 - val_loss: 0.2424 - val_binary_accuracy: 0.9009\n",
      "Epoch 351/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1380 - binary_accuracy: 0.9385 - val_loss: 0.2417 - val_binary_accuracy: 0.9017\n",
      "Epoch 352/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1369 - binary_accuracy: 0.9391 - val_loss: 0.2423 - val_binary_accuracy: 0.9016\n",
      "Epoch 353/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1359 - binary_accuracy: 0.9397 - val_loss: 0.2438 - val_binary_accuracy: 0.9014\n",
      "Epoch 354/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1356 - binary_accuracy: 0.9399 - val_loss: 0.2427 - val_binary_accuracy: 0.9015\n",
      "Epoch 355/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1356 - binary_accuracy: 0.9395 - val_loss: 0.2437 - val_binary_accuracy: 0.9015\n",
      "Epoch 356/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1359 - binary_accuracy: 0.9396 - val_loss: 0.2440 - val_binary_accuracy: 0.9020\n",
      "Epoch 357/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1351 - binary_accuracy: 0.9400 - val_loss: 0.2433 - val_binary_accuracy: 0.9013\n",
      "Epoch 358/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1346 - binary_accuracy: 0.9403 - val_loss: 0.2468 - val_binary_accuracy: 0.9008\n",
      "Epoch 359/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1342 - binary_accuracy: 0.9403 - val_loss: 0.2458 - val_binary_accuracy: 0.9016\n",
      "Epoch 360/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1343 - binary_accuracy: 0.9403 - val_loss: 0.2480 - val_binary_accuracy: 0.9010\n",
      "Epoch 361/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1344 - binary_accuracy: 0.9404 - val_loss: 0.2484 - val_binary_accuracy: 0.9003\n",
      "Epoch 362/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1338 - binary_accuracy: 0.9407 - val_loss: 0.2502 - val_binary_accuracy: 0.9010\n",
      "Epoch 363/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1339 - binary_accuracy: 0.9407 - val_loss: 0.2469 - val_binary_accuracy: 0.9013\n",
      "Epoch 364/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1340 - binary_accuracy: 0.9406 - val_loss: 0.2475 - val_binary_accuracy: 0.9006\n",
      "Epoch 365/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1342 - binary_accuracy: 0.9405 - val_loss: 0.2469 - val_binary_accuracy: 0.9013\n",
      "Epoch 366/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1335 - binary_accuracy: 0.9409 - val_loss: 0.2497 - val_binary_accuracy: 0.8998\n",
      "Epoch 367/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1323 - binary_accuracy: 0.9415 - val_loss: 0.2488 - val_binary_accuracy: 0.9008\n",
      "Epoch 368/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1334 - binary_accuracy: 0.9409 - val_loss: 0.2496 - val_binary_accuracy: 0.9010\n",
      "Epoch 369/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1326 - binary_accuracy: 0.9413 - val_loss: 0.2490 - val_binary_accuracy: 0.9005\n",
      "Epoch 370/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1317 - binary_accuracy: 0.9417 - val_loss: 0.2509 - val_binary_accuracy: 0.9014\n",
      "Epoch 371/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1324 - binary_accuracy: 0.9414 - val_loss: 0.2519 - val_binary_accuracy: 0.9010\n",
      "Epoch 372/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1316 - binary_accuracy: 0.9416 - val_loss: 0.2539 - val_binary_accuracy: 0.9001\n",
      "Epoch 373/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1320 - binary_accuracy: 0.9416 - val_loss: 0.2512 - val_binary_accuracy: 0.9005\n",
      "Epoch 374/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1313 - binary_accuracy: 0.9419 - val_loss: 0.2522 - val_binary_accuracy: 0.9001 0.1309 - binary_ac\n",
      "Epoch 375/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1313 - binary_accuracy: 0.9418 - val_loss: 0.2533 - val_binary_accuracy: 0.9004\n",
      "Epoch 376/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1310 - binary_accuracy: 0.9421 - val_loss: 0.2525 - val_binary_accuracy: 0.9007\n",
      "Epoch 377/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1308 - binary_accuracy: 0.9423 - val_loss: 0.2526 - val_binary_accuracy: 0.9010\n",
      "Epoch 378/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1298 - binary_accuracy: 0.9427 - val_loss: 0.2543 - val_binary_accuracy: 0.9009\n",
      "Epoch 379/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1296 - binary_accuracy: 0.9426 - val_loss: 0.2556 - val_binary_accuracy: 0.9009\n",
      "Epoch 380/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1292 - binary_accuracy: 0.9429 - val_loss: 0.2571 - val_binary_accuracy: 0.9001\n",
      "Epoch 381/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1289 - binary_accuracy: 0.9432 - val_loss: 0.2574 - val_binary_accuracy: 0.8999\n",
      "Epoch 382/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1301 - binary_accuracy: 0.9426 - val_loss: 0.2548 - val_binary_accuracy: 0.8999\n",
      "Epoch 383/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1286 - binary_accuracy: 0.9434 - val_loss: 0.2572 - val_binary_accuracy: 0.9005\n",
      "Epoch 384/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1290 - binary_accuracy: 0.9430 - val_loss: 0.2568 - val_binary_accuracy: 0.9005\n",
      "Epoch 385/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1285 - binary_accuracy: 0.9433 - val_loss: 0.2578 - val_binary_accuracy: 0.8997\n",
      "Epoch 386/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1281 - binary_accuracy: 0.9434 - val_loss: 0.2590 - val_binary_accuracy: 0.8998\n",
      "Epoch 387/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1283 - binary_accuracy: 0.9433 - val_loss: 0.2558 - val_binary_accuracy: 0.9000\n",
      "Epoch 388/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1274 - binary_accuracy: 0.9440 - val_loss: 0.2607 - val_binary_accuracy: 0.89981272 - binary_accurac\n",
      "Epoch 389/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1271 - binary_accuracy: 0.9441 - val_loss: 0.2591 - val_binary_accuracy: 0.9001\n",
      "Epoch 390/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1269 - binary_accuracy: 0.9441 - val_loss: 0.2613 - val_binary_accuracy: 0.9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1268 - binary_accuracy: 0.9444 - val_loss: 0.2599 - val_binary_accuracy: 0.9005\n",
      "Epoch 392/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1265 - binary_accuracy: 0.9443 - val_loss: 0.2623 - val_binary_accuracy: 0.8994\n",
      "Epoch 393/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1265 - binary_accuracy: 0.9444 - val_loss: 0.2627 - val_binary_accuracy: 0.8992\n",
      "Epoch 394/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1270 - binary_accuracy: 0.9440 - val_loss: 0.2621 - val_binary_accuracy: 0.8997\n",
      "Epoch 395/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1259 - binary_accuracy: 0.9446 - val_loss: 0.2641 - val_binary_accuracy: 0.8997\n",
      "Epoch 396/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1262 - binary_accuracy: 0.9444 - val_loss: 0.2637 - val_binary_accuracy: 0.8994\n",
      "Epoch 397/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1258 - binary_accuracy: 0.9448 - val_loss: 0.2625 - val_binary_accuracy: 0.8997\n",
      "Epoch 398/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1253 - binary_accuracy: 0.9450 - val_loss: 0.2630 - val_binary_accuracy: 0.8996\n",
      "Epoch 399/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1254 - binary_accuracy: 0.9447 - val_loss: 0.2617 - val_binary_accuracy: 0.9001\n",
      "Epoch 400/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1254 - binary_accuracy: 0.9450 - val_loss: 0.2620 - val_binary_accuracy: 0.8996\n",
      "Epoch 401/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1250 - binary_accuracy: 0.9452 - val_loss: 0.2642 - val_binary_accuracy: 0.8998\n",
      "Epoch 402/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1247 - binary_accuracy: 0.9453 - val_loss: 0.2638 - val_binary_accuracy: 0.9001\n",
      "Epoch 403/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1243 - binary_accuracy: 0.9454 - val_loss: 0.2661 - val_binary_accuracy: 0.8991\n",
      "Epoch 404/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1238 - binary_accuracy: 0.9458 - val_loss: 0.2661 - val_binary_accuracy: 0.8995\n",
      "Epoch 405/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1245 - binary_accuracy: 0.9455 - val_loss: 0.2668 - val_binary_accuracy: 0.8992\n",
      "Epoch 406/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1247 - binary_accuracy: 0.9454 - val_loss: 0.2676 - val_binary_accuracy: 0.8989\n",
      "Epoch 407/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1237 - binary_accuracy: 0.9458 - val_loss: 0.2683 - val_binary_accuracy: 0.8997\n",
      "Epoch 408/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1235 - binary_accuracy: 0.9458 - val_loss: 0.2655 - val_binary_accuracy: 0.9001\n",
      "Epoch 409/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1229 - binary_accuracy: 0.9461 - val_loss: 0.2703 - val_binary_accuracy: 0.8993\n",
      "Epoch 410/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1235 - binary_accuracy: 0.9458 - val_loss: 0.2683 - val_binary_accuracy: 0.8997\n",
      "Epoch 411/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1234 - binary_accuracy: 0.9460 - val_loss: 0.2711 - val_binary_accuracy: 0.8994\n",
      "Epoch 412/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1229 - binary_accuracy: 0.9462 - val_loss: 0.2680 - val_binary_accuracy: 0.8994\n",
      "Epoch 413/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1224 - binary_accuracy: 0.9466 - val_loss: 0.2703 - val_binary_accuracy: 0.8991\n",
      "Epoch 414/1000\n",
      "85991/85991 [==============================] - 3s 39us/sample - loss: 0.1223 - binary_accuracy: 0.9465 - val_loss: 0.2697 - val_binary_accuracy: 0.8996\n",
      "Epoch 415/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1223 - binary_accuracy: 0.9464 - val_loss: 0.2727 - val_binary_accuracy: 0.8993\n",
      "Epoch 416/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1222 - binary_accuracy: 0.9465 - val_loss: 0.2691 - val_binary_accuracy: 0.8993\n",
      "Epoch 417/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1222 - binary_accuracy: 0.9466 - val_loss: 0.2729 - val_binary_accuracy: 0.8983\n",
      "Epoch 418/1000\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.1212 - binary_accuracy: 0.9470 - val_loss: 0.2725 - val_binary_accuracy: 0.8991\n",
      "Epoch 419/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1214 - binary_accuracy: 0.9469 - val_loss: 0.2741 - val_binary_accuracy: 0.8986\n",
      "Epoch 420/1000\n",
      "85991/85991 [==============================] - 4s 41us/sample - loss: 0.1218 - binary_accuracy: 0.9466 - val_loss: 0.2714 - val_binary_accuracy: 0.8992\n",
      "Epoch 421/1000\n",
      "85991/85991 [==============================] - 4s 45us/sample - loss: 0.1206 - binary_accuracy: 0.9474 - val_loss: 0.2735 - val_binary_accuracy: 0.8992\n",
      "Epoch 422/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1217 - binary_accuracy: 0.9468 - val_loss: 0.2734 - val_binary_accuracy: 0.8991\n",
      "Epoch 423/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1209 - binary_accuracy: 0.9471 - val_loss: 0.2759 - val_binary_accuracy: 0.8993\n",
      "Epoch 424/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1208 - binary_accuracy: 0.9472 - val_loss: 0.2749 - val_binary_accuracy: 0.8989\n",
      "Epoch 425/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1208 - binary_accuracy: 0.9472 - val_loss: 0.2756 - val_binary_accuracy: 0.8991\n",
      "Epoch 426/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1203 - binary_accuracy: 0.9474 - val_loss: 0.2753 - val_binary_accuracy: 0.8993\n",
      "Epoch 427/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1204 - binary_accuracy: 0.9475 - val_loss: 0.2754 - val_binary_accuracy: 0.8988\n",
      "Epoch 428/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1191 - binary_accuracy: 0.9480 - val_loss: 0.2757 - val_binary_accuracy: 0.8991\n",
      "Epoch 429/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1202 - binary_accuracy: 0.9476 - val_loss: 0.2739 - val_binary_accuracy: 0.8992\n",
      "Epoch 430/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1198 - binary_accuracy: 0.9476 - val_loss: 0.2736 - val_binary_accuracy: 0.8990\n",
      "Epoch 431/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1192 - binary_accuracy: 0.9479 - val_loss: 0.2791 - val_binary_accuracy: 0.8993\n",
      "Epoch 432/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1187 - binary_accuracy: 0.9482 - val_loss: 0.2795 - val_binary_accuracy: 0.8990\n",
      "Epoch 433/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1189 - binary_accuracy: 0.9481 - val_loss: 0.2754 - val_binary_accuracy: 0.8991\n",
      "Epoch 434/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1187 - binary_accuracy: 0.9484 - val_loss: 0.2787 - val_binary_accuracy: 0.8983\n",
      "Epoch 435/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1186 - binary_accuracy: 0.9483 - val_loss: 0.2773 - val_binary_accuracy: 0.8991\n",
      "Epoch 436/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1186 - binary_accuracy: 0.9482 - val_loss: 0.2779 - val_binary_accuracy: 0.8986\n",
      "Epoch 437/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1179 - binary_accuracy: 0.9486 - val_loss: 0.2814 - val_binary_accuracy: 0.8988\n",
      "Epoch 438/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1175 - binary_accuracy: 0.9489 - val_loss: 0.2793 - val_binary_accuracy: 0.8993\n",
      "Epoch 439/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1177 - binary_accuracy: 0.9488 - val_loss: 0.2812 - val_binary_accuracy: 0.8980\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1174 - binary_accuracy: 0.9490 - val_loss: 0.2816 - val_binary_accuracy: 0.8983\n",
      "Epoch 441/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1177 - binary_accuracy: 0.9488 - val_loss: 0.2812 - val_binary_accuracy: 0.8993\n",
      "Epoch 442/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1176 - binary_accuracy: 0.9488 - val_loss: 0.2829 - val_binary_accuracy: 0.8991\n",
      "Epoch 443/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1169 - binary_accuracy: 0.9490 - val_loss: 0.2826 - val_binary_accuracy: 0.8984\n",
      "Epoch 444/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1169 - binary_accuracy: 0.9490 - val_loss: 0.2820 - val_binary_accuracy: 0.8986\n",
      "Epoch 445/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1165 - binary_accuracy: 0.9493 - val_loss: 0.2842 - val_binary_accuracy: 0.8981\n",
      "Epoch 446/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1164 - binary_accuracy: 0.9493 - val_loss: 0.2845 - val_binary_accuracy: 0.8979\n",
      "Epoch 447/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1162 - binary_accuracy: 0.9495 - val_loss: 0.2815 - val_binary_accuracy: 0.8989\n",
      "Epoch 448/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1164 - binary_accuracy: 0.9494 - val_loss: 0.2823 - val_binary_accuracy: 0.8983\n",
      "Epoch 449/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1158 - binary_accuracy: 0.9495 - val_loss: 0.2848 - val_binary_accuracy: 0.8980\n",
      "Epoch 450/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1158 - binary_accuracy: 0.9497 - val_loss: 0.2822 - val_binary_accuracy: 0.8980\n",
      "Epoch 451/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1158 - binary_accuracy: 0.9497 - val_loss: 0.2813 - val_binary_accuracy: 0.8976\n",
      "Epoch 452/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1163 - binary_accuracy: 0.9496 - val_loss: 0.2847 - val_binary_accuracy: 0.8985\n",
      "Epoch 453/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1155 - binary_accuracy: 0.9498 - val_loss: 0.2854 - val_binary_accuracy: 0.8977\n",
      "Epoch 454/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1155 - binary_accuracy: 0.9500 - val_loss: 0.2884 - val_binary_accuracy: 0.8982\n",
      "Epoch 455/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1150 - binary_accuracy: 0.9500 - val_loss: 0.2851 - val_binary_accuracy: 0.8984\n",
      "Epoch 456/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1143 - binary_accuracy: 0.9504 - val_loss: 0.2882 - val_binary_accuracy: 0.8981\n",
      "Epoch 457/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1147 - binary_accuracy: 0.9502 - val_loss: 0.2888 - val_binary_accuracy: 0.8979\n",
      "Epoch 458/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1141 - binary_accuracy: 0.9503 - val_loss: 0.2875 - val_binary_accuracy: 0.8987\n",
      "Epoch 459/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1147 - binary_accuracy: 0.9503 - val_loss: 0.2864 - val_binary_accuracy: 0.8977\n",
      "Epoch 460/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1145 - binary_accuracy: 0.9503 - val_loss: 0.2890 - val_binary_accuracy: 0.8983\n",
      "Epoch 461/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1149 - binary_accuracy: 0.9501 - val_loss: 0.2910 - val_binary_accuracy: 0.8984\n",
      "Epoch 462/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1145 - binary_accuracy: 0.9505 - val_loss: 0.2876 - val_binary_accuracy: 0.8983\n",
      "Epoch 463/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1139 - binary_accuracy: 0.9506 - val_loss: 0.2909 - val_binary_accuracy: 0.8977\n",
      "Epoch 464/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1135 - binary_accuracy: 0.9508 - val_loss: 0.2920 - val_binary_accuracy: 0.8984\n",
      "Epoch 465/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1143 - binary_accuracy: 0.9505 - val_loss: 0.2863 - val_binary_accuracy: 0.8986\n",
      "Epoch 466/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1136 - binary_accuracy: 0.9508 - val_loss: 0.2908 - val_binary_accuracy: 0.8983\n",
      "Epoch 467/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1138 - binary_accuracy: 0.9506 - val_loss: 0.2901 - val_binary_accuracy: 0.8979\n",
      "Epoch 468/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1129 - binary_accuracy: 0.9510 - val_loss: 0.2904 - val_binary_accuracy: 0.8980\n",
      "Epoch 469/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1131 - binary_accuracy: 0.9510 - val_loss: 0.2925 - val_binary_accuracy: 0.8975\n",
      "Epoch 470/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1144 - binary_accuracy: 0.9504 - val_loss: 0.2927 - val_binary_accuracy: 0.8985\n",
      "Epoch 471/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1128 - binary_accuracy: 0.9511 - val_loss: 0.2936 - val_binary_accuracy: 0.8975\n",
      "Epoch 472/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1121 - binary_accuracy: 0.9515 - val_loss: 0.2947 - val_binary_accuracy: 0.8975\n",
      "Epoch 473/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1116 - binary_accuracy: 0.9517 - val_loss: 0.2963 - val_binary_accuracy: 0.8976\n",
      "Epoch 474/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1117 - binary_accuracy: 0.9516 - val_loss: 0.2978 - val_binary_accuracy: 0.8980\n",
      "Epoch 475/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1119 - binary_accuracy: 0.9516 - val_loss: 0.2932 - val_binary_accuracy: 0.8979\n",
      "Epoch 476/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1115 - binary_accuracy: 0.9517 - val_loss: 0.2978 - val_binary_accuracy: 0.89790.1113 - binary_accur\n",
      "Epoch 477/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1110 - binary_accuracy: 0.9520 - val_loss: 0.2967 - val_binary_accuracy: 0.8982\n",
      "Epoch 478/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1117 - binary_accuracy: 0.9516 - val_loss: 0.3006 - val_binary_accuracy: 0.8978\n",
      "Epoch 479/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1114 - binary_accuracy: 0.9517 - val_loss: 0.2928 - val_binary_accuracy: 0.8979\n",
      "Epoch 480/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1115 - binary_accuracy: 0.9518 - val_loss: 0.2985 - val_binary_accuracy: 0.8975\n",
      "Epoch 481/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1117 - binary_accuracy: 0.9518 - val_loss: 0.2961 - val_binary_accuracy: 0.8984\n",
      "Epoch 482/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1108 - binary_accuracy: 0.9521 - val_loss: 0.2983 - val_binary_accuracy: 0.8979\n",
      "Epoch 483/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1112 - binary_accuracy: 0.9518 - val_loss: 0.2994 - val_binary_accuracy: 0.8980\n",
      "Epoch 484/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1107 - binary_accuracy: 0.9523 - val_loss: 0.2988 - val_binary_accuracy: 0.89771s - loss: 0.1098 - binar - ETA: 0s - loss: 0.1101 - binary_accur\n",
      "Epoch 485/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1109 - binary_accuracy: 0.9520 - val_loss: 0.2980 - val_binary_accuracy: 0.8974\n",
      "Epoch 486/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1111 - binary_accuracy: 0.9519 - val_loss: 0.2954 - val_binary_accuracy: 0.8982\n",
      "Epoch 487/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1110 - binary_accuracy: 0.9521 - val_loss: 0.2951 - val_binary_accuracy: 0.8972\n",
      "Epoch 488/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1105 - binary_accuracy: 0.9523 - val_loss: 0.2959 - val_binary_accuracy: 0.8978\n",
      "Epoch 489/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1098 - binary_accuracy: 0.9526 - val_loss: 0.3013 - val_binary_accuracy: 0.8975\n",
      "Epoch 490/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1100 - binary_accuracy: 0.9526 - val_loss: 0.2987 - val_binary_accuracy: 0.8978\n",
      "Epoch 491/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1096 - binary_accuracy: 0.9526 - val_loss: 0.2980 - val_binary_accuracy: 0.8972\n",
      "Epoch 492/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1098 - binary_accuracy: 0.9526 - val_loss: 0.3027 - val_binary_accuracy: 0.8969\n",
      "Epoch 493/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1093 - binary_accuracy: 0.9528 - val_loss: 0.3017 - val_binary_accuracy: 0.8972\n",
      "Epoch 494/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1097 - binary_accuracy: 0.9526 - val_loss: 0.3016 - val_binary_accuracy: 0.8978\n",
      "Epoch 495/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1092 - binary_accuracy: 0.9530 - val_loss: 0.3034 - val_binary_accuracy: 0.8976\n",
      "Epoch 496/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1091 - binary_accuracy: 0.9529 - val_loss: 0.2997 - val_binary_accuracy: 0.8982\n",
      "Epoch 497/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1093 - binary_accuracy: 0.9530 - val_loss: 0.3018 - val_binary_accuracy: 0.8977\n",
      "Epoch 498/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1092 - binary_accuracy: 0.9530 - val_loss: 0.3021 - val_binary_accuracy: 0.8972\n",
      "Epoch 499/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1089 - binary_accuracy: 0.9532 - val_loss: 0.3047 - val_binary_accuracy: 0.8977ry_accuracy: 0\n",
      "Epoch 500/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1086 - binary_accuracy: 0.9532 - val_loss: 0.3021 - val_binary_accuracy: 0.8976\n",
      "Epoch 501/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1087 - binary_accuracy: 0.9530 - val_loss: 0.3033 - val_binary_accuracy: 0.8970\n",
      "Epoch 502/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1081 - binary_accuracy: 0.9534 - val_loss: 0.3064 - val_binary_accuracy: 0.8974\n",
      "Epoch 503/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1080 - binary_accuracy: 0.9533 - val_loss: 0.3055 - val_binary_accuracy: 0.8966\n",
      "Epoch 504/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1081 - binary_accuracy: 0.9535 - val_loss: 0.3036 - val_binary_accuracy: 0.8968\n",
      "Epoch 505/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1077 - binary_accuracy: 0.9534 - val_loss: 0.3066 - val_binary_accuracy: 0.8965\n",
      "Epoch 506/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1081 - binary_accuracy: 0.9533 - val_loss: 0.3080 - val_binary_accuracy: 0.8969\n",
      "Epoch 507/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1074 - binary_accuracy: 0.9536 - val_loss: 0.3084 - val_binary_accuracy: 0.8970\n",
      "Epoch 508/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1076 - binary_accuracy: 0.9536 - val_loss: 0.3045 - val_binary_accuracy: 0.8975\n",
      "Epoch 509/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1075 - binary_accuracy: 0.9536 - val_loss: 0.3080 - val_binary_accuracy: 0.8970\n",
      "Epoch 510/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1075 - binary_accuracy: 0.9538 - val_loss: 0.3088 - val_binary_accuracy: 0.8973\n",
      "Epoch 511/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1072 - binary_accuracy: 0.9538 - val_loss: 0.3069 - val_binary_accuracy: 0.8971\n",
      "Epoch 512/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1074 - binary_accuracy: 0.9537 - val_loss: 0.3084 - val_binary_accuracy: 0.8970\n",
      "Epoch 513/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1067 - binary_accuracy: 0.9540 - val_loss: 0.3103 - val_binary_accuracy: 0.8971\n",
      "Epoch 514/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1068 - binary_accuracy: 0.9541 - val_loss: 0.3073 - val_binary_accuracy: 0.8972\n",
      "Epoch 515/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1063 - binary_accuracy: 0.9542 - val_loss: 0.3112 - val_binary_accuracy: 0.8970\n",
      "Epoch 516/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1057 - binary_accuracy: 0.9545 - val_loss: 0.3110 - val_binary_accuracy: 0.8974\n",
      "Epoch 517/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1066 - binary_accuracy: 0.9541 - val_loss: 0.3135 - val_binary_accuracy: 0.8967\n",
      "Epoch 518/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1061 - binary_accuracy: 0.9544 - val_loss: 0.3107 - val_binary_accuracy: 0.8974\n",
      "Epoch 519/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1058 - binary_accuracy: 0.9544 - val_loss: 0.3091 - val_binary_accuracy: 0.8970\n",
      "Epoch 520/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1058 - binary_accuracy: 0.9546 - val_loss: 0.3109 - val_binary_accuracy: 0.8973\n",
      "Epoch 521/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1066 - binary_accuracy: 0.9540 - val_loss: 0.3119 - val_binary_accuracy: 0.8972\n",
      "Epoch 522/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1061 - binary_accuracy: 0.9543 - val_loss: 0.3127 - val_binary_accuracy: 0.8973\n",
      "Epoch 523/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1056 - binary_accuracy: 0.9545 - val_loss: 0.3111 - val_binary_accuracy: 0.8978\n",
      "Epoch 524/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1056 - binary_accuracy: 0.9546 - val_loss: 0.3104 - val_binary_accuracy: 0.8965\n",
      "Epoch 525/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1049 - binary_accuracy: 0.9547 - val_loss: 0.3112 - val_binary_accuracy: 0.8969\n",
      "Epoch 526/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1052 - binary_accuracy: 0.9549 - val_loss: 0.3184 - val_binary_accuracy: 0.8969\n",
      "Epoch 527/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1052 - binary_accuracy: 0.9549 - val_loss: 0.3134 - val_binary_accuracy: 0.8972\n",
      "Epoch 528/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1047 - binary_accuracy: 0.9551 - val_loss: 0.3127 - val_binary_accuracy: 0.8969\n",
      "Epoch 529/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1042 - binary_accuracy: 0.9553 - val_loss: 0.3174 - val_binary_accuracy: 0.8972\n",
      "Epoch 530/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1055 - binary_accuracy: 0.9547 - val_loss: 0.3124 - val_binary_accuracy: 0.8972\n",
      "Epoch 531/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1045 - binary_accuracy: 0.9552 - val_loss: 0.3193 - val_binary_accuracy: 0.8969\n",
      "Epoch 532/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1045 - binary_accuracy: 0.9551 - val_loss: 0.3199 - val_binary_accuracy: 0.8970\n",
      "Epoch 533/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1056 - binary_accuracy: 0.9547 - val_loss: 0.3140 - val_binary_accuracy: 0.8969\n",
      "Epoch 534/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1045 - binary_accuracy: 0.9551 - val_loss: 0.3149 - val_binary_accuracy: 0.8968\n",
      "Epoch 535/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1037 - binary_accuracy: 0.9555 - val_loss: 0.3179 - val_binary_accuracy: 0.8967\n",
      "Epoch 536/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1040 - binary_accuracy: 0.9554 - val_loss: 0.3196 - val_binary_accuracy: 0.8964\n",
      "Epoch 537/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1039 - binary_accuracy: 0.9554 - val_loss: 0.3137 - val_binary_accuracy: 0.8970\n",
      "Epoch 538/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1033 - binary_accuracy: 0.9557 - val_loss: 0.3189 - val_binary_accuracy: 0.8961\n",
      "Epoch 539/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1033 - binary_accuracy: 0.9556 - val_loss: 0.3217 - val_binary_accuracy: 0.8962\n",
      "Epoch 540/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1036 - binary_accuracy: 0.9556 - val_loss: 0.3169 - val_binary_accuracy: 0.8970\n",
      "Epoch 541/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1032 - binary_accuracy: 0.9558 - val_loss: 0.3185 - val_binary_accuracy: 0.8965\n",
      "Epoch 542/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1026 - binary_accuracy: 0.9560 - val_loss: 0.3197 - val_binary_accuracy: 0.8962\n",
      "Epoch 543/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1030 - binary_accuracy: 0.9559 - val_loss: 0.3195 - val_binary_accuracy: 0.8969\n",
      "Epoch 544/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1029 - binary_accuracy: 0.9558 - val_loss: 0.3193 - val_binary_accuracy: 0.8965\n",
      "Epoch 545/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1037 - binary_accuracy: 0.9553 - val_loss: 0.3181 - val_binary_accuracy: 0.8971\n",
      "Epoch 546/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1032 - binary_accuracy: 0.9557 - val_loss: 0.3230 - val_binary_accuracy: 0.8970\n",
      "Epoch 547/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1023 - binary_accuracy: 0.9562 - val_loss: 0.3229 - val_binary_accuracy: 0.8967\n",
      "Epoch 548/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1029 - binary_accuracy: 0.9558 - val_loss: 0.3196 - val_binary_accuracy: 0.8965\n",
      "Epoch 549/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1026 - binary_accuracy: 0.9560 - val_loss: 0.3223 - val_binary_accuracy: 0.8964\n",
      "Epoch 550/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1020 - binary_accuracy: 0.9564 - val_loss: 0.3238 - val_binary_accuracy: 0.8968\n",
      "Epoch 551/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1028 - binary_accuracy: 0.9559 - val_loss: 0.3187 - val_binary_accuracy: 0.8962\n",
      "Epoch 552/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1021 - binary_accuracy: 0.9563 - val_loss: 0.3225 - val_binary_accuracy: 0.8970\n",
      "Epoch 553/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1016 - binary_accuracy: 0.9566 - val_loss: 0.3219 - val_binary_accuracy: 0.8967\n",
      "Epoch 554/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1019 - binary_accuracy: 0.9564 - val_loss: 0.3247 - val_binary_accuracy: 0.8963\n",
      "Epoch 555/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1025 - binary_accuracy: 0.9560 - val_loss: 0.3203 - val_binary_accuracy: 0.8967\n",
      "Epoch 556/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1015 - binary_accuracy: 0.9565 - val_loss: 0.3253 - val_binary_accuracy: 0.8959\n",
      "Epoch 557/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1010 - binary_accuracy: 0.9567 - val_loss: 0.3240 - val_binary_accuracy: 0.8967\n",
      "Epoch 558/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1016 - binary_accuracy: 0.9566 - val_loss: 0.3255 - val_binary_accuracy: 0.8966\n",
      "Epoch 559/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1012 - binary_accuracy: 0.9568 - val_loss: 0.3234 - val_binary_accuracy: 0.8962\n",
      "Epoch 560/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1020 - binary_accuracy: 0.9564 - val_loss: 0.3274 - val_binary_accuracy: 0.8961\n",
      "Epoch 561/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1012 - binary_accuracy: 0.9568 - val_loss: 0.3239 - val_binary_accuracy: 0.8967\n",
      "Epoch 562/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1013 - binary_accuracy: 0.9567 - val_loss: 0.3252 - val_binary_accuracy: 0.8965\n",
      "Epoch 563/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1012 - binary_accuracy: 0.9568 - val_loss: 0.3219 - val_binary_accuracy: 0.8966\n",
      "Epoch 564/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1008 - binary_accuracy: 0.9569 - val_loss: 0.3263 - val_binary_accuracy: 0.8967\n",
      "Epoch 565/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1002 - binary_accuracy: 0.9571 - val_loss: 0.3286 - val_binary_accuracy: 0.8965\n",
      "Epoch 566/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1004 - binary_accuracy: 0.9573 - val_loss: 0.3259 - val_binary_accuracy: 0.8971\n",
      "Epoch 567/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1013 - binary_accuracy: 0.9567 - val_loss: 0.3247 - val_binary_accuracy: 0.8969\n",
      "Epoch 568/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1012 - binary_accuracy: 0.9567 - val_loss: 0.3245 - val_binary_accuracy: 0.8969\n",
      "Epoch 569/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1001 - binary_accuracy: 0.9572 - val_loss: 0.3240 - val_binary_accuracy: 0.8965\n",
      "Epoch 570/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.1004 - binary_accuracy: 0.9571 - val_loss: 0.3287 - val_binary_accuracy: 0.8966\n",
      "Epoch 571/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1001 - binary_accuracy: 0.9573 - val_loss: 0.3261 - val_binary_accuracy: 0.8965\n",
      "Epoch 572/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.1005 - binary_accuracy: 0.9571 - val_loss: 0.3281 - val_binary_accuracy: 0.8963\n",
      "Epoch 573/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.1003 - binary_accuracy: 0.9569 - val_loss: 0.3272 - val_binary_accuracy: 0.8965\n",
      "Epoch 574/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0996 - binary_accuracy: 0.9574 - val_loss: 0.3282 - val_binary_accuracy: 0.8968\n",
      "Epoch 575/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0999 - binary_accuracy: 0.9573 - val_loss: 0.3283 - val_binary_accuracy: 0.8966\n",
      "Epoch 576/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0997 - binary_accuracy: 0.9574 - val_loss: 0.3273 - val_binary_accuracy: 0.8964\n",
      "Epoch 577/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0998 - binary_accuracy: 0.9574 - val_loss: 0.3235 - val_binary_accuracy: 0.8971\n",
      "Epoch 578/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0997 - binary_accuracy: 0.9575 - val_loss: 0.3274 - val_binary_accuracy: 0.8966\n",
      "Epoch 579/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0989 - binary_accuracy: 0.9576 - val_loss: 0.3298 - val_binary_accuracy: 0.8964\n",
      "Epoch 580/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0993 - binary_accuracy: 0.9576 - val_loss: 0.3310 - val_binary_accuracy: 0.8956\n",
      "Epoch 581/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0985 - binary_accuracy: 0.9580 - val_loss: 0.3304 - val_binary_accuracy: 0.8969\n",
      "Epoch 582/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0993 - binary_accuracy: 0.9576 - val_loss: 0.3335 - val_binary_accuracy: 0.8961\n",
      "Epoch 583/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0984 - binary_accuracy: 0.9580 - val_loss: 0.3309 - val_binary_accuracy: 0.8962\n",
      "Epoch 584/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0987 - binary_accuracy: 0.9578 - val_loss: 0.3354 - val_binary_accuracy: 0.8965\n",
      "Epoch 585/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0981 - binary_accuracy: 0.9580 - val_loss: 0.3347 - val_binary_accuracy: 0.8967\n",
      "Epoch 586/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0985 - binary_accuracy: 0.9580 - val_loss: 0.3355 - val_binary_accuracy: 0.8964\n",
      "Epoch 587/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0990 - binary_accuracy: 0.9578 - val_loss: 0.3333 - val_binary_accuracy: 0.8969\n",
      "Epoch 588/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0979 - binary_accuracy: 0.9583 - val_loss: 0.3408 - val_binary_accuracy: 0.8962\n",
      "Epoch 589/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0977 - binary_accuracy: 0.9583 - val_loss: 0.3323 - val_binary_accuracy: 0.8961\n",
      "Epoch 590/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0978 - binary_accuracy: 0.9582 - val_loss: 0.3352 - val_binary_accuracy: 0.8965\n",
      "Epoch 591/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0975 - binary_accuracy: 0.9584 - val_loss: 0.3396 - val_binary_accuracy: 0.8962\n",
      "Epoch 592/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0973 - binary_accuracy: 0.9586 - val_loss: 0.3409 - val_binary_accuracy: 0.8964\n",
      "Epoch 593/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0980 - binary_accuracy: 0.9582 - val_loss: 0.3370 - val_binary_accuracy: 0.8963\n",
      "Epoch 594/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0970 - binary_accuracy: 0.9585 - val_loss: 0.3360 - val_binary_accuracy: 0.8967\n",
      "Epoch 595/1000\n",
      "85991/85991 [==============================] - 3s 39us/sample - loss: 0.0974 - binary_accuracy: 0.9585 - val_loss: 0.3368 - val_binary_accuracy: 0.8962\n",
      "Epoch 596/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0976 - binary_accuracy: 0.9584 - val_loss: 0.3378 - val_binary_accuracy: 0.8960\n",
      "Epoch 597/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0974 - binary_accuracy: 0.9585 - val_loss: 0.3365 - val_binary_accuracy: 0.8959\n",
      "Epoch 598/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0974 - binary_accuracy: 0.9584 - val_loss: 0.3366 - val_binary_accuracy: 0.8962\n",
      "Epoch 599/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0971 - binary_accuracy: 0.9585 - val_loss: 0.3414 - val_binary_accuracy: 0.8962\n",
      "Epoch 600/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0975 - binary_accuracy: 0.9584 - val_loss: 0.3318 - val_binary_accuracy: 0.8959\n",
      "Epoch 601/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0972 - binary_accuracy: 0.9585 - val_loss: 0.3346 - val_binary_accuracy: 0.8964\n",
      "Epoch 602/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0967 - binary_accuracy: 0.9588 - val_loss: 0.3363 - val_binary_accuracy: 0.8966\n",
      "Epoch 603/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0965 - binary_accuracy: 0.9589 - val_loss: 0.3382 - val_binary_accuracy: 0.8965\n",
      "Epoch 604/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0967 - binary_accuracy: 0.9588 - val_loss: 0.3397 - val_binary_accuracy: 0.8963\n",
      "Epoch 605/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0965 - binary_accuracy: 0.9591 - val_loss: 0.3391 - val_binary_accuracy: 0.8959\n",
      "Epoch 606/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0967 - binary_accuracy: 0.9588 - val_loss: 0.3362 - val_binary_accuracy: 0.8959\n",
      "Epoch 607/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0965 - binary_accuracy: 0.9588 - val_loss: 0.3391 - val_binary_accuracy: 0.8957\n",
      "Epoch 608/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0962 - binary_accuracy: 0.9591 - val_loss: 0.3411 - val_binary_accuracy: 0.8964\n",
      "Epoch 609/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0962 - binary_accuracy: 0.9588 - val_loss: 0.3405 - val_binary_accuracy: 0.8968\n",
      "Epoch 610/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0968 - binary_accuracy: 0.9587 - val_loss: 0.3390 - val_binary_accuracy: 0.8961\n",
      "Epoch 611/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0964 - binary_accuracy: 0.9590 - val_loss: 0.3412 - val_binary_accuracy: 0.8963\n",
      "Epoch 612/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0957 - binary_accuracy: 0.9593 - val_loss: 0.3401 - val_binary_accuracy: 0.8967\n",
      "Epoch 613/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0963 - binary_accuracy: 0.9590 - val_loss: 0.3405 - val_binary_accuracy: 0.8964\n",
      "Epoch 614/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0963 - binary_accuracy: 0.9590 - val_loss: 0.3382 - val_binary_accuracy: 0.8965\n",
      "Epoch 615/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0956 - binary_accuracy: 0.9592 - val_loss: 0.3448 - val_binary_accuracy: 0.8959\n",
      "Epoch 616/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0961 - binary_accuracy: 0.9591 - val_loss: 0.3404 - val_binary_accuracy: 0.8966\n",
      "Epoch 617/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0957 - binary_accuracy: 0.9592 - val_loss: 0.3445 - val_binary_accuracy: 0.8969\n",
      "Epoch 618/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0956 - binary_accuracy: 0.9593 - val_loss: 0.3440 - val_binary_accuracy: 0.8966\n",
      "Epoch 619/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0950 - binary_accuracy: 0.9595 - val_loss: 0.3460 - val_binary_accuracy: 0.8957\n",
      "Epoch 620/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0953 - binary_accuracy: 0.9595 - val_loss: 0.3453 - val_binary_accuracy: 0.8968\n",
      "Epoch 621/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0957 - binary_accuracy: 0.9593 - val_loss: 0.3425 - val_binary_accuracy: 0.8963\n",
      "Epoch 622/1000\n",
      "85991/85991 [==============================] - 3s 38us/sample - loss: 0.0953 - binary_accuracy: 0.9595 - val_loss: 0.3481 - val_binary_accuracy: 0.8961\n",
      "Epoch 623/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0944 - binary_accuracy: 0.9599 - val_loss: 0.3464 - val_binary_accuracy: 0.8969\n",
      "Epoch 624/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0941 - binary_accuracy: 0.9600 - val_loss: 0.3470 - val_binary_accuracy: 0.8957\n",
      "Epoch 625/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0950 - binary_accuracy: 0.9595 - val_loss: 0.3487 - val_binary_accuracy: 0.8962\n",
      "Epoch 626/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0947 - binary_accuracy: 0.9598 - val_loss: 0.3414 - val_binary_accuracy: 0.8960\n",
      "Epoch 627/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0953 - binary_accuracy: 0.9596 - val_loss: 0.3431 - val_binary_accuracy: 0.8959\n",
      "Epoch 628/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0950 - binary_accuracy: 0.9595 - val_loss: 0.3419 - val_binary_accuracy: 0.8958\n",
      "Epoch 629/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0941 - binary_accuracy: 0.9601 - val_loss: 0.3440 - val_binary_accuracy: 0.8961\n",
      "Epoch 630/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0938 - binary_accuracy: 0.9602 - val_loss: 0.3484 - val_binary_accuracy: 0.8964\n",
      "Epoch 631/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0938 - binary_accuracy: 0.9602 - val_loss: 0.3495 - val_binary_accuracy: 0.8962\n",
      "Epoch 632/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0945 - binary_accuracy: 0.9598 - val_loss: 0.3438 - val_binary_accuracy: 0.8956943 - binary_accuracy: 0.\n",
      "Epoch 633/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0938 - binary_accuracy: 0.9600 - val_loss: 0.3481 - val_binary_accuracy: 0.8962\n",
      "Epoch 634/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0938 - binary_accuracy: 0.9601 - val_loss: 0.3495 - val_binary_accuracy: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0954 - binary_accuracy: 0.9594 - val_loss: 0.3455 - val_binary_accuracy: 0.8957\n",
      "Epoch 636/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0937 - binary_accuracy: 0.9603 - val_loss: 0.3474 - val_binary_accuracy: 0.8964\n",
      "Epoch 637/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0934 - binary_accuracy: 0.9604 - val_loss: 0.3506 - val_binary_accuracy: 0.8963\n",
      "Epoch 638/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0933 - binary_accuracy: 0.9603 - val_loss: 0.3495 - val_binary_accuracy: 0.8962\n",
      "Epoch 639/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0943 - binary_accuracy: 0.9601 - val_loss: 0.3465 - val_binary_accuracy: 0.8960\n",
      "Epoch 640/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0934 - binary_accuracy: 0.9602 - val_loss: 0.3491 - val_binary_accuracy: 0.8956 0.0934 - binary_accuracy: 0\n",
      "Epoch 641/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0929 - binary_accuracy: 0.9605 - val_loss: 0.3519 - val_binary_accuracy: 0.8959\n",
      "Epoch 642/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0929 - binary_accuracy: 0.9604 - val_loss: 0.3488 - val_binary_accuracy: 0.8960\n",
      "Epoch 643/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0936 - binary_accuracy: 0.9602 - val_loss: 0.3454 - val_binary_accuracy: 0.8958\n",
      "Epoch 644/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0936 - binary_accuracy: 0.9603 - val_loss: 0.3502 - val_binary_accuracy: 0.8956 - bin\n",
      "Epoch 645/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0927 - binary_accuracy: 0.9606 - val_loss: 0.3514 - val_binary_accuracy: 0.8953\n",
      "Epoch 646/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0927 - binary_accuracy: 0.9607 - val_loss: 0.3530 - val_binary_accuracy: 0.8963\n",
      "Epoch 647/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0931 - binary_accuracy: 0.9604 - val_loss: 0.3513 - val_binary_accuracy: 0.8965\n",
      "Epoch 648/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0926 - binary_accuracy: 0.9608 - val_loss: 0.3523 - val_binary_accuracy: 0.8963\n",
      "Epoch 649/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0926 - binary_accuracy: 0.9607 - val_loss: 0.3496 - val_binary_accuracy: 0.8954\n",
      "Epoch 650/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0930 - binary_accuracy: 0.9605 - val_loss: 0.3538 - val_binary_accuracy: 0.8961\n",
      "Epoch 651/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0928 - binary_accuracy: 0.9606 - val_loss: 0.3525 - val_binary_accuracy: 0.8966\n",
      "Epoch 652/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0923 - binary_accuracy: 0.9607 - val_loss: 0.3551 - val_binary_accuracy: 0.8967\n",
      "Epoch 653/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0919 - binary_accuracy: 0.9610 - val_loss: 0.3539 - val_binary_accuracy: 0.8952 - binary\n",
      "Epoch 654/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0920 - binary_accuracy: 0.9611 - val_loss: 0.3539 - val_binary_accuracy: 0.8962\n",
      "Epoch 655/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0922 - binary_accuracy: 0.9608 - val_loss: 0.3523 - val_binary_accuracy: 0.8953\n",
      "Epoch 656/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0926 - binary_accuracy: 0.9606 - val_loss: 0.3499 - val_binary_accuracy: 0.8957\n",
      "Epoch 657/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0918 - binary_accuracy: 0.9611 - val_loss: 0.3530 - val_binary_accuracy: 0.8961\n",
      "Epoch 658/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0923 - binary_accuracy: 0.9608 - val_loss: 0.3546 - val_binary_accuracy: 0.8955\n",
      "Epoch 659/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0919 - binary_accuracy: 0.9610 - val_loss: 0.3571 - val_binary_accuracy: 0.8957\n",
      "Epoch 660/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0917 - binary_accuracy: 0.9610 - val_loss: 0.3572 - val_binary_accuracy: 0.8961\n",
      "Epoch 661/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0916 - binary_accuracy: 0.9610 - val_loss: 0.3528 - val_binary_accuracy: 0.8953\n",
      "Epoch 662/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0919 - binary_accuracy: 0.9611 - val_loss: 0.3557 - val_binary_accuracy: 0.8961\n",
      "Epoch 663/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0909 - binary_accuracy: 0.9617 - val_loss: 0.3625 - val_binary_accuracy: 0.8953\n",
      "Epoch 664/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0916 - binary_accuracy: 0.9611 - val_loss: 0.3583 - val_binary_accuracy: 0.8957\n",
      "Epoch 665/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0917 - binary_accuracy: 0.9612 - val_loss: 0.3547 - val_binary_accuracy: 0.8965\n",
      "Epoch 666/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0920 - binary_accuracy: 0.9610 - val_loss: 0.3591 - val_binary_accuracy: 0.8957\n",
      "Epoch 667/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0911 - binary_accuracy: 0.9614 - val_loss: 0.3557 - val_binary_accuracy: 0.8956s: 0.0908 - binary_accuracy: 0.96 - ETA: 0s - loss: 0.0907 - binary_accuracy:\n",
      "Epoch 668/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0908 - binary_accuracy: 0.9617 - val_loss: 0.3569 - val_binary_accuracy: 0.8956\n",
      "Epoch 669/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0905 - binary_accuracy: 0.9616 - val_loss: 0.3571 - val_binary_accuracy: 0.8962 loss: 0.0895 - bin\n",
      "Epoch 670/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0907 - binary_accuracy: 0.9616 - val_loss: 0.3624 - val_binary_accuracy: 0.8958\n",
      "Epoch 671/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0911 - binary_accuracy: 0.9614 - val_loss: 0.3574 - val_binary_accuracy: 0.8957\n",
      "Epoch 672/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0911 - binary_accuracy: 0.9614 - val_loss: 0.3569 - val_binary_accuracy: 0.8956\n",
      "Epoch 673/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0906 - binary_accuracy: 0.9616 - val_loss: 0.3618 - val_binary_accuracy: 0.8956\n",
      "Epoch 674/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0901 - binary_accuracy: 0.9618 - val_loss: 0.3591 - val_binary_accuracy: 0.8959\n",
      "Epoch 675/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0912 - binary_accuracy: 0.9613 - val_loss: 0.3578 - val_binary_accuracy: 0.8953\n",
      "Epoch 676/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0912 - binary_accuracy: 0.9613 - val_loss: 0.3573 - val_binary_accuracy: 0.8955\n",
      "Epoch 677/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0906 - binary_accuracy: 0.9618 - val_loss: 0.3628 - val_binary_accuracy: 0.8959\n",
      "Epoch 678/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0904 - binary_accuracy: 0.9617 - val_loss: 0.3643 - val_binary_accuracy: 0.8955\n",
      "Epoch 679/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0904 - binary_accuracy: 0.9616 - val_loss: 0.3624 - val_binary_accuracy: 0.8959\n",
      "Epoch 680/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0899 - binary_accuracy: 0.9620 - val_loss: 0.3622 - val_binary_accuracy: 0.8957\n",
      "Epoch 681/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0899 - binary_accuracy: 0.9620 - val_loss: 0.3566 - val_binary_accuracy: 0.8952\n",
      "Epoch 682/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0902 - binary_accuracy: 0.9618 - val_loss: 0.3651 - val_binary_accuracy: 0.8950\n",
      "Epoch 683/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0900 - binary_accuracy: 0.9619 - val_loss: 0.3629 - val_binary_accuracy: 0.8953\n",
      "Epoch 684/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0902 - binary_accuracy: 0.9617 - val_loss: 0.3605 - val_binary_accuracy: 0.8954\n",
      "Epoch 685/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0894 - binary_accuracy: 0.9621 - val_loss: 0.3629 - val_binary_accuracy: 0.8957\n",
      "Epoch 686/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0896 - binary_accuracy: 0.9622 - val_loss: 0.3624 - val_binary_accuracy: 0.8952\n",
      "Epoch 687/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0895 - binary_accuracy: 0.9621 - val_loss: 0.3636 - val_binary_accuracy: 0.8955\n",
      "Epoch 688/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0901 - binary_accuracy: 0.9617 - val_loss: 0.3647 - val_binary_accuracy: 0.8952\n",
      "Epoch 689/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0894 - binary_accuracy: 0.9623 - val_loss: 0.3666 - val_binary_accuracy: 0.8954\n",
      "Epoch 690/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0896 - binary_accuracy: 0.9619 - val_loss: 0.3641 - val_binary_accuracy: 0.8953\n",
      "Epoch 691/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0894 - binary_accuracy: 0.9621 - val_loss: 0.3621 - val_binary_accuracy: 0.8955\n",
      "Epoch 692/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0892 - binary_accuracy: 0.9622 - val_loss: 0.3663 - val_binary_accuracy: 0.8955\n",
      "Epoch 693/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0891 - binary_accuracy: 0.9623 - val_loss: 0.3673 - val_binary_accuracy: 0.8952\n",
      "Epoch 694/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0892 - binary_accuracy: 0.9622 - val_loss: 0.3616 - val_binary_accuracy: 0.8953\n",
      "Epoch 695/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0893 - binary_accuracy: 0.9621 - val_loss: 0.3630 - val_binary_accuracy: 0.8958\n",
      "Epoch 696/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0888 - binary_accuracy: 0.9625 - val_loss: 0.3693 - val_binary_accuracy: 0.8947\n",
      "Epoch 697/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0884 - binary_accuracy: 0.9627 - val_loss: 0.3660 - val_binary_accuracy: 0.8954\n",
      "Epoch 698/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0889 - binary_accuracy: 0.9625 - val_loss: 0.3627 - val_binary_accuracy: 0.8952\n",
      "Epoch 699/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0891 - binary_accuracy: 0.9624 - val_loss: 0.3643 - val_binary_accuracy: 0.8956\n",
      "Epoch 700/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0886 - binary_accuracy: 0.9626 - val_loss: 0.3694 - val_binary_accuracy: 0.8955y_accuracy\n",
      "Epoch 701/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0883 - binary_accuracy: 0.9627 - val_loss: 0.3679 - val_binary_accuracy: 0.8955\n",
      "Epoch 702/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0887 - binary_accuracy: 0.9625 - val_loss: 0.3657 - val_binary_accuracy: 0.8950 - loss: 0.0878 - \n",
      "Epoch 703/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0888 - binary_accuracy: 0.9625 - val_loss: 0.3687 - val_binary_accuracy: 0.8955\n",
      "Epoch 704/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0884 - binary_accuracy: 0.9627 - val_loss: 0.3648 - val_binary_accuracy: 0.8954\n",
      "Epoch 705/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0879 - binary_accuracy: 0.9630 - val_loss: 0.3728 - val_binary_accuracy: 0.8951\n",
      "Epoch 706/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0886 - binary_accuracy: 0.9626 - val_loss: 0.3703 - val_binary_accuracy: 0.8952\n",
      "Epoch 707/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0875 - binary_accuracy: 0.9629 - val_loss: 0.3741 - val_binary_accuracy: 0.8956_accuracy: 0\n",
      "Epoch 708/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0879 - binary_accuracy: 0.9629 - val_loss: 0.3709 - val_binary_accuracy: 0.8951ry_accuracy: 0.96\n",
      "Epoch 709/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0878 - binary_accuracy: 0.9629 - val_loss: 0.3680 - val_binary_accuracy: 0.8959binary_accur\n",
      "Epoch 710/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0874 - binary_accuracy: 0.9631 - val_loss: 0.3752 - val_binary_accuracy: 0.8952\n",
      "Epoch 711/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0883 - binary_accuracy: 0.9627 - val_loss: 0.3717 - val_binary_accuracy: 0.8958\n",
      "Epoch 712/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0878 - binary_accuracy: 0.9630 - val_loss: 0.3690 - val_binary_accuracy: 0.8949\n",
      "Epoch 713/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0884 - binary_accuracy: 0.9626 - val_loss: 0.3710 - val_binary_accuracy: 0.8948\n",
      "Epoch 714/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0881 - binary_accuracy: 0.9627 - val_loss: 0.3716 - val_binary_accuracy: 0.8955\n",
      "Epoch 715/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0873 - binary_accuracy: 0.9630 - val_loss: 0.3700 - val_binary_accuracy: 0.8957\n",
      "Epoch 716/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0880 - binary_accuracy: 0.9629 - val_loss: 0.3639 - val_binary_accuracy: 0.8956 loss: 0.0879 - binary_accuracy: 0.\n",
      "Epoch 717/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0875 - binary_accuracy: 0.9630 - val_loss: 0.3696 - val_binary_accuracy: 0.8952\n",
      "Epoch 718/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0873 - binary_accuracy: 0.9632 - val_loss: 0.3694 - val_binary_accuracy: 0.8954\n",
      "Epoch 719/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0872 - binary_accuracy: 0.9632 - val_loss: 0.3702 - val_binary_accuracy: 0.8950\n",
      "Epoch 720/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0870 - binary_accuracy: 0.9631 - val_loss: 0.3717 - val_binary_accuracy: 0.8952\n",
      "Epoch 721/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0864 - binary_accuracy: 0.9635 - val_loss: 0.3743 - val_binary_accuracy: 0.8950\n",
      "Epoch 722/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0869 - binary_accuracy: 0.9633 - val_loss: 0.3720 - val_binary_accuracy: 0.8947\n",
      "Epoch 723/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0869 - binary_accuracy: 0.9634 - val_loss: 0.3705 - val_binary_accuracy: 0.8950\n",
      "Epoch 724/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0870 - binary_accuracy: 0.9634 - val_loss: 0.3697 - val_binary_accuracy: 0.8950\n",
      "Epoch 725/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0868 - binary_accuracy: 0.9634 - val_loss: 0.3747 - val_binary_accuracy: 0.8950\n",
      "Epoch 726/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0868 - binary_accuracy: 0.9634 - val_loss: 0.3736 - val_binary_accuracy: 0.8951\n",
      "Epoch 727/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0869 - binary_accuracy: 0.9633 - val_loss: 0.3747 - val_binary_accuracy: 0.8950\n",
      "Epoch 728/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0867 - binary_accuracy: 0.9635 - val_loss: 0.3744 - val_binary_accuracy: 0.8945\n",
      "Epoch 729/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0868 - binary_accuracy: 0.9634 - val_loss: 0.3744 - val_binary_accuracy: 0.8950\n",
      "Epoch 730/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0860 - binary_accuracy: 0.9637 - val_loss: 0.3764 - val_binary_accuracy: 0.8943\n",
      "Epoch 731/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0866 - binary_accuracy: 0.9635 - val_loss: 0.3711 - val_binary_accuracy: 0.8951\n",
      "Epoch 732/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0870 - binary_accuracy: 0.9631 - val_loss: 0.3720 - val_binary_accuracy: 0.8954\n",
      "Epoch 733/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0861 - binary_accuracy: 0.9637 - val_loss: 0.3757 - val_binary_accuracy: 0.8949\n",
      "Epoch 734/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0858 - binary_accuracy: 0.9639 - val_loss: 0.3788 - val_binary_accuracy: 0.8951\n",
      "Epoch 735/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0863 - binary_accuracy: 0.9635 - val_loss: 0.3754 - val_binary_accuracy: 0.8947\n",
      "Epoch 736/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0867 - binary_accuracy: 0.9633 - val_loss: 0.3733 - val_binary_accuracy: 0.8944\n",
      "Epoch 737/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0859 - binary_accuracy: 0.9638 - val_loss: 0.3766 - val_binary_accuracy: 0.8953\n",
      "Epoch 738/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0853 - binary_accuracy: 0.9640 - val_loss: 0.3817 - val_binary_accuracy: 0.8948\n",
      "Epoch 739/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0861 - binary_accuracy: 0.9636 - val_loss: 0.3792 - val_binary_accuracy: 0.8953\n",
      "Epoch 740/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0862 - binary_accuracy: 0.9638 - val_loss: 0.3777 - val_binary_accuracy: 0.8947\n",
      "Epoch 741/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0857 - binary_accuracy: 0.9638 - val_loss: 0.3825 - val_binary_accuracy: 0.8953\n",
      "Epoch 742/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0856 - binary_accuracy: 0.9639 - val_loss: 0.3769 - val_binary_accuracy: 0.8948\n",
      "Epoch 743/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0861 - binary_accuracy: 0.9636 - val_loss: 0.3771 - val_binary_accuracy: 0.8951\n",
      "Epoch 744/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0849 - binary_accuracy: 0.9641 - val_loss: 0.3800 - val_binary_accuracy: 0.8953\n",
      "Epoch 745/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0851 - binary_accuracy: 0.9643 - val_loss: 0.3774 - val_binary_accuracy: 0.8953\n",
      "Epoch 746/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0849 - binary_accuracy: 0.9642 - val_loss: 0.3795 - val_binary_accuracy: 0.8953\n",
      "Epoch 747/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0859 - binary_accuracy: 0.9640 - val_loss: 0.3822 - val_binary_accuracy: 0.8948\n",
      "Epoch 748/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0854 - binary_accuracy: 0.9639 - val_loss: 0.3785 - val_binary_accuracy: 0.8949\n",
      "Epoch 749/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0844 - binary_accuracy: 0.9644 - val_loss: 0.3778 - val_binary_accuracy: 0.8948\n",
      "Epoch 750/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0851 - binary_accuracy: 0.9642 - val_loss: 0.3799 - val_binary_accuracy: 0.8944\n",
      "Epoch 751/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0849 - binary_accuracy: 0.9642 - val_loss: 0.3834 - val_binary_accuracy: 0.8949\n",
      "Epoch 752/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0844 - binary_accuracy: 0.9645 - val_loss: 0.3814 - val_binary_accuracy: 0.8946\n",
      "Epoch 753/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0845 - binary_accuracy: 0.9644 - val_loss: 0.3864 - val_binary_accuracy: 0.8943\n",
      "Epoch 754/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0852 - binary_accuracy: 0.9642 - val_loss: 0.3827 - val_binary_accuracy: 0.8951\n",
      "Epoch 755/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0857 - binary_accuracy: 0.9638 - val_loss: 0.3810 - val_binary_accuracy: 0.8950\n",
      "Epoch 756/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0846 - binary_accuracy: 0.9645 - val_loss: 0.3816 - val_binary_accuracy: 0.8949\n",
      "Epoch 757/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0846 - binary_accuracy: 0.9645 - val_loss: 0.3811 - val_binary_accuracy: 0.8946\n",
      "Epoch 758/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0846 - binary_accuracy: 0.9644 - val_loss: 0.3869 - val_binary_accuracy: 0.8958\n",
      "Epoch 759/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0855 - binary_accuracy: 0.9640 - val_loss: 0.3798 - val_binary_accuracy: 0.8950\n",
      "Epoch 760/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0848 - binary_accuracy: 0.9641 - val_loss: 0.3793 - val_binary_accuracy: 0.8950\n",
      "Epoch 761/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0846 - binary_accuracy: 0.9643 - val_loss: 0.3833 - val_binary_accuracy: 0.8946\n",
      "Epoch 762/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0848 - binary_accuracy: 0.9641 - val_loss: 0.3872 - val_binary_accuracy: 0.8951\n",
      "Epoch 763/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0844 - binary_accuracy: 0.9645 - val_loss: 0.3829 - val_binary_accuracy: 0.8946\n",
      "Epoch 764/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0846 - binary_accuracy: 0.9644 - val_loss: 0.3823 - val_binary_accuracy: 0.8946\n",
      "Epoch 765/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0847 - binary_accuracy: 0.9644 - val_loss: 0.3812 - val_binary_accuracy: 0.8948\n",
      "Epoch 766/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0848 - binary_accuracy: 0.9644 - val_loss: 0.3823 - val_binary_accuracy: 0.8944\n",
      "Epoch 767/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0844 - binary_accuracy: 0.9645 - val_loss: 0.3841 - val_binary_accuracy: 0.8947\n",
      "Epoch 768/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0836 - binary_accuracy: 0.9648 - val_loss: 0.3874 - val_binary_accuracy: 0.8946\n",
      "Epoch 769/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0843 - binary_accuracy: 0.9645 - val_loss: 0.3845 - val_binary_accuracy: 0.8951\n",
      "Epoch 770/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0836 - binary_accuracy: 0.9648 - val_loss: 0.3901 - val_binary_accuracy: 0.8944 - loss: 0.0834 - binary_accuracy\n",
      "Epoch 771/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0837 - binary_accuracy: 0.9647 - val_loss: 0.3860 - val_binary_accuracy: 0.8945\n",
      "Epoch 772/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0830 - binary_accuracy: 0.9651 - val_loss: 0.3795 - val_binary_accuracy: 0.8944\n",
      "Epoch 773/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0839 - binary_accuracy: 0.9647 - val_loss: 0.3855 - val_binary_accuracy: 0.8945\n",
      "Epoch 774/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0836 - binary_accuracy: 0.9648 - val_loss: 0.3884 - val_binary_accuracy: 0.8949\n",
      "Epoch 775/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0832 - binary_accuracy: 0.9650 - val_loss: 0.3885 - val_binary_accuracy: 0.8946831 - binary_accuracy:\n",
      "Epoch 776/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0834 - binary_accuracy: 0.9650 - val_loss: 0.3899 - val_binary_accuracy: 0.8941\n",
      "Epoch 777/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0844 - binary_accuracy: 0.9644 - val_loss: 0.3861 - val_binary_accuracy: 0.8945\n",
      "Epoch 778/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0835 - binary_accuracy: 0.9650 - val_loss: 0.3877 - val_binary_accuracy: 0.8944\n",
      "Epoch 779/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0838 - binary_accuracy: 0.9648 - val_loss: 0.3888 - val_binary_accuracy: 0.8946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0826 - binary_accuracy: 0.9652 - val_loss: 0.3916 - val_binary_accuracy: 0.8948\n",
      "Epoch 781/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0832 - binary_accuracy: 0.9650 - val_loss: 0.3920 - val_binary_accuracy: 0.8947\n",
      "Epoch 782/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0830 - binary_accuracy: 0.9651 - val_loss: 0.3876 - val_binary_accuracy: 0.8950\n",
      "Epoch 783/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0832 - binary_accuracy: 0.9650 - val_loss: 0.3866 - val_binary_accuracy: 0.8950\n",
      "Epoch 784/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0830 - binary_accuracy: 0.9651 - val_loss: 0.3908 - val_binary_accuracy: 0.8948\n",
      "Epoch 785/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0825 - binary_accuracy: 0.9653 - val_loss: 0.3857 - val_binary_accuracy: 0.8947\n",
      "Epoch 786/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0829 - binary_accuracy: 0.9651 - val_loss: 0.3912 - val_binary_accuracy: 0.8942\n",
      "Epoch 787/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0839 - binary_accuracy: 0.9646 - val_loss: 0.3851 - val_binary_accuracy: 0.8952 loss:\n",
      "Epoch 788/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0836 - binary_accuracy: 0.9649 - val_loss: 0.3882 - val_binary_accuracy: 0.8947\n",
      "Epoch 789/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0825 - binary_accuracy: 0.9653 - val_loss: 0.3898 - val_binary_accuracy: 0.8949\n",
      "Epoch 790/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0829 - binary_accuracy: 0.9653 - val_loss: 0.3863 - val_binary_accuracy: 0.8948\n",
      "Epoch 791/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0828 - binary_accuracy: 0.9652 - val_loss: 0.3915 - val_binary_accuracy: 0.8941\n",
      "Epoch 792/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0827 - binary_accuracy: 0.9652 - val_loss: 0.3888 - val_binary_accuracy: 0.8945\n",
      "Epoch 793/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0828 - binary_accuracy: 0.9654 - val_loss: 0.3923 - val_binary_accuracy: 0.8941\n",
      "Epoch 794/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0824 - binary_accuracy: 0.9653 - val_loss: 0.3943 - val_binary_accuracy: 0.8951\n",
      "Epoch 795/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0820 - binary_accuracy: 0.9655 - val_loss: 0.3942 - val_binary_accuracy: 0.8944\n",
      "Epoch 796/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0822 - binary_accuracy: 0.9654 - val_loss: 0.3954 - val_binary_accuracy: 0.8945\n",
      "Epoch 797/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0830 - binary_accuracy: 0.9651 - val_loss: 0.3923 - val_binary_accuracy: 0.8944\n",
      "Epoch 798/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0828 - binary_accuracy: 0.9653 - val_loss: 0.3891 - val_binary_accuracy: 0.8951\n",
      "Epoch 799/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0817 - binary_accuracy: 0.9656 - val_loss: 0.3927 - val_binary_accuracy: 0.8941\n",
      "Epoch 800/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0814 - binary_accuracy: 0.9658 - val_loss: 0.3946 - val_binary_accuracy: 0.8947\n",
      "Epoch 801/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0818 - binary_accuracy: 0.9657 - val_loss: 0.3921 - val_binary_accuracy: 0.8946\n",
      "Epoch 802/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0818 - binary_accuracy: 0.9656 - val_loss: 0.3969 - val_binary_accuracy: 0.8942\n",
      "Epoch 803/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0821 - binary_accuracy: 0.9656 - val_loss: 0.3994 - val_binary_accuracy: 0.8945\n",
      "Epoch 804/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0818 - binary_accuracy: 0.9657 - val_loss: 0.3933 - val_binary_accuracy: 0.8951\n",
      "Epoch 805/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0816 - binary_accuracy: 0.9659 - val_loss: 0.3953 - val_binary_accuracy: 0.8942\n",
      "Epoch 806/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0818 - binary_accuracy: 0.9656 - val_loss: 0.3924 - val_binary_accuracy: 0.8940\n",
      "Epoch 807/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0822 - binary_accuracy: 0.9655 - val_loss: 0.3917 - val_binary_accuracy: 0.8947\n",
      "Epoch 808/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0809 - binary_accuracy: 0.9660 - val_loss: 0.3980 - val_binary_accuracy: 0.8944\n",
      "Epoch 809/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0810 - binary_accuracy: 0.9660 - val_loss: 0.3973 - val_binary_accuracy: 0.8946\n",
      "Epoch 810/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0816 - binary_accuracy: 0.9658 - val_loss: 0.3966 - val_binary_accuracy: 0.8937\n",
      "Epoch 811/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0816 - binary_accuracy: 0.9659 - val_loss: 0.3959 - val_binary_accuracy: 0.8942\n",
      "Epoch 812/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0823 - binary_accuracy: 0.9654 - val_loss: 0.3960 - val_binary_accuracy: 0.8948\n",
      "Epoch 813/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0816 - binary_accuracy: 0.9657 - val_loss: 0.3940 - val_binary_accuracy: 0.8939\n",
      "Epoch 814/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0804 - binary_accuracy: 0.9661 - val_loss: 0.4015 - val_binary_accuracy: 0.8943\n",
      "Epoch 815/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0807 - binary_accuracy: 0.9661 - val_loss: 0.3957 - val_binary_accuracy: 0.8942\n",
      "Epoch 816/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0807 - binary_accuracy: 0.9662 - val_loss: 0.3998 - val_binary_accuracy: 0.8946\n",
      "Epoch 817/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0809 - binary_accuracy: 0.9661 - val_loss: 0.3981 - val_binary_accuracy: 0.8949\n",
      "Epoch 818/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0810 - binary_accuracy: 0.9660 - val_loss: 0.3991 - val_binary_accuracy: 0.8947\n",
      "Epoch 819/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0807 - binary_accuracy: 0.9661 - val_loss: 0.4010 - val_binary_accuracy: 0.8942\n",
      "Epoch 820/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0807 - binary_accuracy: 0.9662 - val_loss: 0.3964 - val_binary_accuracy: 0.8940\n",
      "Epoch 821/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0805 - binary_accuracy: 0.9662 - val_loss: 0.4025 - val_binary_accuracy: 0.8941\n",
      "Epoch 822/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0808 - binary_accuracy: 0.9662 - val_loss: 0.3995 - val_binary_accuracy: 0.8942\n",
      "Epoch 823/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0813 - binary_accuracy: 0.9658 - val_loss: 0.3991 - val_binary_accuracy: 0.8936\n",
      "Epoch 824/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0814 - binary_accuracy: 0.9659 - val_loss: 0.3938 - val_binary_accuracy: 0.8940\n",
      "Epoch 825/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0807 - binary_accuracy: 0.9661 - val_loss: 0.3983 - val_binary_accuracy: 0.8944\n",
      "Epoch 826/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0805 - binary_accuracy: 0.9662 - val_loss: 0.4026 - val_binary_accuracy: 0.8945ss: 0.0805 - binary_accuracy\n",
      "Epoch 827/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0805 - binary_accuracy: 0.9663 - val_loss: 0.3984 - val_binary_accuracy: 0.8938\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0812 - binary_accuracy: 0.9659 - val_loss: 0.4024 - val_binary_accuracy: 0.8946\n",
      "Epoch 829/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0795 - binary_accuracy: 0.9667 - val_loss: 0.4039 - val_binary_accuracy: 0.8944\n",
      "Epoch 830/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0803 - binary_accuracy: 0.9664 - val_loss: 0.4029 - val_binary_accuracy: 0.8944\n",
      "Epoch 831/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0808 - binary_accuracy: 0.9662 - val_loss: 0.3941 - val_binary_accuracy: 0.8942\n",
      "Epoch 832/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0806 - binary_accuracy: 0.9662 - val_loss: 0.3944 - val_binary_accuracy: 0.8946\n",
      "Epoch 833/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0800 - binary_accuracy: 0.9666 - val_loss: 0.4060 - val_binary_accuracy: 0.8944\n",
      "Epoch 834/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0805 - binary_accuracy: 0.9661 - val_loss: 0.4004 - val_binary_accuracy: 0.8936\n",
      "Epoch 835/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0799 - binary_accuracy: 0.9665 - val_loss: 0.4022 - val_binary_accuracy: 0.8949\n",
      "Epoch 836/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0800 - binary_accuracy: 0.9664 - val_loss: 0.4045 - val_binary_accuracy: 0.8937\n",
      "Epoch 837/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0799 - binary_accuracy: 0.9664 - val_loss: 0.4051 - val_binary_accuracy: 0.8942\n",
      "Epoch 838/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0799 - binary_accuracy: 0.9666 - val_loss: 0.4023 - val_binary_accuracy: 0.8947\n",
      "Epoch 839/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0797 - binary_accuracy: 0.9666 - val_loss: 0.4044 - val_binary_accuracy: 0.8944\n",
      "Epoch 840/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0808 - binary_accuracy: 0.9662 - val_loss: 0.4003 - val_binary_accuracy: 0.8939\n",
      "Epoch 841/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0798 - binary_accuracy: 0.9666 - val_loss: 0.3998 - val_binary_accuracy: 0.8946\n",
      "Epoch 842/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0798 - binary_accuracy: 0.9665 - val_loss: 0.4051 - val_binary_accuracy: 0.8941\n",
      "Epoch 843/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0793 - binary_accuracy: 0.9668 - val_loss: 0.4018 - val_binary_accuracy: 0.8938\n",
      "Epoch 844/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0791 - binary_accuracy: 0.9669 - val_loss: 0.4067 - val_binary_accuracy: 0.8936\n",
      "Epoch 845/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0789 - binary_accuracy: 0.9669 - val_loss: 0.4067 - val_binary_accuracy: 0.8939\n",
      "Epoch 846/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0798 - binary_accuracy: 0.9666 - val_loss: 0.4059 - val_binary_accuracy: 0.8945\n",
      "Epoch 847/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0806 - binary_accuracy: 0.9661 - val_loss: 0.4002 - val_binary_accuracy: 0.8942\n",
      "Epoch 848/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0792 - binary_accuracy: 0.9668 - val_loss: 0.4035 - val_binary_accuracy: 0.8944\n",
      "Epoch 849/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0797 - binary_accuracy: 0.9666 - val_loss: 0.4084 - val_binary_accuracy: 0.8939\n",
      "Epoch 850/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0800 - binary_accuracy: 0.9665 - val_loss: 0.4069 - val_binary_accuracy: 0.8934\n",
      "Epoch 851/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0793 - binary_accuracy: 0.9669 - val_loss: 0.4015 - val_binary_accuracy: 0.8940\n",
      "Epoch 852/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0787 - binary_accuracy: 0.9672 - val_loss: 0.4083 - val_binary_accuracy: 0.8946\n",
      "Epoch 853/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0788 - binary_accuracy: 0.9670 - val_loss: 0.4057 - val_binary_accuracy: 0.8940\n",
      "Epoch 854/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0787 - binary_accuracy: 0.9671 - val_loss: 0.4076 - val_binary_accuracy: 0.8937\n",
      "Epoch 855/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0788 - binary_accuracy: 0.9670 - val_loss: 0.4085 - val_binary_accuracy: 0.8945\n",
      "Epoch 856/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0786 - binary_accuracy: 0.9670 - val_loss: 0.4107 - val_binary_accuracy: 0.8947\n",
      "Epoch 857/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0783 - binary_accuracy: 0.9672 - val_loss: 0.4090 - val_binary_accuracy: 0.8942\n",
      "Epoch 858/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0788 - binary_accuracy: 0.9669 - val_loss: 0.4090 - val_binary_accuracy: 0.8937\n",
      "Epoch 859/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0787 - binary_accuracy: 0.9671 - val_loss: 0.4064 - val_binary_accuracy: 0.8942\n",
      "Epoch 860/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0792 - binary_accuracy: 0.9668 - val_loss: 0.4058 - val_binary_accuracy: 0.8940\n",
      "Epoch 861/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0788 - binary_accuracy: 0.9669 - val_loss: 0.4107 - val_binary_accuracy: 0.8939\n",
      "Epoch 862/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0785 - binary_accuracy: 0.9672 - val_loss: 0.4122 - val_binary_accuracy: 0.8938\n",
      "Epoch 863/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0788 - binary_accuracy: 0.9669 - val_loss: 0.4122 - val_binary_accuracy: 0.8938\n",
      "Epoch 864/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0792 - binary_accuracy: 0.9668 - val_loss: 0.4116 - val_binary_accuracy: 0.8935\n",
      "Epoch 865/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0786 - binary_accuracy: 0.9672 - val_loss: 0.4097 - val_binary_accuracy: 0.8940\n",
      "Epoch 866/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0779 - binary_accuracy: 0.9675 - val_loss: 0.4109 - val_binary_accuracy: 0.8937\n",
      "Epoch 867/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0789 - binary_accuracy: 0.9670 - val_loss: 0.4114 - val_binary_accuracy: 0.8933\n",
      "Epoch 868/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0791 - binary_accuracy: 0.9668 - val_loss: 0.4078 - val_binary_accuracy: 0.8941\n",
      "Epoch 869/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0783 - binary_accuracy: 0.9674 - val_loss: 0.4081 - val_binary_accuracy: 0.8939\n",
      "Epoch 870/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0784 - binary_accuracy: 0.9671 - val_loss: 0.4101 - val_binary_accuracy: 0.8937\n",
      "Epoch 871/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0777 - binary_accuracy: 0.9676 - val_loss: 0.4128 - val_binary_accuracy: 0.8943\n",
      "Epoch 872/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0781 - binary_accuracy: 0.9672 - val_loss: 0.4126 - val_binary_accuracy: 0.8936\n",
      "Epoch 873/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0779 - binary_accuracy: 0.9674 - val_loss: 0.4097 - val_binary_accuracy: 0.8940\n",
      "Epoch 874/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0780 - binary_accuracy: 0.9673 - val_loss: 0.4107 - val_binary_accuracy: 0.8942\n",
      "Epoch 875/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0786 - binary_accuracy: 0.9672 - val_loss: 0.4111 - val_binary_accuracy: 0.8941\n",
      "Epoch 876/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0781 - binary_accuracy: 0.9673 - val_loss: 0.4148 - val_binary_accuracy: 0.8932\n",
      "Epoch 877/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0779 - binary_accuracy: 0.9674 - val_loss: 0.4140 - val_binary_accuracy: 0.8940\n",
      "Epoch 878/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0774 - binary_accuracy: 0.9675 - val_loss: 0.4161 - val_binary_accuracy: 0.8939\n",
      "Epoch 879/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0776 - binary_accuracy: 0.9676 - val_loss: 0.4168 - val_binary_accuracy: 0.89380s - loss: 0.0777 - binary_accura\n",
      "Epoch 880/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0781 - binary_accuracy: 0.9673 - val_loss: 0.4127 - val_binary_accuracy: 0.8942\n",
      "Epoch 881/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0784 - binary_accuracy: 0.9672 - val_loss: 0.4082 - val_binary_accuracy: 0.8940\n",
      "Epoch 882/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0783 - binary_accuracy: 0.9672 - val_loss: 0.4073 - val_binary_accuracy: 0.8940\n",
      "Epoch 883/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0776 - binary_accuracy: 0.9675 - val_loss: 0.4097 - val_binary_accuracy: 0.8941\n",
      "Epoch 884/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0771 - binary_accuracy: 0.9678 - val_loss: 0.4107 - val_binary_accuracy: 0.8935\n",
      "Epoch 885/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0777 - binary_accuracy: 0.9677 - val_loss: 0.4141 - val_binary_accuracy: 0.8944\n",
      "Epoch 886/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0777 - binary_accuracy: 0.9675 - val_loss: 0.4119 - val_binary_accuracy: 0.8936\n",
      "Epoch 887/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0776 - binary_accuracy: 0.9677 - val_loss: 0.4153 - val_binary_accuracy: 0.8941\n",
      "Epoch 888/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0767 - binary_accuracy: 0.9679 - val_loss: 0.4147 - val_binary_accuracy: 0.8939\n",
      "Epoch 889/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0766 - binary_accuracy: 0.9680 - val_loss: 0.4099 - val_binary_accuracy: 0.8939\n",
      "Epoch 890/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0777 - binary_accuracy: 0.9674 - val_loss: 0.4181 - val_binary_accuracy: 0.8937\n",
      "Epoch 891/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0769 - binary_accuracy: 0.9679 - val_loss: 0.4138 - val_binary_accuracy: 0.8936\n",
      "Epoch 892/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0766 - binary_accuracy: 0.9679 - val_loss: 0.4181 - val_binary_accuracy: 0.8939\n",
      "Epoch 893/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0770 - binary_accuracy: 0.9677 - val_loss: 0.4196 - val_binary_accuracy: 0.8933\n",
      "Epoch 894/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0768 - binary_accuracy: 0.9679 - val_loss: 0.4164 - val_binary_accuracy: 0.8934\n",
      "Epoch 895/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0769 - binary_accuracy: 0.9679 - val_loss: 0.4173 - val_binary_accuracy: 0.8942\n",
      "Epoch 896/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0772 - binary_accuracy: 0.9677 - val_loss: 0.4160 - val_binary_accuracy: 0.8940\n",
      "Epoch 897/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0767 - binary_accuracy: 0.9680 - val_loss: 0.4218 - val_binary_accuracy: 0.8938 - binary_a\n",
      "Epoch 898/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0765 - binary_accuracy: 0.9680 - val_loss: 0.4154 - val_binary_accuracy: 0.8937\n",
      "Epoch 899/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0768 - binary_accuracy: 0.9678 - val_loss: 0.4161 - val_binary_accuracy: 0.8939s - loss: 0.0768 - binary_accuracy: 0.967\n",
      "Epoch 900/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0767 - binary_accuracy: 0.9682 - val_loss: 0.4177 - val_binary_accuracy: 0.8937\n",
      "Epoch 901/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0776 - binary_accuracy: 0.9676 - val_loss: 0.4121 - val_binary_accuracy: 0.8936\n",
      "Epoch 902/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0765 - binary_accuracy: 0.9680 - val_loss: 0.4138 - val_binary_accuracy: 0.8944\n",
      "Epoch 903/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0764 - binary_accuracy: 0.9681 - val_loss: 0.4203 - val_binary_accuracy: 0.8934\n",
      "Epoch 904/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0770 - binary_accuracy: 0.9679 - val_loss: 0.4164 - val_binary_accuracy: 0.8937\n",
      "Epoch 905/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0768 - binary_accuracy: 0.9679 - val_loss: 0.4238 - val_binary_accuracy: 0.8939\n",
      "Epoch 906/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0760 - binary_accuracy: 0.9683 - val_loss: 0.4205 - val_binary_accuracy: 0.8941\n",
      "Epoch 907/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0769 - binary_accuracy: 0.9680 - val_loss: 0.4157 - val_binary_accuracy: 0.8937\n",
      "Epoch 908/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0774 - binary_accuracy: 0.9677 - val_loss: 0.4193 - val_binary_accuracy: 0.8939 loss: 0.0772 - \n",
      "Epoch 909/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0769 - binary_accuracy: 0.9678 - val_loss: 0.4162 - val_binary_accuracy: 0.8936\n",
      "Epoch 910/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0766 - binary_accuracy: 0.9679 - val_loss: 0.4184 - val_binary_accuracy: 0.8940\n",
      "Epoch 911/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0771 - binary_accuracy: 0.9678 - val_loss: 0.4194 - val_binary_accuracy: 0.8938\n",
      "Epoch 912/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0761 - binary_accuracy: 0.9683 - val_loss: 0.4210 - val_binary_accuracy: 0.8936\n",
      "Epoch 913/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0758 - binary_accuracy: 0.9682 - val_loss: 0.4198 - val_binary_accuracy: 0.8934\n",
      "Epoch 914/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0756 - binary_accuracy: 0.9683 - val_loss: 0.4180 - val_binary_accuracy: 0.8940\n",
      "Epoch 915/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0772 - binary_accuracy: 0.9677 - val_loss: 0.4157 - val_binary_accuracy: 0.8941\n",
      "Epoch 916/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0761 - binary_accuracy: 0.9683 - val_loss: 0.4184 - val_binary_accuracy: 0.8934\n",
      "Epoch 917/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0764 - binary_accuracy: 0.9681 - val_loss: 0.4225 - val_binary_accuracy: 0.8939\n",
      "Epoch 918/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0759 - binary_accuracy: 0.9682 - val_loss: 0.4213 - val_binary_accuracy: 0.8937\n",
      "Epoch 919/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0762 - binary_accuracy: 0.9682 - val_loss: 0.4208 - val_binary_accuracy: 0.8933\n",
      "Epoch 920/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0770 - binary_accuracy: 0.9678 - val_loss: 0.4236 - val_binary_accuracy: 0.8941\n",
      "Epoch 921/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0755 - binary_accuracy: 0.9685 - val_loss: 0.4225 - val_binary_accuracy: 0.8939\n",
      "Epoch 922/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0762 - binary_accuracy: 0.9681 - val_loss: 0.4215 - val_binary_accuracy: 0.8930\n",
      "Epoch 923/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0754 - binary_accuracy: 0.9686 - val_loss: 0.4226 - val_binary_accuracy: 0.8936\n",
      "Epoch 924/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0753 - binary_accuracy: 0.9686 - val_loss: 0.4252 - val_binary_accuracy: 0.8931\n",
      "Epoch 925/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0759 - binary_accuracy: 0.9682 - val_loss: 0.4264 - val_binary_accuracy: 0.8934\n",
      "Epoch 926/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0749 - binary_accuracy: 0.9687 - val_loss: 0.4271 - val_binary_accuracy: 0.8938\n",
      "Epoch 927/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0755 - binary_accuracy: 0.9685 - val_loss: 0.4292 - val_binary_accuracy: 0.8936\n",
      "Epoch 928/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0757 - binary_accuracy: 0.9683 - val_loss: 0.4234 - val_binary_accuracy: 0.8934\n",
      "Epoch 929/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0752 - binary_accuracy: 0.9686 - val_loss: 0.4307 - val_binary_accuracy: 0.8931\n",
      "Epoch 930/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0743 - binary_accuracy: 0.9691 - val_loss: 0.4325 - val_binary_accuracy: 0.8935\n",
      "Epoch 931/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0746 - binary_accuracy: 0.9690 - val_loss: 0.4314 - val_binary_accuracy: 0.8934\n",
      "Epoch 932/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0747 - binary_accuracy: 0.9690 - val_loss: 0.4275 - val_binary_accuracy: 0.8938\n",
      "Epoch 933/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0751 - binary_accuracy: 0.9687 - val_loss: 0.4278 - val_binary_accuracy: 0.8938\n",
      "Epoch 934/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0762 - binary_accuracy: 0.9683 - val_loss: 0.4195 - val_binary_accuracy: 0.8938\n",
      "Epoch 935/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0763 - binary_accuracy: 0.9681 - val_loss: 0.4254 - val_binary_accuracy: 0.8937\n",
      "Epoch 936/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0749 - binary_accuracy: 0.9687 - val_loss: 0.4262 - val_binary_accuracy: 0.8931\n",
      "Epoch 937/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0743 - binary_accuracy: 0.9689 - val_loss: 0.4287 - val_binary_accuracy: 0.8937\n",
      "Epoch 938/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0749 - binary_accuracy: 0.9688 - val_loss: 0.4298 - val_binary_accuracy: 0.8932\n",
      "Epoch 939/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0743 - binary_accuracy: 0.9691 - val_loss: 0.4278 - val_binary_accuracy: 0.8939\n",
      "Epoch 940/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0744 - binary_accuracy: 0.9691 - val_loss: 0.4308 - val_binary_accuracy: 0.8928\n",
      "Epoch 941/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0747 - binary_accuracy: 0.9688 - val_loss: 0.4272 - val_binary_accuracy: 0.8936\n",
      "Epoch 942/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0743 - binary_accuracy: 0.9690 - val_loss: 0.4309 - val_binary_accuracy: 0.8935\n",
      "Epoch 943/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0748 - binary_accuracy: 0.9689 - val_loss: 0.4305 - val_binary_accuracy: 0.8942\n",
      "Epoch 944/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0743 - binary_accuracy: 0.9689 - val_loss: 0.4289 - val_binary_accuracy: 0.8933\n",
      "Epoch 945/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0753 - binary_accuracy: 0.9685 - val_loss: 0.4273 - val_binary_accuracy: 0.8936\n",
      "Epoch 946/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0758 - binary_accuracy: 0.9684 - val_loss: 0.4248 - val_binary_accuracy: 0.8935\n",
      "Epoch 947/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0738 - binary_accuracy: 0.9692 - val_loss: 0.4328 - val_binary_accuracy: 0.8930\n",
      "Epoch 948/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0738 - binary_accuracy: 0.9692 - val_loss: 0.4336 - val_binary_accuracy: 0.8935\n",
      "Epoch 949/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0743 - binary_accuracy: 0.9691 - val_loss: 0.4285 - val_binary_accuracy: 0.8934\n",
      "Epoch 950/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0744 - binary_accuracy: 0.9690 - val_loss: 0.4291 - val_binary_accuracy: 0.8932\n",
      "Epoch 951/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0739 - binary_accuracy: 0.9692 - val_loss: 0.4318 - val_binary_accuracy: 0.8930\n",
      "Epoch 952/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0748 - binary_accuracy: 0.9688 - val_loss: 0.4260 - val_binary_accuracy: 0.8930\n",
      "Epoch 953/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0751 - binary_accuracy: 0.9687 - val_loss: 0.4258 - val_binary_accuracy: 0.8932\n",
      "Epoch 954/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0744 - binary_accuracy: 0.9690 - val_loss: 0.4309 - val_binary_accuracy: 0.8931\n",
      "Epoch 955/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0742 - binary_accuracy: 0.9691 - val_loss: 0.4340 - val_binary_accuracy: 0.8933\n",
      "Epoch 956/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0740 - binary_accuracy: 0.9692 - val_loss: 0.4357 - val_binary_accuracy: 0.8938\n",
      "Epoch 957/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0739 - binary_accuracy: 0.9692 - val_loss: 0.4300 - val_binary_accuracy: 0.8938\n",
      "Epoch 958/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0739 - binary_accuracy: 0.9692 - val_loss: 0.4277 - val_binary_accuracy: 0.8931\n",
      "Epoch 959/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0742 - binary_accuracy: 0.9690 - val_loss: 0.4323 - val_binary_accuracy: 0.8938\n",
      "Epoch 960/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0746 - binary_accuracy: 0.9691 - val_loss: 0.4341 - val_binary_accuracy: 0.8933\n",
      "Epoch 961/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0748 - binary_accuracy: 0.9688 - val_loss: 0.4216 - val_binary_accuracy: 0.8936\n",
      "Epoch 962/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0753 - binary_accuracy: 0.9685 - val_loss: 0.4286 - val_binary_accuracy: 0.8934cy: 0.\n",
      "Epoch 963/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0745 - binary_accuracy: 0.9689 - val_loss: 0.4258 - val_binary_accuracy: 0.8936\n",
      "Epoch 964/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0746 - binary_accuracy: 0.9688 - val_loss: 0.4248 - val_binary_accuracy: 0.8934\n",
      "Epoch 965/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0741 - binary_accuracy: 0.9691 - val_loss: 0.4267 - val_binary_accuracy: 0.8936\n",
      "Epoch 966/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0735 - binary_accuracy: 0.9695 - val_loss: 0.4304 - val_binary_accuracy: 0.8938\n",
      "Epoch 967/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0734 - binary_accuracy: 0.9693 - val_loss: 0.4313 - val_binary_accuracy: 0.8933\n",
      "Epoch 968/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0734 - binary_accuracy: 0.9695 - val_loss: 0.4365 - val_binary_accuracy: 0.8935\n",
      "Epoch 969/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0731 - binary_accuracy: 0.9695 - val_loss: 0.4372 - val_binary_accuracy: 0.8932\n",
      "Epoch 970/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0738 - binary_accuracy: 0.9693 - val_loss: 0.4363 - val_binary_accuracy: 0.8935\n",
      "Epoch 971/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0743 - binary_accuracy: 0.9691 - val_loss: 0.4287 - val_binary_accuracy: 0.8935\n",
      "Epoch 972/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0736 - binary_accuracy: 0.9693 - val_loss: 0.4419 - val_binary_accuracy: 0.8935\n",
      "Epoch 973/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0730 - binary_accuracy: 0.9697 - val_loss: 0.4368 - val_binary_accuracy: 0.8929\n",
      "Epoch 974/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0731 - binary_accuracy: 0.9695 - val_loss: 0.4370 - val_binary_accuracy: 0.8933\n",
      "Epoch 975/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0727 - binary_accuracy: 0.9698 - val_loss: 0.4390 - val_binary_accuracy: 0.8937\n",
      "Epoch 976/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0731 - binary_accuracy: 0.9695 - val_loss: 0.4366 - val_binary_accuracy: 0.8931\n",
      "Epoch 977/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0733 - binary_accuracy: 0.9695 - val_loss: 0.4367 - val_binary_accuracy: 0.8931\n",
      "Epoch 978/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0739 - binary_accuracy: 0.9691 - val_loss: 0.4345 - val_binary_accuracy: 0.8930\n",
      "Epoch 979/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0734 - binary_accuracy: 0.9694 - val_loss: 0.4298 - val_binary_accuracy: 0.8934\n",
      "Epoch 980/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0734 - binary_accuracy: 0.9693 - val_loss: 0.4364 - val_binary_accuracy: 0.8935\n",
      "Epoch 981/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0736 - binary_accuracy: 0.9692 - val_loss: 0.4407 - val_binary_accuracy: 0.8931\n",
      "Epoch 982/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0730 - binary_accuracy: 0.9695 - val_loss: 0.4358 - val_binary_accuracy: 0.8931\n",
      "Epoch 983/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0730 - binary_accuracy: 0.9697 - val_loss: 0.4348 - val_binary_accuracy: 0.8934\n",
      "Epoch 984/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0728 - binary_accuracy: 0.9696 - val_loss: 0.4357 - val_binary_accuracy: 0.8935\n",
      "Epoch 985/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0722 - binary_accuracy: 0.9699 - val_loss: 0.4365 - val_binary_accuracy: 0.8933\n",
      "Epoch 986/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0732 - binary_accuracy: 0.9695 - val_loss: 0.4312 - val_binary_accuracy: 0.8931\n",
      "Epoch 987/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0733 - binary_accuracy: 0.9695 - val_loss: 0.4352 - val_binary_accuracy: 0.8930\n",
      "Epoch 988/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0733 - binary_accuracy: 0.9694 - val_loss: 0.4362 - val_binary_accuracy: 0.8929\n",
      "Epoch 989/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0724 - binary_accuracy: 0.9699 - val_loss: 0.4433 - val_binary_accuracy: 0.893221 - binary_ac\n",
      "Epoch 990/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0725 - binary_accuracy: 0.9698 - val_loss: 0.4398 - val_binary_accuracy: 0.8936\n",
      "Epoch 991/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0730 - binary_accuracy: 0.9696 - val_loss: 0.4403 - val_binary_accuracy: 0.8937\n",
      "Epoch 992/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0725 - binary_accuracy: 0.9699 - val_loss: 0.4394 - val_binary_accuracy: 0.8930\n",
      "Epoch 993/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0726 - binary_accuracy: 0.9697 - val_loss: 0.4436 - val_binary_accuracy: 0.8933\n",
      "Epoch 994/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0724 - binary_accuracy: 0.9700 - val_loss: 0.4403 - val_binary_accuracy: 0.8934\n",
      "Epoch 995/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0720 - binary_accuracy: 0.9702 - val_loss: 0.4435 - val_binary_accuracy: 0.8933\n",
      "Epoch 996/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0731 - binary_accuracy: 0.9695 - val_loss: 0.4386 - val_binary_accuracy: 0.8932\n",
      "Epoch 997/1000\n",
      "85991/85991 [==============================] - 3s 36us/sample - loss: 0.0727 - binary_accuracy: 0.9696 - val_loss: 0.4355 - val_binary_accuracy: 0.8932\n",
      "Epoch 998/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0721 - binary_accuracy: 0.9701 - val_loss: 0.4426 - val_binary_accuracy: 0.8934\n",
      "Epoch 999/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0720 - binary_accuracy: 0.9699 - val_loss: 0.4379 - val_binary_accuracy: 0.8932\n",
      "Epoch 1000/1000\n",
      "85991/85991 [==============================] - 3s 37us/sample - loss: 0.0720 - binary_accuracy: 0.9701 - val_loss: 0.4419 - val_binary_accuracy: 0.8931\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=1000, batch_size=2048, workers=4, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'loss, waaaay overfit')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])  ### waaaaay overfitting\n",
    "plt.title('loss, waaaay overfit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['binary_accuracy'])\n",
    "plt.plot(hist.history['val_binary_accuracy'])  ### waaaaay overfitting\n",
    "p=plt.title('binary accuracy, waaaay overfit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling out training data to allow for other thresholds to be applied\n",
    "#fulltraining = pd.concat((pd.DataFrame(y_train), data_df.loc[X_train[:, 0],['Sequence','Charge', 'SeqCharge']].reset_index(drop=True), pd.DataFrame(X_train)), axis=1)\n",
    "#fulltraining.to_csv(\"50percentplusTraining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling out test data to test those other thresholds\n",
    "#fulltesting = pd.concat((pd.DataFrame(y_test), data_df.loc[X_test[:, 0],['Sequence','Charge', 'SeqCharge']].reset_index(drop=True), pd.DataFrame(X_test)), axis=1)\n",
    "#fulltesting.to_csv(\"50percentplusTesting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 2.00000e+00, 7.00000e+00, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [1.00000e+00, 2.00000e+00, 1.40000e+01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [4.00000e+00, 3.00000e+00, 2.40000e+01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [1.22844e+05, 2.00000e+00, 9.00000e+00, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [1.22845e+05, 2.00000e+00, 1.10000e+01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [1.22846e+05, 2.00000e+00, 1.10000e+01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
