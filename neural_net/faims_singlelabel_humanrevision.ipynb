{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Processing Step for Multilabel FAIMS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all my packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax         #finds the index of the maximum value in a vector\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import skmultilearn\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from skmultilearn.model_selection import  iterative_train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff for exploring the classes\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from collections import Counter\n",
    "from skmultilearn.model_selection import iterative_train_test_split, iterative_stratification\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "from skmultilearn.cluster.networkx import NetworkXLabelGraphClusterer\n",
    "from skmultilearn.cluster.igraph import IGraphLabelGraphClusterer\n",
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# device = \"CPU\"  # if no GPU\n",
    "device = \"GPU:0\"\n",
    "\n",
    "\n",
    "### Use this for ecoli data\n",
    "# data_path = \"data/cvmax_singlelabel.csv\"  # data with only one label\n",
    "# df = pd.read_csv(data_path, low_memory=False) #read in data generated from R preprocessing\n",
    "# y = df.loc[ : ,  'X20':'X95'].values\n",
    "\n",
    "### Human data\n",
    "data_path = \"data/NEW_JMMdata_maxCVvalues.txt\"\n",
    "df = pd.read_csv(data_path, low_memory=False, sep=\"\\t\") #read in data generated from R preprocessing\n",
    "cols = df.columns\n",
    "new_cols = []\n",
    "for c in cols:\n",
    "    if c.isnumeric():\n",
    "        new_cols.append(\"X\" + str(c))\n",
    "    elif c == \"z_modseq\":\n",
    "        new_cols.append(\"SeqCharge\")\n",
    "    else:\n",
    "        new_cols.append(c)\n",
    "df.columns = new_cols\n",
    "\n",
    "xcols = [i for i in df.columns if i.startswith(\"X\")]\n",
    "xcols_idx = [i for i, c in enumerate(df.columns) if c.startswith(\"X\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(df.iloc[0,xcols_idx])\n",
    "df[xcols] = 0\n",
    "for i in range(df.shape[0]):\n",
    "    r = df.iloc[i,:]\n",
    "    cvmax = r[\"maxcv_naomit\"]\n",
    "    cvmax_str = \"X\" + str(cvmax)\n",
    "    df.loc[r.name, cvmax_str] = 1\n",
    "    # if i % 1000 == 0:\n",
    "    #     print(i / df.shape[0])\n",
    "y = df.loc[ : ,  'X20':'X95'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/new_jmm_singlelabel.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in the the final labelling scheme data and adding the other features\n",
    "\n",
    "# df = pd.read_csv(data_path, low_memory=False) #read in data generated from R preprocessing\n",
    "# y = df.loc[ : ,  'X20':'X95'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### combine all the letters into a long string, take the set to find the unique values, add 'END' (for use with one-hot), then get length\n",
    "seq = df['SeqCharge']\n",
    "vocab = set(''.join([str(i) for i in seq]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)\n",
    "print(len_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df['maxcv_naomit']\n",
    "set(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make index of the characters in vocab\n",
    "char_index = dict((c, i) for i, c in enumerate(vocab))\n",
    "maxlen = max([len(x) for x in df.SeqCharge])\n",
    "print(char_index)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max and truncate rest\n",
    "# get index in char_index\n",
    "#padd 'END' to shorter sequences\n",
    "\n",
    "x = []\n",
    "x_name = [str(i)[0:maxlen] for i in seq]\n",
    "for i in x_name:\n",
    "    tmp = [char_index[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_index[\"END\"])\n",
    "    x.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the 50%+ threshold data into train and test keeping label distribution proportional\n",
    "# X_train, y_train, X_test, y_test = iterative_train_test_split(np.asarray(x), y, test_size=0.30)\n",
    "\n",
    "# Do stratified split of data\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "sss.get_n_splits(np.asarray(x), df[\"maxcv_naomit\"])\n",
    "train_idx, test_idx = sss.split(x,df[\"maxcv_naomit\"]).__next__()\n",
    "train_idx = list(train_idx)\n",
    "test_idx = list(test_idx)\n",
    "X_train = np.asarray(x)[train_idx, :]\n",
    "X_test = np.asarray(x)[test_idx, :]\n",
    "y_train = y[train_idx, :]\n",
    "y_test = y[test_idx, :]\n",
    "# X_train, y_train, X_test, y_test = iterative_train_test_split(np.asarray(x), y, test_size=0.30)\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols.index(\"X65\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_test[:, 9])  # see how many values are at 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "        \n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"GPU:0\"):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=51, output_dim=40))\n",
    "    model.add(layers.LSTM(128, return_sequences=True, input_shape=(maxlen,len_vocab)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(128, return_sequences=False))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(len(set(cv)), activation='sigmoid'))\n",
    "    adam = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "        name='Adam')\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=adam,  metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"GPU:0\"):\n",
    "    Xtf_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "    ytf_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "    \n",
    "    Xtf_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "    ytf_test = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "hist = model.fit(Xtf_train, ytf_train, epochs=250, batch_size=2048, validation_data=(Xtf_test, ytf_test), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], label=\"Training\")\n",
    "plt.plot(hist.history['val_loss'], label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.title('Model performance', fontsize=26)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.ylabel(\"Binary Cross-Entropy\", fontsize=20)\n",
    "plt.savefig(\"modelperformance_binarycrossentropy_singlelabel_human.png\")\n",
    "plt.savefig(\"modelperformance_binarycrossentropy_singlelabel_human.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['binary_accuracy'], label=\"Training\")\n",
    "plt.plot(hist.history['val_binary_accuracy'], label=\"Validation\")  ### waaaaay overfitting\n",
    "plt.legend()\n",
    "plt.title('Model performance', fontsize=26)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.ylabel(\"Binary Accuracy\", fontsize=20)\n",
    "plt.savefig(\"modelperformance_binaryaccuracy_singlelabel_human.png\")\n",
    "plt.savefig(\"modelperformance_binaryaccuracy_singlelabel_human.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_label = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_label = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "xcols = [i[1:] for i in df.columns if i.startswith(\"X\")]\n",
    "im0 = ax.imshow(confusion_matrix(ytest_label, preds_label, normalize='pred'), origin=\"upper\")\n",
    "plt.xticks(np.arange(16), xcols)\n",
    "plt.yticks(np.arange(16), xcols)\n",
    "plt.xlabel(\"True label\", fontsize=20)\n",
    "plt.ylabel(\"Predicted label\", fontsize=20)\n",
    "fig.colorbar(im0, ax=ax)\n",
    "# Create a square patch\n",
    "for i in range(16):\n",
    "    rect = matplotlib.patches.Rectangle((-0.5+i, -0.5+i), 1, 1, linewidth=2, edgecolor='k', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "# Add the patch to the plot\n",
    "plt.title(\"Single-label prediction\", fontsize=26)\n",
    "plt.savefig(\"singlelabel_confusion_human.svg\")\n",
    "plt.savefig(\"singlelabel_confusion_human.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "xcols = [i[1:] for i in df.columns if i.startswith(\"X\")]\n",
    "im0 = ax.imshow(confusion_matrix(ytest_label, preds_label, normalize='pred'), origin=\"lower\")\n",
    "plt.xticks(np.arange(16), xcols)\n",
    "plt.yticks(np.arange(16), xcols)\n",
    "plt.xlabel(\"True label\", fontsize=20)\n",
    "plt.ylabel(\"Predicted label\", fontsize=20)\n",
    "fig.colorbar(im0, ax=ax)\n",
    "# Create a square patch\n",
    "for i in range(16):\n",
    "    rect = matplotlib.patches.Rectangle((-0.5+i, -0.5+i), 1, 1, linewidth=2, edgecolor='k', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "# Add the patch to the plot\n",
    "plt.title(\"Single-label prediction\", fontsize=26)\n",
    "plt.savefig(\"singlelabel_confusion_inverted_human.svg\")\n",
    "plt.savefig(\"singlelabel_confusion_inverted_human.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "xcols = [i[1:] for i in df.columns if i.startswith(\"X\")]\n",
    "im0 = ax.imshow(confusion_matrix(ytest_label, preds_label, normalize='true'), origin=\"lower\")\n",
    "plt.xticks(np.arange(16), xcols)\n",
    "plt.yticks(np.arange(16), xcols)\n",
    "plt.xlabel(\"True label\", fontsize=20)\n",
    "plt.ylabel(\"Predicted label\", fontsize=20)\n",
    "fig.colorbar(im0, ax=ax)\n",
    "# Create a square patch\n",
    "for i in range(16):\n",
    "    rect = matplotlib.patches.Rectangle((-0.5+i, -0.5+i), 1, 1, linewidth=2, edgecolor='k', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "# Add the patch to the plot\n",
    "plt.title(\"Single-label prediction\", fontsize=26)\n",
    "# plt.savefig(\"singlelabel_confusion_inverted_human.svg\")\n",
    "# plt.savefig(\"singlelabel_confusion_inverted_human.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python311-faimsrevision",
   "language": "python",
   "name": "python311-faimsrevision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
