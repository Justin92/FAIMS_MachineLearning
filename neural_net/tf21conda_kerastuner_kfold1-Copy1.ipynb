{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Processing Step for Multilabel FAIMS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env export --name tf21 > tensorflow21.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "#Load all my packages\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax         #finds the index of the maximum value in a vector\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow import keras\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from skmultilearn.model_selection import iterative_train_test_split, iterative_stratification\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from R\n",
    "df = pd.read_csv(\"P:/JGM_FAIMS_CVprediction/JMM_PreProcessed_Data/50percentMaxPlusThreshold.csv\", low_memory=False) \n",
    "y = df.loc[ : ,  'X20':'X95'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqCharge</th>\n",
       "      <th>X20</th>\n",
       "      <th>X25</th>\n",
       "      <th>X30</th>\n",
       "      <th>X35</th>\n",
       "      <th>X40</th>\n",
       "      <th>X45</th>\n",
       "      <th>X50</th>\n",
       "      <th>X55</th>\n",
       "      <th>X60</th>\n",
       "      <th>...</th>\n",
       "      <th>X80</th>\n",
       "      <th>X85</th>\n",
       "      <th>X90</th>\n",
       "      <th>X95</th>\n",
       "      <th>maxcv_naomit</th>\n",
       "      <th>Charge</th>\n",
       "      <th>ModSequence</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>LabelSequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2AACLCFR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>AACLCFR</td>\n",
       "      <td>7</td>\n",
       "      <td>AACLCFR</td>\n",
       "      <td>1110000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2SEQEDEVLLVSSSR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>14</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>1100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3SEQEDEVLLVSSSR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>14</td>\n",
       "      <td>SEQEDEVLLVSSSR</td>\n",
       "      <td>111100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>24</td>\n",
       "      <td>YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>110000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>24</td>\n",
       "      <td>YPDQWIVPGGGMEPEEEPGGAAVR</td>\n",
       "      <td>11100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SeqCharge  X20  X25  X30  X35  X40  X45  X50  X55  X60  \\\n",
       "0                   2AACLCFR    0    0    0    0    0    0    1    1    1   \n",
       "1            2SEQEDEVLLVSSSR    0    0    0    1    1    0    0    0    0   \n",
       "2            3SEQEDEVLLVSSSR    0    0    0    0    0    0    0    1    1   \n",
       "3  2YPDQWIVPGGGMEPEEEPGGAAVR    0    1    1    0    0    0    0    0    0   \n",
       "4  3YPDQWIVPGGGMEPEEEPGGAAVR    0    0    0    0    0    0    0    0    1   \n",
       "\n",
       "   ...  X80  X85  X90  X95  maxcv_naomit  Charge               ModSequence  \\\n",
       "0  ...    0    0    0    0            50       2                   AACLCFR   \n",
       "1  ...    0    0    0    0            40       2            SEQEDEVLLVSSSR   \n",
       "2  ...    0    0    0    0            60       3            SEQEDEVLLVSSSR   \n",
       "3  ...    0    0    0    0            30       2  YPDQWIVPGGGMEPEEEPGGAAVR   \n",
       "4  ...    0    0    0    0            70       3  YPDQWIVPGGGMEPEEEPGGAAVR   \n",
       "\n",
       "   Length                  Sequence    LabelSequence  \n",
       "0       7                   AACLCFR       1110000000  \n",
       "1      14            SEQEDEVLLVSSSR    1100000000000  \n",
       "2      14            SEQEDEVLLVSSSR        111100000  \n",
       "3      24  YPDQWIVPGGGMEPEEEPGGAAVR  110000000000000  \n",
       "4      24  YPDQWIVPGGGMEPEEEPGGAAVR         11100000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the input to embedding layer - make array of index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "{'2': 0, '3': 1, 'F': 2, 'a': 3, 'E': 4, 'T': 5, 'M': 6, '5': 7, 'm': 8, 'R': 9, 'END': 10, 'V': 11, 'A': 12, 'K': 13, 'I': 14, 'G': 15, 'W': 16, 'P': 17, 'Q': 18, 'D': 19, '4': 20, 'C': 21, 'N': 22, 'L': 23, 'S': 24, 'Y': 25, 'H': 26}\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "### combine all the letters into a long string, take the set to find the unique values, add 'END' (for use with one-hot), then get length\n",
    "seq = df['SeqCharge']\n",
    "vocab = set(''.join([str(i) for i in seq]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)\n",
    "print(len_vocab)\n",
    "cv = df['maxcv_naomit']\n",
    "set(cv)\n",
    "## make index of the characters in vocab\n",
    "char_index = dict((c, i) for i, c in enumerate(vocab))\n",
    "maxlen = max([len(x) for x in df.SeqCharge])\n",
    "print(char_index)\n",
    "print(maxlen)\n",
    "\n",
    "#take input upto max and truncate rest\n",
    "# get index in char_index\n",
    "#padd 'END' to shorter sequences\n",
    "\n",
    "x = []\n",
    "x_name = [str(i)[0:maxlen] for i in seq]\n",
    "for i in x_name:\n",
    "    tmp = [char_index[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_index[\"END\"])\n",
    "    x.append(tmp)\n",
    "x = np.asarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85989, 51)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the 50%+ threshold data into train and test keeping label distribution proportional\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(x, y, test_size=0.30)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F2 score THIS ONE IS WRONG \n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f2(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 5*p*r / (4*p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta2(y_true, y_pred, threshold_shift=0):\n",
    "    beta = 2\n",
    "\n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = beta ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test the tuning in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "from kerastuner import Objective\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile_fix_trainset\", filemode=\"a+\",\n",
    "                        format=\"%(asctime)-15s %(levelname)-8s %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex model\n",
    "METRICS = [\n",
    "    keras.metrics.BinaryAccuracy(name='acc'),\n",
    "    keras.metrics.Precision(name='prec'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    f2\n",
    "    \n",
    "]\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=51, output_dim=hp.Int('embed',\n",
    "                                        min_value=32,\n",
    "                                        max_value=96,\n",
    "                                        step=32)\n",
    "                              ))\n",
    "    model.add(layers.LSTM(hp.Int('lstm1',\n",
    "                                        min_value=32,\n",
    "                                        max_value=96,\n",
    "                                        step=32), \n",
    "                          return_sequences=False, input_shape=(maxlen,len_vocab)))\n",
    "    model.add(layers.Dropout(hp.Float('dropout1', min_value=0, max_value=0.5, sampling='linear', default=0.5)))\n",
    "    model.add(layers.Dense(hp.Int('dense1',\n",
    "                                        min_value=32,\n",
    "                                        max_value=96,\n",
    "                                        step=32), activation='relu'))\n",
    "    model.add(layers.Dropout(hp.Float('dropout3', min_value=0, max_value=0.5, sampling='linear', default=0.5)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(16, activation='sigmoid'))\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', \n",
    "                    min_value=1e-4, \n",
    "                    max_value=1e-2, \n",
    "                    sampling='LOG',\n",
    "                    default=1e-3)),  \n",
    "                  metrics=METRICS)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%capture\n",
    "### do only fold 0\n",
    "# train loop, save predictions and models\n",
    "start = timeit.default_timer()\n",
    "\n",
    "threshacc = []\n",
    "precision = []\n",
    "recall = []\n",
    "rocauc = []\n",
    "f2_score = []\n",
    "times = []\n",
    "\n",
    "best_trial_dict = {}\n",
    "model_dict = {}\n",
    "results_dict={}\n",
    "\n",
    "\n",
    "fold=0\n",
    "k_fold = IterativeStratification(n_splits=5, order=3)#, random_state=23)\n",
    "for train, test in k_fold.split(X_train, y_train):\n",
    "    if fold==0:\n",
    "        logging.info('fold='+str(fold) )\n",
    "        tuner = Hyperband(\n",
    "            build_model,\n",
    "            objective= Objective(\"val_auc\", direction=\"max\"),\n",
    "            max_epochs=1000,\n",
    "            hyperband_iterations=1,\n",
    "            seed=23,\n",
    "            directory='keras_tuner_kfold_6',\n",
    "            project_name='hyperband'+str(fold)\n",
    "            )\n",
    "        logging.info(tuner.search_space_summary())\n",
    "        tuner.search(x[train], y[train], epochs=1000, batch_size=1024, workers=4, \n",
    "                     validation_data=(x[test], y[test]), \n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max')], \n",
    "                 verbose=0)\n",
    "        best_trial_dict[fold]= tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "        model_dict[fold] = tuner.get_best_models(num_models=1)\n",
    "        model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "        #Train the multiforest using the training indices\n",
    "        result=model.evaluate(x[test], y[test])\n",
    "\n",
    "        results_dict[fold] = dict(zip(model.metrics_names, result))\n",
    "        #record and print metrics\n",
    "        f2_score.append(results_dict[fold]['f2'])\n",
    "        threshacc. append(results_dict[fold]['acc'])\n",
    "        precision.append(results_dict[fold]['prec'])\n",
    "        rocauc.append(results_dict[fold]['auc'])\n",
    "        recall.append(results_dict[fold]['recall'])\n",
    "        logging.info('val_f2 =' + str(results_dict[fold]['f2']))\n",
    "        logging.info('val_acc =' + str(results_dict[fold]['acc']))\n",
    "        logging.info('val_prec =' + str(results_dict[fold]['prec']))\n",
    "        logging.info('val_auc =' + str(results_dict[fold]['auc']))\n",
    "        logging.info('val_recall =' + str(results_dict[fold]['recall']))\n",
    "        fold+=1\n",
    "        times.append(timeit.default_timer()-start)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "# get the runtime\n",
    "run_time = stop - start\n",
    "print('total run time = ' + str(run_time) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%capture\n",
    "### do only fold 0\n",
    "# train loop, save predictions and models\n",
    "\n",
    "\n",
    "fold=0\n",
    "k_fold = IterativeStratification(n_splits=5, order=3)#, random_state=23)\n",
    "for train, test in k_fold.split(X_train, y_train):\n",
    "    if fold==1:\n",
    "        logging.info('fold='+str(fold) )\n",
    "        tuner = Hyperband(\n",
    "            build_model,\n",
    "            objective= Objective(\"val_auc\", direction=\"max\"),\n",
    "            max_epochs=1000,\n",
    "            hyperband_iterations=1,\n",
    "            seed=23,\n",
    "            directory='keras_tuner_kfold_6',\n",
    "            project_name='hyperband'+str(fold)\n",
    "            )\n",
    "        logging.info(tuner.search_space_summary())\n",
    "        tuner.search(x[train], y[train], epochs=1000, batch_size=1024, workers=4, \n",
    "                     validation_data=(x[test], y[test]), \n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max')], \n",
    "                 verbose=0)\n",
    "        \n",
    "        best_trial_dict[fold]= tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "        logging.info(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values)\n",
    "        model = tuner.get_best_models(num_models=1)[0]\n",
    "        model_dict[fold] = model\n",
    "        #Train the multiforest using the training indices\n",
    "        result=model.evaluate(x[test], y[test])\n",
    "\n",
    "        results_dict[fold] = dict(zip(model.metrics_names, result))\n",
    "        #record and print metrics\n",
    "        f2_score.append(results_dict[fold]['f2'])\n",
    "        threshacc. append(results_dict[fold]['acc'])\n",
    "        precision.append(results_dict[fold]['prec'])\n",
    "        rocauc.append(results_dict[fold]['auc'])\n",
    "        recall.append(results_dict[fold]['recall'])\n",
    "        logging.info('val_f2 =' + str(results_dict[fold]['f2']))\n",
    "        logging.info('val_acc =' + str(results_dict[fold]['acc']))\n",
    "        logging.info('val_prec =' + str(results_dict[fold]['prec']))\n",
    "        logging.info('val_auc =' + str(results_dict[fold]['auc']))\n",
    "        logging.info('val_recall =' + str(results_dict[fold]['recall']))\n",
    "    fold+=1\n",
    "    times.append(timeit.default_timer()-start)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "# get the runtime\n",
    "run_time = stop - start\n",
    "print('total run time = ' + str(run_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embed': 64,\n",
       " 'lstm1': 64,\n",
       " 'dropout1': 0.15042412861806165,\n",
       " 'dense1': 64,\n",
       " 'dropout3': 0.031469519816518465,\n",
       " 'learning_rate': 0.0024353059331955144,\n",
       " 'tuner/epochs': 1000,\n",
       " 'tuner/initial_epoch': 334,\n",
       " 'tuner/bracket': 4,\n",
       " 'tuner/round': 4,\n",
       " 'tuner/trial_id': '23290a35acdfa07027cf99d0d203396a'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'embed': 96,\n",
       "  'lstm1': 96,\n",
       "  'dropout1': 0.3906271577374155,\n",
       "  'dense1': 64,\n",
       "  'dropout3': 0.004887354825383772,\n",
       "  'learning_rate': 0.0017580406699854202,\n",
       "  'tuner/epochs': 334,\n",
       "  'tuner/initial_epoch': 112,\n",
       "  'tuner/bracket': 5,\n",
       "  'tuner/round': 4,\n",
       "  'tuner/trial_id': '34bb37723a74e88733c47827173bff56'},\n",
       " 1: {'embed': 64,\n",
       "  'lstm1': 64,\n",
       "  'dropout1': 0.15042412861806165,\n",
       "  'dense1': 64,\n",
       "  'dropout3': 0.031469519816518465,\n",
       "  'learning_rate': 0.0024353059331955144,\n",
       "  'tuner/epochs': 1000,\n",
       "  'tuner/initial_epoch': 334,\n",
       "  'tuner/bracket': 4,\n",
       "  'tuner/round': 4,\n",
       "  'tuner/trial_id': '23290a35acdfa07027cf99d0d203396a'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = model_dict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jesse\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: model0\\assets\n"
     ]
    }
   ],
   "source": [
    "model0.save('model0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() got an unexpected keyword argument 'custom_objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-df88a08c24a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mload_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"f2\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: load() got an unexpected keyword argument 'custom_objects'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.saved_model import loader_impl\n",
    "from tensorflow.python.keras.saving.saved_model import load as saved_model_load\n",
    "load_path = 'model0'\n",
    "loader_impl.parse_saved_model(load_path)\n",
    "model = saved_model_load.load(load_path, custom_objects={\"f2\": f2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%capture\n",
    "### do only fold 0\n",
    "# train loop, save predictions and models\n",
    "\n",
    "\n",
    "fold=0\n",
    "k_fold = IterativeStratification(n_splits=5, order=3)#, random_state=23)\n",
    "for train, test in k_fold.split(X_train, y_train):\n",
    "    if fold==2:\n",
    "        logging.info('fold='+str(fold) )\n",
    "        tuner = Hyperband(\n",
    "            build_model,\n",
    "            objective= Objective(\"val_auc\", direction=\"max\"),\n",
    "            max_epochs=1000,\n",
    "            hyperband_iterations=1,\n",
    "            seed=23,\n",
    "            directory='keras_tuner_kfold_6',\n",
    "            project_name='hyperband'+str(fold)\n",
    "            )\n",
    "        logging.info(tuner.search_space_summary())\n",
    "        tuner.search(x[train], y[train], epochs=1000, batch_size=1024, workers=4, \n",
    "                     validation_data=(x[test], y[test]), \n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max')], \n",
    "                 verbose=0)\n",
    "        \n",
    "        best_trial_dict[fold]= tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "        logging.info(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values)\n",
    "        model = tuner.get_best_models(num_models=1)[0]\n",
    "        model_dict[fold] = model\n",
    "        #Train the multiforest using the training indices\n",
    "        result=model.evaluate(x[test], y[test])\n",
    "\n",
    "        results_dict[fold] = dict(zip(model.metrics_names, result))\n",
    "        #record and print metrics\n",
    "        f2_score.append(results_dict[fold]['f2'])\n",
    "        threshacc. append(results_dict[fold]['acc'])\n",
    "        precision.append(results_dict[fold]['prec'])\n",
    "        rocauc.append(results_dict[fold]['auc'])\n",
    "        recall.append(results_dict[fold]['recall'])\n",
    "        logging.info('val_f2 =' + str(results_dict[fold]['f2']))\n",
    "        logging.info('val_acc =' + str(results_dict[fold]['acc']))\n",
    "        logging.info('val_prec =' + str(results_dict[fold]['prec']))\n",
    "        logging.info('val_auc =' + str(results_dict[fold]['auc']))\n",
    "        logging.info('val_recall =' + str(results_dict[fold]['recall']))\n",
    "    fold+=1\n",
    "    times.append(timeit.default_timer()-start)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "# get the runtime\n",
    "run_time = stop - start\n",
    "print('total run time = ' + str(run_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "### do only fold 0\n",
    "# train loop, save predictions and models\n",
    "\n",
    "\n",
    "fold=0\n",
    "k_fold = IterativeStratification(n_splits=5, order=3)#, random_state=23)\n",
    "for train, test in k_fold.split(X_train, y_train):\n",
    "    if fold==3:\n",
    "        logging.info('fold='+str(fold) )\n",
    "        tuner = Hyperband(\n",
    "            build_model,\n",
    "            objective= Objective(\"val_auc\", direction=\"max\"),\n",
    "            max_epochs=1000,\n",
    "            hyperband_iterations=1,\n",
    "            seed=23,\n",
    "            directory='keras_tuner_kfold_6',\n",
    "            project_name='hyperband'+str(fold)\n",
    "            )\n",
    "        logging.info(tuner.search_space_summary())\n",
    "        tuner.search(x[train], y[train], epochs=1000, batch_size=1024, workers=4, \n",
    "                     validation_data=(x[test], y[test]), \n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max')], \n",
    "                 verbose=0)\n",
    "        \n",
    "        best_trial_dict[fold]= tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "        logging.info(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values)\n",
    "        model = tuner.get_best_models(num_models=1)[0]\n",
    "        model_dict[fold] = model\n",
    "        #Train the multiforest using the training indices\n",
    "        result=model.evaluate(x[test], y[test])\n",
    "\n",
    "        results_dict[fold] = dict(zip(model.metrics_names, result))\n",
    "        #record and print metrics\n",
    "        f2_score.append(results_dict[fold]['f2'])\n",
    "        threshacc. append(results_dict[fold]['acc'])\n",
    "        precision.append(results_dict[fold]['prec'])\n",
    "        rocauc.append(results_dict[fold]['auc'])\n",
    "        recall.append(results_dict[fold]['recall'])\n",
    "        logging.info('val_f2 =' + str(results_dict[fold]['f2']))\n",
    "        logging.info('val_acc =' + str(results_dict[fold]['acc']))\n",
    "        logging.info('val_prec =' + str(results_dict[fold]['prec']))\n",
    "        logging.info('val_auc =' + str(results_dict[fold]['auc']))\n",
    "        logging.info('val_recall =' + str(results_dict[fold]['recall']))\n",
    "    fold+=1\n",
    "    #times.append(timeit.default_timer()-start)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "# get the runtime\n",
    "run_time = stop - start\n",
    "print('total run time = ' + str(run_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project keras_tuner_kfold_6\\hyperband4\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from keras_tuner_kfold_6\\hyperband4\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%capture\n",
    "### do only fold 0\n",
    "# train loop, save predictions and models\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "threshacc = []\n",
    "precision = []\n",
    "recall = []\n",
    "rocauc = []\n",
    "f2_score = []\n",
    "times = []\n",
    "\n",
    "best_trial_dict = {}\n",
    "model_dict = {}\n",
    "results_dict={}\n",
    "\n",
    "\n",
    "fold=0\n",
    "k_fold = IterativeStratification(n_splits=5, order=3)#, random_state=23)\n",
    "for train, test in k_fold.split(X_train, y_train):\n",
    "    if fold==4:\n",
    "        logging.info('fold='+str(fold) )\n",
    "        tuner = Hyperband(\n",
    "            build_model,\n",
    "            objective= Objective(\"val_auc\", direction=\"max\"),\n",
    "            max_epochs=1000,\n",
    "            hyperband_iterations=1,\n",
    "            seed=23,\n",
    "            directory='keras_tuner_kfold_6',\n",
    "            project_name='hyperband'+str(fold)\n",
    "            )\n",
    "        logging.info(tuner.search_space_summary())\n",
    "        tuner.search(x[train], y[train], epochs=1000, batch_size=1024, workers=4, \n",
    "                     validation_data=(x[test], y[test]), \n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max')], \n",
    "                 verbose=0)\n",
    "        \n",
    "        best_trial_dict[fold]= tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "        logging.info(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values)\n",
    "        model = tuner.get_best_models(num_models=1)[0]\n",
    "        model_dict[fold] = model\n",
    "        #Train the multiforest using the training indices\n",
    "        result=model.evaluate(x[test], y[test])\n",
    "        results_dict[fold] = dict(zip(model.metrics_names, result))\n",
    "        #record and print metrics\n",
    "        f2_score.append(results_dict[fold]['f2'])\n",
    "        threshacc. append(results_dict[fold]['acc'])\n",
    "        precision.append(results_dict[fold]['prec'])\n",
    "        rocauc.append(results_dict[fold]['auc'])\n",
    "        recall.append(results_dict[fold]['recall'])\n",
    "        logging.info('val_f2 =' + str(results_dict[fold]['f2']))\n",
    "        logging.info('val_acc =' + str(results_dict[fold]['acc']))\n",
    "        logging.info('val_prec =' + str(results_dict[fold]['prec']))\n",
    "        logging.info('val_auc =' + str(results_dict[fold]['auc']))\n",
    "        logging.info('val_recall =' + str(results_dict[fold]['recall']))\n",
    "    fold+=1\n",
    "    #times.append(timeit.default_timer()-start)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "# get the runtime\n",
    "run_time = stop - start\n",
    "print('total run time = ' + str(run_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: {'embed': 96,\n",
       "  'lstm1': 96,\n",
       "  'dropout1': 0.2156097764514988,\n",
       "  'dense1': 96,\n",
       "  'dropout3': 0.02106432867132807,\n",
       "  'learning_rate': 0.0026489221357360827,\n",
       "  'tuner/epochs': 1000,\n",
       "  'tuner/initial_epoch': 334,\n",
       "  'tuner/bracket': 6,\n",
       "  'tuner/round': 6,\n",
       "  'tuner/trial_id': 'c3fb475f68fafd95147f903dc61c13e8'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " best_trial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: {'embed': 96,\n",
       "  'lstm1': 96,\n",
       "  'dropout1': 0.2156097764514988,\n",
       "  'dense1': 96,\n",
       "  'dropout3': 0.02106432867132807,\n",
       "  'learning_rate': 0.0026489221357360827,\n",
       "  'tuner/epochs': 1000,\n",
       "  'tuner/initial_epoch': 334,\n",
       "  'tuner/bracket': 6,\n",
       "  'tuner/round': 6,\n",
       "  'tuner/trial_id': 'c3fb475f68fafd95147f903dc61c13e8'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### view the best parameter dictionary\n",
    "logging.info('best trial hyperparameter summary')\n",
    "for k in best_trial_dict.keys():\n",
    "    logging.info(k)\n",
    "    logging.info(best_trial_dict[k])\n",
    "    \n",
    "best_trial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c3fb475f68fafd95147f903dc61c13e8'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpid = tuner.oracle.get_best_trials()[0].hyperparameters.values['tuner/trial_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_trial = tuner.oracle.get_best_trials()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure out how many epochs to do??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model params\n",
    "METRICS = [\n",
    "    keras.metrics.BinaryAccuracy(name='acc'),\n",
    "    keras.metrics.Precision(name='prec'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    f2, \n",
    "    fbeta2\n",
    "]\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=51, output_dim=96))\n",
    "    model.add(layers.LSTM(96, return_sequences=False, input_shape=(maxlen,len_vocab)))\n",
    "    model.add(layers.Dropout(0.32255))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.02152))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(16, activation='sigmoid'))\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=0.001758),  \n",
    "                  metrics=METRICS)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 68792 samples, validate on 17197 samples\n",
      "Epoch 1/1000\n",
      "68792/68792 - 5s - loss: 0.5567 - acc: 0.8297 - prec: 0.1405 - recall: 0.0658 - auc: 0.5264 - f2: 0.0372 - fbeta2: 0.0496 - val_loss: 0.3877 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7020 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 2/1000\n",
      "68792/68792 - 2s - loss: 0.3509 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7236 - f2: 0.0000e+00 - fbeta2: 6.3877e-11 - val_loss: 0.3379 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7467 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 3/1000\n",
      "68792/68792 - 2s - loss: 0.3353 - acc: 0.8725 - prec: 0.3907 - recall: 8.4148e-04 - auc: 0.7500 - f2: 5.8372e-04 - fbeta2: 0.0010 - val_loss: 0.3346 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7474 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 4/1000\n",
      "68792/68792 - 2s - loss: 0.3340 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7495 - f2: 0.0000e+00 - fbeta2: 6.3707e-11 - val_loss: 0.3339 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7474 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 5/1000\n",
      "68792/68792 - 2s - loss: 0.3337 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7494 - f2: 0.0000e+00 - fbeta2: 6.3890e-11 - val_loss: 0.3337 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7477 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 6/1000\n",
      "68792/68792 - 2s - loss: 0.3336 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7496 - f2: 0.0000e+00 - fbeta2: 6.3731e-11 - val_loss: 0.3336 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7474 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 7/1000\n",
      "68792/68792 - 2s - loss: 0.3332 - acc: 0.8724 - prec: 0.3130 - recall: 0.0012 - auc: 0.7514 - f2: 0.0010 - fbeta2: 0.0014 - val_loss: 0.3329 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7502 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 8/1000\n",
      "68792/68792 - 2s - loss: 0.3319 - acc: 0.8720 - prec: 0.3375 - recall: 0.0046 - auc: 0.7562 - f2: 0.0036 - fbeta2: 0.0053 - val_loss: 0.3339 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7471 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 9/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7495 - f2: 0.0000e+00 - fbeta2: 6.3666e-11 - val_loss: 0.3337 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7471 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 10/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7496 - f2: 0.0000e+00 - fbeta2: 6.3993e-11 - val_loss: 0.3335 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7476 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 11/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7496 - f2: 0.0000e+00 - fbeta2: 6.3584e-11 - val_loss: 0.3335 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7475 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 12/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7494 - f2: 0.0000e+00 - fbeta2: 6.3952e-11 - val_loss: 0.3336 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7475 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 13/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7495 - f2: 0.0000e+00 - fbeta2: 6.3951e-11 - val_loss: 0.3336 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7475 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 14/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7494 - f2: 0.0000e+00 - fbeta2: 6.3925e-11 - val_loss: 0.3335 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7475 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 15/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7495 - f2: 0.0000e+00 - fbeta2: 6.3876e-11 - val_loss: 0.3335 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7477 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 16/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7495 - f2: 0.0000e+00 - fbeta2: 6.3939e-11 - val_loss: 0.3336 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7474 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n",
      "Epoch 17/1000\n",
      "68792/68792 - 2s - loss: 0.3335 - acc: 0.8726 - prec: 0.6667 - recall: 1.4262e-05 - auc: 0.7495 - f2: 1.0028e-05 - fbeta2: 1.7765e-05 - val_loss: 0.3335 - val_acc: 0.8729 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7476 - val_f2: 0.0000e+00 - val_fbeta2: 6.0992e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17197/17197 [==============================] - ETA: 5s - loss: 0.3240 - acc: 0.8730 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7737 - f2: 0.0000e+00 - fbeta2: 1.9231e-0 - ETA: 2s - loss: 0.3256 - acc: 0.8737 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7607 - f2: 0.0000e+00 - fbeta2: 1.9458e-0 - ETA: 2s - loss: 0.3277 - acc: 0.8736 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7567 - f2: 0.0000e+00 - fbeta2: 1.9411e-0 - ETA: 2s - loss: 0.3328 - acc: 0.8725 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7492 - f2: 0.0000e+00 - fbeta2: 1.9292e-0 - ETA: 2s - loss: 0.3331 - acc: 0.8722 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7503 - f2: 0.0000e+00 - fbeta2: 1.9224e-0 - ETA: 2s - loss: 0.3354 - acc: 0.8724 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7443 - f2: 0.0000e+00 - fbeta2: 1.9256e-0 - ETA: 2s - loss: 0.3362 - acc: 0.8721 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7437 - f2: 0.0000e+00 - fbeta2: 1.9204e-0 - ETA: 2s - loss: 0.3366 - acc: 0.8719 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7434 - f2: 0.0000e+00 - fbeta2: 1.9167e-0 - ETA: 2s - loss: 0.3363 - acc: 0.8719 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7442 - f2: 0.0000e+00 - fbeta2: 1.9164e-0 - ETA: 2s - loss: 0.3361 - acc: 0.8720 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7447 - f2: 0.0000e+00 - fbeta2: 1.9186e-0 - ETA: 2s - loss: 0.3348 - acc: 0.8723 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7466 - f2: 0.0000e+00 - fbeta2: 1.9232e-0 - ETA: 1s - loss: 0.3337 - acc: 0.8727 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7481 - f2: 0.0000e+00 - fbeta2: 1.9300e-0 - ETA: 1s - loss: 0.3327 - acc: 0.8731 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7492 - f2: 0.0000e+00 - fbeta2: 1.9354e-0 - ETA: 1s - loss: 0.3322 - acc: 0.8732 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7501 - f2: 0.0000e+00 - fbeta2: 1.9367e-0 - ETA: 1s - loss: 0.3320 - acc: 0.8733 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7501 - f2: 0.0000e+00 - fbeta2: 1.9382e-0 - ETA: 1s - loss: 0.3317 - acc: 0.8735 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7502 - f2: 0.0000e+00 - fbeta2: 1.9409e-0 - ETA: 1s - loss: 0.3320 - acc: 0.8733 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7497 - f2: 0.0000e+00 - fbeta2: 1.9382e-0 - ETA: 1s - loss: 0.3319 - acc: 0.8733 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7499 - f2: 0.0000e+00 - fbeta2: 1.9384e-0 - ETA: 1s - loss: 0.3312 - acc: 0.8735 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7512 - f2: 0.0000e+00 - fbeta2: 1.9409e-0 - ETA: 1s - loss: 0.3308 - acc: 0.8735 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7523 - f2: 0.0000e+00 - fbeta2: 1.9408e-0 - ETA: 1s - loss: 0.3311 - acc: 0.8734 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7519 - f2: 0.0000e+00 - fbeta2: 1.9385e-0 - ETA: 1s - loss: 0.3316 - acc: 0.8732 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7513 - f2: 0.0000e+00 - fbeta2: 1.9360e-0 - ETA: 1s - loss: 0.3320 - acc: 0.8730 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7507 - f2: 0.0000e+00 - fbeta2: 1.9336e-0 - ETA: 1s - loss: 0.3317 - acc: 0.8732 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7510 - f2: 0.0000e+00 - fbeta2: 1.9360e-0 - ETA: 1s - loss: 0.3322 - acc: 0.8730 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7506 - f2: 0.0000e+00 - fbeta2: 1.9331e-0 - ETA: 1s - loss: 0.3324 - acc: 0.8729 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7503 - f2: 0.0000e+00 - fbeta2: 1.9321e-0 - ETA: 1s - loss: 0.3324 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7505 - f2: 0.0000e+00 - fbeta2: 1.9304e-0 - ETA: 1s - loss: 0.3321 - acc: 0.8729 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7509 - f2: 0.0000e+00 - fbeta2: 1.9318e-0 - ETA: 1s - loss: 0.3316 - acc: 0.8730 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7518 - f2: 0.0000e+00 - fbeta2: 1.9330e-0 - ETA: 0s - loss: 0.3315 - acc: 0.8731 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7515 - f2: 0.0000e+00 - fbeta2: 1.9340e-0 - ETA: 0s - loss: 0.3316 - acc: 0.8732 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7512 - f2: 0.0000e+00 - fbeta2: 1.9349e-0 - ETA: 0s - loss: 0.3315 - acc: 0.8731 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7515 - f2: 0.0000e+00 - fbeta2: 1.9342e-0 - ETA: 0s - loss: 0.3314 - acc: 0.8731 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7519 - f2: 0.0000e+00 - fbeta2: 1.9336e-0 - ETA: 0s - loss: 0.3318 - acc: 0.8730 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7510 - f2: 0.0000e+00 - fbeta2: 1.9332e-0 - ETA: 0s - loss: 0.3319 - acc: 0.8730 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7513 - f2: 0.0000e+00 - fbeta2: 1.9319e-0 - ETA: 0s - loss: 0.3318 - acc: 0.8730 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7513 - f2: 0.0000e+00 - fbeta2: 1.9317e-0 - ETA: 0s - loss: 0.3318 - acc: 0.8729 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7517 - f2: 0.0000e+00 - fbeta2: 1.9306e-0 - ETA: 0s - loss: 0.3322 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7511 - f2: 0.0000e+00 - fbeta2: 1.9289e-0 - ETA: 0s - loss: 0.3322 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7512 - f2: 0.0000e+00 - fbeta2: 1.9290e-0 - ETA: 0s - loss: 0.3326 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7502 - f2: 0.0000e+00 - fbeta2: 1.9300e-0 - ETA: 0s - loss: 0.3329 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7494 - f2: 0.0000e+00 - fbeta2: 1.9298e-0 - ETA: 0s - loss: 0.3330 - acc: 0.8729 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7490 - f2: 0.0000e+00 - fbeta2: 1.9315e-0 - ETA: 0s - loss: 0.3330 - acc: 0.8729 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7488 - f2: 0.0000e+00 - fbeta2: 1.9315e-0 - ETA: 0s - loss: 0.3334 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7483 - f2: 0.0000e+00 - fbeta2: 1.9299e-0 - ETA: 0s - loss: 0.3333 - acc: 0.8729 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7482 - f2: 0.0000e+00 - fbeta2: 1.9309e-0 - ETA: 0s - loss: 0.3335 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7481 - f2: 0.0000e+00 - fbeta2: 1.9297e-0 - ETA: 0s - loss: 0.3338 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7475 - f2: 0.0000e+00 - fbeta2: 1.9294e-0 - ETA: 0s - loss: 0.3336 - acc: 0.8728 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7478 - f2: 0.0000e+00 - fbeta2: 1.9304e-0 - 3s 146us/sample - loss: 0.3335 - acc: 0.8729 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7476 - f2: 0.0000e+00 - fbeta2: 1.9359e-09\n",
      "1\n",
      "Train on 68791 samples, validate on 17198 samples\n",
      "Epoch 1/1000\n",
      "68791/68791 - 5s - loss: 0.5538 - acc: 0.8332 - prec: 0.1319 - recall: 0.0558 - auc: 0.5237 - f2: 0.0322 - fbeta2: 0.0403 - val_loss: 0.3881 - val_acc: 0.8720 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7059 - val_f2: 0.0000e+00 - val_fbeta2: 6.0542e-11\n",
      "Epoch 2/1000\n",
      "68791/68791 - 2s - loss: 0.3398 - acc: 0.8718 - prec: 0.3797 - recall: 0.0120 - auc: 0.7661 - f2: 0.0119 - fbeta2: 0.0154 - val_loss: 0.3298 - val_acc: 0.8720 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7835 - val_f2: 0.0000e+00 - val_fbeta2: 6.0542e-11\n",
      "Epoch 3/1000\n",
      "68791/68791 - 2s - loss: 0.2704 - acc: 0.8805 - prec: 0.6174 - recall: 0.1585 - auc: 0.8743 - f2: 0.1345 - fbeta2: 0.1851 - val_loss: 0.3019 - val_acc: 0.8720 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8724 - val_f2: 0.0000e+00 - val_fbeta2: 6.0542e-11\n",
      "Epoch 4/1000\n",
      "68791/68791 - 2s - loss: 0.2564 - acc: 0.8840 - prec: 0.6088 - recall: 0.2460 - auc: 0.8868 - f2: 0.1828 - fbeta2: 0.2788 - val_loss: 0.2775 - val_acc: 0.8720 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8913 - val_f2: 0.0000e+00 - val_fbeta2: 6.0542e-11\n",
      "Epoch 5/1000\n",
      "68791/68791 - 2s - loss: 0.2449 - acc: 0.8861 - prec: 0.6083 - recall: 0.2942 - auc: 0.8989 - f2: 0.2126 - fbeta2: 0.3280 - val_loss: 0.2522 - val_acc: 0.8789 - val_prec: 0.7034 - val_recall: 0.0934 - val_auc: 0.9035 - val_f2: 0.1129 - val_fbeta2: 0.1132\n",
      "Epoch 6/1000\n",
      "68791/68791 - 2s - loss: 0.2355 - acc: 0.8885 - prec: 0.6104 - recall: 0.3412 - auc: 0.9081 - f2: 0.2472 - fbeta2: 0.3737 - val_loss: 0.2369 - val_acc: 0.8839 - val_prec: 0.6811 - val_recall: 0.1750 - val_auc: 0.9121 - val_f2: 0.1582 - val_fbeta2: 0.2057\n",
      "Epoch 7/1000\n",
      "68791/68791 - 2s - loss: 0.2311 - acc: 0.8902 - prec: 0.6151 - recall: 0.3657 - auc: 0.9122 - f2: 0.2638 - fbeta2: 0.3977 - val_loss: 0.2272 - val_acc: 0.8919 - val_prec: 0.6793 - val_recall: 0.2937 - val_auc: 0.9177 - val_f2: 0.2183 - val_fbeta2: 0.3311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "68791/68791 - 2s - loss: 0.2277 - acc: 0.8917 - prec: 0.6189 - recall: 0.3869 - auc: 0.9150 - f2: 0.2798 - fbeta2: 0.4183 - val_loss: 0.2236 - val_acc: 0.8924 - val_prec: 0.6433 - val_recall: 0.3568 - val_auc: 0.9195 - val_f2: 0.2726 - val_fbeta2: 0.3917\n",
      "Epoch 9/1000\n",
      "68791/68791 - 2s - loss: 0.2270 - acc: 0.8912 - prec: 0.6136 - recall: 0.3911 - auc: 0.9156 - f2: 0.2890 - fbeta2: 0.4218 - val_loss: 0.2420 - val_acc: 0.8836 - val_prec: 0.5800 - val_recall: 0.3270 - val_auc: 0.9044 - val_f2: 0.2496 - val_fbeta2: 0.3582\n",
      "Epoch 10/1000\n",
      "68791/68791 - 2s - loss: 0.2241 - acc: 0.8926 - prec: 0.6206 - recall: 0.3998 - auc: 0.9180 - f2: 0.2972 - fbeta2: 0.4307 - val_loss: 0.2253 - val_acc: 0.8940 - val_prec: 0.6394 - val_recall: 0.3937 - val_auc: 0.9176 - val_f2: 0.2785 - val_fbeta2: 0.4264\n",
      "Epoch 11/1000\n",
      "68791/68791 - 2s - loss: 0.2213 - acc: 0.8939 - prec: 0.6246 - recall: 0.4147 - auc: 0.9205 - f2: 0.3102 - fbeta2: 0.4451 - val_loss: 0.2182 - val_acc: 0.8952 - val_prec: 0.6496 - val_recall: 0.3928 - val_auc: 0.9237 - val_f2: 0.2880 - val_fbeta2: 0.4265\n",
      "Epoch 12/1000\n",
      "68791/68791 - 2s - loss: 0.2193 - acc: 0.8952 - prec: 0.6308 - recall: 0.4237 - auc: 0.9222 - f2: 0.3129 - fbeta2: 0.4539 - val_loss: 0.2171 - val_acc: 0.8954 - val_prec: 0.6278 - val_recall: 0.4477 - val_auc: 0.9247 - val_f2: 0.3336 - val_fbeta2: 0.4750\n",
      "Epoch 13/1000\n",
      "68791/68791 - 2s - loss: 0.2178 - acc: 0.8957 - prec: 0.6311 - recall: 0.4324 - auc: 0.9234 - f2: 0.3279 - fbeta2: 0.4611 - val_loss: 0.2192 - val_acc: 0.8943 - val_prec: 0.6204 - val_recall: 0.4484 - val_auc: 0.9228 - val_f2: 0.3269 - val_fbeta2: 0.4748\n",
      "Epoch 14/1000\n",
      "68791/68791 - 2s - loss: 0.2158 - acc: 0.8967 - prec: 0.6339 - recall: 0.4450 - auc: 0.9251 - f2: 0.3406 - fbeta2: 0.4738 - val_loss: 0.2149 - val_acc: 0.8968 - val_prec: 0.6524 - val_recall: 0.4150 - val_auc: 0.9266 - val_f2: 0.3313 - val_fbeta2: 0.4474\n",
      "Epoch 15/1000\n",
      "68791/68791 - 2s - loss: 0.2147 - acc: 0.8972 - prec: 0.6363 - recall: 0.4472 - auc: 0.9260 - f2: 0.3415 - fbeta2: 0.4748 - val_loss: 0.2163 - val_acc: 0.8955 - val_prec: 0.6491 - val_recall: 0.3993 - val_auc: 0.9252 - val_f2: 0.2924 - val_fbeta2: 0.4326\n",
      "Epoch 16/1000\n",
      "68791/68791 - 2s - loss: 0.2145 - acc: 0.8974 - prec: 0.6379 - recall: 0.4466 - auc: 0.9261 - f2: 0.3424 - fbeta2: 0.4743 - val_loss: 0.2098 - val_acc: 0.8994 - val_prec: 0.6468 - val_recall: 0.4716 - val_auc: 0.9303 - val_f2: 0.3249 - val_fbeta2: 0.4984\n",
      "Epoch 17/1000\n",
      "68791/68791 - 2s - loss: 0.2121 - acc: 0.8983 - prec: 0.6396 - recall: 0.4597 - auc: 0.9280 - f2: 0.3545 - fbeta2: 0.4869 - val_loss: 0.2121 - val_acc: 0.8979 - val_prec: 0.6320 - val_recall: 0.4835 - val_auc: 0.9285 - val_f2: 0.3275 - val_fbeta2: 0.5072\n",
      "Epoch 18/1000\n",
      "68791/68791 - 2s - loss: 0.2117 - acc: 0.8986 - prec: 0.6399 - recall: 0.4631 - auc: 0.9284 - f2: 0.3570 - fbeta2: 0.4902 - val_loss: 0.2080 - val_acc: 0.9001 - val_prec: 0.6429 - val_recall: 0.4940 - val_auc: 0.9319 - val_f2: 0.3641 - val_fbeta2: 0.5180\n",
      "Epoch 19/1000\n",
      "68791/68791 - 2s - loss: 0.2103 - acc: 0.8992 - prec: 0.6422 - recall: 0.4685 - auc: 0.9295 - f2: 0.3658 - fbeta2: 0.4948 - val_loss: 0.2071 - val_acc: 0.9010 - val_prec: 0.6420 - val_recall: 0.5122 - val_auc: 0.9325 - val_f2: 0.3946 - val_fbeta2: 0.5336\n",
      "Epoch 20/1000\n",
      "68791/68791 - 2s - loss: 0.2086 - acc: 0.9002 - prec: 0.6463 - recall: 0.4764 - auc: 0.9309 - f2: 0.3696 - fbeta2: 0.5028 - val_loss: 0.2067 - val_acc: 0.9012 - val_prec: 0.6567 - val_recall: 0.4775 - val_auc: 0.9327 - val_f2: 0.3630 - val_fbeta2: 0.5050\n",
      "Epoch 21/1000\n",
      "68791/68791 - 2s - loss: 0.2081 - acc: 0.9004 - prec: 0.6462 - recall: 0.4799 - auc: 0.9312 - f2: 0.3744 - fbeta2: 0.5055 - val_loss: 0.2073 - val_acc: 0.9009 - val_prec: 0.6441 - val_recall: 0.5037 - val_auc: 0.9323 - val_f2: 0.3971 - val_fbeta2: 0.5267\n",
      "Epoch 22/1000\n",
      "68791/68791 - 2s - loss: 0.2069 - acc: 0.9009 - prec: 0.6477 - recall: 0.4838 - auc: 0.9321 - f2: 0.3771 - fbeta2: 0.5090 - val_loss: 0.2133 - val_acc: 0.8974 - val_prec: 0.6283 - val_recall: 0.4846 - val_auc: 0.9276 - val_f2: 0.3679 - val_fbeta2: 0.5078\n",
      "Epoch 23/1000\n",
      "68791/68791 - 2s - loss: 0.2069 - acc: 0.9010 - prec: 0.6459 - recall: 0.4901 - auc: 0.9321 - f2: 0.3833 - fbeta2: 0.5147 - val_loss: 0.2053 - val_acc: 0.9020 - val_prec: 0.6763 - val_recall: 0.4494 - val_auc: 0.9345 - val_f2: 0.3558 - val_fbeta2: 0.4816\n",
      "Epoch 24/1000\n",
      "68791/68791 - 2s - loss: 0.2054 - acc: 0.9018 - prec: 0.6503 - recall: 0.4924 - auc: 0.9332 - f2: 0.3863 - fbeta2: 0.5171 - val_loss: 0.2053 - val_acc: 0.9020 - val_prec: 0.6572 - val_recall: 0.4895 - val_auc: 0.9338 - val_f2: 0.3416 - val_fbeta2: 0.5156\n",
      "Epoch 25/1000\n",
      "68791/68791 - 2s - loss: 0.2042 - acc: 0.9026 - prec: 0.6537 - recall: 0.4982 - auc: 0.9342 - f2: 0.3950 - fbeta2: 0.5228 - val_loss: 0.2047 - val_acc: 0.9021 - val_prec: 0.6545 - val_recall: 0.4974 - val_auc: 0.9343 - val_f2: 0.4168 - val_fbeta2: 0.5225\n",
      "Epoch 26/1000\n",
      "68791/68791 - 2s - loss: 0.2041 - acc: 0.9021 - prec: 0.6505 - recall: 0.4976 - auc: 0.9343 - f2: 0.3980 - fbeta2: 0.5219 - val_loss: 0.2047 - val_acc: 0.9026 - val_prec: 0.6585 - val_recall: 0.4965 - val_auc: 0.9344 - val_f2: 0.4087 - val_fbeta2: 0.5220\n",
      "Epoch 27/1000\n",
      "68791/68791 - 2s - loss: 0.2036 - acc: 0.9025 - prec: 0.6523 - recall: 0.5005 - auc: 0.9347 - f2: 0.3938 - fbeta2: 0.5248 - val_loss: 0.2055 - val_acc: 0.9012 - val_prec: 0.6458 - val_recall: 0.5046 - val_auc: 0.9337 - val_f2: 0.3601 - val_fbeta2: 0.5276\n",
      "Epoch 28/1000\n",
      "68791/68791 - 2s - loss: 0.2027 - acc: 0.9031 - prec: 0.6541 - recall: 0.5055 - auc: 0.9353 - f2: 0.4088 - fbeta2: 0.5294 - val_loss: 0.2034 - val_acc: 0.9032 - val_prec: 0.6487 - val_recall: 0.5309 - val_auc: 0.9353 - val_f2: 0.4358 - val_fbeta2: 0.5508\n",
      "Epoch 29/1000\n",
      "68791/68791 - 2s - loss: 0.2017 - acc: 0.9035 - prec: 0.6548 - recall: 0.5109 - auc: 0.9361 - f2: 0.4039 - fbeta2: 0.5340 - val_loss: 0.2064 - val_acc: 0.9010 - val_prec: 0.6368 - val_recall: 0.5269 - val_auc: 0.9332 - val_f2: 0.3593 - val_fbeta2: 0.5455\n",
      "Epoch 30/1000\n",
      "68791/68791 - 2s - loss: 0.2012 - acc: 0.9041 - prec: 0.6558 - recall: 0.5178 - auc: 0.9365 - f2: 0.4168 - fbeta2: 0.5394 - val_loss: 0.2035 - val_acc: 0.9033 - val_prec: 0.6740 - val_recall: 0.4730 - val_auc: 0.9354 - val_f2: 0.3810 - val_fbeta2: 0.5030\n",
      "Epoch 31/1000\n",
      "68791/68791 - 2s - loss: 0.2016 - acc: 0.9035 - prec: 0.6551 - recall: 0.5095 - auc: 0.9361 - f2: 0.4070 - fbeta2: 0.5323 - val_loss: 0.2036 - val_acc: 0.9026 - val_prec: 0.6506 - val_recall: 0.5151 - val_auc: 0.9350 - val_f2: 0.4032 - val_fbeta2: 0.5374\n",
      "Epoch 32/1000\n",
      "68791/68791 - 2s - loss: 0.2002 - acc: 0.9042 - prec: 0.6559 - recall: 0.5197 - auc: 0.9371 - f2: 0.4152 - fbeta2: 0.5419 - val_loss: 0.2005 - val_acc: 0.9041 - val_prec: 0.6485 - val_recall: 0.5467 - val_auc: 0.9373 - val_f2: 0.3904 - val_fbeta2: 0.5642\n",
      "Epoch 33/1000\n",
      "68791/68791 - 2s - loss: 0.1996 - acc: 0.9044 - prec: 0.6563 - recall: 0.5212 - auc: 0.9375 - f2: 0.4150 - fbeta2: 0.5429 - val_loss: 0.1997 - val_acc: 0.9046 - val_prec: 0.6582 - val_recall: 0.5289 - val_auc: 0.9380 - val_f2: 0.4289 - val_fbeta2: 0.5504\n",
      "Epoch 34/1000\n",
      "68791/68791 - 2s - loss: 0.1993 - acc: 0.9048 - prec: 0.6586 - recall: 0.5217 - auc: 0.9378 - f2: 0.4229 - fbeta2: 0.5443 - val_loss: 0.2064 - val_acc: 0.9013 - val_prec: 0.6428 - val_recall: 0.5156 - val_auc: 0.9333 - val_f2: 0.3982 - val_fbeta2: 0.5368\n",
      "Epoch 35/1000\n",
      "68791/68791 - 2s - loss: 0.1995 - acc: 0.9045 - prec: 0.6568 - recall: 0.5220 - auc: 0.9376 - f2: 0.4225 - fbeta2: 0.5436 - val_loss: 0.2049 - val_acc: 0.9024 - val_prec: 0.6674 - val_recall: 0.4732 - val_auc: 0.9346 - val_f2: 0.3917 - val_fbeta2: 0.5024\n",
      "Epoch 36/1000\n",
      "68791/68791 - 2s - loss: 0.1976 - acc: 0.9057 - prec: 0.6613 - recall: 0.5303 - auc: 0.9390 - f2: 0.4325 - fbeta2: 0.5529 - val_loss: 0.2028 - val_acc: 0.9030 - val_prec: 0.6502 - val_recall: 0.5240 - val_auc: 0.9359 - val_f2: 0.4425 - val_fbeta2: 0.5451\n",
      "Epoch 37/1000\n",
      "68791/68791 - 2s - loss: 0.1976 - acc: 0.9058 - prec: 0.6605 - recall: 0.5340 - auc: 0.9390 - f2: 0.4337 - fbeta2: 0.5561 - val_loss: 0.2008 - val_acc: 0.9038 - val_prec: 0.6569 - val_recall: 0.5201 - val_auc: 0.9372 - val_f2: 0.4141 - val_fbeta2: 0.5428\n",
      "Epoch 38/1000\n",
      "68791/68791 - 2s - loss: 0.1968 - acc: 0.9061 - prec: 0.6615 - recall: 0.5353 - auc: 0.9397 - f2: 0.4315 - fbeta2: 0.5568 - val_loss: 0.2012 - val_acc: 0.9038 - val_prec: 0.6460 - val_recall: 0.5497 - val_auc: 0.9371 - val_f2: 0.4301 - val_fbeta2: 0.5666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000\n",
      "68791/68791 - 2s - loss: 0.1960 - acc: 0.9065 - prec: 0.6619 - recall: 0.5414 - auc: 0.9402 - f2: 0.4400 - fbeta2: 0.5617 - val_loss: 0.1984 - val_acc: 0.9058 - val_prec: 0.6711 - val_recall: 0.5174 - val_auc: 0.9389 - val_f2: 0.4060 - val_fbeta2: 0.5422\n",
      "Epoch 40/1000\n",
      "68791/68791 - 2s - loss: 0.1953 - acc: 0.9068 - prec: 0.6639 - recall: 0.5415 - auc: 0.9407 - f2: 0.4422 - fbeta2: 0.5620 - val_loss: 0.1988 - val_acc: 0.9049 - val_prec: 0.6434 - val_recall: 0.5760 - val_auc: 0.9388 - val_f2: 0.4840 - val_fbeta2: 0.5883\n",
      "Epoch 41/1000\n",
      "68791/68791 - 2s - loss: 0.1955 - acc: 0.9068 - prec: 0.6628 - recall: 0.5442 - auc: 0.9405 - f2: 0.4455 - fbeta2: 0.5648 - val_loss: 0.1993 - val_acc: 0.9051 - val_prec: 0.6672 - val_recall: 0.5155 - val_auc: 0.9382 - val_f2: 0.4272 - val_fbeta2: 0.5400\n",
      "Epoch 42/1000\n",
      "68791/68791 - 2s - loss: 0.1952 - acc: 0.9070 - prec: 0.6642 - recall: 0.5437 - auc: 0.9407 - f2: 0.4429 - fbeta2: 0.5636 - val_loss: 0.1988 - val_acc: 0.9052 - val_prec: 0.6577 - val_recall: 0.5412 - val_auc: 0.9388 - val_f2: 0.4440 - val_fbeta2: 0.5609\n",
      "Epoch 43/1000\n",
      "68791/68791 - 2s - loss: 0.1941 - acc: 0.9079 - prec: 0.6663 - recall: 0.5524 - auc: 0.9415 - f2: 0.4499 - fbeta2: 0.5708 - val_loss: 0.1975 - val_acc: 0.9054 - val_prec: 0.6596 - val_recall: 0.5392 - val_auc: 0.9395 - val_f2: 0.4181 - val_fbeta2: 0.5596\n",
      "Epoch 44/1000\n",
      "68791/68791 - 2s - loss: 0.1932 - acc: 0.9084 - prec: 0.6683 - recall: 0.5549 - auc: 0.9421 - f2: 0.4488 - fbeta2: 0.5748 - val_loss: 0.1978 - val_acc: 0.9053 - val_prec: 0.6405 - val_recall: 0.5918 - val_auc: 0.9396 - val_f2: 0.4918 - val_fbeta2: 0.6008\n",
      "Epoch 45/1000\n",
      "68791/68791 - 2s - loss: 0.1933 - acc: 0.9078 - prec: 0.6656 - recall: 0.5535 - auc: 0.9421 - f2: 0.4556 - fbeta2: 0.5727 - val_loss: 0.1998 - val_acc: 0.9049 - val_prec: 0.6471 - val_recall: 0.5650 - val_auc: 0.9380 - val_f2: 0.4265 - val_fbeta2: 0.5794\n",
      "Epoch 46/1000\n",
      "68791/68791 - 2s - loss: 0.1929 - acc: 0.9081 - prec: 0.6667 - recall: 0.5552 - auc: 0.9423 - f2: 0.4517 - fbeta2: 0.5741 - val_loss: 0.1980 - val_acc: 0.9058 - val_prec: 0.6531 - val_recall: 0.5623 - val_auc: 0.9393 - val_f2: 0.4396 - val_fbeta2: 0.5783\n",
      "Epoch 47/1000\n",
      "68791/68791 - 2s - loss: 0.1926 - acc: 0.9081 - prec: 0.6657 - recall: 0.5578 - auc: 0.9425 - f2: 0.4621 - fbeta2: 0.5762 - val_loss: 0.1979 - val_acc: 0.9057 - val_prec: 0.6518 - val_recall: 0.5654 - val_auc: 0.9394 - val_f2: 0.4348 - val_fbeta2: 0.5807\n",
      "Epoch 48/1000\n",
      "68791/68791 - 2s - loss: 0.1915 - acc: 0.9090 - prec: 0.6691 - recall: 0.5636 - auc: 0.9432 - f2: 0.4661 - fbeta2: 0.5814 - val_loss: 0.1986 - val_acc: 0.9052 - val_prec: 0.6475 - val_recall: 0.5694 - val_auc: 0.9388 - val_f2: 0.4705 - val_fbeta2: 0.5833\n",
      "Epoch 49/1000\n",
      "68791/68791 - 2s - loss: 0.1915 - acc: 0.9092 - prec: 0.6684 - recall: 0.5671 - auc: 0.9433 - f2: 0.4674 - fbeta2: 0.5837 - val_loss: 0.1964 - val_acc: 0.9065 - val_prec: 0.6817 - val_recall: 0.5058 - val_auc: 0.9407 - val_f2: 0.4106 - val_fbeta2: 0.5332\n",
      "Epoch 50/1000\n",
      "68791/68791 - 2s - loss: 0.1898 - acc: 0.9100 - prec: 0.6727 - recall: 0.5692 - auc: 0.9445 - f2: 0.4764 - fbeta2: 0.5870 - val_loss: 0.1984 - val_acc: 0.9058 - val_prec: 0.6518 - val_recall: 0.5674 - val_auc: 0.9391 - val_f2: 0.4654 - val_fbeta2: 0.5824\n",
      "Epoch 51/1000\n",
      "68791/68791 - 2s - loss: 0.1901 - acc: 0.9099 - prec: 0.6727 - recall: 0.5674 - auc: 0.9442 - f2: 0.4656 - fbeta2: 0.5848 - val_loss: 0.1976 - val_acc: 0.9057 - val_prec: 0.6635 - val_recall: 0.5331 - val_auc: 0.9395 - val_f2: 0.4341 - val_fbeta2: 0.5549\n",
      "Epoch 52/1000\n",
      "68791/68791 - 2s - loss: 0.1889 - acc: 0.9104 - prec: 0.6723 - recall: 0.5764 - auc: 0.9450 - f2: 0.4753 - fbeta2: 0.5931 - val_loss: 0.1993 - val_acc: 0.9048 - val_prec: 0.6590 - val_recall: 0.5310 - val_auc: 0.9384 - val_f2: 0.4434 - val_fbeta2: 0.5525\n",
      "Epoch 53/1000\n",
      "68791/68791 - 2s - loss: 0.1891 - acc: 0.9102 - prec: 0.6728 - recall: 0.5720 - auc: 0.9449 - f2: 0.4729 - fbeta2: 0.5892 - val_loss: 0.1972 - val_acc: 0.9057 - val_prec: 0.6450 - val_recall: 0.5854 - val_auc: 0.9398 - val_f2: 0.4762 - val_fbeta2: 0.5962\n",
      "Epoch 54/1000\n",
      "68791/68791 - 2s - loss: 0.1885 - acc: 0.9106 - prec: 0.6726 - recall: 0.5786 - auc: 0.9453 - f2: 0.4814 - fbeta2: 0.5942 - val_loss: 0.1973 - val_acc: 0.9063 - val_prec: 0.6503 - val_recall: 0.5792 - val_auc: 0.9399 - val_f2: 0.4795 - val_fbeta2: 0.5922\n",
      "Epoch 55/1000\n",
      "68791/68791 - 2s - loss: 0.1885 - acc: 0.9106 - prec: 0.6726 - recall: 0.5783 - auc: 0.9453 - f2: 0.4814 - fbeta2: 0.5950 - val_loss: 0.2010 - val_acc: 0.9042 - val_prec: 0.6444 - val_recall: 0.5611 - val_auc: 0.9376 - val_f2: 0.4461 - val_fbeta2: 0.5760\n",
      "Epoch 56/1000\n",
      "68791/68791 - 2s - loss: 0.1871 - acc: 0.9114 - prec: 0.6763 - recall: 0.5821 - auc: 0.9463 - f2: 0.4884 - fbeta2: 0.5991 - val_loss: 0.1972 - val_acc: 0.9061 - val_prec: 0.6488 - val_recall: 0.5804 - val_auc: 0.9398 - val_f2: 0.4907 - val_fbeta2: 0.5927\n",
      "Epoch 57/1000\n",
      "68791/68791 - 2s - loss: 0.1859 - acc: 0.9124 - prec: 0.6786 - recall: 0.5917 - auc: 0.9470 - f2: 0.4946 - fbeta2: 0.6079 - val_loss: 0.1955 - val_acc: 0.9075 - val_prec: 0.6718 - val_recall: 0.5419 - val_auc: 0.9410 - val_f2: 0.4399 - val_fbeta2: 0.5635\n",
      "Epoch 58/1000\n",
      "68791/68791 - 2s - loss: 0.1861 - acc: 0.9121 - prec: 0.6786 - recall: 0.5866 - auc: 0.9469 - f2: 0.4887 - fbeta2: 0.6018 - val_loss: 0.1980 - val_acc: 0.9061 - val_prec: 0.6535 - val_recall: 0.5669 - val_auc: 0.9394 - val_f2: 0.4666 - val_fbeta2: 0.5823\n",
      "Epoch 59/1000\n",
      "68791/68791 - 2s - loss: 0.1856 - acc: 0.9123 - prec: 0.6771 - recall: 0.5932 - auc: 0.9472 - f2: 0.5008 - fbeta2: 0.6084 - val_loss: 0.1977 - val_acc: 0.9069 - val_prec: 0.6683 - val_recall: 0.5409 - val_auc: 0.9395 - val_f2: 0.4241 - val_fbeta2: 0.5623\n",
      "Epoch 60/1000\n",
      "68791/68791 - 2s - loss: 0.1850 - acc: 0.9126 - prec: 0.6804 - recall: 0.5906 - auc: 0.9476 - f2: 0.4996 - fbeta2: 0.6056 - val_loss: 0.1966 - val_acc: 0.9067 - val_prec: 0.6505 - val_recall: 0.5860 - val_auc: 0.9405 - val_f2: 0.4927 - val_fbeta2: 0.5978\n",
      "Epoch 61/1000\n",
      "68791/68791 - 2s - loss: 0.1844 - acc: 0.9130 - prec: 0.6797 - recall: 0.5971 - auc: 0.9479 - f2: 0.4985 - fbeta2: 0.6119 - val_loss: 0.1974 - val_acc: 0.9060 - val_prec: 0.6443 - val_recall: 0.5922 - val_auc: 0.9399 - val_f2: 0.5051 - val_fbeta2: 0.6018\n",
      "Epoch 62/1000\n",
      "68791/68791 - 2s - loss: 0.1843 - acc: 0.9132 - prec: 0.6803 - recall: 0.5986 - auc: 0.9480 - f2: 0.5030 - fbeta2: 0.6125 - val_loss: 0.2004 - val_acc: 0.9047 - val_prec: 0.6374 - val_recall: 0.5913 - val_auc: 0.9382 - val_f2: 0.4874 - val_fbeta2: 0.5999\n",
      "Epoch 63/1000\n",
      "68791/68791 - 2s - loss: 0.1842 - acc: 0.9132 - prec: 0.6810 - recall: 0.5980 - auc: 0.9481 - f2: 0.5033 - fbeta2: 0.6119 - val_loss: 0.2008 - val_acc: 0.9051 - val_prec: 0.6331 - val_recall: 0.6141 - val_auc: 0.9382 - val_f2: 0.5167 - val_fbeta2: 0.6177\n",
      "Epoch 64/1000\n",
      "68791/68791 - 2s - loss: 0.1830 - acc: 0.9137 - prec: 0.6806 - recall: 0.6058 - auc: 0.9488 - f2: 0.5139 - fbeta2: 0.6201 - val_loss: 0.2020 - val_acc: 0.9046 - val_prec: 0.6458 - val_recall: 0.5643 - val_auc: 0.9372 - val_f2: 0.4848 - val_fbeta2: 0.5789\n",
      "Epoch 65/1000\n",
      "68791/68791 - 2s - loss: 0.1826 - acc: 0.9141 - prec: 0.6833 - recall: 0.6049 - auc: 0.9490 - f2: 0.5103 - fbeta2: 0.6191 - val_loss: 0.1974 - val_acc: 0.9067 - val_prec: 0.6475 - val_recall: 0.5953 - val_auc: 0.9402 - val_f2: 0.4890 - val_fbeta2: 0.6049\n",
      "Epoch 66/1000\n",
      "68791/68791 - 2s - loss: 0.1823 - acc: 0.9141 - prec: 0.6820 - recall: 0.6078 - auc: 0.9493 - f2: 0.5177 - fbeta2: 0.6207 - val_loss: 0.1992 - val_acc: 0.9058 - val_prec: 0.6569 - val_recall: 0.5524 - val_auc: 0.9389 - val_f2: 0.4680 - val_fbeta2: 0.5706\n",
      "Epoch 67/1000\n",
      "68791/68791 - 2s - loss: 0.1809 - acc: 0.9150 - prec: 0.6853 - recall: 0.6128 - auc: 0.9501 - f2: 0.5218 - fbeta2: 0.6263 - val_loss: 0.1970 - val_acc: 0.9076 - val_prec: 0.6661 - val_recall: 0.5580 - val_auc: 0.9404 - val_f2: 0.4511 - val_fbeta2: 0.5766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17198/17198 [==============================] - ETA: 5s - loss: 0.2029 - acc: 0.9102 - prec: 0.6545 - recall: 0.5714 - auc: 0.9396 - f2: 0.4260 - fbeta2: 0.586 - ETA: 2s - loss: 0.2006 - acc: 0.9050 - prec: 0.6642 - recall: 0.5309 - auc: 0.9387 - f2: 0.3573 - fbeta2: 0.552 - ETA: 2s - loss: 0.2051 - acc: 0.9025 - prec: 0.6443 - recall: 0.5258 - auc: 0.9347 - f2: 0.3566 - fbeta2: 0.544 - ETA: 2s - loss: 0.2029 - acc: 0.9052 - prec: 0.6600 - recall: 0.5429 - auc: 0.9369 - f2: 0.3777 - fbeta2: 0.561 - ETA: 2s - loss: 0.2006 - acc: 0.9064 - prec: 0.6679 - recall: 0.5456 - auc: 0.9384 - f2: 0.3724 - fbeta2: 0.565 - ETA: 2s - loss: 0.1968 - acc: 0.9077 - prec: 0.6692 - recall: 0.5536 - auc: 0.9404 - f2: 0.3838 - fbeta2: 0.572 - ETA: 2s - loss: 0.1980 - acc: 0.9072 - prec: 0.6627 - recall: 0.5536 - auc: 0.9393 - f2: 0.3809 - fbeta2: 0.571 - ETA: 2s - loss: 0.1981 - acc: 0.9070 - prec: 0.6677 - recall: 0.5522 - auc: 0.9399 - f2: 0.3804 - fbeta2: 0.571 - ETA: 2s - loss: 0.1976 - acc: 0.9073 - prec: 0.6663 - recall: 0.5547 - auc: 0.9399 - f2: 0.3852 - fbeta2: 0.573 - ETA: 1s - loss: 0.1973 - acc: 0.9074 - prec: 0.6683 - recall: 0.5550 - auc: 0.9402 - f2: 0.3879 - fbeta2: 0.574 - ETA: 1s - loss: 0.1974 - acc: 0.9072 - prec: 0.6654 - recall: 0.5543 - auc: 0.9400 - f2: 0.3852 - fbeta2: 0.572 - ETA: 1s - loss: 0.1975 - acc: 0.9068 - prec: 0.6591 - recall: 0.5539 - auc: 0.9395 - f2: 0.3842 - fbeta2: 0.571 - ETA: 1s - loss: 0.1962 - acc: 0.9078 - prec: 0.6609 - recall: 0.5575 - auc: 0.9401 - f2: 0.3858 - fbeta2: 0.574 - ETA: 1s - loss: 0.1959 - acc: 0.9080 - prec: 0.6633 - recall: 0.5588 - auc: 0.9405 - f2: 0.3888 - fbeta2: 0.576 - ETA: 1s - loss: 0.1963 - acc: 0.9077 - prec: 0.6619 - recall: 0.5571 - auc: 0.9402 - f2: 0.3849 - fbeta2: 0.574 - ETA: 1s - loss: 0.1961 - acc: 0.9076 - prec: 0.6624 - recall: 0.5565 - auc: 0.9405 - f2: 0.3861 - fbeta2: 0.574 - ETA: 1s - loss: 0.1956 - acc: 0.9079 - prec: 0.6628 - recall: 0.5577 - auc: 0.9406 - f2: 0.3868 - fbeta2: 0.575 - ETA: 1s - loss: 0.1956 - acc: 0.9080 - prec: 0.6627 - recall: 0.5583 - auc: 0.9407 - f2: 0.3862 - fbeta2: 0.576 - ETA: 1s - loss: 0.1954 - acc: 0.9080 - prec: 0.6639 - recall: 0.5588 - auc: 0.9410 - f2: 0.3871 - fbeta2: 0.576 - ETA: 1s - loss: 0.1949 - acc: 0.9083 - prec: 0.6657 - recall: 0.5593 - auc: 0.9413 - f2: 0.3871 - fbeta2: 0.577 - ETA: 1s - loss: 0.1939 - acc: 0.9085 - prec: 0.6664 - recall: 0.5604 - auc: 0.9418 - f2: 0.3881 - fbeta2: 0.578 - ETA: 1s - loss: 0.1942 - acc: 0.9084 - prec: 0.6655 - recall: 0.5605 - auc: 0.9416 - f2: 0.3884 - fbeta2: 0.578 - ETA: 1s - loss: 0.1940 - acc: 0.9084 - prec: 0.6660 - recall: 0.5604 - auc: 0.9418 - f2: 0.3893 - fbeta2: 0.578 - ETA: 1s - loss: 0.1935 - acc: 0.9086 - prec: 0.6668 - recall: 0.5614 - auc: 0.9422 - f2: 0.3902 - fbeta2: 0.579 - ETA: 1s - loss: 0.1938 - acc: 0.9084 - prec: 0.6656 - recall: 0.5612 - auc: 0.9420 - f2: 0.3896 - fbeta2: 0.578 - ETA: 1s - loss: 0.1937 - acc: 0.9085 - prec: 0.6673 - recall: 0.5610 - auc: 0.9421 - f2: 0.3886 - fbeta2: 0.579 - ETA: 1s - loss: 0.1936 - acc: 0.9086 - prec: 0.6673 - recall: 0.5607 - auc: 0.9421 - f2: 0.3885 - fbeta2: 0.578 - ETA: 1s - loss: 0.1937 - acc: 0.9085 - prec: 0.6677 - recall: 0.5602 - auc: 0.9420 - f2: 0.3875 - fbeta2: 0.578 - ETA: 0s - loss: 0.1934 - acc: 0.9087 - prec: 0.6687 - recall: 0.5609 - auc: 0.9423 - f2: 0.3887 - fbeta2: 0.579 - ETA: 0s - loss: 0.1937 - acc: 0.9087 - prec: 0.6689 - recall: 0.5616 - auc: 0.9421 - f2: 0.3887 - fbeta2: 0.579 - ETA: 0s - loss: 0.1937 - acc: 0.9088 - prec: 0.6693 - recall: 0.5616 - auc: 0.9421 - f2: 0.3884 - fbeta2: 0.579 - ETA: 0s - loss: 0.1940 - acc: 0.9088 - prec: 0.6691 - recall: 0.5614 - auc: 0.9420 - f2: 0.3890 - fbeta2: 0.579 - ETA: 0s - loss: 0.1944 - acc: 0.9085 - prec: 0.6679 - recall: 0.5604 - auc: 0.9417 - f2: 0.3884 - fbeta2: 0.578 - ETA: 0s - loss: 0.1942 - acc: 0.9087 - prec: 0.6695 - recall: 0.5607 - auc: 0.9419 - f2: 0.3887 - fbeta2: 0.579 - ETA: 0s - loss: 0.1945 - acc: 0.9086 - prec: 0.6700 - recall: 0.5603 - auc: 0.9418 - f2: 0.3892 - fbeta2: 0.579 - ETA: 0s - loss: 0.1946 - acc: 0.9087 - prec: 0.6704 - recall: 0.5611 - auc: 0.9418 - f2: 0.3901 - fbeta2: 0.579 - ETA: 0s - loss: 0.1950 - acc: 0.9086 - prec: 0.6700 - recall: 0.5608 - auc: 0.9416 - f2: 0.3897 - fbeta2: 0.579 - ETA: 0s - loss: 0.1951 - acc: 0.9086 - prec: 0.6700 - recall: 0.5603 - auc: 0.9415 - f2: 0.3896 - fbeta2: 0.579 - ETA: 0s - loss: 0.1953 - acc: 0.9084 - prec: 0.6695 - recall: 0.5600 - auc: 0.9414 - f2: 0.3891 - fbeta2: 0.578 - ETA: 0s - loss: 0.1956 - acc: 0.9083 - prec: 0.6686 - recall: 0.5590 - auc: 0.9411 - f2: 0.3886 - fbeta2: 0.577 - ETA: 0s - loss: 0.1961 - acc: 0.9081 - prec: 0.6678 - recall: 0.5589 - auc: 0.9408 - f2: 0.3885 - fbeta2: 0.577 - ETA: 0s - loss: 0.1963 - acc: 0.9080 - prec: 0.6676 - recall: 0.5587 - auc: 0.9408 - f2: 0.3889 - fbeta2: 0.577 - ETA: 0s - loss: 0.1964 - acc: 0.9079 - prec: 0.6672 - recall: 0.5582 - auc: 0.9407 - f2: 0.3892 - fbeta2: 0.576 - ETA: 0s - loss: 0.1966 - acc: 0.9079 - prec: 0.6670 - recall: 0.5584 - auc: 0.9406 - f2: 0.3893 - fbeta2: 0.577 - ETA: 0s - loss: 0.1968 - acc: 0.9078 - prec: 0.6669 - recall: 0.5584 - auc: 0.9405 - f2: 0.3900 - fbeta2: 0.576 - ETA: 0s - loss: 0.1970 - acc: 0.9076 - prec: 0.6656 - recall: 0.5579 - auc: 0.9403 - f2: 0.3897 - fbeta2: 0.576 - ETA: 0s - loss: 0.1970 - acc: 0.9076 - prec: 0.6660 - recall: 0.5579 - auc: 0.9403 - f2: 0.3903 - fbeta2: 0.576 - 2s 142us/sample - loss: 0.1970 - acc: 0.9076 - prec: 0.6661 - recall: 0.5580 - auc: 0.9404 - f2: 0.3904 - fbeta2: 0.5765\n",
      "2\n",
      "Train on 68791 samples, validate on 17198 samples\n",
      "Epoch 1/1000\n",
      "68791/68791 - 5s - loss: 0.5611 - acc: 0.8207 - prec: 0.1384 - recall: 0.0781 - auc: 0.5279 - f2: 0.0456 - fbeta2: 0.0578 - val_loss: 0.3897 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7093 - val_f2: 0.0000e+00 - val_fbeta2: 6.0810e-11\n",
      "Epoch 2/1000\n",
      "68791/68791 - 2s - loss: 0.3504 - acc: 0.8726 - prec: 0.3853 - recall: 2.9962e-04 - auc: 0.7263 - f2: 2.5808e-04 - fbeta2: 3.7063e-04 - val_loss: 0.3364 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7513 - val_f2: 0.0000e+00 - val_fbeta2: 6.0810e-11\n",
      "Epoch 3/1000\n",
      "68791/68791 - 2s - loss: 0.2930 - acc: 0.8736 - prec: 0.5324 - recall: 0.0591 - auc: 0.8439 - f2: 0.0593 - fbeta2: 0.0718 - val_loss: 0.2934 - val_acc: 0.8725 - val_prec: 0.2022 - val_recall: 5.1395e-04 - val_auc: 0.8696 - val_f2: 6.7428e-04 - val_fbeta2: 6.4518e-04\n",
      "Epoch 4/1000\n",
      "68791/68791 - 2s - loss: 0.2596 - acc: 0.8827 - prec: 0.6183 - recall: 0.2061 - auc: 0.8837 - f2: 0.1564 - fbeta2: 0.2384 - val_loss: 0.2699 - val_acc: 0.8795 - val_prec: 0.6963 - val_recall: 0.0943 - val_auc: 0.8820 - val_f2: 0.1152 - val_fbeta2: 0.1140\n",
      "Epoch 5/1000\n",
      "68791/68791 - 2s - loss: 0.2488 - acc: 0.8855 - prec: 0.6159 - recall: 0.2675 - auc: 0.8950 - f2: 0.1932 - fbeta2: 0.3019 - val_loss: 0.2528 - val_acc: 0.8792 - val_prec: 0.6410 - val_recall: 0.1151 - val_auc: 0.8961 - val_f2: 0.1280 - val_fbeta2: 0.1376\n",
      "Epoch 6/1000\n",
      "68791/68791 - 2s - loss: 0.2399 - acc: 0.8863 - prec: 0.6065 - recall: 0.3065 - auc: 0.9041 - f2: 0.2210 - fbeta2: 0.3398 - val_loss: 0.2492 - val_acc: 0.8813 - val_prec: 0.6029 - val_recall: 0.1966 - val_auc: 0.8965 - val_f2: 0.1764 - val_fbeta2: 0.2271\n",
      "Epoch 7/1000\n",
      "68791/68791 - 2s - loss: 0.2349 - acc: 0.8877 - prec: 0.6087 - recall: 0.3320 - auc: 0.9088 - f2: 0.2419 - fbeta2: 0.3646 - val_loss: 0.2363 - val_acc: 0.8869 - val_prec: 0.6087 - val_recall: 0.3123 - val_auc: 0.9079 - val_f2: 0.2573 - val_fbeta2: 0.3456\n",
      "Epoch 8/1000\n",
      "68791/68791 - 2s - loss: 0.2297 - acc: 0.8900 - prec: 0.6169 - recall: 0.3592 - auc: 0.9134 - f2: 0.2620 - fbeta2: 0.3929 - val_loss: 0.2240 - val_acc: 0.8932 - val_prec: 0.6336 - val_recall: 0.3807 - val_auc: 0.9184 - val_f2: 0.2847 - val_fbeta2: 0.4136\n",
      "Epoch 9/1000\n",
      "68791/68791 - 2s - loss: 0.2266 - acc: 0.8914 - prec: 0.6208 - recall: 0.3787 - auc: 0.9162 - f2: 0.2785 - fbeta2: 0.4107 - val_loss: 0.2422 - val_acc: 0.8817 - val_prec: 0.5614 - val_recall: 0.3232 - val_auc: 0.9012 - val_f2: 0.2353 - val_fbeta2: 0.3531\n",
      "Epoch 10/1000\n",
      "68791/68791 - 2s - loss: 0.2242 - acc: 0.8922 - prec: 0.6209 - recall: 0.3936 - auc: 0.9182 - f2: 0.2898 - fbeta2: 0.4244 - val_loss: 0.2341 - val_acc: 0.8865 - val_prec: 0.5903 - val_recall: 0.3535 - val_auc: 0.9095 - val_f2: 0.2803 - val_fbeta2: 0.3841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "68791/68791 - 2s - loss: 0.2225 - acc: 0.8926 - prec: 0.6197 - recall: 0.4050 - auc: 0.9196 - f2: 0.3079 - fbeta2: 0.4340 - val_loss: 0.2225 - val_acc: 0.8932 - val_prec: 0.6269 - val_recall: 0.3981 - val_auc: 0.9199 - val_f2: 0.2869 - val_fbeta2: 0.4293\n",
      "Epoch 12/1000\n",
      "68791/68791 - 2s - loss: 0.2201 - acc: 0.8941 - prec: 0.6258 - recall: 0.4187 - auc: 0.9217 - f2: 0.3151 - fbeta2: 0.4474 - val_loss: 0.2181 - val_acc: 0.8958 - val_prec: 0.6303 - val_recall: 0.4381 - val_auc: 0.9233 - val_f2: 0.3285 - val_fbeta2: 0.4665\n",
      "Epoch 13/1000\n",
      "68791/68791 - 2s - loss: 0.2188 - acc: 0.8947 - prec: 0.6279 - recall: 0.4255 - auc: 0.9228 - f2: 0.3216 - fbeta2: 0.4538 - val_loss: 0.2168 - val_acc: 0.8956 - val_prec: 0.6146 - val_recall: 0.4814 - val_auc: 0.9242 - val_f2: 0.3430 - val_fbeta2: 0.5030\n",
      "Epoch 14/1000\n",
      "68791/68791 - 2s - loss: 0.2164 - acc: 0.8959 - prec: 0.6310 - recall: 0.4401 - auc: 0.9246 - f2: 0.3317 - fbeta2: 0.4682 - val_loss: 0.2228 - val_acc: 0.8938 - val_prec: 0.6110 - val_recall: 0.4549 - val_auc: 0.9194 - val_f2: 0.3706 - val_fbeta2: 0.4792\n",
      "Epoch 15/1000\n",
      "68791/68791 - 2s - loss: 0.2153 - acc: 0.8967 - prec: 0.6354 - recall: 0.4442 - auc: 0.9256 - f2: 0.3397 - fbeta2: 0.4722 - val_loss: 0.2321 - val_acc: 0.8873 - val_prec: 0.5814 - val_recall: 0.4085 - val_auc: 0.9108 - val_f2: 0.2969 - val_fbeta2: 0.4343\n",
      "Epoch 16/1000\n",
      "68791/68791 - 2s - loss: 0.2142 - acc: 0.8970 - prec: 0.6372 - recall: 0.4444 - auc: 0.9265 - f2: 0.3421 - fbeta2: 0.4732 - val_loss: 0.2149 - val_acc: 0.8976 - val_prec: 0.6423 - val_recall: 0.4419 - val_auc: 0.9258 - val_f2: 0.3566 - val_fbeta2: 0.4711\n",
      "Epoch 17/1000\n",
      "68791/68791 - 2s - loss: 0.2133 - acc: 0.8979 - prec: 0.6412 - recall: 0.4500 - auc: 0.9272 - f2: 0.3477 - fbeta2: 0.4793 - val_loss: 0.2149 - val_acc: 0.8967 - val_prec: 0.6189 - val_recall: 0.4909 - val_auc: 0.9258 - val_f2: 0.3416 - val_fbeta2: 0.5117\n",
      "Epoch 18/1000\n",
      "68791/68791 - 2s - loss: 0.2138 - acc: 0.8972 - prec: 0.6363 - recall: 0.4501 - auc: 0.9269 - f2: 0.3470 - fbeta2: 0.4786 - val_loss: 0.2105 - val_acc: 0.8993 - val_prec: 0.6411 - val_recall: 0.4737 - val_auc: 0.9294 - val_f2: 0.3396 - val_fbeta2: 0.4996\n",
      "Epoch 19/1000\n",
      "68791/68791 - 2s - loss: 0.2111 - acc: 0.8986 - prec: 0.6421 - recall: 0.4601 - auc: 0.9290 - f2: 0.3573 - fbeta2: 0.4875 - val_loss: 0.2098 - val_acc: 0.8995 - val_prec: 0.6557 - val_recall: 0.4439 - val_auc: 0.9300 - val_f2: 0.3421 - val_fbeta2: 0.4743\n",
      "Epoch 20/1000\n",
      "68791/68791 - 2s - loss: 0.2103 - acc: 0.8992 - prec: 0.6443 - recall: 0.4661 - auc: 0.9297 - f2: 0.3638 - fbeta2: 0.4931 - val_loss: 0.2131 - val_acc: 0.8979 - val_prec: 0.6651 - val_recall: 0.3987 - val_auc: 0.9278 - val_f2: 0.3165 - val_fbeta2: 0.4333\n",
      "Epoch 21/1000\n",
      "68791/68791 - 2s - loss: 0.2094 - acc: 0.8995 - prec: 0.6459 - recall: 0.4668 - auc: 0.9303 - f2: 0.3660 - fbeta2: 0.4927 - val_loss: 0.2076 - val_acc: 0.9005 - val_prec: 0.6332 - val_recall: 0.5189 - val_auc: 0.9318 - val_f2: 0.3596 - val_fbeta2: 0.5381\n",
      "Epoch 22/1000\n",
      "68791/68791 - 2s - loss: 0.2081 - acc: 0.9000 - prec: 0.6451 - recall: 0.4775 - auc: 0.9313 - f2: 0.3683 - fbeta2: 0.5031 - val_loss: 0.2091 - val_acc: 0.9003 - val_prec: 0.6548 - val_recall: 0.4574 - val_auc: 0.9303 - val_f2: 0.3232 - val_fbeta2: 0.4864\n",
      "Epoch 23/1000\n",
      "68791/68791 - 2s - loss: 0.2071 - acc: 0.9008 - prec: 0.6481 - recall: 0.4840 - auc: 0.9321 - f2: 0.3841 - fbeta2: 0.5093 - val_loss: 0.2058 - val_acc: 0.9021 - val_prec: 0.6725 - val_recall: 0.4498 - val_auc: 0.9332 - val_f2: 0.3150 - val_fbeta2: 0.4815\n",
      "Epoch 24/1000\n",
      "68791/68791 - 2s - loss: 0.2070 - acc: 0.9004 - prec: 0.6458 - recall: 0.4835 - auc: 0.9322 - f2: 0.3821 - fbeta2: 0.5094 - val_loss: 0.2049 - val_acc: 0.9016 - val_prec: 0.6327 - val_recall: 0.5414 - val_auc: 0.9339 - val_f2: 0.4264 - val_fbeta2: 0.5574\n",
      "Epoch 25/1000\n",
      "68791/68791 - 2s - loss: 0.2062 - acc: 0.9011 - prec: 0.6491 - recall: 0.4870 - auc: 0.9327 - f2: 0.3850 - fbeta2: 0.5121 - val_loss: 0.2045 - val_acc: 0.9024 - val_prec: 0.6493 - val_recall: 0.5067 - val_auc: 0.9339 - val_f2: 0.3625 - val_fbeta2: 0.5298\n",
      "Epoch 26/1000\n",
      "68791/68791 - 2s - loss: 0.2048 - acc: 0.9018 - prec: 0.6516 - recall: 0.4923 - auc: 0.9338 - f2: 0.3858 - fbeta2: 0.5169 - val_loss: 0.2119 - val_acc: 0.8982 - val_prec: 0.6391 - val_recall: 0.4605 - val_auc: 0.9283 - val_f2: 0.3377 - val_fbeta2: 0.4874\n",
      "Epoch 27/1000\n",
      "68791/68791 - 2s - loss: 0.2052 - acc: 0.9017 - prec: 0.6493 - recall: 0.4954 - auc: 0.9336 - f2: 0.3946 - fbeta2: 0.5200 - val_loss: 0.2057 - val_acc: 0.9022 - val_prec: 0.6513 - val_recall: 0.4989 - val_auc: 0.9330 - val_f2: 0.3614 - val_fbeta2: 0.5231\n",
      "Epoch 28/1000\n",
      "68791/68791 - 2s - loss: 0.2038 - acc: 0.9025 - prec: 0.6525 - recall: 0.5010 - auc: 0.9346 - f2: 0.4009 - fbeta2: 0.5253 - val_loss: 0.2045 - val_acc: 0.9021 - val_prec: 0.6341 - val_recall: 0.5450 - val_auc: 0.9342 - val_f2: 0.4455 - val_fbeta2: 0.5607\n",
      "Epoch 29/1000\n",
      "68791/68791 - 2s - loss: 0.2041 - acc: 0.9020 - prec: 0.6510 - recall: 0.4971 - auc: 0.9344 - f2: 0.3994 - fbeta2: 0.5217 - val_loss: 0.2023 - val_acc: 0.9036 - val_prec: 0.6572 - val_recall: 0.5070 - val_auc: 0.9356 - val_f2: 0.3951 - val_fbeta2: 0.5311\n",
      "Epoch 30/1000\n",
      "68791/68791 - 2s - loss: 0.2023 - acc: 0.9030 - prec: 0.6545 - recall: 0.5053 - auc: 0.9357 - f2: 0.4068 - fbeta2: 0.5293 - val_loss: 0.2028 - val_acc: 0.9034 - val_prec: 0.6499 - val_recall: 0.5217 - val_auc: 0.9351 - val_f2: 0.4122 - val_fbeta2: 0.5429\n",
      "Epoch 31/1000\n",
      "68791/68791 - 2s - loss: 0.2022 - acc: 0.9033 - prec: 0.6553 - recall: 0.5082 - auc: 0.9358 - f2: 0.4077 - fbeta2: 0.5320 - val_loss: 0.2099 - val_acc: 0.8991 - val_prec: 0.6333 - val_recall: 0.4923 - val_auc: 0.9300 - val_f2: 0.3655 - val_fbeta2: 0.5149\n",
      "Epoch 32/1000\n",
      "68791/68791 - 2s - loss: 0.2015 - acc: 0.9037 - prec: 0.6563 - recall: 0.5119 - auc: 0.9363 - f2: 0.4171 - fbeta2: 0.5351 - val_loss: 0.2053 - val_acc: 0.9019 - val_prec: 0.6488 - val_recall: 0.5002 - val_auc: 0.9334 - val_f2: 0.4177 - val_fbeta2: 0.5241\n",
      "Epoch 33/1000\n",
      "68791/68791 - 2s - loss: 0.2016 - acc: 0.9036 - prec: 0.6564 - recall: 0.5101 - auc: 0.9362 - f2: 0.4099 - fbeta2: 0.5329 - val_loss: 0.2067 - val_acc: 0.9009 - val_prec: 0.6354 - val_recall: 0.5194 - val_auc: 0.9328 - val_f2: 0.3880 - val_fbeta2: 0.5389\n",
      "Epoch 34/1000\n",
      "68791/68791 - 2s - loss: 0.2009 - acc: 0.9038 - prec: 0.6565 - recall: 0.5129 - auc: 0.9368 - f2: 0.4142 - fbeta2: 0.5365 - val_loss: 0.2037 - val_acc: 0.9027 - val_prec: 0.6496 - val_recall: 0.5112 - val_auc: 0.9347 - val_f2: 0.3960 - val_fbeta2: 0.5337\n",
      "Epoch 35/1000\n",
      "68791/68791 - 2s - loss: 0.1997 - acc: 0.9045 - prec: 0.6584 - recall: 0.5197 - auc: 0.9376 - f2: 0.4184 - fbeta2: 0.5410 - val_loss: 0.2004 - val_acc: 0.9048 - val_prec: 0.6556 - val_recall: 0.5312 - val_auc: 0.9374 - val_f2: 0.4387 - val_fbeta2: 0.5520\n",
      "Epoch 36/1000\n",
      "68791/68791 - 2s - loss: 0.2002 - acc: 0.9044 - prec: 0.6568 - recall: 0.5225 - auc: 0.9373 - f2: 0.4258 - fbeta2: 0.5446 - val_loss: 0.2028 - val_acc: 0.9023 - val_prec: 0.6587 - val_recall: 0.4829 - val_auc: 0.9353 - val_f2: 0.4157 - val_fbeta2: 0.5099\n",
      "Epoch 37/1000\n",
      "68791/68791 - 2s - loss: 0.1989 - acc: 0.9048 - prec: 0.6602 - recall: 0.5209 - auc: 0.9382 - f2: 0.4222 - fbeta2: 0.5436 - val_loss: 0.2007 - val_acc: 0.9044 - val_prec: 0.6539 - val_recall: 0.5291 - val_auc: 0.9368 - val_f2: 0.4028 - val_fbeta2: 0.5499\n",
      "Epoch 38/1000\n",
      "68791/68791 - 2s - loss: 0.1976 - acc: 0.9057 - prec: 0.6611 - recall: 0.5330 - auc: 0.9391 - f2: 0.4380 - fbeta2: 0.5548 - val_loss: 0.2040 - val_acc: 0.9018 - val_prec: 0.6389 - val_recall: 0.5251 - val_auc: 0.9344 - val_f2: 0.4197 - val_fbeta2: 0.5442\n",
      "Epoch 39/1000\n",
      "68791/68791 - 2s - loss: 0.1981 - acc: 0.9053 - prec: 0.6598 - recall: 0.5295 - auc: 0.9388 - f2: 0.4359 - fbeta2: 0.5510 - val_loss: 0.1996 - val_acc: 0.9046 - val_prec: 0.6484 - val_recall: 0.5480 - val_auc: 0.9376 - val_f2: 0.4044 - val_fbeta2: 0.5653\n",
      "Epoch 40/1000\n",
      "68791/68791 - 2s - loss: 0.1970 - acc: 0.9061 - prec: 0.6635 - recall: 0.5337 - auc: 0.9396 - f2: 0.4372 - fbeta2: 0.5550 - val_loss: 0.1993 - val_acc: 0.9046 - val_prec: 0.6417 - val_recall: 0.5676 - val_auc: 0.9379 - val_f2: 0.4740 - val_fbeta2: 0.5807\n",
      "Epoch 41/1000\n",
      "68791/68791 - 2s - loss: 0.1970 - acc: 0.9061 - prec: 0.6612 - recall: 0.5385 - auc: 0.9396 - f2: 0.4384 - fbeta2: 0.5586 - val_loss: 0.1987 - val_acc: 0.9050 - val_prec: 0.6506 - val_recall: 0.5477 - val_auc: 0.9384 - val_f2: 0.4381 - val_fbeta2: 0.5654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "68791/68791 - 2s - loss: 0.1963 - acc: 0.9062 - prec: 0.6625 - recall: 0.5377 - auc: 0.9401 - f2: 0.4457 - fbeta2: 0.5580 - val_loss: 0.2021 - val_acc: 0.9033 - val_prec: 0.6571 - val_recall: 0.5026 - val_auc: 0.9358 - val_f2: 0.4146 - val_fbeta2: 0.5273\n",
      "Epoch 43/1000\n",
      "68791/68791 - 2s - loss: 0.1955 - acc: 0.9067 - prec: 0.6643 - recall: 0.5412 - auc: 0.9406 - f2: 0.4435 - fbeta2: 0.5613 - val_loss: 0.1984 - val_acc: 0.9061 - val_prec: 0.6607 - val_recall: 0.5384 - val_auc: 0.9385 - val_f2: 0.4085 - val_fbeta2: 0.5590\n",
      "Epoch 44/1000\n",
      "68791/68791 - 2s - loss: 0.1949 - acc: 0.9072 - prec: 0.6661 - recall: 0.5437 - auc: 0.9411 - f2: 0.4462 - fbeta2: 0.5644 - val_loss: 0.1998 - val_acc: 0.9046 - val_prec: 0.6628 - val_recall: 0.5092 - val_auc: 0.9375 - val_f2: 0.4033 - val_fbeta2: 0.5337\n",
      "Epoch 45/1000\n",
      "68791/68791 - 2s - loss: 0.1945 - acc: 0.9073 - prec: 0.6654 - recall: 0.5472 - auc: 0.9413 - f2: 0.4524 - fbeta2: 0.5668 - val_loss: 0.1991 - val_acc: 0.9054 - val_prec: 0.6670 - val_recall: 0.5121 - val_auc: 0.9381 - val_f2: 0.4166 - val_fbeta2: 0.5368\n",
      "Epoch 46/1000\n",
      "68791/68791 - 2s - loss: 0.1937 - acc: 0.9079 - prec: 0.6674 - recall: 0.5512 - auc: 0.9419 - f2: 0.4573 - fbeta2: 0.5698 - val_loss: 0.2026 - val_acc: 0.9024 - val_prec: 0.6475 - val_recall: 0.5116 - val_auc: 0.9357 - val_f2: 0.4455 - val_fbeta2: 0.5338\n",
      "Epoch 47/1000\n",
      "68791/68791 - 2s - loss: 0.1935 - acc: 0.9079 - prec: 0.6670 - recall: 0.5527 - auc: 0.9421 - f2: 0.4537 - fbeta2: 0.5714 - val_loss: 0.1989 - val_acc: 0.9051 - val_prec: 0.6568 - val_recall: 0.5328 - val_auc: 0.9382 - val_f2: 0.4447 - val_fbeta2: 0.5536\n",
      "Epoch 48/1000\n",
      "68791/68791 - 2s - loss: 0.1928 - acc: 0.9083 - prec: 0.6682 - recall: 0.5563 - auc: 0.9426 - f2: 0.4654 - fbeta2: 0.5757 - val_loss: 0.1999 - val_acc: 0.9048 - val_prec: 0.6480 - val_recall: 0.5514 - val_auc: 0.9376 - val_f2: 0.4609 - val_fbeta2: 0.5682\n",
      "Epoch 49/1000\n",
      "68791/68791 - 2s - loss: 0.1920 - acc: 0.9089 - prec: 0.6705 - recall: 0.5594 - auc: 0.9431 - f2: 0.4631 - fbeta2: 0.5783 - val_loss: 0.1986 - val_acc: 0.9052 - val_prec: 0.6376 - val_recall: 0.5919 - val_auc: 0.9388 - val_f2: 0.4887 - val_fbeta2: 0.6003\n",
      "Epoch 50/1000\n",
      "68791/68791 - 2s - loss: 0.1920 - acc: 0.9089 - prec: 0.6692 - recall: 0.5625 - auc: 0.9431 - f2: 0.4705 - fbeta2: 0.5812 - val_loss: 0.1986 - val_acc: 0.9057 - val_prec: 0.6772 - val_recall: 0.4954 - val_auc: 0.9387 - val_f2: 0.3816 - val_fbeta2: 0.5233\n",
      "Epoch 51/1000\n",
      "68791/68791 - 2s - loss: 0.1916 - acc: 0.9089 - prec: 0.6697 - recall: 0.5614 - auc: 0.9434 - f2: 0.4679 - fbeta2: 0.5803 - val_loss: 0.1973 - val_acc: 0.9062 - val_prec: 0.6588 - val_recall: 0.5451 - val_auc: 0.9394 - val_f2: 0.4130 - val_fbeta2: 0.5644\n",
      "Epoch 52/1000\n",
      "68791/68791 - 2s - loss: 0.1904 - acc: 0.9097 - prec: 0.6734 - recall: 0.5659 - auc: 0.9441 - f2: 0.4717 - fbeta2: 0.5847 - val_loss: 0.1980 - val_acc: 0.9056 - val_prec: 0.6433 - val_recall: 0.5791 - val_auc: 0.9390 - val_f2: 0.4790 - val_fbeta2: 0.5906\n",
      "Epoch 53/1000\n",
      "68791/68791 - 2s - loss: 0.1904 - acc: 0.9097 - prec: 0.6721 - recall: 0.5689 - auc: 0.9441 - f2: 0.4714 - fbeta2: 0.5870 - val_loss: 0.2100 - val_acc: 0.9001 - val_prec: 0.6246 - val_recall: 0.5388 - val_auc: 0.9315 - val_f2: 0.4141 - val_fbeta2: 0.5536\n",
      "Epoch 54/1000\n",
      "68791/68791 - 2s - loss: 0.1905 - acc: 0.9096 - prec: 0.6729 - recall: 0.5646 - auc: 0.9442 - f2: 0.4705 - fbeta2: 0.5836 - val_loss: 0.1972 - val_acc: 0.9063 - val_prec: 0.6477 - val_recall: 0.5778 - val_auc: 0.9395 - val_f2: 0.5007 - val_fbeta2: 0.5903\n",
      "Epoch 55/1000\n",
      "68791/68791 - 2s - loss: 0.1895 - acc: 0.9100 - prec: 0.6726 - recall: 0.5722 - auc: 0.9447 - f2: 0.4771 - fbeta2: 0.5896 - val_loss: 0.1983 - val_acc: 0.9057 - val_prec: 0.6474 - val_recall: 0.5684 - val_auc: 0.9388 - val_f2: 0.4507 - val_fbeta2: 0.5823\n",
      "Epoch 56/1000\n",
      "68791/68791 - 2s - loss: 0.1886 - acc: 0.9104 - prec: 0.6731 - recall: 0.5765 - auc: 0.9453 - f2: 0.4839 - fbeta2: 0.5939 - val_loss: 0.1984 - val_acc: 0.9059 - val_prec: 0.6376 - val_recall: 0.6036 - val_auc: 0.9394 - val_f2: 0.4971 - val_fbeta2: 0.6099\n",
      "Epoch 57/1000\n",
      "68791/68791 - 2s - loss: 0.1885 - acc: 0.9105 - prec: 0.6735 - recall: 0.5774 - auc: 0.9455 - f2: 0.4864 - fbeta2: 0.5947 - val_loss: 0.1960 - val_acc: 0.9075 - val_prec: 0.6643 - val_recall: 0.5526 - val_auc: 0.9402 - val_f2: 0.4657 - val_fbeta2: 0.5716\n",
      "Epoch 58/1000\n",
      "68791/68791 - 2s - loss: 0.1877 - acc: 0.9111 - prec: 0.6763 - recall: 0.5789 - auc: 0.9459 - f2: 0.4866 - fbeta2: 0.5965 - val_loss: 0.2000 - val_acc: 0.9047 - val_prec: 0.6516 - val_recall: 0.5399 - val_auc: 0.9376 - val_f2: 0.4377 - val_fbeta2: 0.5588\n",
      "Epoch 59/1000\n",
      "68791/68791 - 2s - loss: 0.1875 - acc: 0.9110 - prec: 0.6755 - recall: 0.5799 - auc: 0.9460 - f2: 0.4897 - fbeta2: 0.5967 - val_loss: 0.1967 - val_acc: 0.9066 - val_prec: 0.6523 - val_recall: 0.5704 - val_auc: 0.9397 - val_f2: 0.4573 - val_fbeta2: 0.5849\n",
      "Epoch 60/1000\n",
      "68791/68791 - 2s - loss: 0.1868 - acc: 0.9115 - prec: 0.6773 - recall: 0.5823 - auc: 0.9465 - f2: 0.4933 - fbeta2: 0.5992 - val_loss: 0.1961 - val_acc: 0.9070 - val_prec: 0.6600 - val_recall: 0.5561 - val_auc: 0.9401 - val_f2: 0.4595 - val_fbeta2: 0.5739\n",
      "Epoch 61/1000\n",
      "68791/68791 - 2s - loss: 0.1855 - acc: 0.9122 - prec: 0.6790 - recall: 0.5893 - auc: 0.9473 - f2: 0.4984 - fbeta2: 0.6054 - val_loss: 0.1981 - val_acc: 0.9062 - val_prec: 0.6570 - val_recall: 0.5504 - val_auc: 0.9386 - val_f2: 0.4595 - val_fbeta2: 0.5687\n",
      "Epoch 62/1000\n",
      "68791/68791 - 2s - loss: 0.1862 - acc: 0.9119 - prec: 0.6772 - recall: 0.5897 - auc: 0.9470 - f2: 0.4976 - fbeta2: 0.6053 - val_loss: 0.1959 - val_acc: 0.9074 - val_prec: 0.6526 - val_recall: 0.5829 - val_auc: 0.9407 - val_f2: 0.4763 - val_fbeta2: 0.5954\n",
      "Epoch 63/1000\n",
      "68791/68791 - 2s - loss: 0.1845 - acc: 0.9130 - prec: 0.6816 - recall: 0.5955 - auc: 0.9480 - f2: 0.5050 - fbeta2: 0.6107 - val_loss: 0.1992 - val_acc: 0.9056 - val_prec: 0.6438 - val_recall: 0.5782 - val_auc: 0.9383 - val_f2: 0.5006 - val_fbeta2: 0.5900\n",
      "Epoch 64/1000\n",
      "68791/68791 - 2s - loss: 0.1857 - acc: 0.9121 - prec: 0.6769 - recall: 0.5923 - auc: 0.9472 - f2: 0.5010 - fbeta2: 0.6072 - val_loss: 0.1985 - val_acc: 0.9054 - val_prec: 0.6464 - val_recall: 0.5665 - val_auc: 0.9385 - val_f2: 0.4752 - val_fbeta2: 0.5806\n",
      "Epoch 65/1000\n",
      "68791/68791 - 2s - loss: 0.1836 - acc: 0.9135 - prec: 0.6830 - recall: 0.5991 - auc: 0.9486 - f2: 0.5076 - fbeta2: 0.6144 - val_loss: 0.1996 - val_acc: 0.9052 - val_prec: 0.6504 - val_recall: 0.5516 - val_auc: 0.9378 - val_f2: 0.4887 - val_fbeta2: 0.5688\n",
      "Epoch 66/1000\n",
      "68791/68791 - 2s - loss: 0.1839 - acc: 0.9129 - prec: 0.6806 - recall: 0.5961 - auc: 0.9484 - f2: 0.5094 - fbeta2: 0.6112 - val_loss: 0.1985 - val_acc: 0.9060 - val_prec: 0.6460 - val_recall: 0.5792 - val_auc: 0.9386 - val_f2: 0.4925 - val_fbeta2: 0.5911\n",
      "Epoch 67/1000\n",
      "68791/68791 - 2s - loss: 0.1830 - acc: 0.9137 - prec: 0.6824 - recall: 0.6024 - auc: 0.9489 - f2: 0.5180 - fbeta2: 0.6169 - val_loss: 0.2005 - val_acc: 0.9054 - val_prec: 0.6477 - val_recall: 0.5635 - val_auc: 0.9376 - val_f2: 0.4450 - val_fbeta2: 0.5783\n",
      "Epoch 68/1000\n",
      "68791/68791 - 2s - loss: 0.1825 - acc: 0.9139 - prec: 0.6827 - recall: 0.6047 - auc: 0.9492 - f2: 0.5152 - fbeta2: 0.6180 - val_loss: 0.1969 - val_acc: 0.9070 - val_prec: 0.6587 - val_recall: 0.5585 - val_auc: 0.9396 - val_f2: 0.4684 - val_fbeta2: 0.5758\n",
      "Epoch 69/1000\n",
      "68791/68791 - 2s - loss: 0.1818 - acc: 0.9144 - prec: 0.6844 - recall: 0.6085 - auc: 0.9497 - f2: 0.5174 - fbeta2: 0.6226 - val_loss: 0.1995 - val_acc: 0.9055 - val_prec: 0.6546 - val_recall: 0.5457 - val_auc: 0.9378 - val_f2: 0.4530 - val_fbeta2: 0.5642\n",
      "Epoch 70/1000\n",
      "68791/68791 - 2s - loss: 0.1821 - acc: 0.9140 - prec: 0.6838 - recall: 0.6045 - auc: 0.9494 - f2: 0.5205 - fbeta2: 0.6195 - val_loss: 0.1980 - val_acc: 0.9067 - val_prec: 0.6517 - val_recall: 0.5742 - val_auc: 0.9390 - val_f2: 0.4772 - val_fbeta2: 0.5879\n",
      "Epoch 71/1000\n",
      "68791/68791 - 2s - loss: 0.1808 - acc: 0.9149 - prec: 0.6859 - recall: 0.6126 - auc: 0.9503 - f2: 0.5238 - fbeta2: 0.6264 - val_loss: 0.1995 - val_acc: 0.9056 - val_prec: 0.6473 - val_recall: 0.5676 - val_auc: 0.9382 - val_f2: 0.4586 - val_fbeta2: 0.5817\n",
      "Epoch 72/1000\n",
      "68791/68791 - 2s - loss: 0.1809 - acc: 0.9150 - prec: 0.6867 - recall: 0.6120 - auc: 0.9503 - f2: 0.5293 - fbeta2: 0.6258 - val_loss: 0.1993 - val_acc: 0.9057 - val_prec: 0.6447 - val_recall: 0.5765 - val_auc: 0.9382 - val_f2: 0.5064 - val_fbeta2: 0.5887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17198/17198 [==============================] - ETA: 5s - loss: 0.2182 - acc: 0.9043 - prec: 0.5926 - recall: 0.5424 - auc: 0.9154 - f2: 0.2972 - fbeta2: 0.551 - ETA: 2s - loss: 0.1973 - acc: 0.9072 - prec: 0.6506 - recall: 0.5857 - auc: 0.9386 - f2: 0.4009 - fbeta2: 0.595 - ETA: 2s - loss: 0.1974 - acc: 0.9072 - prec: 0.6498 - recall: 0.5769 - auc: 0.9385 - f2: 0.4090 - fbeta2: 0.589 - ETA: 2s - loss: 0.1984 - acc: 0.9071 - prec: 0.6569 - recall: 0.5793 - auc: 0.9390 - f2: 0.4220 - fbeta2: 0.592 - ETA: 2s - loss: 0.1985 - acc: 0.9062 - prec: 0.6498 - recall: 0.5793 - auc: 0.9389 - f2: 0.4208 - fbeta2: 0.590 - ETA: 2s - loss: 0.1973 - acc: 0.9064 - prec: 0.6517 - recall: 0.5785 - auc: 0.9398 - f2: 0.4114 - fbeta2: 0.590 - ETA: 2s - loss: 0.1961 - acc: 0.9070 - prec: 0.6533 - recall: 0.5817 - auc: 0.9405 - f2: 0.4160 - fbeta2: 0.593 - ETA: 2s - loss: 0.1966 - acc: 0.9070 - prec: 0.6513 - recall: 0.5828 - auc: 0.9403 - f2: 0.4168 - fbeta2: 0.593 - ETA: 2s - loss: 0.1974 - acc: 0.9068 - prec: 0.6492 - recall: 0.5843 - auc: 0.9397 - f2: 0.4174 - fbeta2: 0.595 - ETA: 2s - loss: 0.1993 - acc: 0.9061 - prec: 0.6477 - recall: 0.5821 - auc: 0.9387 - f2: 0.4161 - fbeta2: 0.593 - ETA: 2s - loss: 0.1994 - acc: 0.9058 - prec: 0.6472 - recall: 0.5814 - auc: 0.9388 - f2: 0.4183 - fbeta2: 0.592 - ETA: 1s - loss: 0.2006 - acc: 0.9052 - prec: 0.6431 - recall: 0.5797 - auc: 0.9379 - f2: 0.4154 - fbeta2: 0.590 - ETA: 1s - loss: 0.2004 - acc: 0.9053 - prec: 0.6421 - recall: 0.5799 - auc: 0.9379 - f2: 0.4148 - fbeta2: 0.590 - ETA: 1s - loss: 0.1993 - acc: 0.9057 - prec: 0.6427 - recall: 0.5814 - auc: 0.9385 - f2: 0.4155 - fbeta2: 0.591 - ETA: 1s - loss: 0.1990 - acc: 0.9057 - prec: 0.6423 - recall: 0.5814 - auc: 0.9386 - f2: 0.4145 - fbeta2: 0.591 - ETA: 1s - loss: 0.1989 - acc: 0.9057 - prec: 0.6423 - recall: 0.5808 - auc: 0.9386 - f2: 0.4121 - fbeta2: 0.591 - ETA: 1s - loss: 0.1990 - acc: 0.9056 - prec: 0.6415 - recall: 0.5792 - auc: 0.9384 - f2: 0.4120 - fbeta2: 0.589 - ETA: 1s - loss: 0.1988 - acc: 0.9057 - prec: 0.6425 - recall: 0.5792 - auc: 0.9386 - f2: 0.4124 - fbeta2: 0.590 - ETA: 1s - loss: 0.1987 - acc: 0.9057 - prec: 0.6423 - recall: 0.5796 - auc: 0.9387 - f2: 0.4127 - fbeta2: 0.590 - ETA: 1s - loss: 0.1990 - acc: 0.9057 - prec: 0.6428 - recall: 0.5790 - auc: 0.9384 - f2: 0.4132 - fbeta2: 0.590 - ETA: 1s - loss: 0.1986 - acc: 0.9059 - prec: 0.6431 - recall: 0.5801 - auc: 0.9387 - f2: 0.4149 - fbeta2: 0.591 - ETA: 1s - loss: 0.1982 - acc: 0.9060 - prec: 0.6437 - recall: 0.5804 - auc: 0.9390 - f2: 0.4152 - fbeta2: 0.591 - ETA: 1s - loss: 0.1980 - acc: 0.9061 - prec: 0.6449 - recall: 0.5804 - auc: 0.9392 - f2: 0.4150 - fbeta2: 0.591 - ETA: 1s - loss: 0.1982 - acc: 0.9060 - prec: 0.6447 - recall: 0.5792 - auc: 0.9391 - f2: 0.4130 - fbeta2: 0.590 - ETA: 1s - loss: 0.1982 - acc: 0.9058 - prec: 0.6445 - recall: 0.5787 - auc: 0.9391 - f2: 0.4124 - fbeta2: 0.590 - ETA: 1s - loss: 0.1982 - acc: 0.9060 - prec: 0.6456 - recall: 0.5786 - auc: 0.9391 - f2: 0.4114 - fbeta2: 0.590 - ETA: 1s - loss: 0.1980 - acc: 0.9060 - prec: 0.6456 - recall: 0.5785 - auc: 0.9393 - f2: 0.4110 - fbeta2: 0.590 - ETA: 1s - loss: 0.1981 - acc: 0.9060 - prec: 0.6435 - recall: 0.5787 - auc: 0.9390 - f2: 0.4107 - fbeta2: 0.590 - ETA: 1s - loss: 0.1974 - acc: 0.9063 - prec: 0.6458 - recall: 0.5800 - auc: 0.9395 - f2: 0.4124 - fbeta2: 0.591 - ETA: 0s - loss: 0.1974 - acc: 0.9062 - prec: 0.6459 - recall: 0.5795 - auc: 0.9396 - f2: 0.4124 - fbeta2: 0.591 - ETA: 0s - loss: 0.1973 - acc: 0.9063 - prec: 0.6461 - recall: 0.5798 - auc: 0.9396 - f2: 0.4130 - fbeta2: 0.591 - ETA: 0s - loss: 0.1971 - acc: 0.9065 - prec: 0.6465 - recall: 0.5807 - auc: 0.9397 - f2: 0.4136 - fbeta2: 0.592 - ETA: 0s - loss: 0.1972 - acc: 0.9065 - prec: 0.6475 - recall: 0.5804 - auc: 0.9397 - f2: 0.4137 - fbeta2: 0.592 - ETA: 0s - loss: 0.1972 - acc: 0.9065 - prec: 0.6477 - recall: 0.5804 - auc: 0.9397 - f2: 0.4147 - fbeta2: 0.592 - ETA: 0s - loss: 0.1966 - acc: 0.9067 - prec: 0.6483 - recall: 0.5811 - auc: 0.9400 - f2: 0.4146 - fbeta2: 0.593 - ETA: 0s - loss: 0.1969 - acc: 0.9066 - prec: 0.6479 - recall: 0.5804 - auc: 0.9398 - f2: 0.4139 - fbeta2: 0.592 - ETA: 0s - loss: 0.1968 - acc: 0.9068 - prec: 0.6489 - recall: 0.5812 - auc: 0.9400 - f2: 0.4145 - fbeta2: 0.593 - ETA: 0s - loss: 0.1968 - acc: 0.9067 - prec: 0.6486 - recall: 0.5812 - auc: 0.9400 - f2: 0.4148 - fbeta2: 0.593 - ETA: 0s - loss: 0.1970 - acc: 0.9066 - prec: 0.6471 - recall: 0.5807 - auc: 0.9397 - f2: 0.4146 - fbeta2: 0.592 - ETA: 0s - loss: 0.1971 - acc: 0.9065 - prec: 0.6470 - recall: 0.5801 - auc: 0.9397 - f2: 0.4144 - fbeta2: 0.591 - ETA: 0s - loss: 0.1974 - acc: 0.9064 - prec: 0.6468 - recall: 0.5802 - auc: 0.9395 - f2: 0.4149 - fbeta2: 0.592 - ETA: 0s - loss: 0.1975 - acc: 0.9063 - prec: 0.6465 - recall: 0.5791 - auc: 0.9394 - f2: 0.4142 - fbeta2: 0.591 - ETA: 0s - loss: 0.1977 - acc: 0.9062 - prec: 0.6459 - recall: 0.5788 - auc: 0.9393 - f2: 0.4144 - fbeta2: 0.590 - ETA: 0s - loss: 0.1980 - acc: 0.9061 - prec: 0.6456 - recall: 0.5789 - auc: 0.9390 - f2: 0.4152 - fbeta2: 0.590 - ETA: 0s - loss: 0.1982 - acc: 0.9060 - prec: 0.6452 - recall: 0.5784 - auc: 0.9388 - f2: 0.4161 - fbeta2: 0.590 - ETA: 0s - loss: 0.1984 - acc: 0.9060 - prec: 0.6455 - recall: 0.5779 - auc: 0.9388 - f2: 0.4161 - fbeta2: 0.589 - ETA: 0s - loss: 0.1990 - acc: 0.9058 - prec: 0.6446 - recall: 0.5770 - auc: 0.9384 - f2: 0.4154 - fbeta2: 0.588 - 2s 145us/sample - loss: 0.1993 - acc: 0.9057 - prec: 0.6447 - recall: 0.5765 - auc: 0.9382 - f2: 0.4157 - fbeta2: 0.5884\n",
      "3\n",
      "Train on 68791 samples, validate on 17198 samples\n",
      "Epoch 1/1000\n",
      "68791/68791 - 5s - loss: 0.5577 - acc: 0.8299 - prec: 0.1366 - recall: 0.0629 - auc: 0.5281 - f2: 0.0366 - fbeta2: 0.0464 - val_loss: 0.3874 - val_acc: 0.8731 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7123 - val_f2: 0.0000e+00 - val_fbeta2: 6.1028e-11\n",
      "Epoch 2/1000\n",
      "68791/68791 - 2s - loss: 0.3507 - acc: 0.8724 - prec: 0.3525 - recall: 0.0015 - auc: 0.7262 - f2: 0.0012 - fbeta2: 0.0019 - val_loss: 0.3355 - val_acc: 0.8731 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7560 - val_f2: 0.0000e+00 - val_fbeta2: 6.1028e-11\n",
      "Epoch 3/1000\n",
      "68791/68791 - 2s - loss: 0.2972 - acc: 0.8729 - prec: 0.5135 - recall: 0.0520 - auc: 0.8369 - f2: 0.0555 - fbeta2: 0.0633 - val_loss: 0.2892 - val_acc: 0.8730 - val_prec: 0.4674 - val_recall: 0.0049 - val_auc: 0.8660 - val_f2: 0.0059 - val_fbeta2: 0.0061\n",
      "Epoch 4/1000\n",
      "68791/68791 - 2s - loss: 0.2614 - acc: 0.8816 - prec: 0.6080 - recall: 0.1989 - auc: 0.8818 - f2: 0.1525 - fbeta2: 0.2292 - val_loss: 0.2795 - val_acc: 0.8752 - val_prec: 0.5777 - val_recall: 0.0636 - val_auc: 0.8693 - val_f2: 0.0901 - val_fbeta2: 0.0773\n",
      "Epoch 5/1000\n",
      "68791/68791 - 2s - loss: 0.2536 - acc: 0.8834 - prec: 0.6025 - recall: 0.2502 - auc: 0.8896 - f2: 0.1824 - fbeta2: 0.2835 - val_loss: 0.2632 - val_acc: 0.8764 - val_prec: 0.7291 - val_recall: 0.0412 - val_auc: 0.8829 - val_f2: 0.0657 - val_fbeta2: 0.0507\n",
      "Epoch 6/1000\n",
      "68791/68791 - 2s - loss: 0.2445 - acc: 0.8859 - prec: 0.6099 - recall: 0.2905 - auc: 0.8991 - f2: 0.2073 - fbeta2: 0.3256 - val_loss: 0.2481 - val_acc: 0.8809 - val_prec: 0.6643 - val_recall: 0.1244 - val_auc: 0.8964 - val_f2: 0.1307 - val_fbeta2: 0.1483\n",
      "Epoch 7/1000\n",
      "68791/68791 - 2s - loss: 0.2356 - acc: 0.8883 - prec: 0.6133 - recall: 0.3335 - auc: 0.9080 - f2: 0.2409 - fbeta2: 0.3669 - val_loss: 0.2460 - val_acc: 0.8812 - val_prec: 0.5898 - val_recall: 0.2100 - val_auc: 0.8976 - val_f2: 0.1918 - val_fbeta2: 0.2409\n",
      "Epoch 8/1000\n",
      "68791/68791 - 2s - loss: 0.2311 - acc: 0.8896 - prec: 0.6126 - recall: 0.3642 - auc: 0.9121 - f2: 0.2605 - fbeta2: 0.3964 - val_loss: 0.2271 - val_acc: 0.8918 - val_prec: 0.6444 - val_recall: 0.3293 - val_auc: 0.9154 - val_f2: 0.2306 - val_fbeta2: 0.3651\n",
      "Epoch 9/1000\n",
      "68791/68791 - 2s - loss: 0.2283 - acc: 0.8904 - prec: 0.6156 - recall: 0.3729 - auc: 0.9146 - f2: 0.2707 - fbeta2: 0.4046 - val_loss: 0.2284 - val_acc: 0.8911 - val_prec: 0.6699 - val_recall: 0.2801 - val_auc: 0.9153 - val_f2: 0.2130 - val_fbeta2: 0.3169\n",
      "Epoch 10/1000\n",
      "68791/68791 - 2s - loss: 0.2254 - acc: 0.8916 - prec: 0.6187 - recall: 0.3888 - auc: 0.9171 - f2: 0.2814 - fbeta2: 0.4208 - val_loss: 0.2351 - val_acc: 0.8856 - val_prec: 0.5707 - val_recall: 0.3973 - val_auc: 0.9088 - val_f2: 0.2466 - val_fbeta2: 0.4230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "68791/68791 - 2s - loss: 0.2237 - acc: 0.8922 - prec: 0.6191 - recall: 0.4015 - auc: 0.9185 - f2: 0.2949 - fbeta2: 0.4313 - val_loss: 0.2170 - val_acc: 0.8957 - val_prec: 0.6358 - val_recall: 0.4167 - val_auc: 0.9237 - val_f2: 0.2900 - val_fbeta2: 0.4475\n",
      "Epoch 12/1000\n",
      "68791/68791 - 2s - loss: 0.2215 - acc: 0.8933 - prec: 0.6230 - recall: 0.4131 - auc: 0.9205 - f2: 0.3056 - fbeta2: 0.4424 - val_loss: 0.2178 - val_acc: 0.8964 - val_prec: 0.6740 - val_recall: 0.3564 - val_auc: 0.9239 - val_f2: 0.2442 - val_fbeta2: 0.3935\n",
      "Epoch 13/1000\n",
      "68791/68791 - 2s - loss: 0.2198 - acc: 0.8941 - prec: 0.6259 - recall: 0.4209 - auc: 0.9219 - f2: 0.3194 - fbeta2: 0.4511 - val_loss: 0.2161 - val_acc: 0.8963 - val_prec: 0.6213 - val_recall: 0.4695 - val_auc: 0.9245 - val_f2: 0.3308 - val_fbeta2: 0.4937\n",
      "Epoch 14/1000\n",
      "68791/68791 - 2s - loss: 0.2182 - acc: 0.8950 - prec: 0.6280 - recall: 0.4325 - auc: 0.9232 - f2: 0.3276 - fbeta2: 0.4611 - val_loss: 0.2151 - val_acc: 0.8964 - val_prec: 0.6227 - val_recall: 0.4668 - val_auc: 0.9255 - val_f2: 0.3623 - val_fbeta2: 0.4915\n",
      "Epoch 15/1000\n",
      "68791/68791 - 2s - loss: 0.2164 - acc: 0.8960 - prec: 0.6324 - recall: 0.4399 - auc: 0.9247 - f2: 0.3392 - fbeta2: 0.4683 - val_loss: 0.2140 - val_acc: 0.8985 - val_prec: 0.6346 - val_recall: 0.4731 - val_auc: 0.9263 - val_f2: 0.3870 - val_fbeta2: 0.4985\n",
      "Epoch 16/1000\n",
      "68791/68791 - 2s - loss: 0.2150 - acc: 0.8969 - prec: 0.6338 - recall: 0.4516 - auc: 0.9260 - f2: 0.3462 - fbeta2: 0.4774 - val_loss: 0.2185 - val_acc: 0.8946 - val_prec: 0.6117 - val_recall: 0.4655 - val_auc: 0.9229 - val_f2: 0.3114 - val_fbeta2: 0.4888\n",
      "Epoch 17/1000\n",
      "68791/68791 - 2s - loss: 0.2138 - acc: 0.8974 - prec: 0.6367 - recall: 0.4533 - auc: 0.9270 - f2: 0.3511 - fbeta2: 0.4803 - val_loss: 0.2126 - val_acc: 0.8988 - val_prec: 0.6433 - val_recall: 0.4557 - val_auc: 0.9278 - val_f2: 0.3587 - val_fbeta2: 0.4838\n",
      "Epoch 18/1000\n",
      "68791/68791 - 2s - loss: 0.2131 - acc: 0.8978 - prec: 0.6386 - recall: 0.4568 - auc: 0.9275 - f2: 0.3480 - fbeta2: 0.4843 - val_loss: 0.2107 - val_acc: 0.8998 - val_prec: 0.6435 - val_recall: 0.4724 - val_auc: 0.9289 - val_f2: 0.3383 - val_fbeta2: 0.4989\n",
      "Epoch 19/1000\n",
      "68791/68791 - 2s - loss: 0.2117 - acc: 0.8985 - prec: 0.6405 - recall: 0.4638 - auc: 0.9286 - f2: 0.3629 - fbeta2: 0.4910 - val_loss: 0.2125 - val_acc: 0.8982 - val_prec: 0.6382 - val_recall: 0.4581 - val_auc: 0.9277 - val_f2: 0.3307 - val_fbeta2: 0.4855\n",
      "Epoch 20/1000\n",
      "68791/68791 - 2s - loss: 0.2113 - acc: 0.8985 - prec: 0.6411 - recall: 0.4620 - auc: 0.9289 - f2: 0.3613 - fbeta2: 0.4885 - val_loss: 0.2083 - val_acc: 0.9003 - val_prec: 0.6595 - val_recall: 0.4443 - val_auc: 0.9308 - val_f2: 0.3433 - val_fbeta2: 0.4753\n",
      "Epoch 21/1000\n",
      "68791/68791 - 2s - loss: 0.2097 - acc: 0.8992 - prec: 0.6428 - recall: 0.4702 - auc: 0.9301 - f2: 0.3703 - fbeta2: 0.4971 - val_loss: 0.2145 - val_acc: 0.8967 - val_prec: 0.6245 - val_recall: 0.4665 - val_auc: 0.9259 - val_f2: 0.3381 - val_fbeta2: 0.4912\n",
      "Epoch 22/1000\n",
      "68791/68791 - 2s - loss: 0.2102 - acc: 0.8988 - prec: 0.6405 - recall: 0.4690 - auc: 0.9298 - f2: 0.3679 - fbeta2: 0.4947 - val_loss: 0.2077 - val_acc: 0.9010 - val_prec: 0.6508 - val_recall: 0.4744 - val_auc: 0.9313 - val_f2: 0.3405 - val_fbeta2: 0.5015\n",
      "Epoch 23/1000\n",
      "68791/68791 - 2s - loss: 0.2085 - acc: 0.9000 - prec: 0.6456 - recall: 0.4778 - auc: 0.9311 - f2: 0.3775 - fbeta2: 0.5038 - val_loss: 0.2062 - val_acc: 0.9013 - val_prec: 0.6573 - val_recall: 0.4646 - val_auc: 0.9323 - val_f2: 0.3210 - val_fbeta2: 0.4936\n",
      "Epoch 24/1000\n",
      "68791/68791 - 2s - loss: 0.2078 - acc: 0.9001 - prec: 0.6463 - recall: 0.4774 - auc: 0.9317 - f2: 0.3706 - fbeta2: 0.5032 - val_loss: 0.2075 - val_acc: 0.9009 - val_prec: 0.6434 - val_recall: 0.4923 - val_auc: 0.9313 - val_f2: 0.3958 - val_fbeta2: 0.5167\n",
      "Epoch 25/1000\n",
      "68791/68791 - 2s - loss: 0.2068 - acc: 0.9010 - prec: 0.6492 - recall: 0.4860 - auc: 0.9324 - f2: 0.3797 - fbeta2: 0.5111 - val_loss: 0.2114 - val_acc: 0.8999 - val_prec: 0.6313 - val_recall: 0.5084 - val_auc: 0.9292 - val_f2: 0.3952 - val_fbeta2: 0.5290\n",
      "Epoch 26/1000\n",
      "68791/68791 - 2s - loss: 0.2066 - acc: 0.9006 - prec: 0.6475 - recall: 0.4838 - auc: 0.9325 - f2: 0.3818 - fbeta2: 0.5096 - val_loss: 0.2052 - val_acc: 0.9022 - val_prec: 0.6605 - val_recall: 0.4730 - val_auc: 0.9332 - val_f2: 0.4045 - val_fbeta2: 0.5016\n",
      "Epoch 27/1000\n",
      "68791/68791 - 2s - loss: 0.2052 - acc: 0.9016 - prec: 0.6505 - recall: 0.4928 - auc: 0.9337 - f2: 0.3934 - fbeta2: 0.5174 - val_loss: 0.2039 - val_acc: 0.9028 - val_prec: 0.6522 - val_recall: 0.5013 - val_auc: 0.9341 - val_f2: 0.3573 - val_fbeta2: 0.5257\n",
      "Epoch 28/1000\n",
      "68791/68791 - 2s - loss: 0.2046 - acc: 0.9019 - prec: 0.6499 - recall: 0.4998 - auc: 0.9341 - f2: 0.4005 - fbeta2: 0.5236 - val_loss: 0.2041 - val_acc: 0.9027 - val_prec: 0.6573 - val_recall: 0.4875 - val_auc: 0.9341 - val_f2: 0.3800 - val_fbeta2: 0.5141\n",
      "Epoch 29/1000\n",
      "68791/68791 - 2s - loss: 0.2035 - acc: 0.9022 - prec: 0.6529 - recall: 0.4963 - auc: 0.9348 - f2: 0.3921 - fbeta2: 0.5213 - val_loss: 0.2023 - val_acc: 0.9039 - val_prec: 0.6562 - val_recall: 0.5099 - val_auc: 0.9354 - val_f2: 0.3828 - val_fbeta2: 0.5337\n",
      "Epoch 30/1000\n",
      "68791/68791 - 2s - loss: 0.2036 - acc: 0.9024 - prec: 0.6518 - recall: 0.5023 - auc: 0.9348 - f2: 0.4022 - fbeta2: 0.5267 - val_loss: 0.2040 - val_acc: 0.9021 - val_prec: 0.6387 - val_recall: 0.5271 - val_auc: 0.9343 - val_f2: 0.4223 - val_fbeta2: 0.5463\n",
      "Epoch 31/1000\n",
      "68791/68791 - 2s - loss: 0.2028 - acc: 0.9025 - prec: 0.6520 - recall: 0.5044 - auc: 0.9354 - f2: 0.4063 - fbeta2: 0.5283 - val_loss: 0.2025 - val_acc: 0.9032 - val_prec: 0.6428 - val_recall: 0.5338 - val_auc: 0.9354 - val_f2: 0.3873 - val_fbeta2: 0.5526\n",
      "Epoch 32/1000\n",
      "68791/68791 - 2s - loss: 0.2021 - acc: 0.9030 - prec: 0.6526 - recall: 0.5113 - auc: 0.9359 - f2: 0.4112 - fbeta2: 0.5340 - val_loss: 0.2008 - val_acc: 0.9043 - val_prec: 0.6462 - val_recall: 0.5432 - val_auc: 0.9364 - val_f2: 0.4096 - val_fbeta2: 0.5611\n",
      "Epoch 33/1000\n",
      "68791/68791 - 2s - loss: 0.2009 - acc: 0.9037 - prec: 0.6557 - recall: 0.5141 - auc: 0.9368 - f2: 0.4076 - fbeta2: 0.5375 - val_loss: 0.2044 - val_acc: 0.9027 - val_prec: 0.6450 - val_recall: 0.5184 - val_auc: 0.9337 - val_f2: 0.4061 - val_fbeta2: 0.5396\n",
      "Epoch 34/1000\n",
      "68791/68791 - 2s - loss: 0.2003 - acc: 0.9041 - prec: 0.6572 - recall: 0.5174 - auc: 0.9372 - f2: 0.4187 - fbeta2: 0.5400 - val_loss: 0.2017 - val_acc: 0.9032 - val_prec: 0.6261 - val_recall: 0.5898 - val_auc: 0.9363 - val_f2: 0.5179 - val_fbeta2: 0.5968\n",
      "Epoch 35/1000\n",
      "68791/68791 - 2s - loss: 0.1999 - acc: 0.9043 - prec: 0.6573 - recall: 0.5204 - auc: 0.9376 - f2: 0.4206 - fbeta2: 0.5432 - val_loss: 0.2048 - val_acc: 0.9022 - val_prec: 0.6520 - val_recall: 0.4922 - val_auc: 0.9336 - val_f2: 0.3769 - val_fbeta2: 0.5176\n",
      "Epoch 36/1000\n",
      "68791/68791 - 2s - loss: 0.2000 - acc: 0.9041 - prec: 0.6564 - recall: 0.5188 - auc: 0.9375 - f2: 0.4143 - fbeta2: 0.5408 - val_loss: 0.2012 - val_acc: 0.9042 - val_prec: 0.6439 - val_recall: 0.5494 - val_auc: 0.9362 - val_f2: 0.3790 - val_fbeta2: 0.5660\n",
      "Epoch 37/1000\n",
      "68791/68791 - 2s - loss: 0.1993 - acc: 0.9047 - prec: 0.6577 - recall: 0.5261 - auc: 0.9379 - f2: 0.4208 - fbeta2: 0.5468 - val_loss: 0.2015 - val_acc: 0.9040 - val_prec: 0.6484 - val_recall: 0.5325 - val_auc: 0.9359 - val_f2: 0.4515 - val_fbeta2: 0.5524\n",
      "Epoch 38/1000\n",
      "68791/68791 - 2s - loss: 0.1984 - acc: 0.9050 - prec: 0.6599 - recall: 0.5260 - auc: 0.9386 - f2: 0.4268 - fbeta2: 0.5478 - val_loss: 0.1999 - val_acc: 0.9051 - val_prec: 0.6483 - val_recall: 0.5517 - val_auc: 0.9372 - val_f2: 0.4248 - val_fbeta2: 0.5686\n",
      "Epoch 39/1000\n",
      "68791/68791 - 2s - loss: 0.1975 - acc: 0.9056 - prec: 0.6612 - recall: 0.5327 - auc: 0.9392 - f2: 0.4354 - fbeta2: 0.5536 - val_loss: 0.1978 - val_acc: 0.9062 - val_prec: 0.6621 - val_recall: 0.5338 - val_auc: 0.9385 - val_f2: 0.4209 - val_fbeta2: 0.5555\n",
      "Epoch 40/1000\n",
      "68791/68791 - 2s - loss: 0.1973 - acc: 0.9057 - prec: 0.6605 - recall: 0.5351 - auc: 0.9394 - f2: 0.4393 - fbeta2: 0.5562 - val_loss: 0.1978 - val_acc: 0.9058 - val_prec: 0.6458 - val_recall: 0.5704 - val_auc: 0.9387 - val_f2: 0.4675 - val_fbeta2: 0.5841\n",
      "Epoch 41/1000\n",
      "68791/68791 - 2s - loss: 0.1972 - acc: 0.9057 - prec: 0.6608 - recall: 0.5349 - auc: 0.9395 - f2: 0.4361 - fbeta2: 0.5554 - val_loss: 0.1986 - val_acc: 0.9057 - val_prec: 0.6506 - val_recall: 0.5561 - val_auc: 0.9380 - val_f2: 0.4482 - val_fbeta2: 0.5727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "68791/68791 - 2s - loss: 0.1957 - acc: 0.9066 - prec: 0.6640 - recall: 0.5416 - auc: 0.9405 - f2: 0.4470 - fbeta2: 0.5628 - val_loss: 0.1972 - val_acc: 0.9065 - val_prec: 0.6672 - val_recall: 0.5250 - val_auc: 0.9391 - val_f2: 0.4310 - val_fbeta2: 0.5484\n",
      "Epoch 43/1000\n",
      "68791/68791 - 2s - loss: 0.1953 - acc: 0.9067 - prec: 0.6641 - recall: 0.5425 - auc: 0.9407 - f2: 0.4410 - fbeta2: 0.5626 - val_loss: 0.1980 - val_acc: 0.9058 - val_prec: 0.6514 - val_recall: 0.5551 - val_auc: 0.9386 - val_f2: 0.4400 - val_fbeta2: 0.5721\n",
      "Epoch 44/1000\n",
      "68791/68791 - 2s - loss: 0.1951 - acc: 0.9069 - prec: 0.6636 - recall: 0.5466 - auc: 0.9410 - f2: 0.4531 - fbeta2: 0.5670 - val_loss: 0.2001 - val_acc: 0.9048 - val_prec: 0.6475 - val_recall: 0.5488 - val_auc: 0.9370 - val_f2: 0.4504 - val_fbeta2: 0.5661\n",
      "Epoch 45/1000\n",
      "68791/68791 - 2s - loss: 0.1945 - acc: 0.9071 - prec: 0.6650 - recall: 0.5460 - auc: 0.9414 - f2: 0.4542 - fbeta2: 0.5662 - val_loss: 0.1990 - val_acc: 0.9052 - val_prec: 0.6447 - val_recall: 0.5636 - val_auc: 0.9378 - val_f2: 0.4638 - val_fbeta2: 0.5783\n",
      "Epoch 46/1000\n",
      "68791/68791 - 2s - loss: 0.1950 - acc: 0.9069 - prec: 0.6640 - recall: 0.5447 - auc: 0.9411 - f2: 0.4475 - fbeta2: 0.5647 - val_loss: 0.1984 - val_acc: 0.9053 - val_prec: 0.6421 - val_recall: 0.5743 - val_auc: 0.9383 - val_f2: 0.4724 - val_fbeta2: 0.5868\n",
      "Epoch 47/1000\n",
      "68791/68791 - 2s - loss: 0.1938 - acc: 0.9078 - prec: 0.6678 - recall: 0.5509 - auc: 0.9419 - f2: 0.4553 - fbeta2: 0.5714 - val_loss: 0.1980 - val_acc: 0.9060 - val_prec: 0.6544 - val_recall: 0.5498 - val_auc: 0.9384 - val_f2: 0.4188 - val_fbeta2: 0.5679\n",
      "Epoch 48/1000\n",
      "68791/68791 - 2s - loss: 0.1931 - acc: 0.9080 - prec: 0.6672 - recall: 0.5548 - auc: 0.9423 - f2: 0.4557 - fbeta2: 0.5737 - val_loss: 0.1962 - val_acc: 0.9070 - val_prec: 0.6601 - val_recall: 0.5508 - val_auc: 0.9400 - val_f2: 0.4577 - val_fbeta2: 0.5697\n",
      "Epoch 49/1000\n",
      "68791/68791 - 2s - loss: 0.1917 - acc: 0.9089 - prec: 0.6701 - recall: 0.5615 - auc: 0.9433 - f2: 0.4669 - fbeta2: 0.5805 - val_loss: 0.1958 - val_acc: 0.9066 - val_prec: 0.6559 - val_recall: 0.5559 - val_auc: 0.9401 - val_f2: 0.4279 - val_fbeta2: 0.5734\n",
      "Epoch 50/1000\n",
      "68791/68791 - 2s - loss: 0.1917 - acc: 0.9088 - prec: 0.6683 - recall: 0.5648 - auc: 0.9432 - f2: 0.4695 - fbeta2: 0.5828 - val_loss: 0.1985 - val_acc: 0.9057 - val_prec: 0.6555 - val_recall: 0.5422 - val_auc: 0.9380 - val_f2: 0.4071 - val_fbeta2: 0.5617\n",
      "Epoch 51/1000\n",
      "68791/68791 - 2s - loss: 0.1915 - acc: 0.9088 - prec: 0.6698 - recall: 0.5611 - auc: 0.9434 - f2: 0.4696 - fbeta2: 0.5803 - val_loss: 0.1955 - val_acc: 0.9074 - val_prec: 0.6616 - val_recall: 0.5534 - val_auc: 0.9403 - val_f2: 0.4419 - val_fbeta2: 0.5723\n",
      "Epoch 52/1000\n",
      "68791/68791 - 2s - loss: 0.1907 - acc: 0.9091 - prec: 0.6696 - recall: 0.5667 - auc: 0.9439 - f2: 0.4705 - fbeta2: 0.5849 - val_loss: 0.1987 - val_acc: 0.9056 - val_prec: 0.6385 - val_recall: 0.5908 - val_auc: 0.9383 - val_f2: 0.5095 - val_fbeta2: 0.5997\n",
      "Epoch 53/1000\n",
      "68791/68791 - 2s - loss: 0.1903 - acc: 0.9093 - prec: 0.6705 - recall: 0.5665 - auc: 0.9442 - f2: 0.4706 - fbeta2: 0.5847 - val_loss: 0.1959 - val_acc: 0.9075 - val_prec: 0.6542 - val_recall: 0.5760 - val_auc: 0.9402 - val_f2: 0.4581 - val_fbeta2: 0.5903\n",
      "Epoch 54/1000\n",
      "68791/68791 - 2s - loss: 0.1898 - acc: 0.9097 - prec: 0.6715 - recall: 0.5714 - auc: 0.9446 - f2: 0.4755 - fbeta2: 0.5882 - val_loss: 0.1961 - val_acc: 0.9075 - val_prec: 0.6664 - val_recall: 0.5429 - val_auc: 0.9398 - val_f2: 0.4238 - val_fbeta2: 0.5639\n",
      "Epoch 55/1000\n",
      "68791/68791 - 2s - loss: 0.1892 - acc: 0.9101 - prec: 0.6726 - recall: 0.5732 - auc: 0.9450 - f2: 0.4808 - fbeta2: 0.5906 - val_loss: 0.1992 - val_acc: 0.9055 - val_prec: 0.6481 - val_recall: 0.5591 - val_auc: 0.9381 - val_f2: 0.4567 - val_fbeta2: 0.5749\n",
      "Epoch 56/1000\n",
      "68791/68791 - 2s - loss: 0.1886 - acc: 0.9104 - prec: 0.6740 - recall: 0.5753 - auc: 0.9454 - f2: 0.4833 - fbeta2: 0.5928 - val_loss: 0.2013 - val_acc: 0.9034 - val_prec: 0.6276 - val_recall: 0.5880 - val_auc: 0.9369 - val_f2: 0.4905 - val_fbeta2: 0.5955\n",
      "Epoch 57/1000\n",
      "68791/68791 - 2s - loss: 0.1893 - acc: 0.9099 - prec: 0.6712 - recall: 0.5740 - auc: 0.9449 - f2: 0.4814 - fbeta2: 0.5913 - val_loss: 0.1982 - val_acc: 0.9066 - val_prec: 0.6639 - val_recall: 0.5354 - val_auc: 0.9387 - val_f2: 0.4270 - val_fbeta2: 0.5572\n",
      "Epoch 58/1000\n",
      "68791/68791 - 2s - loss: 0.1877 - acc: 0.9108 - prec: 0.6749 - recall: 0.5793 - auc: 0.9460 - f2: 0.4841 - fbeta2: 0.5970 - val_loss: 0.1999 - val_acc: 0.9049 - val_prec: 0.6424 - val_recall: 0.5665 - val_auc: 0.9376 - val_f2: 0.4769 - val_fbeta2: 0.5803\n",
      "Epoch 59/1000\n",
      "68791/68791 - 2s - loss: 0.1873 - acc: 0.9111 - prec: 0.6750 - recall: 0.5839 - auc: 0.9462 - f2: 0.4889 - fbeta2: 0.5996 - val_loss: 0.1951 - val_acc: 0.9081 - val_prec: 0.6674 - val_recall: 0.5506 - val_auc: 0.9407 - val_f2: 0.4501 - val_fbeta2: 0.5707\n",
      "Epoch 60/1000\n",
      "68791/68791 - 2s - loss: 0.1869 - acc: 0.9112 - prec: 0.6752 - recall: 0.5843 - auc: 0.9465 - f2: 0.4937 - fbeta2: 0.6003 - val_loss: 0.1989 - val_acc: 0.9055 - val_prec: 0.6412 - val_recall: 0.5796 - val_auc: 0.9382 - val_f2: 0.4370 - val_fbeta2: 0.5909\n",
      "Epoch 61/1000\n",
      "68791/68791 - 2s - loss: 0.1863 - acc: 0.9118 - prec: 0.6770 - recall: 0.5889 - auc: 0.9469 - f2: 0.4969 - fbeta2: 0.6042 - val_loss: 0.1970 - val_acc: 0.9069 - val_prec: 0.6477 - val_recall: 0.5839 - val_auc: 0.9395 - val_f2: 0.4723 - val_fbeta2: 0.5958\n",
      "Epoch 62/1000\n",
      "68791/68791 - 2s - loss: 0.1858 - acc: 0.9120 - prec: 0.6781 - recall: 0.5888 - auc: 0.9472 - f2: 0.4950 - fbeta2: 0.6040 - val_loss: 0.1977 - val_acc: 0.9060 - val_prec: 0.6443 - val_recall: 0.5794 - val_auc: 0.9393 - val_f2: 0.5109 - val_fbeta2: 0.5915\n",
      "Epoch 63/1000\n",
      "68791/68791 - 2s - loss: 0.1854 - acc: 0.9122 - prec: 0.6788 - recall: 0.5903 - auc: 0.9475 - f2: 0.5004 - fbeta2: 0.6065 - val_loss: 0.1967 - val_acc: 0.9070 - val_prec: 0.6466 - val_recall: 0.5900 - val_auc: 0.9396 - val_f2: 0.4768 - val_fbeta2: 0.6005\n",
      "Epoch 64/1000\n",
      "68791/68791 - 2s - loss: 0.1846 - acc: 0.9126 - prec: 0.6792 - recall: 0.5957 - auc: 0.9479 - f2: 0.5082 - fbeta2: 0.6105 - val_loss: 0.1986 - val_acc: 0.9063 - val_prec: 0.6445 - val_recall: 0.5844 - val_auc: 0.9386 - val_f2: 0.4820 - val_fbeta2: 0.5956\n",
      "Epoch 65/1000\n",
      "68791/68791 - 2s - loss: 0.1839 - acc: 0.9129 - prec: 0.6799 - recall: 0.5987 - auc: 0.9484 - f2: 0.5087 - fbeta2: 0.6136 - val_loss: 0.1969 - val_acc: 0.9069 - val_prec: 0.6543 - val_recall: 0.5655 - val_auc: 0.9395 - val_f2: 0.4492 - val_fbeta2: 0.5814\n",
      "Epoch 66/1000\n",
      "68791/68791 - 2s - loss: 0.1842 - acc: 0.9129 - prec: 0.6786 - recall: 0.6013 - auc: 0.9482 - f2: 0.5132 - fbeta2: 0.6151 - val_loss: 0.1961 - val_acc: 0.9077 - val_prec: 0.6536 - val_recall: 0.5803 - val_auc: 0.9402 - val_f2: 0.4590 - val_fbeta2: 0.5937\n",
      "Epoch 67/1000\n",
      "68791/68791 - 2s - loss: 0.1824 - acc: 0.9138 - prec: 0.6832 - recall: 0.6036 - auc: 0.9493 - f2: 0.5138 - fbeta2: 0.6178 - val_loss: 0.1969 - val_acc: 0.9077 - val_prec: 0.6557 - val_recall: 0.5743 - val_auc: 0.9397 - val_f2: 0.4404 - val_fbeta2: 0.5890\n",
      "Epoch 68/1000\n",
      "68791/68791 - 2s - loss: 0.1821 - acc: 0.9140 - prec: 0.6826 - recall: 0.6079 - auc: 0.9495 - f2: 0.5192 - fbeta2: 0.6206 - val_loss: 0.1981 - val_acc: 0.9067 - val_prec: 0.6390 - val_recall: 0.6091 - val_auc: 0.9393 - val_f2: 0.5409 - val_fbeta2: 0.6150\n",
      "Epoch 69/1000\n",
      "68791/68791 - 2s - loss: 0.1816 - acc: 0.9144 - prec: 0.6837 - recall: 0.6115 - auc: 0.9499 - f2: 0.5190 - fbeta2: 0.6244 - val_loss: 0.1985 - val_acc: 0.9074 - val_prec: 0.6517 - val_recall: 0.5810 - val_auc: 0.9389 - val_f2: 0.4910 - val_fbeta2: 0.5941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17198/17198 [==============================] - ETA: 5s - loss: 0.1960 - acc: 0.9004 - prec: 0.6462 - recall: 0.6000 - auc: 0.9450 - f2: 0.3989 - fbeta2: 0.608 - ETA: 2s - loss: 0.2043 - acc: 0.9011 - prec: 0.6216 - recall: 0.5611 - auc: 0.9361 - f2: 0.4003 - fbeta2: 0.570 - ETA: 2s - loss: 0.2052 - acc: 0.9031 - prec: 0.6338 - recall: 0.5637 - auc: 0.9355 - f2: 0.3881 - fbeta2: 0.575 - ETA: 2s - loss: 0.2033 - acc: 0.9046 - prec: 0.6386 - recall: 0.5706 - auc: 0.9357 - f2: 0.3969 - fbeta2: 0.581 - ETA: 2s - loss: 0.2048 - acc: 0.9049 - prec: 0.6481 - recall: 0.5646 - auc: 0.9356 - f2: 0.4001 - fbeta2: 0.577 - ETA: 2s - loss: 0.2043 - acc: 0.9061 - prec: 0.6549 - recall: 0.5724 - auc: 0.9363 - f2: 0.4072 - fbeta2: 0.585 - ETA: 2s - loss: 0.2030 - acc: 0.9064 - prec: 0.6579 - recall: 0.5735 - auc: 0.9370 - f2: 0.4128 - fbeta2: 0.587 - ETA: 2s - loss: 0.2021 - acc: 0.9068 - prec: 0.6566 - recall: 0.5769 - auc: 0.9373 - f2: 0.4167 - fbeta2: 0.590 - ETA: 2s - loss: 0.2008 - acc: 0.9073 - prec: 0.6589 - recall: 0.5790 - auc: 0.9380 - f2: 0.4139 - fbeta2: 0.592 - ETA: 1s - loss: 0.2002 - acc: 0.9073 - prec: 0.6579 - recall: 0.5796 - auc: 0.9383 - f2: 0.4139 - fbeta2: 0.592 - ETA: 1s - loss: 0.1995 - acc: 0.9074 - prec: 0.6554 - recall: 0.5806 - auc: 0.9386 - f2: 0.4122 - fbeta2: 0.592 - ETA: 1s - loss: 0.1994 - acc: 0.9073 - prec: 0.6532 - recall: 0.5818 - auc: 0.9384 - f2: 0.4103 - fbeta2: 0.593 - ETA: 1s - loss: 0.1987 - acc: 0.9077 - prec: 0.6535 - recall: 0.5837 - auc: 0.9389 - f2: 0.4114 - fbeta2: 0.595 - ETA: 1s - loss: 0.1989 - acc: 0.9074 - prec: 0.6512 - recall: 0.5822 - auc: 0.9386 - f2: 0.4100 - fbeta2: 0.593 - ETA: 1s - loss: 0.1987 - acc: 0.9073 - prec: 0.6507 - recall: 0.5818 - auc: 0.9387 - f2: 0.4112 - fbeta2: 0.593 - ETA: 1s - loss: 0.1980 - acc: 0.9076 - prec: 0.6512 - recall: 0.5824 - auc: 0.9391 - f2: 0.4115 - fbeta2: 0.594 - ETA: 1s - loss: 0.1977 - acc: 0.9078 - prec: 0.6529 - recall: 0.5827 - auc: 0.9395 - f2: 0.4125 - fbeta2: 0.594 - ETA: 1s - loss: 0.1977 - acc: 0.9082 - prec: 0.6539 - recall: 0.5845 - auc: 0.9394 - f2: 0.4135 - fbeta2: 0.596 - ETA: 1s - loss: 0.1977 - acc: 0.9083 - prec: 0.6549 - recall: 0.5849 - auc: 0.9394 - f2: 0.4123 - fbeta2: 0.597 - ETA: 1s - loss: 0.1972 - acc: 0.9085 - prec: 0.6562 - recall: 0.5851 - auc: 0.9398 - f2: 0.4138 - fbeta2: 0.597 - ETA: 1s - loss: 0.1969 - acc: 0.9085 - prec: 0.6556 - recall: 0.5845 - auc: 0.9399 - f2: 0.4132 - fbeta2: 0.596 - ETA: 1s - loss: 0.1972 - acc: 0.9083 - prec: 0.6549 - recall: 0.5843 - auc: 0.9397 - f2: 0.4115 - fbeta2: 0.596 - ETA: 1s - loss: 0.1970 - acc: 0.9082 - prec: 0.6550 - recall: 0.5843 - auc: 0.9399 - f2: 0.4116 - fbeta2: 0.596 - ETA: 1s - loss: 0.1968 - acc: 0.9082 - prec: 0.6548 - recall: 0.5838 - auc: 0.9400 - f2: 0.4098 - fbeta2: 0.596 - ETA: 1s - loss: 0.1967 - acc: 0.9082 - prec: 0.6547 - recall: 0.5839 - auc: 0.9400 - f2: 0.4100 - fbeta2: 0.596 - ETA: 1s - loss: 0.1970 - acc: 0.9081 - prec: 0.6532 - recall: 0.5832 - auc: 0.9398 - f2: 0.4080 - fbeta2: 0.595 - ETA: 1s - loss: 0.1968 - acc: 0.9081 - prec: 0.6528 - recall: 0.5827 - auc: 0.9398 - f2: 0.4066 - fbeta2: 0.594 - ETA: 0s - loss: 0.1970 - acc: 0.9081 - prec: 0.6527 - recall: 0.5827 - auc: 0.9397 - f2: 0.4078 - fbeta2: 0.594 - ETA: 0s - loss: 0.1964 - acc: 0.9083 - prec: 0.6534 - recall: 0.5831 - auc: 0.9400 - f2: 0.4077 - fbeta2: 0.595 - ETA: 0s - loss: 0.1958 - acc: 0.9084 - prec: 0.6539 - recall: 0.5836 - auc: 0.9404 - f2: 0.4083 - fbeta2: 0.595 - ETA: 0s - loss: 0.1958 - acc: 0.9083 - prec: 0.6544 - recall: 0.5829 - auc: 0.9405 - f2: 0.4088 - fbeta2: 0.595 - ETA: 0s - loss: 0.1963 - acc: 0.9081 - prec: 0.6538 - recall: 0.5814 - auc: 0.9402 - f2: 0.4097 - fbeta2: 0.594 - ETA: 0s - loss: 0.1965 - acc: 0.9080 - prec: 0.6532 - recall: 0.5816 - auc: 0.9402 - f2: 0.4107 - fbeta2: 0.594 - ETA: 0s - loss: 0.1968 - acc: 0.9080 - prec: 0.6540 - recall: 0.5817 - auc: 0.9401 - f2: 0.4110 - fbeta2: 0.594 - ETA: 0s - loss: 0.1966 - acc: 0.9081 - prec: 0.6550 - recall: 0.5820 - auc: 0.9402 - f2: 0.4111 - fbeta2: 0.594 - ETA: 0s - loss: 0.1967 - acc: 0.9080 - prec: 0.6546 - recall: 0.5821 - auc: 0.9402 - f2: 0.4116 - fbeta2: 0.594 - ETA: 0s - loss: 0.1971 - acc: 0.9078 - prec: 0.6537 - recall: 0.5813 - auc: 0.9399 - f2: 0.4109 - fbeta2: 0.594 - ETA: 0s - loss: 0.1974 - acc: 0.9077 - prec: 0.6534 - recall: 0.5809 - auc: 0.9398 - f2: 0.4113 - fbeta2: 0.593 - ETA: 0s - loss: 0.1976 - acc: 0.9076 - prec: 0.6527 - recall: 0.5809 - auc: 0.9396 - f2: 0.4118 - fbeta2: 0.593 - ETA: 0s - loss: 0.1978 - acc: 0.9075 - prec: 0.6525 - recall: 0.5804 - auc: 0.9395 - f2: 0.4122 - fbeta2: 0.593 - ETA: 0s - loss: 0.1983 - acc: 0.9073 - prec: 0.6514 - recall: 0.5797 - auc: 0.9391 - f2: 0.4128 - fbeta2: 0.592 - ETA: 0s - loss: 0.1980 - acc: 0.9074 - prec: 0.6519 - recall: 0.5802 - auc: 0.9392 - f2: 0.4126 - fbeta2: 0.592 - ETA: 0s - loss: 0.1984 - acc: 0.9073 - prec: 0.6513 - recall: 0.5800 - auc: 0.9390 - f2: 0.4128 - fbeta2: 0.592 - ETA: 0s - loss: 0.1984 - acc: 0.9073 - prec: 0.6516 - recall: 0.5799 - auc: 0.9390 - f2: 0.4135 - fbeta2: 0.592 - ETA: 0s - loss: 0.1987 - acc: 0.9072 - prec: 0.6508 - recall: 0.5802 - auc: 0.9387 - f2: 0.4146 - fbeta2: 0.592 - ETA: 0s - loss: 0.1985 - acc: 0.9074 - prec: 0.6517 - recall: 0.5808 - auc: 0.9389 - f2: 0.4152 - fbeta2: 0.593 - 2s 141us/sample - loss: 0.1985 - acc: 0.9074 - prec: 0.6517 - recall: 0.5810 - auc: 0.9389 - f2: 0.4158 - fbeta2: 0.5935\n",
      "4\n",
      "Train on 68791 samples, validate on 17198 samples\n",
      "Epoch 1/1000\n",
      "68791/68791 - 5s - loss: 0.5566 - acc: 0.8294 - prec: 0.1341 - recall: 0.0623 - auc: 0.5195 - f2: 0.0359 - fbeta2: 0.0463 - val_loss: 0.3901 - val_acc: 0.8726 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6764 - val_f2: 0.0000e+00 - val_fbeta2: 6.0838e-11\n",
      "Epoch 2/1000\n",
      "68791/68791 - 2s - loss: 0.3532 - acc: 0.8727 - prec: 0.4369 - recall: 3.2111e-04 - auc: 0.7157 - f2: 2.0631e-04 - fbeta2: 3.9442e-04 - val_loss: 0.3389 - val_acc: 0.8726 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7437 - val_f2: 0.0000e+00 - val_fbeta2: 6.0838e-11\n",
      "Epoch 3/1000\n",
      "68791/68791 - 2s - loss: 0.3363 - acc: 0.8726 - prec: 0.4118 - recall: 5.4946e-04 - auc: 0.7475 - f2: 4.2511e-04 - fbeta2: 6.7373e-04 - val_loss: 0.3348 - val_acc: 0.8726 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7495 - val_f2: 0.0000e+00 - val_fbeta2: 6.0838e-11\n",
      "Epoch 4/1000\n",
      "68791/68791 - 2s - loss: 0.2954 - acc: 0.8729 - prec: 0.5068 - recall: 0.0598 - auc: 0.8381 - f2: 0.0553 - fbeta2: 0.0733 - val_loss: 0.2902 - val_acc: 0.8734 - val_prec: 0.5277 - val_recall: 0.0611 - val_auc: 0.8690 - val_f2: 0.0833 - val_fbeta2: 0.0742\n",
      "Epoch 5/1000\n",
      "68791/68791 - 2s - loss: 0.2578 - acc: 0.8832 - prec: 0.6063 - recall: 0.2348 - auc: 0.8854 - f2: 0.1689 - fbeta2: 0.2676 - val_loss: 0.2614 - val_acc: 0.8797 - val_prec: 0.7056 - val_recall: 0.0965 - val_auc: 0.8917 - val_f2: 0.1134 - val_fbeta2: 0.1166\n",
      "Epoch 6/1000\n",
      "68791/68791 - 2s - loss: 0.2465 - acc: 0.8859 - prec: 0.6119 - recall: 0.2829 - auc: 0.8972 - f2: 0.2015 - fbeta2: 0.3174 - val_loss: 0.2470 - val_acc: 0.8803 - val_prec: 0.7150 - val_recall: 0.1013 - val_auc: 0.9002 - val_f2: 0.1431 - val_fbeta2: 0.1223\n",
      "Epoch 7/1000\n",
      "68791/68791 - 2s - loss: 0.2363 - acc: 0.8878 - prec: 0.6075 - recall: 0.3353 - auc: 0.9075 - f2: 0.2470 - fbeta2: 0.3671 - val_loss: 0.2355 - val_acc: 0.8871 - val_prec: 0.6441 - val_recall: 0.2548 - val_auc: 0.9089 - val_f2: 0.1988 - val_fbeta2: 0.2898\n",
      "Epoch 8/1000\n",
      "68791/68791 - 2s - loss: 0.2317 - acc: 0.8889 - prec: 0.6096 - recall: 0.3542 - auc: 0.9117 - f2: 0.2630 - fbeta2: 0.3869 - val_loss: 0.2352 - val_acc: 0.8891 - val_prec: 0.6271 - val_recall: 0.3197 - val_auc: 0.9080 - val_f2: 0.2581 - val_fbeta2: 0.3545\n",
      "Epoch 9/1000\n",
      "68791/68791 - 2s - loss: 0.2267 - acc: 0.8913 - prec: 0.6190 - recall: 0.3805 - auc: 0.9160 - f2: 0.2797 - fbeta2: 0.4127 - val_loss: 0.2329 - val_acc: 0.8874 - val_prec: 0.5940 - val_recall: 0.3689 - val_auc: 0.9104 - val_f2: 0.2969 - val_fbeta2: 0.3990\n",
      "Epoch 10/1000\n",
      "68791/68791 - 2s - loss: 0.2251 - acc: 0.8922 - prec: 0.6205 - recall: 0.3951 - auc: 0.9174 - f2: 0.2896 - fbeta2: 0.4253 - val_loss: 0.2256 - val_acc: 0.8915 - val_prec: 0.6180 - val_recall: 0.3892 - val_auc: 0.9165 - val_f2: 0.2743 - val_fbeta2: 0.4202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "68791/68791 - 2s - loss: 0.2251 - acc: 0.8916 - prec: 0.6160 - recall: 0.3954 - auc: 0.9174 - f2: 0.2977 - fbeta2: 0.4254 - val_loss: 0.2305 - val_acc: 0.8885 - val_prec: 0.5898 - val_recall: 0.4102 - val_auc: 0.9124 - val_f2: 0.3333 - val_fbeta2: 0.4366\n",
      "Epoch 12/1000\n",
      "68791/68791 - 2s - loss: 0.2209 - acc: 0.8938 - prec: 0.6280 - recall: 0.4069 - auc: 0.9210 - f2: 0.3086 - fbeta2: 0.4381 - val_loss: 0.2221 - val_acc: 0.8946 - val_prec: 0.6481 - val_recall: 0.3782 - val_auc: 0.9198 - val_f2: 0.2925 - val_fbeta2: 0.4123\n",
      "Epoch 13/1000\n",
      "68791/68791 - 2s - loss: 0.2203 - acc: 0.8939 - prec: 0.6255 - recall: 0.4154 - auc: 0.9213 - f2: 0.3181 - fbeta2: 0.4456 - val_loss: 0.2175 - val_acc: 0.8962 - val_prec: 0.6332 - val_recall: 0.4405 - val_auc: 0.9238 - val_f2: 0.3356 - val_fbeta2: 0.4688\n",
      "Epoch 14/1000\n",
      "68791/68791 - 2s - loss: 0.2188 - acc: 0.8944 - prec: 0.6258 - recall: 0.4234 - auc: 0.9227 - f2: 0.3229 - fbeta2: 0.4528 - val_loss: 0.2230 - val_acc: 0.8929 - val_prec: 0.6316 - val_recall: 0.3832 - val_auc: 0.9196 - val_f2: 0.3134 - val_fbeta2: 0.4155\n",
      "Epoch 15/1000\n",
      "68791/68791 - 2s - loss: 0.2167 - acc: 0.8955 - prec: 0.6311 - recall: 0.4316 - auc: 0.9244 - f2: 0.3363 - fbeta2: 0.4608 - val_loss: 0.2171 - val_acc: 0.8968 - val_prec: 0.6529 - val_recall: 0.4062 - val_auc: 0.9241 - val_f2: 0.3134 - val_fbeta2: 0.4392\n",
      "Epoch 16/1000\n",
      "68791/68791 - 2s - loss: 0.2159 - acc: 0.8961 - prec: 0.6325 - recall: 0.4383 - auc: 0.9251 - f2: 0.3409 - fbeta2: 0.4667 - val_loss: 0.2245 - val_acc: 0.8943 - val_prec: 0.6188 - val_recall: 0.4447 - val_auc: 0.9176 - val_f2: 0.3683 - val_fbeta2: 0.4710\n",
      "Epoch 17/1000\n",
      "68791/68791 - 2s - loss: 0.2149 - acc: 0.8964 - prec: 0.6344 - recall: 0.4401 - auc: 0.9259 - f2: 0.3415 - fbeta2: 0.4694 - val_loss: 0.2160 - val_acc: 0.8969 - val_prec: 0.6265 - val_recall: 0.4729 - val_auc: 0.9251 - val_f2: 0.3441 - val_fbeta2: 0.4970\n",
      "Epoch 18/1000\n",
      "68791/68791 - 2s - loss: 0.2126 - acc: 0.8977 - prec: 0.6370 - recall: 0.4560 - auc: 0.9278 - f2: 0.3595 - fbeta2: 0.4836 - val_loss: 0.2268 - val_acc: 0.8919 - val_prec: 0.6061 - val_recall: 0.4331 - val_auc: 0.9169 - val_f2: 0.3233 - val_fbeta2: 0.4591\n",
      "Epoch 19/1000\n",
      "68791/68791 - 2s - loss: 0.2135 - acc: 0.8970 - prec: 0.6340 - recall: 0.4518 - auc: 0.9271 - f2: 0.3527 - fbeta2: 0.4787 - val_loss: 0.2104 - val_acc: 0.9001 - val_prec: 0.6541 - val_recall: 0.4581 - val_auc: 0.9296 - val_f2: 0.3642 - val_fbeta2: 0.4871\n",
      "Epoch 20/1000\n",
      "68791/68791 - 2s - loss: 0.2104 - acc: 0.8990 - prec: 0.6427 - recall: 0.4662 - auc: 0.9296 - f2: 0.3690 - fbeta2: 0.4935 - val_loss: 0.2100 - val_acc: 0.8999 - val_prec: 0.6368 - val_recall: 0.4992 - val_auc: 0.9298 - val_f2: 0.4242 - val_fbeta2: 0.5216\n",
      "Epoch 21/1000\n",
      "68791/68791 - 2s - loss: 0.2095 - acc: 0.8995 - prec: 0.6424 - recall: 0.4755 - auc: 0.9302 - f2: 0.3788 - fbeta2: 0.5012 - val_loss: 0.2126 - val_acc: 0.8984 - val_prec: 0.6530 - val_recall: 0.4324 - val_auc: 0.9280 - val_f2: 0.3502 - val_fbeta2: 0.4636\n",
      "Epoch 22/1000\n",
      "68791/68791 - 2s - loss: 0.2093 - acc: 0.8997 - prec: 0.6426 - recall: 0.4776 - auc: 0.9304 - f2: 0.3777 - fbeta2: 0.5035 - val_loss: 0.2229 - val_acc: 0.8919 - val_prec: 0.6065 - val_recall: 0.4329 - val_auc: 0.9192 - val_f2: 0.3105 - val_fbeta2: 0.4589\n",
      "Epoch 23/1000\n",
      "68791/68791 - 2s - loss: 0.2094 - acc: 0.8997 - prec: 0.6434 - recall: 0.4756 - auc: 0.9304 - f2: 0.3762 - fbeta2: 0.5013 - val_loss: 0.2126 - val_acc: 0.8995 - val_prec: 0.6393 - val_recall: 0.4845 - val_auc: 0.9279 - val_f2: 0.3907 - val_fbeta2: 0.5088\n",
      "Epoch 24/1000\n",
      "68791/68791 - 2s - loss: 0.2071 - acc: 0.9009 - prec: 0.6475 - recall: 0.4864 - auc: 0.9322 - f2: 0.3842 - fbeta2: 0.5105 - val_loss: 0.2145 - val_acc: 0.8966 - val_prec: 0.6142 - val_recall: 0.5083 - val_auc: 0.9268 - val_f2: 0.3886 - val_fbeta2: 0.5261\n",
      "Epoch 25/1000\n",
      "68791/68791 - 2s - loss: 0.2070 - acc: 0.9006 - prec: 0.6446 - recall: 0.4893 - auc: 0.9321 - f2: 0.3935 - fbeta2: 0.5148 - val_loss: 0.2095 - val_acc: 0.9005 - val_prec: 0.6585 - val_recall: 0.4560 - val_auc: 0.9301 - val_f2: 0.3387 - val_fbeta2: 0.4857\n",
      "Epoch 26/1000\n",
      "68791/68791 - 2s - loss: 0.2063 - acc: 0.9009 - prec: 0.6470 - recall: 0.4874 - auc: 0.9327 - f2: 0.3899 - fbeta2: 0.5119 - val_loss: 0.2107 - val_acc: 0.8996 - val_prec: 0.6393 - val_recall: 0.4868 - val_auc: 0.9293 - val_f2: 0.3599 - val_fbeta2: 0.5109\n",
      "Epoch 27/1000\n",
      "68791/68791 - 2s - loss: 0.2057 - acc: 0.9014 - prec: 0.6471 - recall: 0.4961 - auc: 0.9332 - f2: 0.3963 - fbeta2: 0.5195 - val_loss: 0.2105 - val_acc: 0.8994 - val_prec: 0.6393 - val_recall: 0.4836 - val_auc: 0.9298 - val_f2: 0.3906 - val_fbeta2: 0.5082\n",
      "Epoch 28/1000\n",
      "68791/68791 - 2s - loss: 0.2051 - acc: 0.9017 - prec: 0.6493 - recall: 0.4959 - auc: 0.9336 - f2: 0.3981 - fbeta2: 0.5192 - val_loss: 0.2094 - val_acc: 0.8998 - val_prec: 0.6315 - val_recall: 0.5129 - val_auc: 0.9303 - val_f2: 0.4353 - val_fbeta2: 0.5326\n",
      "Epoch 29/1000\n",
      "68791/68791 - 2s - loss: 0.2053 - acc: 0.9015 - prec: 0.6482 - recall: 0.4958 - auc: 0.9335 - f2: 0.3982 - fbeta2: 0.5206 - val_loss: 0.2096 - val_acc: 0.8997 - val_prec: 0.6319 - val_recall: 0.5105 - val_auc: 0.9308 - val_f2: 0.4082 - val_fbeta2: 0.5306\n",
      "Epoch 30/1000\n",
      "68791/68791 - 2s - loss: 0.2037 - acc: 0.9022 - prec: 0.6496 - recall: 0.5025 - auc: 0.9347 - f2: 0.4039 - fbeta2: 0.5257 - val_loss: 0.2059 - val_acc: 0.9011 - val_prec: 0.6365 - val_recall: 0.5228 - val_auc: 0.9330 - val_f2: 0.4163 - val_fbeta2: 0.5418\n",
      "Epoch 31/1000\n",
      "68791/68791 - 2s - loss: 0.2036 - acc: 0.9023 - prec: 0.6497 - recall: 0.5047 - auc: 0.9348 - f2: 0.4048 - fbeta2: 0.5285 - val_loss: 0.2063 - val_acc: 0.9018 - val_prec: 0.6433 - val_recall: 0.5156 - val_auc: 0.9326 - val_f2: 0.3642 - val_fbeta2: 0.5365\n",
      "Epoch 32/1000\n",
      "68791/68791 - 2s - loss: 0.2023 - acc: 0.9031 - prec: 0.6529 - recall: 0.5094 - auc: 0.9357 - f2: 0.4091 - fbeta2: 0.5328 - val_loss: 0.2077 - val_acc: 0.9017 - val_prec: 0.6491 - val_recall: 0.4972 - val_auc: 0.9316 - val_f2: 0.3735 - val_fbeta2: 0.5212\n",
      "Epoch 33/1000\n",
      "68791/68791 - 2s - loss: 0.2024 - acc: 0.9030 - prec: 0.6515 - recall: 0.5126 - auc: 0.9357 - f2: 0.4151 - fbeta2: 0.5365 - val_loss: 0.2038 - val_acc: 0.9029 - val_prec: 0.6550 - val_recall: 0.5035 - val_auc: 0.9344 - val_f2: 0.3947 - val_fbeta2: 0.5275\n",
      "Epoch 34/1000\n",
      "68791/68791 - 2s - loss: 0.2011 - acc: 0.9039 - prec: 0.6559 - recall: 0.5154 - auc: 0.9367 - f2: 0.4176 - fbeta2: 0.5380 - val_loss: 0.2044 - val_acc: 0.9027 - val_prec: 0.6461 - val_recall: 0.5234 - val_auc: 0.9342 - val_f2: 0.3725 - val_fbeta2: 0.5437\n",
      "Epoch 35/1000\n",
      "68791/68791 - 2s - loss: 0.2013 - acc: 0.9038 - prec: 0.6546 - recall: 0.5173 - auc: 0.9365 - f2: 0.4190 - fbeta2: 0.5397 - val_loss: 0.2046 - val_acc: 0.9027 - val_prec: 0.6507 - val_recall: 0.5098 - val_auc: 0.9339 - val_f2: 0.3617 - val_fbeta2: 0.5326\n",
      "Epoch 36/1000\n",
      "68791/68791 - 2s - loss: 0.2006 - acc: 0.9039 - prec: 0.6547 - recall: 0.5187 - auc: 0.9370 - f2: 0.4186 - fbeta2: 0.5419 - val_loss: 0.2141 - val_acc: 0.8978 - val_prec: 0.6242 - val_recall: 0.4974 - val_auc: 0.9273 - val_f2: 0.3950 - val_fbeta2: 0.5182\n",
      "Epoch 37/1000\n",
      "68791/68791 - 2s - loss: 0.2002 - acc: 0.9042 - prec: 0.6558 - recall: 0.5214 - auc: 0.9372 - f2: 0.4257 - fbeta2: 0.5420 - val_loss: 0.2033 - val_acc: 0.9030 - val_prec: 0.6449 - val_recall: 0.5309 - val_auc: 0.9350 - val_f2: 0.4357 - val_fbeta2: 0.5502\n",
      "Epoch 38/1000\n",
      "68791/68791 - 2s - loss: 0.1992 - acc: 0.9045 - prec: 0.6568 - recall: 0.5240 - auc: 0.9380 - f2: 0.4248 - fbeta2: 0.5456 - val_loss: 0.2055 - val_acc: 0.9024 - val_prec: 0.6360 - val_recall: 0.5476 - val_auc: 0.9338 - val_f2: 0.4141 - val_fbeta2: 0.5628\n",
      "Epoch 39/1000\n",
      "68791/68791 - 2s - loss: 0.1983 - acc: 0.9051 - prec: 0.6569 - recall: 0.5330 - auc: 0.9386 - f2: 0.4375 - fbeta2: 0.5529 - val_loss: 0.2029 - val_acc: 0.9039 - val_prec: 0.6425 - val_recall: 0.5546 - val_auc: 0.9353 - val_f2: 0.4154 - val_fbeta2: 0.5698\n",
      "Epoch 40/1000\n",
      "68791/68791 - 2s - loss: 0.1981 - acc: 0.9054 - prec: 0.6598 - recall: 0.5311 - auc: 0.9388 - f2: 0.4343 - fbeta2: 0.5532 - val_loss: 0.2034 - val_acc: 0.9038 - val_prec: 0.6518 - val_recall: 0.5258 - val_auc: 0.9350 - val_f2: 0.4001 - val_fbeta2: 0.5467\n",
      "Epoch 41/1000\n",
      "68791/68791 - 2s - loss: 0.1981 - acc: 0.9053 - prec: 0.6595 - recall: 0.5291 - auc: 0.9388 - f2: 0.4310 - fbeta2: 0.5508 - val_loss: 0.2033 - val_acc: 0.9030 - val_prec: 0.6492 - val_recall: 0.5200 - val_auc: 0.9350 - val_f2: 0.3966 - val_fbeta2: 0.5412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "68791/68791 - 2s - loss: 0.1972 - acc: 0.9057 - prec: 0.6601 - recall: 0.5347 - auc: 0.9395 - f2: 0.4375 - fbeta2: 0.5557 - val_loss: 0.2102 - val_acc: 0.8987 - val_prec: 0.6301 - val_recall: 0.4973 - val_auc: 0.9297 - val_f2: 0.3761 - val_fbeta2: 0.5188\n",
      "Epoch 43/1000\n",
      "68791/68791 - 2s - loss: 0.1979 - acc: 0.9053 - prec: 0.6579 - recall: 0.5337 - auc: 0.9390 - f2: 0.4426 - fbeta2: 0.5547 - val_loss: 0.2039 - val_acc: 0.9028 - val_prec: 0.6397 - val_recall: 0.5430 - val_auc: 0.9347 - val_f2: 0.4720 - val_fbeta2: 0.5597\n",
      "Epoch 44/1000\n",
      "68791/68791 - 2s - loss: 0.1965 - acc: 0.9061 - prec: 0.6610 - recall: 0.5394 - auc: 0.9399 - f2: 0.4346 - fbeta2: 0.5596 - val_loss: 0.2012 - val_acc: 0.9045 - val_prec: 0.6485 - val_recall: 0.5477 - val_auc: 0.9366 - val_f2: 0.4074 - val_fbeta2: 0.5650\n",
      "Epoch 45/1000\n",
      "68791/68791 - 2s - loss: 0.1955 - acc: 0.9065 - prec: 0.6615 - recall: 0.5446 - auc: 0.9406 - f2: 0.4483 - fbeta2: 0.5652 - val_loss: 0.2032 - val_acc: 0.9035 - val_prec: 0.6519 - val_recall: 0.5213 - val_auc: 0.9352 - val_f2: 0.4172 - val_fbeta2: 0.5429\n",
      "Epoch 46/1000\n",
      "68791/68791 - 2s - loss: 0.1957 - acc: 0.9065 - prec: 0.6624 - recall: 0.5411 - auc: 0.9404 - f2: 0.4414 - fbeta2: 0.5606 - val_loss: 0.2008 - val_acc: 0.9050 - val_prec: 0.6397 - val_recall: 0.5823 - val_auc: 0.9373 - val_f2: 0.4826 - val_fbeta2: 0.5928\n",
      "Epoch 47/1000\n",
      "68791/68791 - 2s - loss: 0.1944 - acc: 0.9073 - prec: 0.6639 - recall: 0.5508 - auc: 0.9414 - f2: 0.4552 - fbeta2: 0.5696 - val_loss: 0.2006 - val_acc: 0.9046 - val_prec: 0.6454 - val_recall: 0.5582 - val_auc: 0.9370 - val_f2: 0.4356 - val_fbeta2: 0.5736\n",
      "Epoch 48/1000\n",
      "68791/68791 - 2s - loss: 0.1943 - acc: 0.9074 - prec: 0.6646 - recall: 0.5502 - auc: 0.9415 - f2: 0.4505 - fbeta2: 0.5699 - val_loss: 0.1987 - val_acc: 0.9057 - val_prec: 0.6544 - val_recall: 0.5507 - val_auc: 0.9382 - val_f2: 0.4313 - val_fbeta2: 0.5684\n",
      "Epoch 49/1000\n",
      "68791/68791 - 2s - loss: 0.1935 - acc: 0.9077 - prec: 0.6649 - recall: 0.5550 - auc: 0.9420 - f2: 0.4530 - fbeta2: 0.5731 - val_loss: 0.2000 - val_acc: 0.9056 - val_prec: 0.6558 - val_recall: 0.5451 - val_auc: 0.9376 - val_f2: 0.4205 - val_fbeta2: 0.5638\n",
      "Epoch 50/1000\n",
      "68791/68791 - 2s - loss: 0.1934 - acc: 0.9076 - prec: 0.6639 - recall: 0.5552 - auc: 0.9421 - f2: 0.4609 - fbeta2: 0.5740 - val_loss: 0.1989 - val_acc: 0.9064 - val_prec: 0.6599 - val_recall: 0.5484 - val_auc: 0.9382 - val_f2: 0.4275 - val_fbeta2: 0.5674\n",
      "Epoch 51/1000\n",
      "68791/68791 - 2s - loss: 0.1924 - acc: 0.9084 - prec: 0.6675 - recall: 0.5592 - auc: 0.9427 - f2: 0.4649 - fbeta2: 0.5769 - val_loss: 0.2020 - val_acc: 0.9046 - val_prec: 0.6568 - val_recall: 0.5264 - val_auc: 0.9360 - val_f2: 0.4294 - val_fbeta2: 0.5478\n",
      "Epoch 52/1000\n",
      "68791/68791 - 2s - loss: 0.1926 - acc: 0.9082 - prec: 0.6668 - recall: 0.5568 - auc: 0.9425 - f2: 0.4608 - fbeta2: 0.5752 - val_loss: 0.2031 - val_acc: 0.9035 - val_prec: 0.6412 - val_recall: 0.5514 - val_auc: 0.9352 - val_f2: 0.4978 - val_fbeta2: 0.5673\n",
      "Epoch 53/1000\n",
      "68791/68791 - 2s - loss: 0.1918 - acc: 0.9086 - prec: 0.6679 - recall: 0.5620 - auc: 0.9432 - f2: 0.4627 - fbeta2: 0.5807 - val_loss: 0.1984 - val_acc: 0.9059 - val_prec: 0.6547 - val_recall: 0.5528 - val_auc: 0.9384 - val_f2: 0.4452 - val_fbeta2: 0.5703\n",
      "Epoch 54/1000\n",
      "68791/68791 - 2s - loss: 0.1916 - acc: 0.9089 - prec: 0.6689 - recall: 0.5634 - auc: 0.9433 - f2: 0.4711 - fbeta2: 0.5811 - val_loss: 0.2044 - val_acc: 0.9032 - val_prec: 0.6429 - val_recall: 0.5404 - val_auc: 0.9341 - val_f2: 0.4441 - val_fbeta2: 0.5581\n",
      "Epoch 55/1000\n",
      "68791/68791 - 2s - loss: 0.1907 - acc: 0.9091 - prec: 0.6681 - recall: 0.5692 - auc: 0.9439 - f2: 0.4719 - fbeta2: 0.5869 - val_loss: 0.1981 - val_acc: 0.9068 - val_prec: 0.6654 - val_recall: 0.5406 - val_auc: 0.9387 - val_f2: 0.4085 - val_fbeta2: 0.5613\n",
      "Epoch 56/1000\n",
      "68791/68791 - 2s - loss: 0.1899 - acc: 0.9099 - prec: 0.6717 - recall: 0.5719 - auc: 0.9445 - f2: 0.4702 - fbeta2: 0.5901 - val_loss: 0.1992 - val_acc: 0.9060 - val_prec: 0.6593 - val_recall: 0.5431 - val_auc: 0.9381 - val_f2: 0.4780 - val_fbeta2: 0.5628\n",
      "Epoch 57/1000\n",
      "68791/68791 - 2s - loss: 0.1892 - acc: 0.9101 - prec: 0.6724 - recall: 0.5734 - auc: 0.9448 - f2: 0.4802 - fbeta2: 0.5912 - val_loss: 0.1981 - val_acc: 0.9064 - val_prec: 0.6547 - val_recall: 0.5612 - val_auc: 0.9388 - val_f2: 0.4563 - val_fbeta2: 0.5776\n",
      "Epoch 58/1000\n",
      "68791/68791 - 2s - loss: 0.1896 - acc: 0.9101 - prec: 0.6719 - recall: 0.5743 - auc: 0.9446 - f2: 0.4823 - fbeta2: 0.5913 - val_loss: 0.2017 - val_acc: 0.9041 - val_prec: 0.6444 - val_recall: 0.5515 - val_auc: 0.9363 - val_f2: 0.3889 - val_fbeta2: 0.5675\n",
      "Epoch 59/1000\n",
      "68791/68791 - 2s - loss: 0.1886 - acc: 0.9105 - prec: 0.6732 - recall: 0.5774 - auc: 0.9453 - f2: 0.4822 - fbeta2: 0.5945 - val_loss: 0.1975 - val_acc: 0.9065 - val_prec: 0.6480 - val_recall: 0.5836 - val_auc: 0.9392 - val_f2: 0.4733 - val_fbeta2: 0.5953\n",
      "Epoch 60/1000\n",
      "68791/68791 - 2s - loss: 0.1889 - acc: 0.9104 - prec: 0.6717 - recall: 0.5794 - auc: 0.9451 - f2: 0.4829 - fbeta2: 0.5954 - val_loss: 0.1975 - val_acc: 0.9068 - val_prec: 0.6583 - val_recall: 0.5582 - val_auc: 0.9391 - val_f2: 0.4308 - val_fbeta2: 0.5756\n",
      "Epoch 61/1000\n",
      "68791/68791 - 2s - loss: 0.1876 - acc: 0.9110 - prec: 0.6749 - recall: 0.5804 - auc: 0.9460 - f2: 0.4883 - fbeta2: 0.5975 - val_loss: 0.2015 - val_acc: 0.9043 - val_prec: 0.6342 - val_recall: 0.5874 - val_auc: 0.9368 - val_f2: 0.4622 - val_fbeta2: 0.5960\n",
      "Epoch 62/1000\n",
      "68791/68791 - 2s - loss: 0.1873 - acc: 0.9112 - prec: 0.6746 - recall: 0.5843 - auc: 0.9461 - f2: 0.4900 - fbeta2: 0.6002 - val_loss: 0.2008 - val_acc: 0.9052 - val_prec: 0.6348 - val_recall: 0.6025 - val_auc: 0.9372 - val_f2: 0.5065 - val_fbeta2: 0.6086\n",
      "Epoch 63/1000\n",
      "68791/68791 - 2s - loss: 0.1867 - acc: 0.9116 - prec: 0.6750 - recall: 0.5891 - auc: 0.9465 - f2: 0.4979 - fbeta2: 0.6045 - val_loss: 0.2068 - val_acc: 0.9025 - val_prec: 0.6303 - val_recall: 0.5684 - val_auc: 0.9335 - val_f2: 0.4414 - val_fbeta2: 0.5796\n",
      "Epoch 64/1000\n",
      "68791/68791 - 2s - loss: 0.1868 - acc: 0.9114 - prec: 0.6756 - recall: 0.5857 - auc: 0.9465 - f2: 0.4906 - fbeta2: 0.6014 - val_loss: 0.1976 - val_acc: 0.9070 - val_prec: 0.6525 - val_recall: 0.5777 - val_auc: 0.9392 - val_f2: 0.4745 - val_fbeta2: 0.5911\n",
      "Epoch 65/1000\n",
      "68791/68791 - 2s - loss: 0.1858 - acc: 0.9120 - prec: 0.6769 - recall: 0.5914 - auc: 0.9471 - f2: 0.4979 - fbeta2: 0.6064 - val_loss: 0.1975 - val_acc: 0.9063 - val_prec: 0.6432 - val_recall: 0.5938 - val_auc: 0.9394 - val_f2: 0.5191 - val_fbeta2: 0.6029\n",
      "Epoch 66/1000\n",
      "68791/68791 - 2s - loss: 0.1852 - acc: 0.9123 - prec: 0.6775 - recall: 0.5947 - auc: 0.9475 - f2: 0.5073 - fbeta2: 0.6094 - val_loss: 0.2007 - val_acc: 0.9059 - val_prec: 0.6519 - val_recall: 0.5605 - val_auc: 0.9373 - val_f2: 0.4143 - val_fbeta2: 0.5764\n",
      "Epoch 67/1000\n",
      "68791/68791 - 2s - loss: 0.1849 - acc: 0.9123 - prec: 0.6776 - recall: 0.5943 - auc: 0.9477 - f2: 0.5001 - fbeta2: 0.6099 - val_loss: 0.1993 - val_acc: 0.9057 - val_prec: 0.6460 - val_recall: 0.5758 - val_auc: 0.9381 - val_f2: 0.4648 - val_fbeta2: 0.5884\n",
      "Epoch 68/1000\n",
      "68791/68791 - 2s - loss: 0.1848 - acc: 0.9127 - prec: 0.6792 - recall: 0.5962 - auc: 0.9478 - f2: 0.5035 - fbeta2: 0.6098 - val_loss: 0.1993 - val_acc: 0.9060 - val_prec: 0.6449 - val_recall: 0.5838 - val_auc: 0.9382 - val_f2: 0.4983 - val_fbeta2: 0.5948\n",
      "Epoch 69/1000\n",
      "68791/68791 - 2s - loss: 0.1837 - acc: 0.9133 - prec: 0.6800 - recall: 0.6031 - auc: 0.9485 - f2: 0.5128 - fbeta2: 0.6170 - val_loss: 0.2006 - val_acc: 0.9058 - val_prec: 0.6511 - val_recall: 0.5623 - val_auc: 0.9373 - val_f2: 0.3979 - val_fbeta2: 0.5777\n",
      "Epoch 70/1000\n",
      "68791/68791 - 2s - loss: 0.1837 - acc: 0.9133 - prec: 0.6796 - recall: 0.6032 - auc: 0.9485 - f2: 0.5104 - fbeta2: 0.6167 - val_loss: 0.1996 - val_acc: 0.9063 - val_prec: 0.6514 - val_recall: 0.5689 - val_auc: 0.9378 - val_f2: 0.4555 - val_fbeta2: 0.5834\n",
      "Epoch 71/1000\n",
      "68791/68791 - 2s - loss: 0.1830 - acc: 0.9138 - prec: 0.6835 - recall: 0.6016 - auc: 0.9490 - f2: 0.5117 - fbeta2: 0.6159 - val_loss: 0.2025 - val_acc: 0.9048 - val_prec: 0.6364 - val_recall: 0.5899 - val_auc: 0.9363 - val_f2: 0.5091 - val_fbeta2: 0.5984\n",
      "Epoch 72/1000\n",
      "68791/68791 - 2s - loss: 0.1834 - acc: 0.9135 - prec: 0.6801 - recall: 0.6049 - auc: 0.9486 - f2: 0.5074 - fbeta2: 0.6179 - val_loss: 0.2002 - val_acc: 0.9063 - val_prec: 0.6486 - val_recall: 0.5773 - val_auc: 0.9378 - val_f2: 0.4398 - val_fbeta2: 0.5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "68791/68791 - 2s - loss: 0.1819 - acc: 0.9147 - prec: 0.6848 - recall: 0.6110 - auc: 0.9496 - f2: 0.5224 - fbeta2: 0.6238 - val_loss: 0.1990 - val_acc: 0.9066 - val_prec: 0.6466 - val_recall: 0.5882 - val_auc: 0.9387 - val_f2: 0.4679 - val_fbeta2: 0.5988\n",
      "Epoch 74/1000\n",
      "68791/68791 - 2s - loss: 0.1811 - acc: 0.9148 - prec: 0.6852 - recall: 0.6122 - auc: 0.9501 - f2: 0.5207 - fbeta2: 0.6254 - val_loss: 0.2015 - val_acc: 0.9056 - val_prec: 0.6407 - val_recall: 0.5898 - val_auc: 0.9374 - val_f2: 0.4939 - val_fbeta2: 0.5992\n",
      "Epoch 75/1000\n",
      "68791/68791 - 2s - loss: 0.1809 - acc: 0.9149 - prec: 0.6844 - recall: 0.6148 - auc: 0.9502 - f2: 0.5274 - fbeta2: 0.6277 - val_loss: 0.1985 - val_acc: 0.9061 - val_prec: 0.6493 - val_recall: 0.5723 - val_auc: 0.9387 - val_f2: 0.4612 - val_fbeta2: 0.5861\n",
      "17198/17198 [==============================] - ETA: 5s - loss: 0.2613 - acc: 0.8828 - prec: 0.5263 - recall: 0.4762 - auc: 0.8899 - f2: 0.3582 - fbeta2: 0.485 - ETA: 2s - loss: 0.1952 - acc: 0.9089 - prec: 0.6574 - recall: 0.5794 - auc: 0.9397 - f2: 0.3939 - fbeta2: 0.592 - ETA: 2s - loss: 0.1989 - acc: 0.9075 - prec: 0.6545 - recall: 0.5841 - auc: 0.9378 - f2: 0.4114 - fbeta2: 0.596 - ETA: 2s - loss: 0.1979 - acc: 0.9089 - prec: 0.6550 - recall: 0.5871 - auc: 0.9378 - f2: 0.4094 - fbeta2: 0.599 - ETA: 2s - loss: 0.2007 - acc: 0.9084 - prec: 0.6527 - recall: 0.5871 - auc: 0.9361 - f2: 0.4036 - fbeta2: 0.599 - ETA: 2s - loss: 0.2001 - acc: 0.9078 - prec: 0.6502 - recall: 0.5885 - auc: 0.9366 - f2: 0.4028 - fbeta2: 0.600 - ETA: 2s - loss: 0.2016 - acc: 0.9068 - prec: 0.6478 - recall: 0.5836 - auc: 0.9359 - f2: 0.4047 - fbeta2: 0.595 - ETA: 2s - loss: 0.1985 - acc: 0.9077 - prec: 0.6510 - recall: 0.5848 - auc: 0.9379 - f2: 0.4024 - fbeta2: 0.597 - ETA: 2s - loss: 0.1993 - acc: 0.9067 - prec: 0.6462 - recall: 0.5791 - auc: 0.9372 - f2: 0.3975 - fbeta2: 0.591 - ETA: 1s - loss: 0.1989 - acc: 0.9070 - prec: 0.6471 - recall: 0.5788 - auc: 0.9372 - f2: 0.3965 - fbeta2: 0.591 - ETA: 1s - loss: 0.1997 - acc: 0.9069 - prec: 0.6435 - recall: 0.5794 - auc: 0.9364 - f2: 0.3953 - fbeta2: 0.591 - ETA: 1s - loss: 0.1995 - acc: 0.9069 - prec: 0.6420 - recall: 0.5801 - auc: 0.9365 - f2: 0.3953 - fbeta2: 0.591 - ETA: 1s - loss: 0.2001 - acc: 0.9064 - prec: 0.6391 - recall: 0.5776 - auc: 0.9359 - f2: 0.3933 - fbeta2: 0.588 - ETA: 1s - loss: 0.1991 - acc: 0.9068 - prec: 0.6424 - recall: 0.5787 - auc: 0.9368 - f2: 0.3917 - fbeta2: 0.590 - ETA: 1s - loss: 0.1989 - acc: 0.9068 - prec: 0.6443 - recall: 0.5760 - auc: 0.9371 - f2: 0.3907 - fbeta2: 0.588 - ETA: 1s - loss: 0.1982 - acc: 0.9067 - prec: 0.6448 - recall: 0.5758 - auc: 0.9377 - f2: 0.3910 - fbeta2: 0.588 - ETA: 1s - loss: 0.1982 - acc: 0.9066 - prec: 0.6446 - recall: 0.5750 - auc: 0.9378 - f2: 0.3924 - fbeta2: 0.587 - ETA: 1s - loss: 0.1983 - acc: 0.9067 - prec: 0.6462 - recall: 0.5758 - auc: 0.9380 - f2: 0.3921 - fbeta2: 0.588 - ETA: 1s - loss: 0.1981 - acc: 0.9067 - prec: 0.6474 - recall: 0.5760 - auc: 0.9383 - f2: 0.3950 - fbeta2: 0.588 - ETA: 1s - loss: 0.1978 - acc: 0.9066 - prec: 0.6472 - recall: 0.5758 - auc: 0.9385 - f2: 0.3953 - fbeta2: 0.588 - ETA: 1s - loss: 0.1977 - acc: 0.9068 - prec: 0.6489 - recall: 0.5771 - auc: 0.9387 - f2: 0.3952 - fbeta2: 0.589 - ETA: 1s - loss: 0.1979 - acc: 0.9065 - prec: 0.6480 - recall: 0.5754 - auc: 0.9387 - f2: 0.3939 - fbeta2: 0.587 - ETA: 1s - loss: 0.1976 - acc: 0.9068 - prec: 0.6492 - recall: 0.5759 - auc: 0.9389 - f2: 0.3946 - fbeta2: 0.588 - ETA: 1s - loss: 0.1972 - acc: 0.9069 - prec: 0.6499 - recall: 0.5764 - auc: 0.9392 - f2: 0.3936 - fbeta2: 0.589 - ETA: 1s - loss: 0.1966 - acc: 0.9073 - prec: 0.6523 - recall: 0.5775 - auc: 0.9397 - f2: 0.3932 - fbeta2: 0.590 - ETA: 1s - loss: 0.1964 - acc: 0.9073 - prec: 0.6520 - recall: 0.5777 - auc: 0.9398 - f2: 0.3938 - fbeta2: 0.590 - ETA: 1s - loss: 0.1965 - acc: 0.9072 - prec: 0.6513 - recall: 0.5773 - auc: 0.9396 - f2: 0.3934 - fbeta2: 0.590 - ETA: 0s - loss: 0.1966 - acc: 0.9071 - prec: 0.6511 - recall: 0.5768 - auc: 0.9396 - f2: 0.3926 - fbeta2: 0.589 - ETA: 0s - loss: 0.1965 - acc: 0.9071 - prec: 0.6521 - recall: 0.5763 - auc: 0.9399 - f2: 0.3941 - fbeta2: 0.589 - ETA: 0s - loss: 0.1971 - acc: 0.9068 - prec: 0.6514 - recall: 0.5755 - auc: 0.9395 - f2: 0.3933 - fbeta2: 0.588 - ETA: 0s - loss: 0.1972 - acc: 0.9069 - prec: 0.6523 - recall: 0.5757 - auc: 0.9395 - f2: 0.3942 - fbeta2: 0.589 - ETA: 0s - loss: 0.1975 - acc: 0.9068 - prec: 0.6514 - recall: 0.5756 - auc: 0.9393 - f2: 0.3937 - fbeta2: 0.588 - ETA: 0s - loss: 0.1976 - acc: 0.9067 - prec: 0.6510 - recall: 0.5748 - auc: 0.9392 - f2: 0.3936 - fbeta2: 0.588 - ETA: 0s - loss: 0.1971 - acc: 0.9068 - prec: 0.6521 - recall: 0.5757 - auc: 0.9396 - f2: 0.3953 - fbeta2: 0.589 - ETA: 0s - loss: 0.1973 - acc: 0.9066 - prec: 0.6514 - recall: 0.5750 - auc: 0.9395 - f2: 0.3954 - fbeta2: 0.588 - ETA: 0s - loss: 0.1973 - acc: 0.9068 - prec: 0.6519 - recall: 0.5752 - auc: 0.9394 - f2: 0.3958 - fbeta2: 0.588 - ETA: 0s - loss: 0.1972 - acc: 0.9067 - prec: 0.6520 - recall: 0.5748 - auc: 0.9395 - f2: 0.3958 - fbeta2: 0.588 - ETA: 0s - loss: 0.1971 - acc: 0.9067 - prec: 0.6518 - recall: 0.5749 - auc: 0.9395 - f2: 0.3962 - fbeta2: 0.588 - ETA: 0s - loss: 0.1973 - acc: 0.9067 - prec: 0.6516 - recall: 0.5748 - auc: 0.9394 - f2: 0.3963 - fbeta2: 0.588 - ETA: 0s - loss: 0.1978 - acc: 0.9064 - prec: 0.6511 - recall: 0.5737 - auc: 0.9391 - f2: 0.3960 - fbeta2: 0.587 - ETA: 0s - loss: 0.1982 - acc: 0.9061 - prec: 0.6501 - recall: 0.5725 - auc: 0.9389 - f2: 0.3952 - fbeta2: 0.586 - ETA: 0s - loss: 0.1984 - acc: 0.9060 - prec: 0.6496 - recall: 0.5725 - auc: 0.9388 - f2: 0.3953 - fbeta2: 0.586 - ETA: 0s - loss: 0.1984 - acc: 0.9060 - prec: 0.6491 - recall: 0.5723 - auc: 0.9388 - f2: 0.3957 - fbeta2: 0.585 - ETA: 0s - loss: 0.1984 - acc: 0.9061 - prec: 0.6501 - recall: 0.5727 - auc: 0.9388 - f2: 0.3959 - fbeta2: 0.586 - ETA: 0s - loss: 0.1983 - acc: 0.9062 - prec: 0.6502 - recall: 0.5728 - auc: 0.9388 - f2: 0.3960 - fbeta2: 0.586 - ETA: 0s - loss: 0.1984 - acc: 0.9062 - prec: 0.6497 - recall: 0.5725 - auc: 0.9388 - f2: 0.3955 - fbeta2: 0.585 - 2s 141us/sample - loss: 0.1985 - acc: 0.9061 - prec: 0.6493 - recall: 0.5723 - auc: 0.9387 - f2: 0.3954 - fbeta2: 0.5857\n"
     ]
    }
   ],
   "source": [
    "fold=0\n",
    "k_fold = IterativeStratification(n_splits=5, order=3)#, random_state=23)\n",
    "for train, test in k_fold.split(X_train, y_train):\n",
    "    print(fold)\n",
    "    model = build_model()\n",
    "    hist = model.fit(x[train], y[train], epochs=1000, batch_size=1024, workers=4, \n",
    "                 validation_data=(x[test], y[test]), \n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max')], \n",
    "             verbose=2)\n",
    "\n",
    "    #Train the multiforest using the training indices\n",
    "    result=model.evaluate(x[test], y[test])\n",
    "    results_dict = dict(zip(model.metrics_names, result))\n",
    "    #record and print metrics\n",
    "\n",
    "    fold+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85989 samples, validate on 36858 samples\n",
      "Epoch 1/52\n",
      "85989/85989 - 5s - loss: 0.5211 - acc: 0.8388 - prec: 0.1396 - recall: 0.0514 - auc: 0.5277 - f2: 0.0296 - fbeta2: 0.0391 - val_loss: 0.3611 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7135 - val_f2: 0.0000e+00 - val_fbeta2: 5.9935e-11\n",
      "Epoch 2/52\n",
      "85989/85989 - 3s - loss: 0.3431 - acc: 0.8726 - prec: 1.0000 - recall: 5.7071e-06 - auc: 0.7357 - f2: 3.1184e-06 - fbeta2: 7.0552e-06 - val_loss: 0.3365 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7474 - val_f2: 0.0000e+00 - val_fbeta2: 5.9935e-11\n",
      "Epoch 3/52\n",
      "85989/85989 - 3s - loss: 0.3355 - acc: 0.8726 - prec: 0.2714 - recall: 1.0844e-04 - auc: 0.7473 - f2: 7.9933e-05 - fbeta2: 1.3533e-04 - val_loss: 0.3348 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7474 - val_f2: 0.0000e+00 - val_fbeta2: 5.9935e-11\n",
      "Epoch 4/52\n",
      "85989/85989 - 3s - loss: 0.3346 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7474 - f2: 0.0000e+00 - fbeta2: 5.9933e-11 - val_loss: 0.3344 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7476 - val_f2: 0.0000e+00 - val_fbeta2: 5.9935e-11\n",
      "Epoch 5/52\n",
      "85989/85989 - 3s - loss: 0.3344 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7474 - f2: 0.0000e+00 - fbeta2: 5.9934e-11 - val_loss: 0.3343 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7474 - val_f2: 0.0000e+00 - val_fbeta2: 5.9935e-11\n",
      "Epoch 6/52\n",
      "85989/85989 - 3s - loss: 0.3343 - acc: 0.8726 - prec: 0.2937 - recall: 2.1116e-04 - auc: 0.7479 - f2: 2.1492e-04 - fbeta2: 2.6228e-04 - val_loss: 0.3343 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7473 - val_f2: 0.0000e+00 - val_fbeta2: 5.9935e-11\n",
      "Epoch 7/52\n",
      "85989/85989 - 3s - loss: 0.3343 - acc: 0.8726 - prec: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7473 - f2: 0.0000e+00 - fbeta2: 5.9789e-11 - val_loss: 0.3343 - val_acc: 0.8727 - val_prec: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7474 - val_f2: 0.0000e+00 - val_fbeta2: 5.9935e-11\n",
      "Epoch 8/52\n",
      "85989/85989 - 3s - loss: 0.3343 - acc: 0.8726 - prec: 0.5455 - recall: 6.8485e-05 - auc: 0.7474 - f2: 5.0882e-05 - fbeta2: 8.4437e-05 - val_loss: 0.3339 - val_acc: 0.8726 - val_prec: 0.4000 - val_recall: 3.9948e-04 - val_auc: 0.7483 - val_f2: 3.0887e-04 - val_fbeta2: 5.0101e-04\n",
      "Epoch 9/52\n",
      "85989/85989 - 3s - loss: 0.3115 - acc: 0.8733 - prec: 0.5476 - recall: 0.0304 - auc: 0.8021 - f2: 0.0324 - fbeta2: 0.0366 - val_loss: 0.3942 - val_acc: 0.7910 - val_prec: 0.2663 - val_recall: 0.3653 - val_auc: 0.7718 - val_f2: 0.2710 - val_fbeta2: 0.3400\n",
      "Epoch 10/52\n",
      "85989/85989 - 3s - loss: 0.2560 - acc: 0.8836 - prec: 0.6136 - recall: 0.2331 - auc: 0.8863 - f2: 0.1749 - fbeta2: 0.2652 - val_loss: 0.2580 - val_acc: 0.8821 - val_prec: 0.6403 - val_recall: 0.1684 - val_auc: 0.8875 - val_f2: 0.1569 - val_fbeta2: 0.1974\n",
      "Epoch 11/52\n",
      "85989/85989 - 3s - loss: 0.2402 - acc: 0.8870 - prec: 0.6072 - recall: 0.3193 - auc: 0.9033 - f2: 0.2338 - fbeta2: 0.3523 - val_loss: 0.2325 - val_acc: 0.8901 - val_prec: 0.6189 - val_recall: 0.3567 - val_auc: 0.9108 - val_f2: 0.2866 - val_fbeta2: 0.3897\n",
      "Epoch 12/52\n",
      "85989/85989 - 3s - loss: 0.2308 - acc: 0.8903 - prec: 0.6139 - recall: 0.3741 - auc: 0.9124 - f2: 0.2751 - fbeta2: 0.4054 - val_loss: 0.2310 - val_acc: 0.8888 - val_prec: 0.5758 - val_recall: 0.4807 - val_auc: 0.9135 - val_f2: 0.4014 - val_fbeta2: 0.4971\n",
      "Epoch 13/52\n",
      "85989/85989 - 3s - loss: 0.2255 - acc: 0.8925 - prec: 0.6196 - recall: 0.4046 - auc: 0.9171 - f2: 0.3056 - fbeta2: 0.4344 - val_loss: 0.2205 - val_acc: 0.8943 - val_prec: 0.6365 - val_recall: 0.3967 - val_auc: 0.9215 - val_f2: 0.3029 - val_fbeta2: 0.4288\n",
      "Epoch 14/52\n",
      "85989/85989 - 3s - loss: 0.2224 - acc: 0.8936 - prec: 0.6234 - recall: 0.4151 - auc: 0.9198 - f2: 0.3164 - fbeta2: 0.4445 - val_loss: 0.2163 - val_acc: 0.8961 - val_prec: 0.6099 - val_recall: 0.5105 - val_auc: 0.9252 - val_f2: 0.4054 - val_fbeta2: 0.5277\n",
      "Epoch 15/52\n",
      "85989/85989 - 3s - loss: 0.2183 - acc: 0.8956 - prec: 0.6299 - recall: 0.4367 - auc: 0.9232 - f2: 0.3440 - fbeta2: 0.4650 - val_loss: 0.2199 - val_acc: 0.8941 - val_prec: 0.6003 - val_recall: 0.5037 - val_auc: 0.9228 - val_f2: 0.4088 - val_fbeta2: 0.5204\n",
      "Epoch 16/52\n",
      "85989/85989 - 3s - loss: 0.2155 - acc: 0.8965 - prec: 0.6330 - recall: 0.4448 - auc: 0.9254 - f2: 0.3443 - fbeta2: 0.4725 - val_loss: 0.2117 - val_acc: 0.8982 - val_prec: 0.6443 - val_recall: 0.4474 - val_auc: 0.9287 - val_f2: 0.3643 - val_fbeta2: 0.4764\n",
      "Epoch 17/52\n",
      "85989/85989 - 3s - loss: 0.2131 - acc: 0.8980 - prec: 0.6385 - recall: 0.4588 - auc: 0.9274 - f2: 0.3610 - fbeta2: 0.4858 - val_loss: 0.2097 - val_acc: 0.8995 - val_prec: 0.6401 - val_recall: 0.4814 - val_auc: 0.9301 - val_f2: 0.3791 - val_fbeta2: 0.5064\n",
      "Epoch 18/52\n",
      "85989/85989 - 3s - loss: 0.2109 - acc: 0.8991 - prec: 0.6423 - recall: 0.4679 - auc: 0.9291 - f2: 0.3703 - fbeta2: 0.4945 - val_loss: 0.2093 - val_acc: 0.9001 - val_prec: 0.6323 - val_recall: 0.5158 - val_auc: 0.9304 - val_f2: 0.3830 - val_fbeta2: 0.5353\n",
      "Epoch 19/52\n",
      "85989/85989 - 3s - loss: 0.2098 - acc: 0.8997 - prec: 0.6440 - recall: 0.4744 - auc: 0.9300 - f2: 0.3767 - fbeta2: 0.5006 - val_loss: 0.2053 - val_acc: 0.9017 - val_prec: 0.6465 - val_recall: 0.5024 - val_auc: 0.9335 - val_f2: 0.4155 - val_fbeta2: 0.5257\n",
      "Epoch 20/52\n",
      "85989/85989 - 3s - loss: 0.2081 - acc: 0.9004 - prec: 0.6460 - recall: 0.4817 - auc: 0.9313 - f2: 0.3860 - fbeta2: 0.5071 - val_loss: 0.2077 - val_acc: 0.9011 - val_prec: 0.6662 - val_recall: 0.4485 - val_auc: 0.9316 - val_f2: 0.3355 - val_fbeta2: 0.4797\n",
      "Epoch 21/52\n",
      "85989/85989 - 3s - loss: 0.2062 - acc: 0.9015 - prec: 0.6494 - recall: 0.4918 - auc: 0.9328 - f2: 0.3951 - fbeta2: 0.5167 - val_loss: 0.2038 - val_acc: 0.9027 - val_prec: 0.6512 - val_recall: 0.5072 - val_auc: 0.9347 - val_f2: 0.3837 - val_fbeta2: 0.5306\n",
      "Epoch 22/52\n",
      "85989/85989 - 3s - loss: 0.2062 - acc: 0.9012 - prec: 0.6472 - recall: 0.4936 - auc: 0.9328 - f2: 0.3967 - fbeta2: 0.5179 - val_loss: 0.2043 - val_acc: 0.9024 - val_prec: 0.6550 - val_recall: 0.4931 - val_auc: 0.9343 - val_f2: 0.3530 - val_fbeta2: 0.5185\n",
      "Epoch 23/52\n",
      "85989/85989 - 3s - loss: 0.2047 - acc: 0.9023 - prec: 0.6516 - recall: 0.5011 - auc: 0.9339 - f2: 0.4039 - fbeta2: 0.5252 - val_loss: 0.2065 - val_acc: 0.9013 - val_prec: 0.6389 - val_recall: 0.5171 - val_auc: 0.9327 - val_f2: 0.4081 - val_fbeta2: 0.5375\n",
      "Epoch 24/52\n",
      "85989/85989 - 3s - loss: 0.2046 - acc: 0.9024 - prec: 0.6518 - recall: 0.5010 - auc: 0.9340 - f2: 0.4024 - fbeta2: 0.5251 - val_loss: 0.2027 - val_acc: 0.9030 - val_prec: 0.6573 - val_recall: 0.4987 - val_auc: 0.9353 - val_f2: 0.3796 - val_fbeta2: 0.5237\n",
      "Epoch 25/52\n",
      "85989/85989 - 3s - loss: 0.2027 - acc: 0.9033 - prec: 0.6551 - recall: 0.5091 - auc: 0.9354 - f2: 0.4129 - fbeta2: 0.5327 - val_loss: 0.2017 - val_acc: 0.9039 - val_prec: 0.6659 - val_recall: 0.4918 - val_auc: 0.9363 - val_f2: 0.3707 - val_fbeta2: 0.5188\n",
      "Epoch 26/52\n",
      "85989/85989 - 3s - loss: 0.2028 - acc: 0.9033 - prec: 0.6541 - recall: 0.5111 - auc: 0.9353 - f2: 0.4176 - fbeta2: 0.5342 - val_loss: 0.2072 - val_acc: 0.9001 - val_prec: 0.6188 - val_recall: 0.5606 - val_auc: 0.9323 - val_f2: 0.4731 - val_fbeta2: 0.5713\n",
      "Epoch 27/52\n",
      "85989/85989 - 3s - loss: 0.2018 - acc: 0.9038 - prec: 0.6565 - recall: 0.5132 - auc: 0.9360 - f2: 0.4145 - fbeta2: 0.5364 - val_loss: 0.2068 - val_acc: 0.9011 - val_prec: 0.6505 - val_recall: 0.4827 - val_auc: 0.9327 - val_f2: 0.3829 - val_fbeta2: 0.5088\n",
      "Epoch 28/52\n",
      "85989/85989 - 3s - loss: 0.2008 - acc: 0.9044 - prec: 0.6570 - recall: 0.5211 - auc: 0.9368 - f2: 0.4206 - fbeta2: 0.5434 - val_loss: 0.2027 - val_acc: 0.9033 - val_prec: 0.6453 - val_recall: 0.5342 - val_auc: 0.9354 - val_f2: 0.4775 - val_fbeta2: 0.5532\n",
      "Epoch 29/52\n",
      "85989/85989 - 3s - loss: 0.2000 - acc: 0.9048 - prec: 0.6598 - recall: 0.5214 - auc: 0.9374 - f2: 0.4240 - fbeta2: 0.5440 - val_loss: 0.2027 - val_acc: 0.9038 - val_prec: 0.6407 - val_recall: 0.5569 - val_auc: 0.9355 - val_f2: 0.4645 - val_fbeta2: 0.5718\n",
      "Epoch 30/52\n",
      "85989/85989 - 3s - loss: 0.1990 - acc: 0.9055 - prec: 0.6606 - recall: 0.5302 - auc: 0.9381 - f2: 0.4314 - fbeta2: 0.5517 - val_loss: 0.1990 - val_acc: 0.9051 - val_prec: 0.6662 - val_recall: 0.5108 - val_auc: 0.9380 - val_f2: 0.4055 - val_fbeta2: 0.5356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/52\n",
      "85989/85989 - 3s - loss: 0.1984 - acc: 0.9056 - prec: 0.6618 - recall: 0.5296 - auc: 0.9385 - f2: 0.4334 - fbeta2: 0.5515 - val_loss: 0.2014 - val_acc: 0.9035 - val_prec: 0.6439 - val_recall: 0.5419 - val_auc: 0.9364 - val_f2: 0.4731 - val_fbeta2: 0.5596\n",
      "Epoch 32/52\n",
      "85989/85989 - 3s - loss: 0.1985 - acc: 0.9057 - prec: 0.6618 - recall: 0.5315 - auc: 0.9385 - f2: 0.4375 - fbeta2: 0.5531 - val_loss: 0.1989 - val_acc: 0.9054 - val_prec: 0.6525 - val_recall: 0.5509 - val_auc: 0.9381 - val_f2: 0.4242 - val_fbeta2: 0.5685\n",
      "Epoch 33/52\n",
      "85989/85989 - 3s - loss: 0.1972 - acc: 0.9063 - prec: 0.6639 - recall: 0.5350 - auc: 0.9393 - f2: 0.4372 - fbeta2: 0.5565 - val_loss: 0.1981 - val_acc: 0.9057 - val_prec: 0.6623 - val_recall: 0.5290 - val_auc: 0.9387 - val_f2: 0.4079 - val_fbeta2: 0.5510\n",
      "Epoch 34/52\n",
      "85989/85989 - 3s - loss: 0.1963 - acc: 0.9070 - prec: 0.6656 - recall: 0.5425 - auc: 0.9401 - f2: 0.4490 - fbeta2: 0.5631 - val_loss: 0.1973 - val_acc: 0.9063 - val_prec: 0.6618 - val_recall: 0.5406 - val_auc: 0.9393 - val_f2: 0.4363 - val_fbeta2: 0.5610\n",
      "Epoch 35/52\n",
      "85989/85989 - 3s - loss: 0.1959 - acc: 0.9072 - prec: 0.6659 - recall: 0.5440 - auc: 0.9403 - f2: 0.4432 - fbeta2: 0.5646 - val_loss: 0.1999 - val_acc: 0.9048 - val_prec: 0.6541 - val_recall: 0.5356 - val_auc: 0.9374 - val_f2: 0.4393 - val_fbeta2: 0.5557\n",
      "Epoch 36/52\n",
      "85989/85989 - 3s - loss: 0.1957 - acc: 0.9071 - prec: 0.6655 - recall: 0.5440 - auc: 0.9404 - f2: 0.4510 - fbeta2: 0.5644 - val_loss: 0.1968 - val_acc: 0.9063 - val_prec: 0.6579 - val_recall: 0.5498 - val_auc: 0.9396 - val_f2: 0.4197 - val_fbeta2: 0.5684\n",
      "Epoch 37/52\n",
      "85989/85989 - 3s - loss: 0.1945 - acc: 0.9080 - prec: 0.6681 - recall: 0.5510 - auc: 0.9413 - f2: 0.4563 - fbeta2: 0.5710 - val_loss: 0.1981 - val_acc: 0.9057 - val_prec: 0.6637 - val_recall: 0.5259 - val_auc: 0.9388 - val_f2: 0.4231 - val_fbeta2: 0.5485\n",
      "Epoch 38/52\n",
      "85989/85989 - 3s - loss: 0.1943 - acc: 0.9080 - prec: 0.6680 - recall: 0.5517 - auc: 0.9414 - f2: 0.4588 - fbeta2: 0.5714 - val_loss: 0.1982 - val_acc: 0.9055 - val_prec: 0.6593 - val_recall: 0.5340 - val_auc: 0.9387 - val_f2: 0.4077 - val_fbeta2: 0.5550\n",
      "Epoch 39/52\n",
      "85989/85989 - 3s - loss: 0.1934 - acc: 0.9082 - prec: 0.6686 - recall: 0.5537 - auc: 0.9420 - f2: 0.4582 - fbeta2: 0.5732 - val_loss: 0.1963 - val_acc: 0.9065 - val_prec: 0.6604 - val_recall: 0.5467 - val_auc: 0.9400 - val_f2: 0.4328 - val_fbeta2: 0.5660\n",
      "Epoch 40/52\n",
      "85989/85989 - 3s - loss: 0.1926 - acc: 0.9088 - prec: 0.6700 - recall: 0.5602 - auc: 0.9426 - f2: 0.4659 - fbeta2: 0.5791 - val_loss: 0.1963 - val_acc: 0.9069 - val_prec: 0.6637 - val_recall: 0.5458 - val_auc: 0.9400 - val_f2: 0.4318 - val_fbeta2: 0.5657\n",
      "Epoch 41/52\n",
      "85989/85989 - 3s - loss: 0.1923 - acc: 0.9091 - prec: 0.6704 - recall: 0.5627 - auc: 0.9428 - f2: 0.4678 - fbeta2: 0.5813 - val_loss: 0.1975 - val_acc: 0.9061 - val_prec: 0.6622 - val_recall: 0.5360 - val_auc: 0.9392 - val_f2: 0.4685 - val_fbeta2: 0.5571\n",
      "Epoch 42/52\n",
      "85989/85989 - 3s - loss: 0.1921 - acc: 0.9091 - prec: 0.6710 - recall: 0.5610 - auc: 0.9430 - f2: 0.4702 - fbeta2: 0.5799 - val_loss: 0.1960 - val_acc: 0.9066 - val_prec: 0.6561 - val_recall: 0.5607 - val_auc: 0.9401 - val_f2: 0.4393 - val_fbeta2: 0.5773\n",
      "Epoch 43/52\n",
      "85989/85989 - 3s - loss: 0.1918 - acc: 0.9093 - prec: 0.6710 - recall: 0.5641 - auc: 0.9431 - f2: 0.4750 - fbeta2: 0.5825 - val_loss: 0.1958 - val_acc: 0.9068 - val_prec: 0.6638 - val_recall: 0.5434 - val_auc: 0.9405 - val_f2: 0.4334 - val_fbeta2: 0.5637\n",
      "Epoch 44/52\n",
      "85989/85989 - 3s - loss: 0.1904 - acc: 0.9101 - prec: 0.6733 - recall: 0.5709 - auc: 0.9441 - f2: 0.4746 - fbeta2: 0.5887 - val_loss: 0.1944 - val_acc: 0.9079 - val_prec: 0.6721 - val_recall: 0.5401 - val_auc: 0.9414 - val_f2: 0.4294 - val_fbeta2: 0.5620\n",
      "Epoch 45/52\n",
      "85989/85989 - 3s - loss: 0.1904 - acc: 0.9099 - prec: 0.6732 - recall: 0.5690 - auc: 0.9441 - f2: 0.4751 - fbeta2: 0.5870 - val_loss: 0.1961 - val_acc: 0.9070 - val_prec: 0.6580 - val_recall: 0.5606 - val_auc: 0.9401 - val_f2: 0.4750 - val_fbeta2: 0.5777\n",
      "Epoch 46/52\n",
      "85989/85989 - 3s - loss: 0.1900 - acc: 0.9101 - prec: 0.6739 - recall: 0.5702 - auc: 0.9444 - f2: 0.4754 - fbeta2: 0.5883 - val_loss: 0.1949 - val_acc: 0.9071 - val_prec: 0.6533 - val_recall: 0.5766 - val_auc: 0.9410 - val_f2: 0.4689 - val_fbeta2: 0.5903\n",
      "Epoch 47/52\n",
      "85989/85989 - 3s - loss: 0.1888 - acc: 0.9108 - prec: 0.6755 - recall: 0.5769 - auc: 0.9451 - f2: 0.4845 - fbeta2: 0.5941 - val_loss: 0.1944 - val_acc: 0.9076 - val_prec: 0.6668 - val_recall: 0.5478 - val_auc: 0.9413 - val_f2: 0.4330 - val_fbeta2: 0.5680\n",
      "Epoch 48/52\n",
      "85989/85989 - 3s - loss: 0.1889 - acc: 0.9107 - prec: 0.6750 - recall: 0.5761 - auc: 0.9450 - f2: 0.4839 - fbeta2: 0.5933 - val_loss: 0.1961 - val_acc: 0.9065 - val_prec: 0.6750 - val_recall: 0.5128 - val_auc: 0.9403 - val_f2: 0.4051 - val_fbeta2: 0.5385\n",
      "Epoch 49/52\n",
      "85989/85989 - 3s - loss: 0.1885 - acc: 0.9110 - prec: 0.6763 - recall: 0.5783 - auc: 0.9454 - f2: 0.4861 - fbeta2: 0.5954 - val_loss: 0.1949 - val_acc: 0.9068 - val_prec: 0.6583 - val_recall: 0.5581 - val_auc: 0.9410 - val_f2: 0.4351 - val_fbeta2: 0.5755\n",
      "Epoch 50/52\n",
      "85989/85989 - 3s - loss: 0.1875 - acc: 0.9116 - prec: 0.6773 - recall: 0.5846 - auc: 0.9460 - f2: 0.4943 - fbeta2: 0.6010 - val_loss: 0.1961 - val_acc: 0.9070 - val_prec: 0.6538 - val_recall: 0.5737 - val_auc: 0.9404 - val_f2: 0.4691 - val_fbeta2: 0.5880\n",
      "Epoch 51/52\n",
      "85989/85989 - 3s - loss: 0.1871 - acc: 0.9117 - prec: 0.6775 - recall: 0.5855 - auc: 0.9462 - f2: 0.4972 - fbeta2: 0.6018 - val_loss: 0.1950 - val_acc: 0.9074 - val_prec: 0.6574 - val_recall: 0.5698 - val_auc: 0.9410 - val_f2: 0.4476 - val_fbeta2: 0.5853\n",
      "Epoch 52/52\n",
      "85989/85989 - 3s - loss: 0.1860 - acc: 0.9125 - prec: 0.6807 - recall: 0.5889 - auc: 0.9470 - f2: 0.4951 - fbeta2: 0.6051 - val_loss: 0.1952 - val_acc: 0.9073 - val_prec: 0.6610 - val_recall: 0.5581 - val_auc: 0.9409 - val_f2: 0.4770 - val_fbeta2: 0.5759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26784/36858 [====================>.........] - ETA: 11s - loss: 0.2468 - acc: 0.8770 - prec: 0.5789 - recall: 0.4583 - auc: 0.9150 - f2: 0.4087 - fbeta2: 0.47 - ETA: 5s - loss: 0.2034 - acc: 0.9067 - prec: 0.6596 - recall: 0.5514 - auc: 0.9351 - f2: 0.4045 - fbeta2: 0.5719 - ETA: 5s - loss: 0.1998 - acc: 0.9103 - prec: 0.6754 - recall: 0.5575 - auc: 0.9372 - f2: 0.3997 - fbeta2: 0.578 - ETA: 5s - loss: 0.1976 - acc: 0.9093 - prec: 0.6736 - recall: 0.5540 - auc: 0.9392 - f2: 0.3983 - fbeta2: 0.574 - ETA: 5s - loss: 0.1980 - acc: 0.9089 - prec: 0.6697 - recall: 0.5569 - auc: 0.9387 - f2: 0.3980 - fbeta2: 0.575 - ETA: 4s - loss: 0.1995 - acc: 0.9066 - prec: 0.6570 - recall: 0.5507 - auc: 0.9375 - f2: 0.3933 - fbeta2: 0.568 - ETA: 4s - loss: 0.1977 - acc: 0.9071 - prec: 0.6604 - recall: 0.5536 - auc: 0.9390 - f2: 0.3941 - fbeta2: 0.571 - ETA: 4s - loss: 0.1983 - acc: 0.9065 - prec: 0.6576 - recall: 0.5512 - auc: 0.9384 - f2: 0.3932 - fbeta2: 0.568 - ETA: 4s - loss: 0.1989 - acc: 0.9064 - prec: 0.6595 - recall: 0.5502 - auc: 0.9385 - f2: 0.3930 - fbeta2: 0.568 - ETA: 4s - loss: 0.1982 - acc: 0.9068 - prec: 0.6606 - recall: 0.5506 - auc: 0.9388 - f2: 0.3904 - fbeta2: 0.568 - ETA: 4s - loss: 0.1983 - acc: 0.9064 - prec: 0.6600 - recall: 0.5493 - auc: 0.9388 - f2: 0.3897 - fbeta2: 0.567 - ETA: 4s - loss: 0.1983 - acc: 0.9062 - prec: 0.6600 - recall: 0.5512 - auc: 0.9391 - f2: 0.3920 - fbeta2: 0.569 - ETA: 4s - loss: 0.1966 - acc: 0.9071 - prec: 0.6625 - recall: 0.5543 - auc: 0.9401 - f2: 0.3972 - fbeta2: 0.572 - ETA: 4s - loss: 0.1962 - acc: 0.9073 - prec: 0.6637 - recall: 0.5560 - auc: 0.9404 - f2: 0.4006 - fbeta2: 0.573 - ETA: 4s - loss: 0.1962 - acc: 0.9075 - prec: 0.6639 - recall: 0.5580 - auc: 0.9404 - f2: 0.4029 - fbeta2: 0.575 - ETA: 4s - loss: 0.1961 - acc: 0.9072 - prec: 0.6625 - recall: 0.5574 - auc: 0.9404 - f2: 0.4027 - fbeta2: 0.574 - ETA: 4s - loss: 0.1961 - acc: 0.9072 - prec: 0.6613 - recall: 0.5588 - auc: 0.9404 - f2: 0.4038 - fbeta2: 0.575 - ETA: 4s - loss: 0.1960 - acc: 0.9073 - prec: 0.6625 - recall: 0.5589 - auc: 0.9405 - f2: 0.4049 - fbeta2: 0.575 - ETA: 4s - loss: 0.1951 - acc: 0.9075 - prec: 0.6629 - recall: 0.5608 - auc: 0.9411 - f2: 0.4061 - fbeta2: 0.577 - ETA: 4s - loss: 0.1954 - acc: 0.9074 - prec: 0.6621 - recall: 0.5602 - auc: 0.9408 - f2: 0.4056 - fbeta2: 0.577 - ETA: 4s - loss: 0.1953 - acc: 0.9075 - prec: 0.6626 - recall: 0.5610 - auc: 0.9410 - f2: 0.4067 - fbeta2: 0.577 - ETA: 4s - loss: 0.1958 - acc: 0.9074 - prec: 0.6623 - recall: 0.5595 - auc: 0.9406 - f2: 0.4077 - fbeta2: 0.576 - ETA: 3s - loss: 0.1957 - acc: 0.9073 - prec: 0.6623 - recall: 0.5585 - auc: 0.9406 - f2: 0.4072 - fbeta2: 0.575 - ETA: 3s - loss: 0.1955 - acc: 0.9073 - prec: 0.6618 - recall: 0.5585 - auc: 0.9407 - f2: 0.4065 - fbeta2: 0.575 - ETA: 3s - loss: 0.1953 - acc: 0.9075 - prec: 0.6615 - recall: 0.5589 - auc: 0.9407 - f2: 0.4068 - fbeta2: 0.575 - ETA: 3s - loss: 0.1953 - acc: 0.9074 - prec: 0.6610 - recall: 0.5589 - auc: 0.9408 - f2: 0.4068 - fbeta2: 0.575 - ETA: 3s - loss: 0.1952 - acc: 0.9075 - prec: 0.6599 - recall: 0.5593 - auc: 0.9406 - f2: 0.4075 - fbeta2: 0.575 - ETA: 3s - loss: 0.1953 - acc: 0.9074 - prec: 0.6583 - recall: 0.5594 - auc: 0.9404 - f2: 0.4083 - fbeta2: 0.575 - ETA: 3s - loss: 0.1955 - acc: 0.9073 - prec: 0.6581 - recall: 0.5589 - auc: 0.9403 - f2: 0.4078 - fbeta2: 0.575 - ETA: 3s - loss: 0.1947 - acc: 0.9077 - prec: 0.6589 - recall: 0.5606 - auc: 0.9408 - f2: 0.4085 - fbeta2: 0.576 - ETA: 3s - loss: 0.1949 - acc: 0.9075 - prec: 0.6576 - recall: 0.5602 - auc: 0.9406 - f2: 0.4083 - fbeta2: 0.576 - ETA: 3s - loss: 0.1945 - acc: 0.9076 - prec: 0.6584 - recall: 0.5609 - auc: 0.9409 - f2: 0.4088 - fbeta2: 0.576 - ETA: 3s - loss: 0.1946 - acc: 0.9076 - prec: 0.6585 - recall: 0.5603 - auc: 0.9408 - f2: 0.4083 - fbeta2: 0.576 - ETA: 3s - loss: 0.1946 - acc: 0.9076 - prec: 0.6583 - recall: 0.5598 - auc: 0.9408 - f2: 0.4074 - fbeta2: 0.576 - ETA: 3s - loss: 0.1947 - acc: 0.9076 - prec: 0.6583 - recall: 0.5597 - auc: 0.9408 - f2: 0.4068 - fbeta2: 0.575 - ETA: 3s - loss: 0.1945 - acc: 0.9076 - prec: 0.6583 - recall: 0.5598 - auc: 0.9409 - f2: 0.4067 - fbeta2: 0.576 - ETA: 3s - loss: 0.1943 - acc: 0.9076 - prec: 0.6586 - recall: 0.5606 - auc: 0.9410 - f2: 0.4065 - fbeta2: 0.576 - ETA: 3s - loss: 0.1942 - acc: 0.9076 - prec: 0.6586 - recall: 0.5603 - auc: 0.9411 - f2: 0.4063 - fbeta2: 0.576 - ETA: 3s - loss: 0.1942 - acc: 0.9076 - prec: 0.6581 - recall: 0.5603 - auc: 0.9411 - f2: 0.4065 - fbeta2: 0.576 - ETA: 3s - loss: 0.1942 - acc: 0.9075 - prec: 0.6582 - recall: 0.5596 - auc: 0.9411 - f2: 0.4069 - fbeta2: 0.575 - ETA: 3s - loss: 0.1940 - acc: 0.9075 - prec: 0.6585 - recall: 0.5597 - auc: 0.9413 - f2: 0.4072 - fbeta2: 0.576 - ETA: 2s - loss: 0.1941 - acc: 0.9075 - prec: 0.6584 - recall: 0.5596 - auc: 0.9413 - f2: 0.4063 - fbeta2: 0.575 - ETA: 2s - loss: 0.1939 - acc: 0.9076 - prec: 0.6589 - recall: 0.5605 - auc: 0.9414 - f2: 0.4065 - fbeta2: 0.576 - ETA: 2s - loss: 0.1938 - acc: 0.9077 - prec: 0.6591 - recall: 0.5607 - auc: 0.9415 - f2: 0.4068 - fbeta2: 0.577 - ETA: 2s - loss: 0.1938 - acc: 0.9077 - prec: 0.6598 - recall: 0.5606 - auc: 0.9415 - f2: 0.4071 - fbeta2: 0.577 - ETA: 2s - loss: 0.1936 - acc: 0.9078 - prec: 0.6607 - recall: 0.5610 - auc: 0.9417 - f2: 0.4073 - fbeta2: 0.577 - ETA: 2s - loss: 0.1934 - acc: 0.9080 - prec: 0.6616 - recall: 0.5618 - auc: 0.9419 - f2: 0.4078 - fbeta2: 0.578 - ETA: 2s - loss: 0.1932 - acc: 0.9081 - prec: 0.6624 - recall: 0.5625 - auc: 0.9420 - f2: 0.4080 - fbeta2: 0.579 - ETA: 2s - loss: 0.1931 - acc: 0.9082 - prec: 0.6626 - recall: 0.5622 - auc: 0.9421 - f2: 0.4079 - fbeta2: 0.578 - ETA: 2s - loss: 0.1931 - acc: 0.9081 - prec: 0.6623 - recall: 0.5624 - auc: 0.9421 - f2: 0.4075 - fbeta2: 0.578 - ETA: 2s - loss: 0.1929 - acc: 0.9083 - prec: 0.6634 - recall: 0.5628 - auc: 0.9423 - f2: 0.4079 - fbeta2: 0.579 - ETA: 2s - loss: 0.1929 - acc: 0.9084 - prec: 0.6636 - recall: 0.5630 - auc: 0.9423 - f2: 0.4080 - fbeta2: 0.579 - ETA: 2s - loss: 0.1928 - acc: 0.9084 - prec: 0.6636 - recall: 0.5632 - auc: 0.9423 - f2: 0.4081 - fbeta2: 0.579 - ETA: 2s - loss: 0.1926 - acc: 0.9085 - prec: 0.6639 - recall: 0.5637 - auc: 0.9424 - f2: 0.4091 - fbeta2: 0.580 - ETA: 2s - loss: 0.1927 - acc: 0.9084 - prec: 0.6637 - recall: 0.5632 - auc: 0.9424 - f2: 0.4085 - fbeta2: 0.579 - ETA: 2s - loss: 0.1925 - acc: 0.9085 - prec: 0.6642 - recall: 0.5635 - auc: 0.9425 - f2: 0.4088 - fbeta2: 0.580 - ETA: 2s - loss: 0.1926 - acc: 0.9084 - prec: 0.6641 - recall: 0.5634 - auc: 0.9425 - f2: 0.4083 - fbeta2: 0.580 - ETA: 2s - loss: 0.1924 - acc: 0.9085 - prec: 0.6643 - recall: 0.5637 - auc: 0.9426 - f2: 0.4082 - fbeta2: 0.580 - ETA: 2s - loss: 0.1923 - acc: 0.9085 - prec: 0.6645 - recall: 0.5638 - auc: 0.9427 - f2: 0.4082 - fbeta2: 0.580 - ETA: 2s - loss: 0.1924 - acc: 0.9084 - prec: 0.6645 - recall: 0.5634 - auc: 0.9426 - f2: 0.4079 - fbeta2: 0.580 - ETA: 1s - loss: 0.1923 - acc: 0.9085 - prec: 0.6650 - recall: 0.5637 - auc: 0.9428 - f2: 0.4087 - fbeta2: 0.580 - ETA: 1s - loss: 0.1925 - acc: 0.9084 - prec: 0.6648 - recall: 0.5633 - auc: 0.9426 - f2: 0.4083 - fbeta2: 0.580 - ETA: 1s - loss: 0.1924 - acc: 0.9085 - prec: 0.6655 - recall: 0.5636 - auc: 0.9427 - f2: 0.4083 - fbeta2: 0.580 - ETA: 1s - loss: 0.1924 - acc: 0.9085 - prec: 0.6649 - recall: 0.5636 - auc: 0.9426 - f2: 0.4082 - fbeta2: 0.580 - ETA: 1s - loss: 0.1923 - acc: 0.9086 - prec: 0.6650 - recall: 0.5638 - auc: 0.9427 - f2: 0.4081 - fbeta2: 0.580 - ETA: 1s - loss: 0.1924 - acc: 0.9086 - prec: 0.6651 - recall: 0.5637 - auc: 0.9426 - f2: 0.4080 - fbeta2: 0.580 - ETA: 1s - loss: 0.1925 - acc: 0.9086 - prec: 0.6649 - recall: 0.5629 - auc: 0.9425 - f2: 0.4075 - fbeta2: 0.579 - ETA: 1s - loss: 0.1925 - acc: 0.9085 - prec: 0.6650 - recall: 0.5629 - auc: 0.9426 - f2: 0.4071 - fbeta2: 0.579 - ETA: 1s - loss: 0.1925 - acc: 0.9086 - prec: 0.6653 - recall: 0.5627 - auc: 0.9426 - f2: 0.4070 - fbeta2: 0.579 - ETA: 1s - loss: 0.1925 - acc: 0.9085 - prec: 0.6651 - recall: 0.5627 - auc: 0.9426 - f2: 0.4068 - fbeta2: 0.579 - ETA: 1s - loss: 0.1926 - acc: 0.9085 - prec: 0.6650 - recall: 0.5624 - auc: 0.9425 - f2: 0.4063 - fbeta2: 0.579 - ETA: 1s - loss: 0.1927 - acc: 0.9084 - prec: 0.6648 - recall: 0.5623 - auc: 0.9425 - f2: 0.4065 - fbeta2: 0.5794"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36858/36858 [==============================] - ETA: 1s - loss: 0.1927 - acc: 0.9084 - prec: 0.6645 - recall: 0.5621 - auc: 0.9425 - f2: 0.4062 - fbeta2: 0.579 - ETA: 1s - loss: 0.1926 - acc: 0.9084 - prec: 0.6648 - recall: 0.5622 - auc: 0.9425 - f2: 0.4066 - fbeta2: 0.579 - ETA: 1s - loss: 0.1927 - acc: 0.9084 - prec: 0.6647 - recall: 0.5622 - auc: 0.9425 - f2: 0.4066 - fbeta2: 0.579 - ETA: 1s - loss: 0.1928 - acc: 0.9083 - prec: 0.6643 - recall: 0.5620 - auc: 0.9424 - f2: 0.4064 - fbeta2: 0.579 - ETA: 1s - loss: 0.1929 - acc: 0.9083 - prec: 0.6642 - recall: 0.5620 - auc: 0.9423 - f2: 0.4068 - fbeta2: 0.579 - ETA: 1s - loss: 0.1929 - acc: 0.9083 - prec: 0.6646 - recall: 0.5624 - auc: 0.9423 - f2: 0.4073 - fbeta2: 0.579 - ETA: 1s - loss: 0.1932 - acc: 0.9082 - prec: 0.6643 - recall: 0.5620 - auc: 0.9422 - f2: 0.4070 - fbeta2: 0.579 - ETA: 0s - loss: 0.1932 - acc: 0.9082 - prec: 0.6639 - recall: 0.5621 - auc: 0.9422 - f2: 0.4071 - fbeta2: 0.579 - ETA: 0s - loss: 0.1932 - acc: 0.9082 - prec: 0.6641 - recall: 0.5622 - auc: 0.9422 - f2: 0.4070 - fbeta2: 0.579 - ETA: 0s - loss: 0.1932 - acc: 0.9082 - prec: 0.6642 - recall: 0.5619 - auc: 0.9422 - f2: 0.4069 - fbeta2: 0.579 - ETA: 0s - loss: 0.1934 - acc: 0.9081 - prec: 0.6641 - recall: 0.5619 - auc: 0.9421 - f2: 0.4068 - fbeta2: 0.579 - ETA: 0s - loss: 0.1933 - acc: 0.9082 - prec: 0.6646 - recall: 0.5620 - auc: 0.9421 - f2: 0.4073 - fbeta2: 0.579 - ETA: 0s - loss: 0.1934 - acc: 0.9081 - prec: 0.6644 - recall: 0.5616 - auc: 0.9421 - f2: 0.4070 - fbeta2: 0.578 - ETA: 0s - loss: 0.1935 - acc: 0.9081 - prec: 0.6647 - recall: 0.5615 - auc: 0.9421 - f2: 0.4068 - fbeta2: 0.578 - ETA: 0s - loss: 0.1935 - acc: 0.9081 - prec: 0.6647 - recall: 0.5615 - auc: 0.9421 - f2: 0.4071 - fbeta2: 0.578 - ETA: 0s - loss: 0.1934 - acc: 0.9081 - prec: 0.6647 - recall: 0.5617 - auc: 0.9421 - f2: 0.4074 - fbeta2: 0.579 - ETA: 0s - loss: 0.1934 - acc: 0.9081 - prec: 0.6648 - recall: 0.5619 - auc: 0.9421 - f2: 0.4077 - fbeta2: 0.579 - ETA: 0s - loss: 0.1935 - acc: 0.9081 - prec: 0.6645 - recall: 0.5615 - auc: 0.9421 - f2: 0.4074 - fbeta2: 0.578 - ETA: 0s - loss: 0.1935 - acc: 0.9080 - prec: 0.6644 - recall: 0.5612 - auc: 0.9421 - f2: 0.4073 - fbeta2: 0.578 - ETA: 0s - loss: 0.1936 - acc: 0.9080 - prec: 0.6643 - recall: 0.5611 - auc: 0.9420 - f2: 0.4074 - fbeta2: 0.578 - ETA: 0s - loss: 0.1938 - acc: 0.9079 - prec: 0.6640 - recall: 0.5608 - auc: 0.9419 - f2: 0.4072 - fbeta2: 0.578 - ETA: 0s - loss: 0.1938 - acc: 0.9079 - prec: 0.6641 - recall: 0.5607 - auc: 0.9419 - f2: 0.4071 - fbeta2: 0.578 - ETA: 0s - loss: 0.1938 - acc: 0.9080 - prec: 0.6643 - recall: 0.5611 - auc: 0.9419 - f2: 0.4074 - fbeta2: 0.578 - ETA: 0s - loss: 0.1940 - acc: 0.9079 - prec: 0.6638 - recall: 0.5608 - auc: 0.9418 - f2: 0.4073 - fbeta2: 0.578 - ETA: 0s - loss: 0.1940 - acc: 0.9079 - prec: 0.6637 - recall: 0.5607 - auc: 0.9417 - f2: 0.4071 - fbeta2: 0.578 - ETA: 0s - loss: 0.1945 - acc: 0.9076 - prec: 0.6621 - recall: 0.5597 - auc: 0.9413 - f2: 0.4059 - fbeta2: 0.576 - 5s 140us/sample - loss: 0.1952 - acc: 0.9073 - prec: 0.6610 - recall: 0.5581 - auc: 0.9409 - f2: 0.4042 - fbeta2: 0.5753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.19521527745990358,\n",
       " 'acc': 0.9072674,\n",
       " 'prec': 0.66095227,\n",
       " 'recall': 0.5580575,\n",
       " 'auc': 0.9408676,\n",
       " 'f2': 0.40420324,\n",
       " 'fbeta2': 0.57525325}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "hist = model.fit(X_train, y_train, epochs=52, batch_size=1024, workers=4, \n",
    "             validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "#Train the multiforest using the training indices\n",
    "result=model.evaluate(X_test, y_test)\n",
    "results_dict = dict(zip(model.metrics_names, result))\n",
    "results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mload = keras.models.load_model('final_model_human_train.h5', custom_objects={'f2':f2, 'fbeta2':fbeta2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13568/36858 [==========>...................] - ETA: 9:43 - loss: 0.2468 - acc: 0.8770 - prec: 0.5789 - recall: 0.4583 - auc: 0.9150 - f2: 0.4087 - fbeta2: 0.478 - ETA: 1:47 - loss: 0.2126 - acc: 0.8971 - prec: 0.6136 - recall: 0.5293 - auc: 0.9287 - f2: 0.4006 - fbeta2: 0.546 - ETA: 58s - loss: 0.2039 - acc: 0.9054 - prec: 0.6540 - recall: 0.5479 - auc: 0.9349 - f2: 0.3940 - fbeta2: 0.568 - ETA: 42s - loss: 0.2067 - acc: 0.9064 - prec: 0.6552 - recall: 0.5405 - auc: 0.9319 - f2: 0.3953 - fbeta2: 0.56 - ETA: 34s - loss: 0.2014 - acc: 0.9095 - prec: 0.6737 - recall: 0.5524 - auc: 0.9361 - f2: 0.3950 - fbeta2: 0.57 - ETA: 29s - loss: 0.1992 - acc: 0.9095 - prec: 0.6750 - recall: 0.5538 - auc: 0.9378 - f2: 0.3974 - fbeta2: 0.57 - ETA: 26s - loss: 0.1980 - acc: 0.9091 - prec: 0.6730 - recall: 0.5550 - auc: 0.9390 - f2: 0.3989 - fbeta2: 0.57 - ETA: 23s - loss: 0.1980 - acc: 0.9092 - prec: 0.6716 - recall: 0.5542 - auc: 0.9385 - f2: 0.3978 - fbeta2: 0.57 - ETA: 21s - loss: 0.1980 - acc: 0.9089 - prec: 0.6697 - recall: 0.5569 - auc: 0.9387 - f2: 0.3980 - fbeta2: 0.57 - ETA: 20s - loss: 0.1989 - acc: 0.9076 - prec: 0.6638 - recall: 0.5519 - auc: 0.9381 - f2: 0.3927 - fbeta2: 0.57 - ETA: 19s - loss: 0.1995 - acc: 0.9066 - prec: 0.6570 - recall: 0.5507 - auc: 0.9375 - f2: 0.3933 - fbeta2: 0.56 - ETA: 18s - loss: 0.1984 - acc: 0.9074 - prec: 0.6631 - recall: 0.5538 - auc: 0.9387 - f2: 0.3967 - fbeta2: 0.57 - ETA: 17s - loss: 0.1977 - acc: 0.9071 - prec: 0.6604 - recall: 0.5536 - auc: 0.9390 - f2: 0.3941 - fbeta2: 0.57 - ETA: 16s - loss: 0.1980 - acc: 0.9065 - prec: 0.6571 - recall: 0.5489 - auc: 0.9386 - f2: 0.3924 - fbeta2: 0.56 - ETA: 16s - loss: 0.1983 - acc: 0.9065 - prec: 0.6576 - recall: 0.5512 - auc: 0.9384 - f2: 0.3932 - fbeta2: 0.56 - ETA: 15s - loss: 0.1981 - acc: 0.9064 - prec: 0.6578 - recall: 0.5523 - auc: 0.9387 - f2: 0.3951 - fbeta2: 0.56 - ETA: 15s - loss: 0.1989 - acc: 0.9064 - prec: 0.6595 - recall: 0.5502 - auc: 0.9385 - f2: 0.3930 - fbeta2: 0.56 - ETA: 14s - loss: 0.1989 - acc: 0.9062 - prec: 0.6581 - recall: 0.5487 - auc: 0.9383 - f2: 0.3910 - fbeta2: 0.56 - ETA: 14s - loss: 0.1982 - acc: 0.9068 - prec: 0.6606 - recall: 0.5506 - auc: 0.9388 - f2: 0.3904 - fbeta2: 0.56 - ETA: 14s - loss: 0.1983 - acc: 0.9066 - prec: 0.6603 - recall: 0.5500 - auc: 0.9388 - f2: 0.3902 - fbeta2: 0.56 - ETA: 13s - loss: 0.1978 - acc: 0.9066 - prec: 0.6603 - recall: 0.5510 - auc: 0.9391 - f2: 0.3914 - fbeta2: 0.56 - ETA: 13s - loss: 0.1981 - acc: 0.9063 - prec: 0.6603 - recall: 0.5514 - auc: 0.9391 - f2: 0.3920 - fbeta2: 0.56 - ETA: 13s - loss: 0.1983 - acc: 0.9062 - prec: 0.6600 - recall: 0.5512 - auc: 0.9391 - f2: 0.3920 - fbeta2: 0.56 - ETA: 13s - loss: 0.1970 - acc: 0.9069 - prec: 0.6624 - recall: 0.5538 - auc: 0.9399 - f2: 0.3964 - fbeta2: 0.57 - ETA: 12s - loss: 0.1966 - acc: 0.9071 - prec: 0.6625 - recall: 0.5543 - auc: 0.9401 - f2: 0.3972 - fbeta2: 0.57 - ETA: 12s - loss: 0.1961 - acc: 0.9074 - prec: 0.6637 - recall: 0.5568 - auc: 0.9405 - f2: 0.4001 - fbeta2: 0.57 - ETA: 12s - loss: 0.1962 - acc: 0.9073 - prec: 0.6637 - recall: 0.5560 - auc: 0.9404 - f2: 0.4006 - fbeta2: 0.57 - ETA: 12s - loss: 0.1955 - acc: 0.9077 - prec: 0.6654 - recall: 0.5581 - auc: 0.9408 - f2: 0.4019 - fbeta2: 0.57 - ETA: 12s - loss: 0.1962 - acc: 0.9075 - prec: 0.6639 - recall: 0.5580 - auc: 0.9404 - f2: 0.4029 - fbeta2: 0.57 - ETA: 11s - loss: 0.1965 - acc: 0.9071 - prec: 0.6618 - recall: 0.5563 - auc: 0.9401 - f2: 0.4024 - fbeta2: 0.57 - ETA: 11s - loss: 0.1961 - acc: 0.9072 - prec: 0.6625 - recall: 0.5574 - auc: 0.9404 - f2: 0.4027 - fbeta2: 0.57 - ETA: 11s - loss: 0.1961 - acc: 0.9072 - prec: 0.6616 - recall: 0.5582 - auc: 0.9403 - f2: 0.4035 - fbeta2: 0.57 - ETA: 11s - loss: 0.1961 - acc: 0.9072 - prec: 0.6616 - recall: 0.5588 - auc: 0.9404 - f2: 0.4041 - fbeta2: 0.57 - ETA: 11s - loss: 0.1960 - acc: 0.9073 - prec: 0.6625 - recall: 0.5595 - auc: 0.9405 - f2: 0.4052 - fbeta2: 0.57 - ETA: 11s - loss: 0.1960 - acc: 0.9072 - prec: 0.6623 - recall: 0.5584 - auc: 0.9405 - f2: 0.4045 - fbeta2: 0.57 - ETA: 11s - loss: 0.1953 - acc: 0.9075 - prec: 0.6629 - recall: 0.5608 - auc: 0.9409 - f2: 0.4056 - fbeta2: 0.57 - ETA: 10s - loss: 0.1952 - acc: 0.9074 - prec: 0.6624 - recall: 0.5605 - auc: 0.9410 - f2: 0.4056 - fbeta2: 0.57 - ETA: 10s - loss: 0.1957 - acc: 0.9073 - prec: 0.6620 - recall: 0.5603 - auc: 0.9407 - f2: 0.4062 - fbeta2: 0.57 - ETA: 10s - loss: 0.1953 - acc: 0.9075 - prec: 0.6623 - recall: 0.5604 - auc: 0.9409 - f2: 0.4056 - fbeta2: 0.57 - ETA: 10s - loss: 0.1953 - acc: 0.9075 - prec: 0.6622 - recall: 0.5611 - auc: 0.9409 - f2: 0.4067 - fbeta2: 0.57 - ETA: 10s - loss: 0.1953 - acc: 0.9075 - prec: 0.6628 - recall: 0.5604 - auc: 0.9410 - f2: 0.4061 - fbeta2: 0.57 - ETA: 10s - loss: 0.1955 - acc: 0.9075 - prec: 0.6628 - recall: 0.5602 - auc: 0.9408 - f2: 0.4067 - fbeta2: 0.57 - ETA: 10s - loss: 0.1959 - acc: 0.9073 - prec: 0.6622 - recall: 0.5590 - auc: 0.9405 - f2: 0.4072 - fbeta2: 0.57 - ETA: 10s - loss: 0.1957 - acc: 0.9073 - prec: 0.6623 - recall: 0.5590 - auc: 0.9407 - f2: 0.4071 - fbeta2: 0.57 - ETA: 9s - loss: 0.1957 - acc: 0.9073 - prec: 0.6626 - recall: 0.5587 - auc: 0.9407 - f2: 0.4072 - fbeta2: 0.5759 - ETA: 9s - loss: 0.1957 - acc: 0.9073 - prec: 0.6614 - recall: 0.5584 - auc: 0.9406 - f2: 0.4058 - fbeta2: 0.575 - ETA: 9s - loss: 0.1954 - acc: 0.9074 - prec: 0.6624 - recall: 0.5587 - auc: 0.9408 - f2: 0.4071 - fbeta2: 0.575 - ETA: 9s - loss: 0.1953 - acc: 0.9075 - prec: 0.6617 - recall: 0.5590 - auc: 0.9408 - f2: 0.4067 - fbeta2: 0.575 - ETA: 9s - loss: 0.1952 - acc: 0.9075 - prec: 0.6616 - recall: 0.5591 - auc: 0.9408 - f2: 0.4067 - fbeta2: 0.575 - ETA: 9s - loss: 0.1954 - acc: 0.9074 - prec: 0.6607 - recall: 0.5587 - auc: 0.9407 - f2: 0.4067 - fbeta2: 0.575 - ETA: 9s - loss: 0.1952 - acc: 0.9075 - prec: 0.6601 - recall: 0.5591 - auc: 0.9407 - f2: 0.4065 - fbeta2: 0.575 - ETA: 9s - loss: 0.1953 - acc: 0.9074 - prec: 0.6597 - recall: 0.5591 - auc: 0.9406 - f2: 0.4070 - fbeta2: 0.575 - ETA: 9s - loss: 0.1954 - acc: 0.9074 - prec: 0.6587 - recall: 0.5590 - auc: 0.9404 - f2: 0.4072 - fbeta2: 0.575 - ETA: 9s - loss: 0.1954 - acc: 0.9073 - prec: 0.6579 - recall: 0.5592 - auc: 0.9404 - f2: 0.4082 - fbeta2: 0.575 - ETA: 8s - loss: 0.1954 - acc: 0.9074 - prec: 0.6588 - recall: 0.5595 - auc: 0.9404 - f2: 0.4080 - fbeta2: 0.575 - ETA: 8s - loss: 0.1953 - acc: 0.9074 - prec: 0.6583 - recall: 0.5592 - auc: 0.9404 - f2: 0.4079 - fbeta2: 0.575 - ETA: 8s - loss: 0.1953 - acc: 0.9074 - prec: 0.6584 - recall: 0.5593 - auc: 0.9405 - f2: 0.4085 - fbeta2: 0.575 - ETA: 8s - loss: 0.1949 - acc: 0.9076 - prec: 0.6588 - recall: 0.5602 - auc: 0.9407 - f2: 0.4084 - fbeta2: 0.576 - ETA: 8s - loss: 0.1950 - acc: 0.9074 - prec: 0.6573 - recall: 0.5592 - auc: 0.9405 - f2: 0.4071 - fbeta2: 0.575 - ETA: 8s - loss: 0.1949 - acc: 0.9075 - prec: 0.6576 - recall: 0.5602 - auc: 0.9406 - f2: 0.4081 - fbeta2: 0.576 - ETA: 8s - loss: 0.1946 - acc: 0.9077 - prec: 0.6585 - recall: 0.5612 - auc: 0.9408 - f2: 0.4092 - fbeta2: 0.577 - ETA: 8s - loss: 0.1945 - acc: 0.9077 - prec: 0.6587 - recall: 0.5611 - auc: 0.9409 - f2: 0.4091 - fbeta2: 0.577 - ETA: 8s - loss: 0.1947 - acc: 0.9076 - prec: 0.6580 - recall: 0.5603 - auc: 0.9408 - f2: 0.4084 - fbeta2: 0.576 - ETA: 8s - loss: 0.1946 - acc: 0.9076 - prec: 0.6583 - recall: 0.5605 - auc: 0.9408 - f2: 0.4086 - fbeta2: 0.576 - ETA: 8s - loss: 0.1945 - acc: 0.9076 - prec: 0.6585 - recall: 0.5600 - auc: 0.9409 - f2: 0.4076 - fbeta2: 0.576 - ETA: 8s - loss: 0.1946 - acc: 0.9076 - prec: 0.6585 - recall: 0.5600 - auc: 0.9409 - f2: 0.4075 - fbeta2: 0.576 - ETA: 7s - loss: 0.1946 - acc: 0.9076 - prec: 0.6584 - recall: 0.5598 - auc: 0.9408 - f2: 0.4071 - fbeta2: 0.576 - ETA: 7s - loss: 0.1949 - acc: 0.9075 - prec: 0.6579 - recall: 0.5595 - auc: 0.9406 - f2: 0.4063 - fbeta2: 0.575 - ETA: 7s - loss: 0.1946 - acc: 0.9076 - prec: 0.6585 - recall: 0.5597 - auc: 0.9408 - f2: 0.4065 - fbeta2: 0.576 - ETA: 7s - loss: 0.1945 - acc: 0.9076 - prec: 0.6585 - recall: 0.5599 - auc: 0.9409 - f2: 0.4068 - fbeta2: 0.576 - ETA: 7s - loss: 0.1946 - acc: 0.9075 - prec: 0.6582 - recall: 0.5598 - auc: 0.9409 - f2: 0.4060 - fbeta2: 0.576 - ETA: 7s - loss: 0.1944 - acc: 0.9076 - prec: 0.6586 - recall: 0.5604 - auc: 0.9410 - f2: 0.4066 - fbeta2: 0.5766"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27232/36858 [=====================>........] - ETA: 7s - loss: 0.1942 - acc: 0.9077 - prec: 0.6589 - recall: 0.5604 - auc: 0.9411 - f2: 0.4063 - fbeta2: 0.576 - ETA: 7s - loss: 0.1943 - acc: 0.9076 - prec: 0.6585 - recall: 0.5603 - auc: 0.9411 - f2: 0.4062 - fbeta2: 0.576 - ETA: 7s - loss: 0.1942 - acc: 0.9076 - prec: 0.6583 - recall: 0.5604 - auc: 0.9411 - f2: 0.4061 - fbeta2: 0.576 - ETA: 7s - loss: 0.1942 - acc: 0.9076 - prec: 0.6581 - recall: 0.5603 - auc: 0.9411 - f2: 0.4066 - fbeta2: 0.576 - ETA: 7s - loss: 0.1942 - acc: 0.9076 - prec: 0.6583 - recall: 0.5599 - auc: 0.9412 - f2: 0.4069 - fbeta2: 0.576 - ETA: 7s - loss: 0.1942 - acc: 0.9075 - prec: 0.6581 - recall: 0.5596 - auc: 0.9412 - f2: 0.4069 - fbeta2: 0.575 - ETA: 7s - loss: 0.1940 - acc: 0.9076 - prec: 0.6587 - recall: 0.5602 - auc: 0.9413 - f2: 0.4072 - fbeta2: 0.576 - ETA: 7s - loss: 0.1940 - acc: 0.9075 - prec: 0.6587 - recall: 0.5598 - auc: 0.9413 - f2: 0.4073 - fbeta2: 0.576 - ETA: 6s - loss: 0.1939 - acc: 0.9075 - prec: 0.6585 - recall: 0.5597 - auc: 0.9414 - f2: 0.4068 - fbeta2: 0.576 - ETA: 6s - loss: 0.1941 - acc: 0.9075 - prec: 0.6584 - recall: 0.5595 - auc: 0.9413 - f2: 0.4062 - fbeta2: 0.575 - ETA: 6s - loss: 0.1941 - acc: 0.9076 - prec: 0.6586 - recall: 0.5601 - auc: 0.9413 - f2: 0.4069 - fbeta2: 0.576 - ETA: 6s - loss: 0.1940 - acc: 0.9076 - prec: 0.6585 - recall: 0.5603 - auc: 0.9413 - f2: 0.4063 - fbeta2: 0.576 - ETA: 6s - loss: 0.1938 - acc: 0.9077 - prec: 0.6591 - recall: 0.5610 - auc: 0.9415 - f2: 0.4070 - fbeta2: 0.577 - ETA: 6s - loss: 0.1938 - acc: 0.9076 - prec: 0.6589 - recall: 0.5606 - auc: 0.9415 - f2: 0.4068 - fbeta2: 0.576 - ETA: 6s - loss: 0.1938 - acc: 0.9077 - prec: 0.6598 - recall: 0.5606 - auc: 0.9415 - f2: 0.4069 - fbeta2: 0.577 - ETA: 6s - loss: 0.1938 - acc: 0.9077 - prec: 0.6597 - recall: 0.5606 - auc: 0.9415 - f2: 0.4071 - fbeta2: 0.577 - ETA: 6s - loss: 0.1937 - acc: 0.9078 - prec: 0.6603 - recall: 0.5607 - auc: 0.9416 - f2: 0.4072 - fbeta2: 0.577 - ETA: 6s - loss: 0.1936 - acc: 0.9078 - prec: 0.6607 - recall: 0.5610 - auc: 0.9417 - f2: 0.4073 - fbeta2: 0.577 - ETA: 6s - loss: 0.1934 - acc: 0.9079 - prec: 0.6611 - recall: 0.5614 - auc: 0.9418 - f2: 0.4076 - fbeta2: 0.577 - ETA: 6s - loss: 0.1934 - acc: 0.9080 - prec: 0.6616 - recall: 0.5618 - auc: 0.9419 - f2: 0.4078 - fbeta2: 0.578 - ETA: 6s - loss: 0.1932 - acc: 0.9081 - prec: 0.6620 - recall: 0.5622 - auc: 0.9420 - f2: 0.4076 - fbeta2: 0.578 - ETA: 6s - loss: 0.1933 - acc: 0.9081 - prec: 0.6622 - recall: 0.5624 - auc: 0.9420 - f2: 0.4078 - fbeta2: 0.578 - ETA: 6s - loss: 0.1932 - acc: 0.9081 - prec: 0.6622 - recall: 0.5622 - auc: 0.9420 - f2: 0.4077 - fbeta2: 0.578 - ETA: 5s - loss: 0.1932 - acc: 0.9081 - prec: 0.6623 - recall: 0.5621 - auc: 0.9420 - f2: 0.4078 - fbeta2: 0.578 - ETA: 5s - loss: 0.1930 - acc: 0.9082 - prec: 0.6627 - recall: 0.5625 - auc: 0.9422 - f2: 0.4082 - fbeta2: 0.579 - ETA: 5s - loss: 0.1929 - acc: 0.9082 - prec: 0.6626 - recall: 0.5625 - auc: 0.9422 - f2: 0.4078 - fbeta2: 0.579 - ETA: 5s - loss: 0.1931 - acc: 0.9082 - prec: 0.6625 - recall: 0.5626 - auc: 0.9421 - f2: 0.4078 - fbeta2: 0.579 - ETA: 5s - loss: 0.1930 - acc: 0.9082 - prec: 0.6632 - recall: 0.5628 - auc: 0.9422 - f2: 0.4078 - fbeta2: 0.579 - ETA: 5s - loss: 0.1929 - acc: 0.9083 - prec: 0.6635 - recall: 0.5630 - auc: 0.9423 - f2: 0.4079 - fbeta2: 0.579 - ETA: 5s - loss: 0.1929 - acc: 0.9083 - prec: 0.6633 - recall: 0.5630 - auc: 0.9422 - f2: 0.4079 - fbeta2: 0.579 - ETA: 5s - loss: 0.1928 - acc: 0.9084 - prec: 0.6635 - recall: 0.5632 - auc: 0.9423 - f2: 0.4078 - fbeta2: 0.579 - ETA: 5s - loss: 0.1927 - acc: 0.9084 - prec: 0.6637 - recall: 0.5632 - auc: 0.9424 - f2: 0.4080 - fbeta2: 0.579 - ETA: 5s - loss: 0.1928 - acc: 0.9084 - prec: 0.6635 - recall: 0.5632 - auc: 0.9423 - f2: 0.4084 - fbeta2: 0.579 - ETA: 5s - loss: 0.1927 - acc: 0.9084 - prec: 0.6638 - recall: 0.5635 - auc: 0.9424 - f2: 0.4091 - fbeta2: 0.580 - ETA: 5s - loss: 0.1926 - acc: 0.9084 - prec: 0.6640 - recall: 0.5634 - auc: 0.9425 - f2: 0.4089 - fbeta2: 0.580 - ETA: 5s - loss: 0.1928 - acc: 0.9084 - prec: 0.6635 - recall: 0.5631 - auc: 0.9423 - f2: 0.4085 - fbeta2: 0.579 - ETA: 5s - loss: 0.1926 - acc: 0.9084 - prec: 0.6639 - recall: 0.5632 - auc: 0.9425 - f2: 0.4085 - fbeta2: 0.579 - ETA: 5s - loss: 0.1925 - acc: 0.9085 - prec: 0.6642 - recall: 0.5635 - auc: 0.9425 - f2: 0.4088 - fbeta2: 0.580 - ETA: 5s - loss: 0.1926 - acc: 0.9084 - prec: 0.6639 - recall: 0.5635 - auc: 0.9425 - f2: 0.4086 - fbeta2: 0.580 - ETA: 4s - loss: 0.1926 - acc: 0.9084 - prec: 0.6641 - recall: 0.5635 - auc: 0.9425 - f2: 0.4084 - fbeta2: 0.580 - ETA: 4s - loss: 0.1925 - acc: 0.9084 - prec: 0.6642 - recall: 0.5635 - auc: 0.9426 - f2: 0.4083 - fbeta2: 0.580 - ETA: 4s - loss: 0.1924 - acc: 0.9085 - prec: 0.6645 - recall: 0.5638 - auc: 0.9427 - f2: 0.4083 - fbeta2: 0.580 - ETA: 4s - loss: 0.1924 - acc: 0.9085 - prec: 0.6645 - recall: 0.5638 - auc: 0.9427 - f2: 0.4083 - fbeta2: 0.580 - ETA: 4s - loss: 0.1923 - acc: 0.9085 - prec: 0.6645 - recall: 0.5638 - auc: 0.9427 - f2: 0.4082 - fbeta2: 0.580 - ETA: 4s - loss: 0.1924 - acc: 0.9085 - prec: 0.6648 - recall: 0.5636 - auc: 0.9427 - f2: 0.4080 - fbeta2: 0.580 - ETA: 4s - loss: 0.1924 - acc: 0.9084 - prec: 0.6645 - recall: 0.5634 - auc: 0.9426 - f2: 0.4079 - fbeta2: 0.580 - ETA: 4s - loss: 0.1924 - acc: 0.9085 - prec: 0.6649 - recall: 0.5636 - auc: 0.9427 - f2: 0.4084 - fbeta2: 0.580 - ETA: 4s - loss: 0.1923 - acc: 0.9085 - prec: 0.6650 - recall: 0.5637 - auc: 0.9428 - f2: 0.4087 - fbeta2: 0.580 - ETA: 4s - loss: 0.1925 - acc: 0.9085 - prec: 0.6649 - recall: 0.5634 - auc: 0.9426 - f2: 0.4085 - fbeta2: 0.580 - ETA: 4s - loss: 0.1925 - acc: 0.9085 - prec: 0.6649 - recall: 0.5634 - auc: 0.9427 - f2: 0.4084 - fbeta2: 0.580 - ETA: 4s - loss: 0.1924 - acc: 0.9085 - prec: 0.6654 - recall: 0.5637 - auc: 0.9427 - f2: 0.4084 - fbeta2: 0.580 - ETA: 4s - loss: 0.1923 - acc: 0.9086 - prec: 0.6655 - recall: 0.5636 - auc: 0.9427 - f2: 0.4082 - fbeta2: 0.580 - ETA: 4s - loss: 0.1924 - acc: 0.9085 - prec: 0.6652 - recall: 0.5637 - auc: 0.9427 - f2: 0.4084 - fbeta2: 0.580 - ETA: 4s - loss: 0.1924 - acc: 0.9085 - prec: 0.6648 - recall: 0.5636 - auc: 0.9426 - f2: 0.4081 - fbeta2: 0.580 - ETA: 4s - loss: 0.1923 - acc: 0.9086 - prec: 0.6649 - recall: 0.5640 - auc: 0.9427 - f2: 0.4084 - fbeta2: 0.580 - ETA: 3s - loss: 0.1924 - acc: 0.9086 - prec: 0.6649 - recall: 0.5637 - auc: 0.9427 - f2: 0.4080 - fbeta2: 0.580 - ETA: 3s - loss: 0.1924 - acc: 0.9086 - prec: 0.6650 - recall: 0.5635 - auc: 0.9426 - f2: 0.4078 - fbeta2: 0.580 - ETA: 3s - loss: 0.1924 - acc: 0.9086 - prec: 0.6651 - recall: 0.5635 - auc: 0.9426 - f2: 0.4078 - fbeta2: 0.580 - ETA: 3s - loss: 0.1924 - acc: 0.9086 - prec: 0.6649 - recall: 0.5629 - auc: 0.9426 - f2: 0.4075 - fbeta2: 0.579 - ETA: 3s - loss: 0.1924 - acc: 0.9086 - prec: 0.6649 - recall: 0.5630 - auc: 0.9426 - f2: 0.4075 - fbeta2: 0.580 - ETA: 3s - loss: 0.1925 - acc: 0.9085 - prec: 0.6650 - recall: 0.5628 - auc: 0.9426 - f2: 0.4070 - fbeta2: 0.579 - ETA: 3s - loss: 0.1925 - acc: 0.9086 - prec: 0.6651 - recall: 0.5629 - auc: 0.9426 - f2: 0.4071 - fbeta2: 0.579 - ETA: 3s - loss: 0.1924 - acc: 0.9086 - prec: 0.6652 - recall: 0.5629 - auc: 0.9426 - f2: 0.4071 - fbeta2: 0.580 - ETA: 3s - loss: 0.1924 - acc: 0.9086 - prec: 0.6654 - recall: 0.5628 - auc: 0.9426 - f2: 0.4070 - fbeta2: 0.579 - ETA: 3s - loss: 0.1924 - acc: 0.9086 - prec: 0.6653 - recall: 0.5627 - auc: 0.9426 - f2: 0.4066 - fbeta2: 0.579 - ETA: 3s - loss: 0.1924 - acc: 0.9085 - prec: 0.6653 - recall: 0.5628 - auc: 0.9426 - f2: 0.4068 - fbeta2: 0.579 - ETA: 3s - loss: 0.1925 - acc: 0.9085 - prec: 0.6650 - recall: 0.5625 - auc: 0.9426 - f2: 0.4065 - fbeta2: 0.579 - ETA: 3s - loss: 0.1926 - acc: 0.9084 - prec: 0.6649 - recall: 0.5622 - auc: 0.9425 - f2: 0.4064 - fbeta2: 0.579 - ETA: 3s - loss: 0.1927 - acc: 0.9084 - prec: 0.6647 - recall: 0.5621 - auc: 0.9425 - f2: 0.4064 - fbeta2: 0.579 - ETA: 3s - loss: 0.1928 - acc: 0.9084 - prec: 0.6646 - recall: 0.5621 - auc: 0.9424 - f2: 0.4063 - fbeta2: 0.579 - ETA: 3s - loss: 0.1928 - acc: 0.9084 - prec: 0.6645 - recall: 0.5620 - auc: 0.9424 - f2: 0.4060 - fbeta2: 0.579 - ETA: 2s - loss: 0.1927 - acc: 0.9084 - prec: 0.6645 - recall: 0.5620 - auc: 0.9424 - f2: 0.4061 - fbeta2: 0.5791"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36858/36858 [==============================] - ETA: 2s - loss: 0.1927 - acc: 0.9084 - prec: 0.6648 - recall: 0.5621 - auc: 0.9425 - f2: 0.4063 - fbeta2: 0.579 - ETA: 2s - loss: 0.1926 - acc: 0.9084 - prec: 0.6649 - recall: 0.5622 - auc: 0.9425 - f2: 0.4066 - fbeta2: 0.579 - ETA: 2s - loss: 0.1926 - acc: 0.9084 - prec: 0.6648 - recall: 0.5622 - auc: 0.9425 - f2: 0.4068 - fbeta2: 0.579 - ETA: 2s - loss: 0.1927 - acc: 0.9084 - prec: 0.6647 - recall: 0.5623 - auc: 0.9425 - f2: 0.4067 - fbeta2: 0.579 - ETA: 2s - loss: 0.1927 - acc: 0.9084 - prec: 0.6646 - recall: 0.5622 - auc: 0.9425 - f2: 0.4068 - fbeta2: 0.579 - ETA: 2s - loss: 0.1928 - acc: 0.9083 - prec: 0.6644 - recall: 0.5622 - auc: 0.9424 - f2: 0.4064 - fbeta2: 0.579 - ETA: 2s - loss: 0.1928 - acc: 0.9083 - prec: 0.6643 - recall: 0.5620 - auc: 0.9424 - f2: 0.4066 - fbeta2: 0.579 - ETA: 2s - loss: 0.1928 - acc: 0.9083 - prec: 0.6642 - recall: 0.5620 - auc: 0.9424 - f2: 0.4069 - fbeta2: 0.579 - ETA: 2s - loss: 0.1929 - acc: 0.9083 - prec: 0.6642 - recall: 0.5623 - auc: 0.9423 - f2: 0.4071 - fbeta2: 0.579 - ETA: 2s - loss: 0.1929 - acc: 0.9083 - prec: 0.6646 - recall: 0.5623 - auc: 0.9423 - f2: 0.4074 - fbeta2: 0.579 - ETA: 2s - loss: 0.1930 - acc: 0.9083 - prec: 0.6645 - recall: 0.5623 - auc: 0.9423 - f2: 0.4071 - fbeta2: 0.579 - ETA: 2s - loss: 0.1931 - acc: 0.9083 - prec: 0.6644 - recall: 0.5622 - auc: 0.9422 - f2: 0.4072 - fbeta2: 0.579 - ETA: 2s - loss: 0.1932 - acc: 0.9082 - prec: 0.6642 - recall: 0.5619 - auc: 0.9422 - f2: 0.4070 - fbeta2: 0.579 - ETA: 2s - loss: 0.1932 - acc: 0.9082 - prec: 0.6639 - recall: 0.5619 - auc: 0.9422 - f2: 0.4070 - fbeta2: 0.579 - ETA: 2s - loss: 0.1931 - acc: 0.9082 - prec: 0.6641 - recall: 0.5621 - auc: 0.9422 - f2: 0.4071 - fbeta2: 0.579 - ETA: 2s - loss: 0.1932 - acc: 0.9082 - prec: 0.6640 - recall: 0.5621 - auc: 0.9422 - f2: 0.4070 - fbeta2: 0.579 - ETA: 1s - loss: 0.1931 - acc: 0.9082 - prec: 0.6641 - recall: 0.5622 - auc: 0.9422 - f2: 0.4070 - fbeta2: 0.579 - ETA: 1s - loss: 0.1932 - acc: 0.9082 - prec: 0.6641 - recall: 0.5619 - auc: 0.9422 - f2: 0.4069 - fbeta2: 0.579 - ETA: 1s - loss: 0.1932 - acc: 0.9082 - prec: 0.6642 - recall: 0.5620 - auc: 0.9422 - f2: 0.4068 - fbeta2: 0.579 - ETA: 1s - loss: 0.1934 - acc: 0.9081 - prec: 0.6641 - recall: 0.5618 - auc: 0.9421 - f2: 0.4068 - fbeta2: 0.579 - ETA: 1s - loss: 0.1934 - acc: 0.9081 - prec: 0.6644 - recall: 0.5619 - auc: 0.9421 - f2: 0.4071 - fbeta2: 0.579 - ETA: 1s - loss: 0.1933 - acc: 0.9082 - prec: 0.6645 - recall: 0.5620 - auc: 0.9421 - f2: 0.4074 - fbeta2: 0.579 - ETA: 1s - loss: 0.1934 - acc: 0.9081 - prec: 0.6645 - recall: 0.5617 - auc: 0.9421 - f2: 0.4071 - fbeta2: 0.578 - ETA: 1s - loss: 0.1934 - acc: 0.9081 - prec: 0.6645 - recall: 0.5617 - auc: 0.9421 - f2: 0.4070 - fbeta2: 0.578 - ETA: 1s - loss: 0.1934 - acc: 0.9081 - prec: 0.6645 - recall: 0.5617 - auc: 0.9421 - f2: 0.4069 - fbeta2: 0.578 - ETA: 1s - loss: 0.1935 - acc: 0.9081 - prec: 0.6647 - recall: 0.5615 - auc: 0.9421 - f2: 0.4067 - fbeta2: 0.578 - ETA: 1s - loss: 0.1935 - acc: 0.9081 - prec: 0.6648 - recall: 0.5615 - auc: 0.9421 - f2: 0.4070 - fbeta2: 0.578 - ETA: 1s - loss: 0.1935 - acc: 0.9081 - prec: 0.6647 - recall: 0.5615 - auc: 0.9421 - f2: 0.4071 - fbeta2: 0.578 - ETA: 1s - loss: 0.1933 - acc: 0.9081 - prec: 0.6647 - recall: 0.5617 - auc: 0.9422 - f2: 0.4073 - fbeta2: 0.579 - ETA: 1s - loss: 0.1934 - acc: 0.9081 - prec: 0.6647 - recall: 0.5617 - auc: 0.9421 - f2: 0.4074 - fbeta2: 0.579 - ETA: 1s - loss: 0.1934 - acc: 0.9081 - prec: 0.6648 - recall: 0.5618 - auc: 0.9421 - f2: 0.4076 - fbeta2: 0.579 - ETA: 1s - loss: 0.1934 - acc: 0.9081 - prec: 0.6648 - recall: 0.5619 - auc: 0.9421 - f2: 0.4077 - fbeta2: 0.579 - ETA: 1s - loss: 0.1935 - acc: 0.9081 - prec: 0.6646 - recall: 0.5619 - auc: 0.9421 - f2: 0.4076 - fbeta2: 0.579 - ETA: 0s - loss: 0.1935 - acc: 0.9081 - prec: 0.6645 - recall: 0.5615 - auc: 0.9421 - f2: 0.4074 - fbeta2: 0.578 - ETA: 0s - loss: 0.1935 - acc: 0.9081 - prec: 0.6646 - recall: 0.5615 - auc: 0.9421 - f2: 0.4073 - fbeta2: 0.578 - ETA: 0s - loss: 0.1935 - acc: 0.9080 - prec: 0.6644 - recall: 0.5612 - auc: 0.9421 - f2: 0.4073 - fbeta2: 0.578 - ETA: 0s - loss: 0.1936 - acc: 0.9080 - prec: 0.6643 - recall: 0.5612 - auc: 0.9420 - f2: 0.4073 - fbeta2: 0.578 - ETA: 0s - loss: 0.1936 - acc: 0.9080 - prec: 0.6643 - recall: 0.5611 - auc: 0.9420 - f2: 0.4074 - fbeta2: 0.578 - ETA: 0s - loss: 0.1937 - acc: 0.9080 - prec: 0.6641 - recall: 0.5611 - auc: 0.9419 - f2: 0.4074 - fbeta2: 0.578 - ETA: 0s - loss: 0.1938 - acc: 0.9079 - prec: 0.6640 - recall: 0.5608 - auc: 0.9419 - f2: 0.4072 - fbeta2: 0.578 - ETA: 0s - loss: 0.1938 - acc: 0.9079 - prec: 0.6641 - recall: 0.5607 - auc: 0.9419 - f2: 0.4073 - fbeta2: 0.578 - ETA: 0s - loss: 0.1938 - acc: 0.9079 - prec: 0.6640 - recall: 0.5608 - auc: 0.9419 - f2: 0.4072 - fbeta2: 0.578 - ETA: 0s - loss: 0.1938 - acc: 0.9079 - prec: 0.6641 - recall: 0.5609 - auc: 0.9419 - f2: 0.4074 - fbeta2: 0.578 - ETA: 0s - loss: 0.1938 - acc: 0.9080 - prec: 0.6643 - recall: 0.5611 - auc: 0.9419 - f2: 0.4076 - fbeta2: 0.578 - ETA: 0s - loss: 0.1939 - acc: 0.9079 - prec: 0.6641 - recall: 0.5609 - auc: 0.9418 - f2: 0.4074 - fbeta2: 0.578 - ETA: 0s - loss: 0.1940 - acc: 0.9079 - prec: 0.6637 - recall: 0.5608 - auc: 0.9417 - f2: 0.4073 - fbeta2: 0.578 - ETA: 0s - loss: 0.1940 - acc: 0.9079 - prec: 0.6638 - recall: 0.5608 - auc: 0.9418 - f2: 0.4073 - fbeta2: 0.578 - ETA: 0s - loss: 0.1941 - acc: 0.9079 - prec: 0.6635 - recall: 0.5606 - auc: 0.9417 - f2: 0.4069 - fbeta2: 0.577 - ETA: 0s - loss: 0.1943 - acc: 0.9077 - prec: 0.6626 - recall: 0.5600 - auc: 0.9414 - f2: 0.4064 - fbeta2: 0.577 - ETA: 0s - loss: 0.1947 - acc: 0.9075 - prec: 0.6616 - recall: 0.5593 - auc: 0.9412 - f2: 0.4053 - fbeta2: 0.576 - 11s 307us/sample - loss: 0.1952 - acc: 0.9073 - prec: 0.6610 - recall: 0.5581 - auc: 0.9409 - f2: 0.4042 - fbeta2: 0.5753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.19521527745990358,\n",
       " 'acc': 0.9072674,\n",
       " 'prec': 0.66095227,\n",
       " 'recall': 0.5580575,\n",
       " 'auc': 0.9408676,\n",
       " 'f2': 0.40420324,\n",
       " 'fbeta2': 0.57525325}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = mload.evaluate(X_test, y_test)\n",
    "results_dict = dict(zip(mload.metrics_names, result))\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the model on all human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122847 samples\n",
      "Epoch 1/52\n",
      "122847/122847 - 5s - loss: 0.4669 - acc: 0.8493 - prec: 0.1372 - recall: 0.0347 - auc: 0.5610 - f2: 0.0204 - fbeta2: 0.0262\n",
      "Epoch 2/52\n",
      "122847/122847 - 3s - loss: 0.2815 - acc: 0.8770 - prec: 0.5825 - recall: 0.1203 - auc: 0.8587 - f2: 0.1004 - fbeta2: 0.1406\n",
      "Epoch 3/52\n",
      "122847/122847 - 3s - loss: 0.2481 - acc: 0.8850 - prec: 0.6040 - recall: 0.2816 - auc: 0.8960 - f2: 0.2077 - fbeta2: 0.3146\n",
      "Epoch 4/52\n",
      "122847/122847 - 3s - loss: 0.2322 - acc: 0.8897 - prec: 0.6133 - recall: 0.3626 - auc: 0.9113 - f2: 0.2631 - fbeta2: 0.3946\n",
      "Epoch 5/52\n",
      "122847/122847 - 3s - loss: 0.2267 - acc: 0.8917 - prec: 0.6177 - recall: 0.3923 - auc: 0.9160 - f2: 0.2899 - fbeta2: 0.4229\n",
      "Epoch 6/52\n",
      "122847/122847 - 3s - loss: 0.2229 - acc: 0.8929 - prec: 0.6204 - recall: 0.4090 - auc: 0.9192 - f2: 0.3082 - fbeta2: 0.4385\n",
      "Epoch 7/52\n",
      "122847/122847 - 3s - loss: 0.2198 - acc: 0.8942 - prec: 0.6251 - recall: 0.4224 - auc: 0.9218 - f2: 0.3232 - fbeta2: 0.4514\n",
      "Epoch 8/52\n",
      "122847/122847 - 3s - loss: 0.2169 - acc: 0.8957 - prec: 0.6311 - recall: 0.4360 - auc: 0.9242 - f2: 0.3392 - fbeta2: 0.4644\n",
      "Epoch 9/52\n",
      "122847/122847 - 3s - loss: 0.2147 - acc: 0.8967 - prec: 0.6342 - recall: 0.4472 - auc: 0.9261 - f2: 0.3491 - fbeta2: 0.4748\n",
      "Epoch 10/52\n",
      "122847/122847 - 3s - loss: 0.2122 - acc: 0.8981 - prec: 0.6396 - recall: 0.4575 - auc: 0.9281 - f2: 0.3592 - fbeta2: 0.4848\n",
      "Epoch 11/52\n",
      "122847/122847 - 3s - loss: 0.2098 - acc: 0.8995 - prec: 0.6445 - recall: 0.4705 - auc: 0.9300 - f2: 0.3750 - fbeta2: 0.4972\n",
      "Epoch 12/52\n",
      "122847/122847 - 3s - loss: 0.2089 - acc: 0.9000 - prec: 0.6455 - recall: 0.4761 - auc: 0.9307 - f2: 0.3834 - fbeta2: 0.5022\n",
      "Epoch 13/52\n",
      "122847/122847 - 3s - loss: 0.2077 - acc: 0.9004 - prec: 0.6459 - recall: 0.4816 - auc: 0.9316 - f2: 0.3861 - fbeta2: 0.5072\n",
      "Epoch 14/52\n",
      "122847/122847 - 3s - loss: 0.2069 - acc: 0.9008 - prec: 0.6474 - recall: 0.4859 - auc: 0.9322 - f2: 0.3899 - fbeta2: 0.5112\n",
      "Epoch 15/52\n",
      "122847/122847 - 3s - loss: 0.2050 - acc: 0.9019 - prec: 0.6513 - recall: 0.4953 - auc: 0.9337 - f2: 0.4006 - fbeta2: 0.5199\n",
      "Epoch 16/52\n",
      "122847/122847 - 3s - loss: 0.2037 - acc: 0.9024 - prec: 0.6521 - recall: 0.5007 - auc: 0.9347 - f2: 0.4058 - fbeta2: 0.5249\n",
      "Epoch 17/52\n",
      "122847/122847 - 3s - loss: 0.2029 - acc: 0.9031 - prec: 0.6550 - recall: 0.5058 - auc: 0.9352 - f2: 0.4127 - fbeta2: 0.5298\n",
      "Epoch 18/52\n",
      "122847/122847 - 3s - loss: 0.2020 - acc: 0.9034 - prec: 0.6552 - recall: 0.5101 - auc: 0.9359 - f2: 0.4160 - fbeta2: 0.5336\n",
      "Epoch 19/52\n",
      "122847/122847 - 3s - loss: 0.2012 - acc: 0.9041 - prec: 0.6575 - recall: 0.5157 - auc: 0.9365 - f2: 0.4214 - fbeta2: 0.5388\n",
      "Epoch 20/52\n",
      "122847/122847 - 3s - loss: 0.2002 - acc: 0.9045 - prec: 0.6585 - recall: 0.5193 - auc: 0.9372 - f2: 0.4256 - fbeta2: 0.5420\n",
      "Epoch 21/52\n",
      "122847/122847 - 3s - loss: 0.1991 - acc: 0.9051 - prec: 0.6610 - recall: 0.5233 - auc: 0.9380 - f2: 0.4288 - fbeta2: 0.5459\n",
      "Epoch 22/52\n",
      "122847/122847 - 3s - loss: 0.1991 - acc: 0.9049 - prec: 0.6590 - recall: 0.5249 - auc: 0.9379 - f2: 0.4324 - fbeta2: 0.5470\n",
      "Epoch 23/52\n",
      "122847/122847 - 3s - loss: 0.1976 - acc: 0.9058 - prec: 0.6626 - recall: 0.5307 - auc: 0.9391 - f2: 0.4387 - fbeta2: 0.5525\n",
      "Epoch 24/52\n",
      "122847/122847 - 3s - loss: 0.1974 - acc: 0.9058 - prec: 0.6617 - recall: 0.5319 - auc: 0.9392 - f2: 0.4399 - fbeta2: 0.5535\n",
      "Epoch 25/52\n",
      "122847/122847 - 3s - loss: 0.1971 - acc: 0.9061 - prec: 0.6636 - recall: 0.5321 - auc: 0.9394 - f2: 0.4423 - fbeta2: 0.5539\n",
      "Epoch 26/52\n",
      "122847/122847 - 3s - loss: 0.1960 - acc: 0.9066 - prec: 0.6645 - recall: 0.5387 - auc: 0.9402 - f2: 0.4454 - fbeta2: 0.5597\n",
      "Epoch 27/52\n",
      "122847/122847 - 3s - loss: 0.1959 - acc: 0.9066 - prec: 0.6648 - recall: 0.5383 - auc: 0.9403 - f2: 0.4467 - fbeta2: 0.5595\n",
      "Epoch 28/52\n",
      "122847/122847 - 3s - loss: 0.1947 - acc: 0.9073 - prec: 0.6663 - recall: 0.5456 - auc: 0.9411 - f2: 0.4526 - fbeta2: 0.5660\n",
      "Epoch 29/52\n",
      "122847/122847 - 3s - loss: 0.1937 - acc: 0.9078 - prec: 0.6678 - recall: 0.5486 - auc: 0.9418 - f2: 0.4554 - fbeta2: 0.5688\n",
      "Epoch 30/52\n",
      "122847/122847 - 3s - loss: 0.1933 - acc: 0.9082 - prec: 0.6682 - recall: 0.5539 - auc: 0.9421 - f2: 0.4621 - fbeta2: 0.5734\n",
      "Epoch 31/52\n",
      "122847/122847 - 3s - loss: 0.1926 - acc: 0.9086 - prec: 0.6709 - recall: 0.5548 - auc: 0.9425 - f2: 0.4640 - fbeta2: 0.5745\n",
      "Epoch 32/52\n",
      "122847/122847 - 3s - loss: 0.1922 - acc: 0.9087 - prec: 0.6707 - recall: 0.5563 - auc: 0.9428 - f2: 0.4643 - fbeta2: 0.5758\n",
      "Epoch 33/52\n",
      "122847/122847 - 3s - loss: 0.1914 - acc: 0.9093 - prec: 0.6719 - recall: 0.5627 - auc: 0.9434 - f2: 0.4708 - fbeta2: 0.5815\n",
      "Epoch 34/52\n",
      "122847/122847 - 3s - loss: 0.1911 - acc: 0.9093 - prec: 0.6721 - recall: 0.5621 - auc: 0.9436 - f2: 0.4727 - fbeta2: 0.5810\n",
      "Epoch 35/52\n",
      "122847/122847 - 3s - loss: 0.1905 - acc: 0.9096 - prec: 0.6730 - recall: 0.5643 - auc: 0.9439 - f2: 0.4720 - fbeta2: 0.5830\n",
      "Epoch 36/52\n",
      "122847/122847 - 3s - loss: 0.1895 - acc: 0.9102 - prec: 0.6745 - recall: 0.5698 - auc: 0.9447 - f2: 0.4777 - fbeta2: 0.5879\n",
      "Epoch 37/52\n",
      "122847/122847 - 3s - loss: 0.1895 - acc: 0.9102 - prec: 0.6746 - recall: 0.5694 - auc: 0.9446 - f2: 0.4810 - fbeta2: 0.5876\n",
      "Epoch 38/52\n",
      "122847/122847 - 3s - loss: 0.1883 - acc: 0.9109 - prec: 0.6763 - recall: 0.5767 - auc: 0.9455 - f2: 0.4867 - fbeta2: 0.5941\n",
      "Epoch 39/52\n",
      "122847/122847 - 3s - loss: 0.1882 - acc: 0.9108 - prec: 0.6761 - recall: 0.5751 - auc: 0.9455 - f2: 0.4869 - fbeta2: 0.5927\n",
      "Epoch 40/52\n",
      "122847/122847 - 3s - loss: 0.1875 - acc: 0.9112 - prec: 0.6767 - recall: 0.5800 - auc: 0.9459 - f2: 0.4935 - fbeta2: 0.5969\n",
      "Epoch 41/52\n",
      "122847/122847 - 3s - loss: 0.1866 - acc: 0.9116 - prec: 0.6787 - recall: 0.5815 - auc: 0.9465 - f2: 0.4955 - fbeta2: 0.5985\n",
      "Epoch 42/52\n",
      "122847/122847 - 3s - loss: 0.1867 - acc: 0.9118 - prec: 0.6788 - recall: 0.5842 - auc: 0.9465 - f2: 0.4980 - fbeta2: 0.6009\n",
      "Epoch 43/52\n",
      "122847/122847 - 3s - loss: 0.1862 - acc: 0.9120 - prec: 0.6787 - recall: 0.5862 - auc: 0.9469 - f2: 0.4967 - fbeta2: 0.6025\n",
      "Epoch 44/52\n",
      "122847/122847 - 3s - loss: 0.1855 - acc: 0.9124 - prec: 0.6806 - recall: 0.5887 - auc: 0.9473 - f2: 0.5032 - fbeta2: 0.6049\n",
      "Epoch 45/52\n",
      "122847/122847 - 3s - loss: 0.1852 - acc: 0.9125 - prec: 0.6802 - recall: 0.5912 - auc: 0.9475 - f2: 0.5026 - fbeta2: 0.6070\n",
      "Epoch 46/52\n",
      "122847/122847 - 3s - loss: 0.1846 - acc: 0.9128 - prec: 0.6813 - recall: 0.5931 - auc: 0.9478 - f2: 0.5069 - fbeta2: 0.6088\n",
      "Epoch 47/52\n",
      "122847/122847 - 3s - loss: 0.1834 - acc: 0.9134 - prec: 0.6824 - recall: 0.5991 - auc: 0.9486 - f2: 0.5146 - fbeta2: 0.6140\n",
      "Epoch 48/52\n",
      "122847/122847 - 3s - loss: 0.1832 - acc: 0.9137 - prec: 0.6835 - recall: 0.5999 - auc: 0.9487 - f2: 0.5165 - fbeta2: 0.6148\n",
      "Epoch 49/52\n",
      "122847/122847 - 3s - loss: 0.1825 - acc: 0.9141 - prec: 0.6840 - recall: 0.6043 - auc: 0.9492 - f2: 0.5190 - fbeta2: 0.6186\n",
      "Epoch 50/52\n",
      "122847/122847 - 3s - loss: 0.1821 - acc: 0.9145 - prec: 0.6857 - recall: 0.6069 - auc: 0.9494 - f2: 0.5225 - fbeta2: 0.6211\n",
      "Epoch 51/52\n",
      "122847/122847 - 3s - loss: 0.1815 - acc: 0.9146 - prec: 0.6854 - recall: 0.6096 - auc: 0.9497 - f2: 0.5243 - fbeta2: 0.6234\n",
      "Epoch 52/52\n",
      "122847/122847 - 3s - loss: 0.1814 - acc: 0.9146 - prec: 0.6857 - recall: 0.6088 - auc: 0.9499 - f2: 0.5212 - fbeta2: 0.6226\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "hist = model.fit(x, y, epochs=52, batch_size=1024, workers=4, \n",
    "             validation_data=(), verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_all_human_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf21conda",
   "language": "python",
   "name": "tf21conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
